version: "1.0"

# Default Visor configuration - provides comprehensive code analysis out-of-the-box
# Uses mock provider for CI compatibility when no AI API keys are configured
# Users can override this by creating their own .visor.yaml in their project root

# Global AI provider settings - users should configure their preferred provider
# For CI testing, use --provider mock CLI flag instead

# Run checks sequentially to ensure session reuse works correctly
max_parallelism: 1

# üîÑ AI Session Reuse Feature:
# This configuration demonstrates the new 'reuse_ai_session' feature that allows
# dependent checks to continue conversations with the same AI session, providing
# context continuity and more intelligent follow-up analysis.
#
# Example: security-remediation reuses the session from the security check,
# allowing the AI to reference the previous security analysis discussion.

# Global fail condition - fail if critical or error severity issues are found
fail_if: "output.issues && output.issues.some(i => i.severity === 'critical' || i.severity === 'error')"

checks:
  # AI-powered release notes generation - manual execution only for release workflows
  release-notes:
    type: ai
    group: release
    schema: plain
    prompt: |
      Generate professional release notes for version {{ env.TAG_NAME }} of this project.

      Analyze the git commits since the last release:
      ```
      {{ env.GIT_LOG }}
      ```

      And the file changes summary:
      ```
      {{ env.GIT_DIFF_STAT }}
      ```

      Create release notes with these sections:

      ## üöÄ What's New in {{ env.TAG_NAME }}

      ### ‚ú® New Features
      List any new features added (look for feat: commits)

      ### üêõ Bug Fixes
      List any bugs fixed (look for fix: commits)

      ### üìà Improvements
      List any improvements or refactoring (look for refactor:, perf:, chore:, build: commits)

      ### üî• Breaking Changes
      List any breaking changes if present (look for BREAKING CHANGE or ! in commits)

      ### üìä Statistics
      - Number of commits since last release
      - Number of contributors involved
      - Number of files changed

      Keep descriptions concise and user-friendly. Focus on what changed from a user perspective, not implementation details.
      Use present tense and action-oriented language. Group similar changes together.
    on: [manual]

  # PR overview with intelligent analysis - runs first to establish context
  overview:
    type: ai
    group: overview
    schema: overview
    prompt: |
        You are generating PR overview, to help others understand what this PR is above, and help reviewer to point to the right parts using attached schema.

        ## Files Changed Analysis
        Summarize insights from `<files_summary>`: changed files, additions/deletions, notable patterns.
          
        ## Architecture & Impact Assessment
          - What this PR accomplishes
          - Key technical changes introduced
          - Affected system components
          - Include one or more mermaid diagrams when useful to visualize component relationships or flow.
          
        ## Scope Discovery & Context Expansion
        - From the `<files_summary>` and code diffs, infer the broader scope of impact across modules, services, and boundaries.
        - If your environment supports code search/extract tools, use them to peek at immediately-related files (tests, configs, entrypoints) for better context. If tools are not available, infer and list what you would search next.

        You may also be asked to assign labels to PR; if so use this:
        - `tags.review-effort`: integer 1‚Äì5 estimating review effort (1=trivial, 5=very high).
        - `tags.label`: one of [bug, feature, chore, docs, refactor, test]. Choose the best fit.

        Be concise, specific, and actionable. Avoid praise or celebration.
    on: [pr_opened, pr_updated]

  # Security analysis - Critical for all projects
  security:
    type: ai
    group: review
    schema: code-review
    prompt: |
        Based on our overview discussion, please perform a comprehensive security analysis of the code changes.

        Analyze the files listed in the `<files_summary>` section and focus on the code changes shown in the diff sections.

        ## Security Analysis Areas

        **Input Validation & Injection:**
        - SQL injection in database queries
        - XSS vulnerabilities in user input handling
        - Command injection in system calls
        - Path traversal in file operations

        **Authentication & Authorization:**
        - Weak authentication mechanisms
        - Session management flaws
        - Access control bypasses
        - Privilege escalation opportunities

        **Data Protection:**
        - Sensitive data exposure in logs/errors
        - Unencrypted data storage
        - API key or credential leaks
        - Privacy regulation compliance

        **Infrastructure Security:**
        - Insecure configurations
        - Missing security headers
        - Vulnerable dependencies
        - Resource exhaustion vulnerabilities

        Provide specific findings with clear explanations and actionable remediation steps.

        ## Severity Guidelines
        Use the following severity levels appropriately:
        - **critical**: Security vulnerabilities that could lead to immediate compromise (RCE, SQL injection, authentication bypass, exposed secrets)
        - **error**: Security issues that must be fixed before production (XSS, path traversal, weak crypto, missing auth checks)
        - **warning**: Security concerns that should be addressed (verbose errors, missing rate limiting, insecure defaults)
        - **info**: Security best practices and hardening suggestions (defense in depth, additional validation)
    depends_on: [overview]
    reuse_ai_session: overview  # üîÑ Reuses the overview check's AI session for context continuity
    on: [pr_opened, pr_updated]

  # Performance analysis - Important for all applications
  performance:
    type: ai
    group: review
    schema: code-review
    prompt: |
        Building on our overview analysis, now review the code changes for performance issues.

        Focus on the files listed in `<files_summary>` and analyze the code changes shown in the `<full_diff>` or `<commit_diff>` sections.

        ## Performance Analysis Areas
        **Algorithm & Data Structure Efficiency:**
        - Time complexity analysis (O(n), O(n¬≤), etc.)
        - Space complexity and memory usage
        - Inefficient loops and nested operations
        - Suboptimal data structure choices

        **Database Performance:**
        - N+1 query problems
        - Missing database indexes
        - Inefficient JOIN operations
        - Large result set retrievals

        **Resource Management:**
        - Memory leaks and excessive allocations
        - File handle management
        - Connection pooling issues
        - Resource cleanup patterns

        **Async & Concurrency:**
        - Blocking operations in async contexts
        - Race conditions and deadlocks
        - Inefficient parallel processing

        Building on our overview analysis, identify performance issues and provide optimization recommendations.

        ## Severity Guidelines
        Use the following severity levels appropriately:
        - **critical**: Performance issues causing system failure or severe degradation (infinite loops, memory leaks causing OOM)
        - **error**: Significant performance problems affecting user experience (O(n¬≤) in critical path, N+1 queries, blocking I/O)
        - **warning**: Performance concerns that should be optimized (inefficient algorithms, missing indexes, unnecessary operations)
        - **info**: Performance best practices and optimization opportunities (caching suggestions, async improvements)
    depends_on: [overview]
    reuse_ai_session: overview  # üîÑ Reuses the overview check's AI session for context continuity
    on: [pr_opened, pr_updated]

  # Code quality and maintainability
  quality:
    type: ai
    group: review
    schema: code-review
    prompt: |
        Building on our overview discussion, evaluate the code quality and maintainability.

        Review the code changes shown in the `<full_diff>` or `<commit_diff>` sections, considering the files listed in `<files_summary>`.

        ## Quality Assessment Areas
        **Code Structure & Design:**
        - SOLID principles adherence
        - Design pattern appropriateness
        - Separation of concerns
        - Code organization and clarity

        **Error Handling & Reliability:**
        - Exception handling completeness
        - Error propagation patterns
        - Input validation thoroughness
        - Edge case coverage

        **Testing & Test Coverage:**
        - Missing tests for critical functionality
        - Test coverage gaps
        - Test quality and effectiveness
        - Edge cases and error scenarios coverage

        **Maintainability:**
        - Code testability issues
        - Dependencies and coupling problems
        - Technical debt introduction
        - Code duplication (DRY violations)

        **Language-Specific Best Practices:**
        - Idiomatic code usage
        - Framework/library best practices
        - Type safety (if applicable)

        Focus on actionable improvements that enhance code maintainability based on the overview analysis.

        ## Severity Guidelines
        Use the following severity levels appropriately:
        - **critical**: Code quality issues that will cause bugs or failures (logic errors, race conditions, null pointer issues)
        - **error**: Quality problems that significantly impact maintainability (no error handling, high complexity, severe coupling)
        - **warning**: Quality concerns that should be addressed (missing tests, code duplication, poor naming)
        - **info**: Best practices and improvement suggestions (refactoring opportunities, documentation improvements)
    depends_on: [overview]
    reuse_ai_session: overview  # üîÑ Reuses the overview check's AI session for context continuity
    on: [pr_opened, pr_updated]
    # After the first successful pass, jump back to 'overview' once and
    # re-run this step under simulated PR update semantics to refresh context.
    on_success:
      goto_js: |
        return attempt === 1 ? 'overview' : null
      goto_event: pr_updated

  # Code style and formatting analysis
  style:
    type: ai
    group: review
    schema: code-review
    prompt: |
        Building on our overview discussion, analyze the code style and formatting consistency.

        Review the code changes shown in the `<full_diff>` or `<commit_diff>` sections, considering the files listed in `<files_summary>`.

        ## Style Assessment Areas
        **Code Formatting & Consistency:**
        - Indentation and spacing consistency
        - Naming conventions adherence
        - Code organization and structure
        - Comment style and documentation

        **Language-Specific Style Guidelines:**
        - Adherence to language style guides (PEP 8, ESLint, etc.)
        - Import/require statement organization
        - Variable and function naming patterns
        - Code readability and clarity

        **Team Standards:**
        - Consistency with existing codebase patterns
        - Formatting tool configuration compliance
        - Documentation standards adherence
        - Code comment quality and completeness

        Focus on style improvements that enhance code readability and maintainability based on the overview analysis.

        ## Severity Guidelines
        Use the following severity levels appropriately:
        - **critical**: Never use for style issues (style issues are never critical)
        - **error**: Major style violations that significantly harm readability (completely inconsistent formatting, misleading names)
        - **warning**: Style inconsistencies that should be fixed (mixed conventions, unclear naming, formatting issues)
        - **info**: Style suggestions and minor improvements (spacing, comment formatting, optional conventions)
    depends_on: [overview]
    reuse_ai_session: overview  # üîÑ Reuses the overview check's AI session for context continuity
    on: [pr_opened, pr_updated]

  # Apply labels based on overview tags ‚Äî runs only in GitHub environments
  apply-overview-labels:
    type: github
    group: github
    tags: [github]
    depends_on: [overview]
    on: [pr_opened, pr_updated]
    op: labels.add
    values:
      - "{{ outputs.overview.tags.label | default: '' | safe_label }}"
      - "{{ outputs.overview.tags['review-effort'] | default: '' | prepend: 'review/effort:' | safe_label }}"

  # Apply labels to new issues based on assistant output (GitHub-only)
  apply-issue-labels:
    type: github
    group: github
    tags: [github]
    depends_on: [issue-assistant]
    on: [issue_opened, issue_comment]
    if: "outputs['issue-assistant'].tags.intent == 'issue'"
    op: labels.add
    values:
      - "{{ outputs['issue-assistant'].tags.label | default: '' | safe_label }}"

  # Handle issue assistant intents: disable checks and/or retrigger workflow
  handle-issue-intents:
    type: command
    group: github
    tags: [github]
    depends_on: [issue-assistant]
    on: [issue_opened, issue_comment]
    # Only run when a retrigger or disable request is detected in a comment context
    if: |
      outputs['issue-assistant'].tags.intent == 'comment' && (
        outputs['issue-assistant'].tags.action == 'retrigger' ||
        (outputs['issue-assistant'].tags.action == 'disable-check' && outputs['issue-assistant'].tags.checks && outputs['issue-assistant'].tags.checks.length > 0)
      )
    exec: |
      # Comment-driven disable only; no labels created


      # Internally re-invoke Visor Action as a synthetic PR update (no full workflow rerun)
      ACTION="{{ outputs['issue-assistant'].tags.action | default: 'none' }}"
      if [ "$ACTION" = "retrigger" ] || [ "$ACTION" = "disable-check" ]; then
        # Only makes sense when the thread is a PR discussion (issue with pull_request)
        if echo "{{ event.issue | json }}" | jq -e '.pull_request' >/dev/null 2>&1; then
          PR_NUM={{ event.issue.number }}
          EVENT_FILE="$(mktemp)"
          echo '{"action":"synchronize","pull_request":{"number":'"$PR_NUM"'}}' > "$EVENT_FILE"
          echo "Synthesizing PR event (synchronize) for PR #$PR_NUM"
          # Prefer the packaged action path; fallback to local dist
          ENTRY="${GITHUB_ACTION_PATH:-.}/dist/index.js"
          if [ ! -f "$ENTRY" ]; then ENTRY="./dist/index.js"; fi
          export GITHUB_EVENT_NAME=pull_request
          export GITHUB_EVENT_PATH="$EVENT_FILE"
          # Inherit INPUT_* (github-token, etc.) from the parent Action; do NOT set INPUT_TAGS
          node "$ENTRY" --mode github-actions || true
        else
          echo "Not a PR thread; skipping internal PR retrigger"
        fi
      fi

  # Command orchestrator - demonstrates noop type for triggering multiple checks
  review-all:
    type: noop
    command: '/review'
    depends_on: [overview, security, performance, quality, style]
    on: [issue_comment]
    if: "event.isPullRequest"  # Only trigger on PR comments, not issues
    group: orchestrator

  # Intelligent Issue Assistant - provides sophisticated issue triage and assistance
  issue-assistant:
    type: ai
    group: dynamic  # Special group: creates new comment each time instead of updating
    schema: issue-assistant
    command: "visor"
    # The check runs for issue events; avoid giant runtime 'if' that depends on unknown event shape
    prompt: |
        You are an intelligent GitHub issue assistant for the {{ event.repository.fullName }} repository.

        Return ONE JSON object (no prose outside JSON) that validates the `issue-assistant` schema with:
        - `text`: a clear, well-structured markdown reply to post as a comment.
        - `tags.intent`: MUST be:
          - "issue" when this event is a newly opened issue.
          - "comment" when this event is an issue comment.
          Use the event context below to set this value deterministically.
        - `tags.action`: one of ["none", "retrigger", "disable-check"].
          - Set to "retrigger" when the user asks to re-run/retrigger the job, workflow, or Visor.
          - Set to "disable-check" when the user asks to disable specific check(s). Populate `tags.checks` with the check IDs to disable (e.g., security, performance, style, architecture, or exact config IDs).
          - Otherwise set to "none".
        - `tags.label` (for new issues only): choose one primary label from [bug, feature, enhancement, maintenance, documentation, question].
        - `tags.labels` (optional): additional helpful labels as an array of strings.
        - `tags.checks` (optional): array of checks referenced when `tags.action == 'disable-check'`.

        Event context (use this to set intent):
        - name: {{ event.name | default: 'unknown' }}
        - action: {{ event.action | default: 'unknown' }}

        Guidance:
        - For new issues (intent = "issue"), perform triage: classify, suggest next steps, and ask targeted questions if needed.
        - For comments (intent = "comment"), answer the question or follow up concisely and helpfully.
        - Be professional and actionable; include code snippets or links when useful.
    on: [issue_opened, issue_comment]

output:
  pr_comment:
    format: markdown
    group_by: check
    collapse: true
