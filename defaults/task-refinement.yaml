version: "1.0"

# Simple agent: task-refinement
# - Collects user input, refines it with AI (skip code context), and loops until refined.
# - Returns final refined text via the `finish` step output.

steps:
  ask:
    type: human-input
    group: task-refinement
    # No explicit event trigger; run in CLI by default but guard via if
    prompt: |
      {% if outputs["refine"] and outputs["refine"].refined == false %}
      {{ outputs.refine.text }}
      {% else %}
      Provide the task you want to accomplish. Be specific about constraints
      (inputs, outputs, environment, success criteria).
      {% endif %}
    multiline: false
    allow_empty: false
    on_success:
      goto: refine

  refine:
    type: ai
    group: task-refinement
    # Run only after 'ask' (scheduled via ask.on_success.run), never as a root step
    depends_on: [ask]
    ai_persona: "requirements analyst"
    ai:
      skip_code_context: true
    # Schema ensures the agent either finalizes or asks to clarify
    schema:
      type: object
      additionalProperties: false
      properties:
        refined: { type: boolean, description: "true if the task is fully specified and accepted" }
        text: { type: string, description: "final refined task or question to user" }
      required: [refined, text]
    prompt: |
      <system>
      You are a helpful, precise task refinement assistant (role: requirements-analyst).
      - Refine the user's task into a clear, executable description with minimal assumptions.
      - If information is missing, set refined=false and ask_user=true and put a single, specific
        clarification question in the "text" field.
      - If everything is sufficient, set refined=true and put the final refined wording in "text".
      - Be succinct and unambiguous.
      </system>

      <history>
        {% assign umsgs = outputs_history.ask | default: [] %}
        {% assign amsgs = outputs_history.refine | default: [] %}
        {% assign merged = umsgs | concat: amsgs | sort: 'ts' %}
        {% for m in merged %}
          {# Treat any refine output (has 'refined' key) as assistant; ask outputs as user #}
          {% if m.refined != nil %}
            <assistant>{{ m.text }}</assistant>
          {% else %}
            <user>{{ m.text }}</user>
          {% endif %}
        {% endfor %}
      </history>

      <input>
        {{ outputs['ask'].text }}
      </input>

    # Loop control using fail_if + on_fail (no goto_js)
    fail_if: "output['refined'] !== true"
    on_fail:
      goto: ask

  finish:
    type: log
    group: task-refinement
    depends_on: [refine]
    message: "{{ outputs['refine'].text }}"
    level: info
    include_pr_context: false
    include_dependencies: false
    include_metadata: false

tests:
  defaults:
    strict: true
    ai_provider: mock
  cases:
    - name: one-pass-refinement
      description: Single turn; AI is happy and returns refined text.
      event: manual
      fixture: local.minimal
      mocks:
        ask: "Build a small Node CLI that prints \"hello\""
        refine:
          refined: true
          text: "Create a Node.js CLI (using Node >=18) that prints 'hello' when run; include usage example and exit code 0."
      expect:
        calls:
          - step: ask
            exactly: 1
          - step: refine
            exactly: 1
          - step: finish
            exactly: 1

    - name: multi-turn-refinement-loop
      description: Two clarifying turns followed by a final refinement; manual-only chat.
      event: manual
      fixture: local.minimal
      mocks:
        ask[]:
          - "Create a CI job"
          - "GitHub Actions; run on push to main"
          - "Use Node 18 and npm ci + npm test"
        refine[]:
          - { refined: false, ask_user: true, text: "Which CI platform and trigger conditions?" }
          - { refined: false, ask_user: true, text: "What Node version and commands should run?" }
          - { refined: true, text: "Set up GitHub Actions workflow: on push to main, use Node 18.x, cache npm, run npm ci && npm test." }
      expect:
        calls:
          - step: ask
            exactly: 3
          - step: refine
            exactly: 3
          - step: finish
            exactly: 1
        prompts:
          - step: refine
            index: last
            contains:
              - "Which CI platform and trigger conditions?"
              - "Use Node 18 and npm ci + npm test"
              - "What Node version and commands should run?"
          # Keep prompt assertions resilient to minor formatting changes by using 'contains'
          # instead of a single large regex.
