# Confluence Context Extraction Workflow
# Reusable workflow to extract Confluence page URLs from text and fetch full context
#
# Usage as a workflow check:
#   confluence-context:
#     type: workflow
#     config: defaults/confluence-context.yaml
#     workflow_inputs:
#       text: "{{ outputs['ask'].text }}"
#
# Usage in on_init:
#   on_init:
#     run:
#       - workflow: confluence-context
#         with:
#           text: "{{ pr.title }} {{ pr.body }}"
#         as: confluence-context
#
# Environment variables required:
#   CONFLUENCE_BASE_URL - https://company.atlassian.net/wiki (optional, falls back to JIRA_BASE_URL + /wiki)
#   CONFLUENCE_EMAIL - user@company.com (optional, falls back to JIRA_EMAIL)
#   CONFLUENCE_API_TOKEN - your API token (optional, falls back to JIRA_API_TOKEN)
#
# For Atlassian Cloud, you can just set JIRA_BASE_URL, JIRA_EMAIL, JIRA_API_TOKEN
# and Confluence will use the same credentials automatically.
#
# Supported URL formats:
#   - https://company.atlassian.net/wiki/spaces/SPACE/pages/123456/Page+Title
#   - https://company.atlassian.net/wiki/display/SPACE/Page+Title (legacy)
#   - https://company.atlassian.net/wiki/x/AbCdEf (short links)

version: "1.0"

# Workflow metadata
id: confluence-context
name: Confluence Context Extraction
description: |
  Extracts Confluence page URLs from text and fetches full page context including content.
  Returns structured XML output suitable for AI consumption.

# Workflow inputs
inputs:
  - name: text
    schema:
      type: string
    required: false
    default: ""
    description: Text to scan for Confluence URLs (e.g., Slack message or PR body)

  - name: page_ids
    schema:
      type: array
      items:
        type: string
    required: false
    default: []
    description: |
      Direct list of Confluence page IDs to fetch (bypasses URL extraction).
      Example: ["123456", "789012"]

  - name: max_pages
    schema:
      type: number
    required: false
    default: 5
    description: Maximum number of pages to fetch (to prevent overloading context)

  - name: include_children
    schema:
      type: boolean
    required: false
    default: false
    description: Whether to include child page titles in the output

  - name: max_content_length
    schema:
      type: number
    required: false
    default: 10000
    description: Maximum content length per page (truncates if longer)

# Workflow outputs
outputs:
  - name: confluence_context_xml
    description: Full Confluence context in XML format
    value: "{{ outputs['format-output'] }}"

  - name: pages
    description: Raw page data as array
    value_js: |
      return outputs['fetch-pages']?.data || [];

  - name: page_count
    description: Number of pages found
    value_js: |
      const pages = outputs['fetch-pages']?.data || [];
      return Array.isArray(pages) ? pages.length : 0;

steps:
  # Step 1: Extract Confluence page IDs/URLs from input text
  extract-urls:
    type: script
    schema:
      type: object
      properties:
        data:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              url:
                type: string
              space:
                type: string
          description: Array of extracted page info
        count:
          type: number
          description: Number of pages found
        direct_mode:
          type: boolean
          description: True if using direct page IDs instead of URL extraction
      required: [data, count, direct_mode]
    content: |
      var text = inputs.text || '';
      var directIds = inputs.page_ids || [];
      var maxPages = inputs.max_pages || 5;

      // If direct page IDs provided, use them
      if (directIds.length > 0) {
        var pages = [];
        for (var i = 0; i < Math.min(directIds.length, maxPages); i++) {
          pages.push({ id: directIds[i], url: '', space: '' });
        }
        return { data: pages, count: pages.length, direct_mode: true };
      }

      // Extract Confluence URLs from text
      // Matches:
      // - /wiki/spaces/SPACE/pages/123456/Title
      // - /wiki/display/SPACE/Title
      // - /wiki/x/AbCdEf (short links)
      // - Full URLs with domain

      var pages = [];
      var seen = {};

      // Pattern 1: /wiki/spaces/SPACE/pages/PAGEID/Title
      var spacesPattern = /https?:\/\/[^\/]+\/wiki\/spaces\/([A-Za-z0-9_-]+)\/pages\/(\d+)(?:\/[^\s<>\)\]]*)?/g;
      var match;
      while ((match = spacesPattern.exec(text)) !== null) {
        var pageId = match[2];
        if (!seen[pageId]) {
          seen[pageId] = true;
          pages.push({ id: pageId, url: match[0], space: match[1] });
        }
      }

      // Pattern 2: /wiki/display/SPACE/Title (legacy format - need to resolve via API)
      var displayPattern = /https?:\/\/([^\/]+)\/wiki\/display\/([A-Za-z0-9_-]+)\/([^\s<>\)\]]+)/g;
      while ((match = displayPattern.exec(text)) !== null) {
        var displayKey = match[2] + '/' + match[3];
        if (!seen[displayKey]) {
          seen[displayKey] = true;
          // Store space and title for resolution
          pages.push({
            id: '',
            url: match[0],
            space: match[2],
            title: decodeURIComponent(match[3].replace(/\+/g, ' '))
          });
        }
      }

      // Pattern 3: /wiki/x/SHORTCODE (tiny links)
      var shortPattern = /https?:\/\/[^\/]+\/wiki\/x\/([A-Za-z0-9_-]+)/g;
      while ((match = shortPattern.exec(text)) !== null) {
        var shortCode = match[1];
        if (!seen['short:' + shortCode]) {
          seen['short:' + shortCode] = true;
          pages.push({ id: '', url: match[0], space: '', shortCode: shortCode });
        }
      }

      // Limit results
      pages = pages.slice(0, maxPages);

      return { data: pages, count: pages.length, direct_mode: false };

  # Step 2: Fetch pages from Confluence REST API
  # Uses the v2 API for modern Confluence Cloud
  fetch-pages:
    type: script
    criticality: external
    depends_on: [extract-urls]
    if: "outputs['extract-urls'].count > 0"
    schema:
      type: object
      properties:
        data:
          type: array
          description: Array of normalized Confluence pages
          items:
            type: object
            properties:
              id:
                type: string
                description: Confluence page ID
              title:
                type: string
                description: Page title
              space:
                type: string
                description: Space key
              url:
                type: string
                description: Web URL to the page
              content:
                type: string
                description: Page content (HTML converted to text)
              created:
                type: string
                description: Creation date
              updated:
                type: string
                description: Last update date
              author:
                type: string
                description: Author display name
              labels:
                type: array
                items:
                  type: string
                description: Page labels
            required: [id, title, space]
      required: [data]
    content: |
      var extractedPages = outputs['extract-urls'].data || [];
      var maxContentLength = inputs.max_content_length || 10000;
      var includeChildren = inputs.include_children || false;

      // Confluence URL fallback: CONFLUENCE_BASE_URL > JIRA_BASE_URL + /wiki
      var baseUrl = env.CONFLUENCE_BASE_URL || '';
      if (!baseUrl && env.JIRA_BASE_URL) {
        // For Atlassian Cloud, Confluence is at the same domain as Jira
        baseUrl = env.JIRA_BASE_URL;
      }
      var email = env.CONFLUENCE_EMAIL || env.JIRA_EMAIL || '';
      var token = env.CONFLUENCE_API_TOKEN || env.JIRA_API_TOKEN || '';

      if (!baseUrl || !email || !token) {
        log('Confluence: Missing env vars. Set CONFLUENCE_BASE_URL or JIRA_BASE_URL, plus EMAIL and API_TOKEN');
        return { data: [] };
      }

      // Remove trailing /wiki if present (we'll add it in API calls)
      baseUrl = baseUrl.replace(/\/wiki\/?$/, '');

      var authHeader = 'Basic ' + btoa(email + ':' + token);
      var results = [];

      // Helper to strip HTML tags
      function stripHtml(html) {
        if (!html) return '';
        // Remove script/style tags and their content
        html = html.replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '');
        html = html.replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '');
        // Replace block elements with newlines
        html = html.replace(/<\/(p|div|h[1-6]|li|tr|br)[^>]*>/gi, '\n');
        html = html.replace(/<br[^>]*\/?>/gi, '\n');
        // Strip remaining tags
        html = html.replace(/<[^>]+>/g, '');
        // Decode common entities
        html = html.replace(/&nbsp;/g, ' ');
        html = html.replace(/&amp;/g, '&');
        html = html.replace(/&lt;/g, '<');
        html = html.replace(/&gt;/g, '>');
        html = html.replace(/&quot;/g, '"');
        // Collapse whitespace
        html = html.replace(/\n\s*\n/g, '\n\n');
        return html.trim();
      }

      for (var i = 0; i < extractedPages.length; i++) {
        var page = extractedPages[i];
        var pageId = page.id;

        try {
          // If we have a page ID, fetch directly
          if (pageId) {
            var apiUrl = baseUrl + '/wiki/api/v2/pages/' + pageId + '?body-format=storage';
            log('Confluence: Fetching page ID ' + pageId);

            var resp = httpGet(apiUrl, {
              headers: {
                'Authorization': authHeader,
                'Accept': 'application/json'
              }
            });

            if (resp.status === 200 && resp.body) {
              var data = JSON.parse(resp.body);
              var content = '';
              if (data.body && data.body.storage && data.body.storage.value) {
                content = stripHtml(data.body.storage.value);
                if (content.length > maxContentLength) {
                  content = content.substring(0, maxContentLength) + '\n\n[Content truncated...]';
                }
              }

              results.push({
                id: data.id || pageId,
                title: data.title || '',
                space: data.spaceId || page.space || '',
                url: page.url || (baseUrl + '/wiki/spaces/' + (data.spaceId || '') + '/pages/' + pageId),
                content: content,
                created: data.createdAt || '',
                updated: data.version ? data.version.createdAt : '',
                author: data.version && data.version.authorId ? data.version.authorId : '',
                labels: []
              });
            } else {
              log('Confluence: Failed to fetch page ' + pageId + ': ' + resp.status);
            }
          }
          // If we have a title/space combo (legacy URL), search for it
          else if (page.space && page.title) {
            var searchUrl = baseUrl + '/wiki/rest/api/content?spaceKey=' + encodeURIComponent(page.space) +
                            '&title=' + encodeURIComponent(page.title) + '&expand=body.storage,version';
            log('Confluence: Searching for page "' + page.title + '" in space ' + page.space);

            var searchResp = httpGet(searchUrl, {
              headers: {
                'Authorization': authHeader,
                'Accept': 'application/json'
              }
            });

            if (searchResp.status === 200 && searchResp.body) {
              var searchData = JSON.parse(searchResp.body);
              if (searchData.results && searchData.results.length > 0) {
                var found = searchData.results[0];
                var content = '';
                if (found.body && found.body.storage && found.body.storage.value) {
                  content = stripHtml(found.body.storage.value);
                  if (content.length > maxContentLength) {
                    content = content.substring(0, maxContentLength) + '\n\n[Content truncated...]';
                  }
                }

                results.push({
                  id: found.id || '',
                  title: found.title || page.title,
                  space: page.space,
                  url: page.url || (baseUrl + '/wiki' + (found._links && found._links.webui ? found._links.webui : '')),
                  content: content,
                  created: found.history ? found.history.createdDate : '',
                  updated: found.version ? found.version.when : '',
                  author: found.version && found.version.by ? found.version.by.displayName : '',
                  labels: []
                });
              }
            }
          }
          // Short links need to be resolved via redirect or API
          else if (page.shortCode) {
            log('Confluence: Short link resolution not yet implemented for ' + page.shortCode);
            // TODO: Implement short link resolution via /wiki/x/CODE redirect
          }
        } catch (e) {
          log('Confluence: Error fetching page: ' + (e.message || e));
        }
      }

      return { data: results };

  # Step 3: Format output as XML
  format-output:
    type: script
    depends_on: [fetch-pages]
    content: |
      var pages = outputs['fetch-pages'] && outputs['fetch-pages'].data ? outputs['fetch-pages'].data : [];

      var xml = '<confluence_context>\n';
      xml += '  <page_count>' + pages.length + '</page_count>\n';

      for (var i = 0; i < pages.length; i++) {
        var page = pages[i];
        xml += '  <page id="' + escapeXml(page.id) + '">\n';
        xml += '    <title>' + escapeXml(page.title) + '</title>\n';
        xml += '    <space>' + escapeXml(page.space) + '</space>\n';
        xml += '    <url>' + escapeXml(page.url) + '</url>\n';

        if (page.author) {
          xml += '    <author>' + escapeXml(page.author) + '</author>\n';
        }
        if (page.created) {
          xml += '    <created>' + escapeXml(page.created) + '</created>\n';
        }
        if (page.updated) {
          xml += '    <updated>' + escapeXml(page.updated) + '</updated>\n';
        }

        if (page.labels && page.labels.length) {
          var escapedLabels = [];
          for (var j = 0; j < page.labels.length; j++) {
            escapedLabels.push(escapeXml(page.labels[j]));
          }
          xml += '    <labels>' + escapedLabels.join(', ') + '</labels>\n';
        }

        if (page.content) {
          xml += '    <content>\n' + escapeXml(page.content) + '\n    </content>\n';
        }

        xml += '  </page>\n';
      }

      xml += '</confluence_context>';
      return xml;

  # Fallback step when no pages found
  no-pages-fallback:
    type: command
    depends_on: [extract-urls]
    if: "outputs['extract-urls'].count == 0"
    exec: |
      echo '<confluence_context><page_count>0</page_count><message>No Confluence URLs found in the provided text</message></confluence_context>'

# =============================================================================
# TESTS
# =============================================================================
tests:
  defaults:
    strict: true
    fail_on_unexpected_calls: true

  fixtures:
    - name: local.minimal
      webhook:
        name: manual
      git:
        branch: main
        baseBranch: main
      files: []
      diff: ""

  cases:
    # Test 1: Extract Confluence URLs and format as XML
    - name: extract-confluence-urls
      description: Extract page IDs from Confluence URLs and fetch content
      event: manual
      fixture: local.minimal
      workflow_input:
        text: "See docs at https://company.atlassian.net/wiki/spaces/ENG/pages/123456/API+Guide"
      mocks:
        extract-urls:
          data:
            - id: "123456"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/123456/API+Guide"
              space: "ENG"
          count: 1
          direct_mode: false
        fetch-pages:
          data:
            - id: "123456"
              title: "API Guide"
              space: "ENG"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/123456/API+Guide"
              content: "This guide explains the API endpoints..."
              created: "2024-01-15T10:00:00Z"
              updated: "2024-06-20T14:30:00Z"
              author: "John Doe"
              labels: ["api", "documentation"]
        format-output: |
          <confluence_context>
            <page_count>1</page_count>
            <page id="123456">
              <title>API Guide</title>
              <space>ENG</space>
              <url>https://company.atlassian.net/wiki/spaces/ENG/pages/123456/API+Guide</url>
              <author>John Doe</author>
              <content>This guide explains the API endpoints...</content>
            </page>
          </confluence_context>
      expect:
        calls:
          - step: extract-urls
            exactly: 1
          - step: fetch-pages
            exactly: 1
          - step: format-output
            exactly: 1
        workflow_output:
          - path: page_count
            equals: 1
          - path: confluence_context_xml
            contains: "<page id=\"123456\">"
          - path: confluence_context_xml
            contains: "API Guide"

    # Test 2: No Confluence URLs in text
    - name: no-confluence-urls-found
      description: Text without Confluence URLs should produce empty context
      event: manual
      fixture: local.minimal
      workflow_input:
        text: "This is a regular message without any Confluence links"
      mocks:
        extract-urls:
          data: []
          count: 0
          direct_mode: false
        no-pages-fallback: |
          <confluence_context><page_count>0</page_count><message>No Confluence URLs found in the provided text</message></confluence_context>
      expect:
        calls:
          - step: extract-urls
            exactly: 1
          - step: fetch-pages
            exactly: 0
          - step: no-pages-fallback
            exactly: 1
        workflow_output:
          - path: page_count
            equals: 0

    # Test 3: Multiple Confluence URLs
    - name: multiple-confluence-urls
      description: Extract and fetch multiple Confluence pages
      event: manual
      fixture: local.minimal
      workflow_input:
        text: |
          Check these docs:
          - https://company.atlassian.net/wiki/spaces/ENG/pages/111/Setup
          - https://company.atlassian.net/wiki/spaces/ENG/pages/222/Config
      mocks:
        extract-urls:
          data:
            - id: "111"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/111/Setup"
              space: "ENG"
            - id: "222"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/222/Config"
              space: "ENG"
          count: 2
          direct_mode: false
        fetch-pages:
          data:
            - id: "111"
              title: "Setup"
              space: "ENG"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/111/Setup"
              content: "Setup instructions..."
              author: "Jane Doe"
              labels: []
            - id: "222"
              title: "Config"
              space: "ENG"
              url: "https://company.atlassian.net/wiki/spaces/ENG/pages/222/Config"
              content: "Configuration guide..."
              author: "John Smith"
              labels: []
        format-output: |
          <confluence_context>
            <page_count>2</page_count>
            <page id="111">
              <title>Setup</title>
              <space>ENG</space>
            </page>
            <page id="222">
              <title>Config</title>
              <space>ENG</space>
            </page>
          </confluence_context>
      expect:
        calls:
          - step: extract-urls
            exactly: 1
          - step: fetch-pages
            exactly: 1
          - step: format-output
            exactly: 1
        workflow_output:
          - path: page_count
            equals: 2
          - path: confluence_context_xml
            contains: "<page id=\"111\">"
          - path: confluence_context_xml
            contains: "<page id=\"222\">"

    # Test 4: Direct page IDs input
    - name: direct-page-ids
      description: Use page_ids input directly instead of extracting from text
      event: manual
      fixture: local.minimal
      workflow_input:
        page_ids: ["123456", "789012"]
        max_pages: 5
      mocks:
        extract-urls:
          data:
            - id: "123456"
              url: ""
              space: ""
            - id: "789012"
              url: ""
              space: ""
          count: 2
          direct_mode: true
        fetch-pages:
          data:
            - id: "123456"
              title: "Page One"
              space: "DOCS"
              url: ""
              content: "Content of page one..."
              author: "Author 1"
              labels: []
            - id: "789012"
              title: "Page Two"
              space: "DOCS"
              url: ""
              content: "Content of page two..."
              author: "Author 2"
              labels: []
        format-output: |
          <confluence_context>
            <page_count>2</page_count>
            <page id="123456">
              <title>Page One</title>
            </page>
            <page id="789012">
              <title>Page Two</title>
            </page>
          </confluence_context>
      expect:
        calls:
          - step: extract-urls
            exactly: 1
          - step: fetch-pages
            exactly: 1
          - step: format-output
            exactly: 1
        workflow_output:
          - path: page_count
            equals: 2
