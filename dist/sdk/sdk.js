"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/utils/human-id.ts
function randomSuffix() {
  const chars = "abcdefghjkmnpqrstuvwxyz23456789";
  let result = "";
  for (let i = 0; i < 4; i++) {
    result += chars[Math.floor(Math.random() * chars.length)];
  }
  return result;
}
function generateHumanId() {
  const adj = adjectives[Math.floor(Math.random() * adjectives.length)];
  const noun = nouns[Math.floor(Math.random() * nouns.length)];
  const suffix = randomSuffix();
  return `${adj}-${noun}-${suffix}`;
}
function generateShortHumanId() {
  const adj = adjectives[Math.floor(Math.random() * adjectives.length)];
  const noun = nouns[Math.floor(Math.random() * nouns.length)];
  return `${adj}-${noun}`;
}
var adjectives, nouns;
var init_human_id = __esm({
  "src/utils/human-id.ts"() {
    "use strict";
    adjectives = [
      "bold",
      "calm",
      "cool",
      "dark",
      "fast",
      "gold",
      "green",
      "happy",
      "kind",
      "loud",
      "mild",
      "neat",
      "nice",
      "pink",
      "pure",
      "quick",
      "rare",
      "rich",
      "safe",
      "slim",
      "soft",
      "tall",
      "tidy",
      "tiny",
      "warm",
      "wise",
      "young",
      "able",
      "blue",
      "brave",
      "busy",
      "clean",
      "crisp",
      "eager",
      "fair",
      "fresh",
      "glad",
      "grand",
      "keen",
      "lush",
      "prime",
      "proud",
      "sharp",
      "sleek",
      "smart",
      "solid",
      "swift",
      "vivid",
      "wild",
      "witty",
      "zesty"
    ];
    nouns = [
      "ant",
      "bat",
      "bear",
      "bee",
      "bird",
      "bull",
      "cat",
      "cow",
      "crab",
      "crow",
      "deer",
      "dog",
      "dove",
      "duck",
      "eagle",
      "elk",
      "fish",
      "fox",
      "frog",
      "goat",
      "hawk",
      "hare",
      "horse",
      "jay",
      "lark",
      "lion",
      "lynx",
      "mole",
      "moth",
      "mouse",
      "newt",
      "owl",
      "panda",
      "pig",
      "puma",
      "rat",
      "raven",
      "seal",
      "shark",
      "sheep",
      "sloth",
      "snail",
      "snake",
      "spider",
      "swan",
      "tiger",
      "toad",
      "trout",
      "viper",
      "wasp",
      "whale",
      "wolf",
      "wren",
      "yak",
      "zebra"
    ];
  }
});

// src/telemetry/lazy-otel.ts
function getOtelApi() {
  if (otelApiAttempted) return otelApi;
  otelApiAttempted = true;
  try {
    otelApi = (function(name) {
      return require(name);
    })(OTEL_API_MODULE);
  } catch {
    otelApi = null;
  }
  return otelApi;
}
function createNoOpTracer() {
  return {
    startSpan: () => createNoOpSpan(),
    // Support both OTel v1 and v2 overloads:
    // - startActiveSpan(name, callback)
    // - startActiveSpan(name, options, callback)
    // - startActiveSpan(name, options, context, callback)
    startActiveSpan: (name, arg2, arg3, arg4) => {
      const span = createNoOpSpan();
      let cb = void 0;
      if (typeof arg2 === "function") cb = arg2;
      else if (typeof arg3 === "function") cb = arg3;
      else if (typeof arg4 === "function") cb = arg4;
      if (typeof cb === "function") {
        try {
          return cb(span);
        } catch {
          return void 0;
        }
      }
      return span;
    }
  };
}
function createNoOpSpan() {
  return {
    spanContext: () => ({ traceId: "", spanId: "", traceFlags: 0 }),
    setAttribute: () => {
    },
    setAttributes: () => {
    },
    addEvent: () => {
    },
    setStatus: () => {
    },
    updateName: () => {
    },
    end: () => {
    },
    isRecording: () => false,
    recordException: () => {
    }
  };
}
function createNoOpMeter() {
  return {
    createCounter: () => ({ add: () => {
    } }),
    createHistogram: () => ({ record: () => {
    } }),
    createUpDownCounter: () => ({ add: () => {
    } }),
    createObservableGauge: () => {
    },
    createObservableCounter: () => {
    },
    createObservableUpDownCounter: () => {
    }
  };
}
var otelApi, otelApiAttempted, OTEL_API_MODULE, trace, context, metrics, SpanStatusCode;
var init_lazy_otel = __esm({
  "src/telemetry/lazy-otel.ts"() {
    "use strict";
    otelApi = null;
    otelApiAttempted = false;
    OTEL_API_MODULE = "@opentelemetry/api";
    trace = {
      getTracer(name, version) {
        const api = getOtelApi();
        if (!api) return createNoOpTracer();
        return api.trace.getTracer(name, version);
      },
      getSpan(context2) {
        const api = getOtelApi();
        if (!api) return void 0;
        return api.trace.getSpan(context2);
      },
      getActiveSpan() {
        const api = getOtelApi();
        if (!api) return void 0;
        return api.trace.getActiveSpan();
      }
    };
    context = {
      active() {
        const api = getOtelApi();
        if (!api) return {};
        return api.context.active();
      },
      with(context2, fn, thisArg, ...args) {
        const api = getOtelApi();
        if (!api) return fn.call(thisArg, ...args);
        return api.context.with(context2, fn, thisArg, ...args);
      }
    };
    metrics = {
      getMeter(name, version) {
        const api = getOtelApi();
        if (!api?.metrics) return createNoOpMeter();
        return api.metrics.getMeter(name, version);
      }
    };
    SpanStatusCode = {
      get UNSET() {
        const api = getOtelApi();
        return api?.SpanStatusCode?.UNSET ?? 0;
      },
      get OK() {
        const api = getOtelApi();
        return api?.SpanStatusCode?.OK ?? 1;
      },
      get ERROR() {
        const api = getOtelApi();
        return api?.SpanStatusCode?.ERROR ?? 2;
      }
    };
  }
});

// src/logger.ts
var logger_exports = {};
__export(logger_exports, {
  configureLoggerFromCli: () => configureLoggerFromCli,
  logger: () => logger
});
function levelToNumber(level) {
  switch (level) {
    case "silent":
      return 0;
    case "error":
      return 10;
    case "warn":
      return 20;
    case "info":
      return 30;
    case "verbose":
      return 40;
    case "debug":
      return 50;
  }
}
function configureLoggerFromCli(options) {
  logger.configure({
    outputFormat: options.output,
    debug: options.debug,
    verbose: options.verbose,
    quiet: options.quiet
  });
  try {
    if (options.output) process.env.VISOR_OUTPUT_FORMAT = String(options.output);
    if (typeof options.debug === "boolean") {
      process.env.VISOR_DEBUG = options.debug ? "true" : "false";
    }
  } catch {
  }
}
var Logger, logger;
var init_logger = __esm({
  "src/logger.ts"() {
    "use strict";
    init_lazy_otel();
    Logger = class {
      level = "info";
      isJsonLike = false;
      isTTY = typeof process !== "undefined" ? !!process.stderr.isTTY : false;
      showTimestamps = true;
      // default: always show timestamps
      sink;
      sinkPassthrough = true;
      sinkErrorMode = "throw";
      sinkErrorHandler;
      configure(opts = {}) {
        let lvl = "info";
        if (opts.debug || process.env.VISOR_DEBUG === "true") {
          lvl = "debug";
        } else if (opts.verbose || process.env.VISOR_LOG_LEVEL === "verbose") {
          lvl = "verbose";
        } else if (opts.quiet || process.env.VISOR_LOG_LEVEL === "quiet") {
          lvl = "warn";
        } else if (opts.level) {
          lvl = opts.level;
        } else if (process.env.VISOR_LOG_LEVEL) {
          const envLvl = process.env.VISOR_LOG_LEVEL;
          if (["silent", "error", "warn", "info", "verbose", "debug"].includes(envLvl)) {
            lvl = envLvl;
          }
        }
        this.level = lvl;
        const output = opts.outputFormat || process.env.VISOR_OUTPUT_FORMAT || "table";
        this.isJsonLike = output === "json" || output === "sarif";
      }
      setSink(sink, opts = {}) {
        this.sink = sink;
        this.sinkPassthrough = opts.passthrough !== void 0 ? opts.passthrough : true;
        this.sinkErrorMode = opts.errorMode || "throw";
        this.sinkErrorHandler = opts.onError;
      }
      shouldLog(level) {
        const desired = levelToNumber(level);
        const current = levelToNumber(this.level);
        if (desired > current) return false;
        if (this.isJsonLike && desired < levelToNumber("error") && this.level !== "debug" && this.level !== "verbose") {
          return false;
        }
        return true;
      }
      getTraceSuffix(msg) {
        if (!msg) return "";
        if (msg.includes("trace_id=") || msg.includes("trace_id:")) return "";
        try {
          const span = trace.getSpan(context.active()) || trace.getActiveSpan();
          const ctx = span?.spanContext?.();
          if (!ctx?.traceId) return "";
          return ` [trace_id=${ctx.traceId} span_id=${ctx.spanId}]`;
        } catch {
          return "";
        }
      }
      write(msg, level) {
        const suffix = this.getTraceSuffix(msg);
        const decoratedMsg = suffix ? `${msg}${suffix}` : msg;
        const lvl = level || "info";
        if (this.sink) {
          try {
            this.sink(decoratedMsg, lvl);
          } catch (error) {
            if (this.sinkErrorMode === "warn") {
              try {
                if (this.sinkErrorHandler) {
                  this.sinkErrorHandler(error);
                } else {
                  const errMsg = error instanceof Error ? error.message : String(error);
                  process.stderr.write(`[logger] sink failed: ${errMsg}
`);
                }
              } catch {
              }
            }
            if (this.sinkErrorMode === "throw") {
              throw error;
            }
            return;
          }
          if (!this.sinkPassthrough) return;
        }
        try {
          if (this.showTimestamps) {
            const ts = (/* @__PURE__ */ new Date()).toISOString();
            const lvl2 = level ? level : void 0;
            let tsToken = `[${ts}]`;
            let lvlToken = lvl2 ? `[${lvl2}]` : "";
            if (this.isTTY && !this.isJsonLike) {
              const reset = "\x1B[0m";
              const dim = "\x1B[2m";
              const colours = {
                silent: "",
                error: "\x1B[31m",
                // red
                warn: "\x1B[33m",
                // yellow
                info: "\x1B[36m",
                // cyan
                verbose: "\x1B[35m",
                // magenta
                debug: "\x1B[90m"
                // bright black / gray
              };
              tsToken = `${dim}${tsToken}${reset}`;
              if (lvl2) {
                const colour = colours[lvl2] || "";
                if (colour) {
                  lvlToken = `${colour}${lvlToken}${reset}`;
                }
              }
            }
            const prefix = lvl2 ? `${tsToken} ${lvlToken}` : tsToken;
            process.stderr.write(`${prefix} ${decoratedMsg}
`);
          } else {
            process.stderr.write(decoratedMsg + "\n");
          }
        } catch {
        }
      }
      info(msg) {
        if (this.shouldLog("info")) this.write(msg, "info");
      }
      warn(msg) {
        if (this.shouldLog("warn")) this.write(msg, "warn");
      }
      error(msg) {
        if (this.shouldLog("error")) this.write(msg, "error");
      }
      verbose(msg) {
        if (this.shouldLog("verbose")) this.write(msg, "verbose");
      }
      debug(msg) {
        if (this.shouldLog("debug")) this.write(msg, "debug");
      }
      step(msg) {
        if (this.shouldLog("info")) this.write(`\u25B6 ${msg}`, "info");
      }
      success(msg) {
        if (this.shouldLog("info")) this.write(`\u2714 ${msg}`, "info");
      }
    };
    logger = new Logger();
  }
});

// src/telemetry/fallback-ndjson.ts
var fallback_ndjson_exports = {};
__export(fallback_ndjson_exports, {
  emitNdjsonFallback: () => emitNdjsonFallback,
  emitNdjsonSpanWithEvents: () => emitNdjsonSpanWithEvents,
  flushNdjson: () => flushNdjson
});
function resolveTargetPath(outDir) {
  if (process.env.VISOR_FALLBACK_TRACE_FILE) {
    CURRENT_FILE = process.env.VISOR_FALLBACK_TRACE_FILE;
    return CURRENT_FILE;
  }
  if (CURRENT_FILE) return CURRENT_FILE;
  const ts = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
  CURRENT_FILE = path.join(outDir, `${ts}.ndjson`);
  return CURRENT_FILE;
}
function isEnabled() {
  if (process.env.VISOR_FALLBACK_TRACE_FILE) return true;
  return process.env.VISOR_TELEMETRY_ENABLED === "true" && (process.env.VISOR_TELEMETRY_SINK || "file") === "file";
}
function appendAsync(outDir, line) {
  writeChain = writeChain.then(async () => {
    if (!dirReady) {
      try {
        await fs.promises.mkdir(outDir, { recursive: true });
      } catch {
      }
      dirReady = true;
    }
    const target = resolveTargetPath(outDir);
    await fs.promises.appendFile(target, line, "utf8");
  }).catch(() => {
  });
}
async function flushNdjson() {
  try {
    await writeChain;
  } catch {
  }
}
function emitNdjsonFallback(name, attrs) {
  try {
    if (!isEnabled()) return;
    const outDir = process.env.VISOR_TRACE_DIR || path.join(process.cwd(), "output", "traces");
    const line = JSON.stringify({ name, attributes: attrs }) + "\n";
    appendAsync(outDir, line);
  } catch {
  }
}
function emitNdjsonSpanWithEvents(name, attrs, events) {
  try {
    if (!isEnabled()) return;
    const outDir = process.env.VISOR_TRACE_DIR || path.join(process.cwd(), "output", "traces");
    const line = JSON.stringify({ name, attributes: attrs, events }) + "\n";
    appendAsync(outDir, line);
  } catch {
  }
}
var fs, path, CURRENT_FILE, dirReady, writeChain;
var init_fallback_ndjson = __esm({
  "src/telemetry/fallback-ndjson.ts"() {
    "use strict";
    fs = __toESM(require("fs"));
    path = __toESM(require("path"));
    CURRENT_FILE = null;
    dirReady = false;
    writeChain = Promise.resolve();
  }
});

// src/telemetry/trace-helpers.ts
var trace_helpers_exports = {};
__export(trace_helpers_exports, {
  __getOrCreateNdjsonPath: () => __getOrCreateNdjsonPath,
  _appendRunMarker: () => _appendRunMarker,
  addEvent: () => addEvent,
  getTracer: () => getTracer,
  setSpanAttributes: () => setSpanAttributes,
  setSpanError: () => setSpanError,
  withActiveSpan: () => withActiveSpan
});
function getTracer() {
  return trace.getTracer("visor");
}
async function withActiveSpan(name, attrs, fn) {
  const tracer = getTracer();
  return await new Promise((resolve9, reject) => {
    const callback = async (span) => {
      try {
        const res = await fn(span);
        resolve9(res);
      } catch (err) {
        try {
          if (err instanceof Error) span.recordException(err);
          span.setStatus({ code: SpanStatusCode.ERROR });
        } catch {
        }
        reject(err);
      } finally {
        try {
          span.end();
        } catch {
        }
      }
    };
    const options = attrs ? { attributes: attrs } : {};
    tracer.startActiveSpan(name, options, callback);
  });
}
function addEvent(name, attrs) {
  const span = trace.getSpan(context.active());
  if (span) {
    try {
      span.addEvent(name, attrs);
    } catch {
    }
  }
  try {
    const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
    emitNdjsonSpanWithEvents2("visor.event", {}, [{ name, attrs }]);
    if (name === "fail_if.triggered") {
      emitNdjsonSpanWithEvents2("visor.event", {}, [
        { name: "fail_if.evaluated", attrs },
        { name: "fail_if.triggered", attrs }
      ]);
    }
  } catch {
  }
}
function setSpanAttributes(attrs) {
  const span = trace.getSpan(context.active());
  if (!span) return;
  try {
    for (const [k, v] of Object.entries(attrs)) span.setAttribute(k, v);
  } catch {
  }
}
function setSpanError(err) {
  const span = trace.getSpan(context.active());
  if (!span) return;
  try {
    if (err instanceof Error) span.recordException(err);
    span.setStatus({ code: SpanStatusCode.ERROR });
  } catch {
  }
}
function __getOrCreateNdjsonPath() {
  try {
    if (process.env.VISOR_TELEMETRY_SINK && process.env.VISOR_TELEMETRY_SINK !== "file")
      return null;
    const path22 = require("path");
    const fs20 = require("fs");
    if (process.env.VISOR_FALLBACK_TRACE_FILE) {
      __ndjsonPath = process.env.VISOR_FALLBACK_TRACE_FILE;
      const dir = path22.dirname(__ndjsonPath);
      if (!fs20.existsSync(dir)) fs20.mkdirSync(dir, { recursive: true });
      return __ndjsonPath;
    }
    const outDir = process.env.VISOR_TRACE_DIR || path22.join(process.cwd(), "output", "traces");
    if (!fs20.existsSync(outDir)) fs20.mkdirSync(outDir, { recursive: true });
    if (!__ndjsonPath) {
      const ts = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
      __ndjsonPath = path22.join(outDir, `${ts}.ndjson`);
    }
    return __ndjsonPath;
  } catch {
    return null;
  }
}
function _appendRunMarker() {
  try {
    const fs20 = require("fs");
    const p = __getOrCreateNdjsonPath();
    if (!p) return;
    const line = { name: "visor.run", attributes: { started: true } };
    fs20.appendFileSync(p, JSON.stringify(line) + "\n", "utf8");
  } catch {
  }
}
var __ndjsonPath;
var init_trace_helpers = __esm({
  "src/telemetry/trace-helpers.ts"() {
    "use strict";
    init_lazy_otel();
    __ndjsonPath = null;
  }
});

// src/state-machine/states/init.ts
async function handleInit(context2, state, transition) {
  if (context2.debug) {
    logger.info("[Init] Initializing state machine...");
  }
  if (!context2.config) {
    throw new Error("Configuration is required");
  }
  if (context2.memory) {
    await context2.memory.initialize();
  }
  if (context2.gitHubChecks) {
    if (context2.debug) {
      logger.info("[Init] GitHub checks service available");
    }
  }
  if (context2.debug) {
    logger.info(`[Init] Session ID: ${context2.sessionId}`);
  }
  transition("PlanReady");
}
var init_init = __esm({
  "src/state-machine/states/init.ts"() {
    "use strict";
    init_logger();
  }
});

// src/dependency-resolver.ts
var DependencyResolver;
var init_dependency_resolver = __esm({
  "src/dependency-resolver.ts"() {
    "use strict";
    DependencyResolver = class {
      /**
       * Build dependency graph from check dependencies
       */
      static buildDependencyGraph(checkDependencies) {
        const nodes = /* @__PURE__ */ new Map();
        for (const checkId of Object.keys(checkDependencies)) {
          nodes.set(checkId, {
            id: checkId,
            dependencies: checkDependencies[checkId] || [],
            dependents: [],
            depth: 0
          });
        }
        for (const [checkId, dependencies] of Object.entries(checkDependencies)) {
          for (const depId of dependencies || []) {
            if (!nodes.has(depId)) {
              throw new Error(`Check "${checkId}" depends on "${depId}" but "${depId}" is not defined`);
            }
            const depNode = nodes.get(depId);
            depNode.dependents.push(checkId);
          }
        }
        const cycleDetection = this.detectCycles(nodes);
        if (cycleDetection.hasCycles) {
          return {
            nodes,
            executionOrder: [],
            hasCycles: true,
            cycleNodes: cycleDetection.cycleNodes
          };
        }
        const executionOrder = this.topologicalSort(nodes);
        return {
          nodes,
          executionOrder,
          hasCycles: false
        };
      }
      /**
       * Detect cycles in the dependency graph using DFS
       */
      static detectCycles(nodes) {
        const visited = /* @__PURE__ */ new Set();
        const recursionStack = /* @__PURE__ */ new Set();
        const cycleNodes = [];
        const dfs = (nodeId) => {
          if (recursionStack.has(nodeId)) {
            cycleNodes.push(nodeId);
            return true;
          }
          if (visited.has(nodeId)) {
            return false;
          }
          visited.add(nodeId);
          recursionStack.add(nodeId);
          const node = nodes.get(nodeId);
          if (node) {
            for (const depId of node.dependencies) {
              if (dfs(depId)) {
                cycleNodes.push(nodeId);
                return true;
              }
            }
          }
          recursionStack.delete(nodeId);
          return false;
        };
        for (const nodeId of nodes.keys()) {
          if (!visited.has(nodeId)) {
            if (dfs(nodeId)) {
              return { hasCycles: true, cycleNodes: [...new Set(cycleNodes)] };
            }
          }
        }
        return { hasCycles: false };
      }
      /**
       * Perform topological sort to determine execution order
       * Groups checks that can run in parallel at each level
       */
      static topologicalSort(nodes) {
        const remainingNodes = new Map(nodes);
        const executionGroups = [];
        let level = 0;
        while (remainingNodes.size > 0) {
          const readyNodes = [];
          for (const [nodeId, node] of remainingNodes.entries()) {
            const unmetDependencies = node.dependencies.filter((depId) => remainingNodes.has(depId));
            if (unmetDependencies.length === 0) {
              readyNodes.push(nodeId);
            }
          }
          if (readyNodes.length === 0) {
            throw new Error("Unable to resolve dependencies - possible circular dependency detected");
          }
          executionGroups.push({
            parallel: readyNodes,
            level
          });
          for (const nodeId of readyNodes) {
            remainingNodes.delete(nodeId);
          }
          level++;
        }
        return executionGroups;
      }
      /**
       * Validate that all dependencies exist
       */
      static validateDependencies(checkIds, dependencies) {
        const errors = [];
        const checkIdSet = new Set(checkIds);
        for (const [checkId, deps] of Object.entries(dependencies)) {
          if (!checkIdSet.has(checkId)) {
            errors.push(`Check "${checkId}" is not in the list of available checks`);
            continue;
          }
          for (const depId of deps || []) {
            if (!checkIdSet.has(depId)) {
              errors.push(`Check "${checkId}" depends on "${depId}" which is not available`);
            }
          }
        }
        return {
          valid: errors.length === 0,
          errors
        };
      }
      /**
       * Get all transitive dependencies (ancestors) for a given check
       * This returns all checks that must complete before the given check can run,
       * not just the direct dependencies.
       *
       * For example, if A -> B -> C, then:
       * - getAllDependencies(C) returns [A, B]
       * - getAllDependencies(B) returns [A]
       * - getAllDependencies(A) returns []
       *
       * @param checkId The check to find dependencies for
       * @param nodes The dependency graph nodes
       * @returns Array of all transitive dependency IDs
       */
      static getAllDependencies(checkId, nodes) {
        const allDeps = /* @__PURE__ */ new Set();
        const visited = /* @__PURE__ */ new Set();
        const collectDependencies = (currentId) => {
          if (visited.has(currentId)) {
            return;
          }
          visited.add(currentId);
          const node = nodes.get(currentId);
          if (!node) {
            return;
          }
          for (const depId of node.dependencies) {
            allDeps.add(depId);
            collectDependencies(depId);
          }
        };
        collectDependencies(checkId);
        return Array.from(allDeps);
      }
      /**
       * Get execution statistics for debugging
       */
      static getExecutionStats(graph) {
        const totalChecks = graph.nodes.size;
        const parallelLevels = graph.executionOrder.length;
        const maxParallelism = Math.max(...graph.executionOrder.map((group) => group.parallel.length));
        const averageParallelism = totalChecks / parallelLevels;
        const checksWithDependencies = Array.from(graph.nodes.values()).filter(
          (node) => node.dependencies.length > 0
        ).length;
        return {
          totalChecks,
          parallelLevels,
          maxParallelism,
          averageParallelism,
          checksWithDependencies
        };
      }
    };
  }
});

// src/state-machine/states/plan-ready.ts
async function handlePlanReady(context2, state, transition) {
  if (context2.debug) {
    logger.info("[PlanReady] Building dependency graph...");
    if (context2.requestedChecks) {
      logger.info(`[PlanReady] Requested checks: ${context2.requestedChecks.join(", ")}`);
    }
    if (context2.config.tag_filter) {
      logger.info(
        `[PlanReady] Tag filter: include=${JSON.stringify(context2.config.tag_filter.include)}, exclude=${JSON.stringify(context2.config.tag_filter.exclude)}`
      );
    } else {
      logger.info("[PlanReady] No tag filter specified - will include only untagged checks");
    }
  }
  const eventTrigger = context2.event;
  const tagFilter = context2.config.tag_filter;
  const expandWithTransitives = (rootChecks) => {
    const expanded = new Set(rootChecks);
    const allowByTags = (checkId) => {
      if (!tagFilter) return true;
      const cfg = context2.config.checks?.[checkId];
      const tags = cfg?.tags || [];
      if (tagFilter.exclude && tagFilter.exclude.some((t) => tags.includes(t))) return false;
      if (tagFilter.include && tagFilter.include.length > 0) {
        return tagFilter.include.some((t) => tags.includes(t));
      }
      return true;
    };
    const allowByEvent = (checkId) => {
      const cfg = context2.config.checks?.[checkId];
      const triggers = cfg?.on || [];
      if (!triggers || triggers.length === 0) return true;
      const current = eventTrigger || "manual";
      return triggers.includes(current);
    };
    const visit = (checkId) => {
      const cfg = context2.config.checks?.[checkId];
      if (!cfg || !cfg.depends_on) return null;
      const depTokens = Array.isArray(cfg.depends_on) ? cfg.depends_on : [cfg.depends_on];
      const expandDep = (tok) => {
        if (tok.includes("|")) {
          return tok.split("|").map((s) => s.trim()).filter(Boolean);
        }
        return [tok];
      };
      const deps = depTokens.flatMap(expandDep);
      for (const depId of deps) {
        if (!context2.config.checks?.[depId]) {
          return `Check "${checkId}" depends on "${depId}" but "${depId}" is not defined`;
        }
        if (!allowByTags(depId)) continue;
        if (!allowByEvent(depId)) continue;
        if (!expanded.has(depId)) {
          expanded.add(depId);
          const err = visit(depId);
          if (err) return err;
        }
      }
      return null;
    };
    for (const checkId of rootChecks) {
      const err = visit(checkId);
      if (err) {
        const validationIssue = {
          file: "system",
          line: 0,
          message: err,
          category: "logic",
          severity: "error",
          ruleId: "system/error"
        };
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          scope: [],
          checkId: "system",
          result: {
            issues: [validationIssue],
            output: void 0
          }
        });
        return null;
      }
    }
    return expanded;
  };
  const requestedChecksSet = context2.requestedChecks ? expandWithTransitives(context2.requestedChecks) : void 0;
  if (context2.requestedChecks && requestedChecksSet === null) {
    logger.error(`[PlanReady] Dependency validation failed during expansion`);
    state.currentState = "Completed";
    return;
  }
  if (context2.debug && requestedChecksSet && context2.requestedChecks) {
    const added = Array.from(requestedChecksSet).filter((c) => !context2.requestedChecks.includes(c));
    if (added.length > 0) {
      logger.info(
        `[PlanReady] Expanded requested checks with transitive dependencies: ${added.join(", ")}`
      );
    }
  }
  const filteredChecks = {};
  const routingRunTargets = /* @__PURE__ */ new Set();
  for (const [, cfg] of Object.entries(context2.config.checks || {})) {
    const onFinish = cfg.on_finish || {};
    const onSuccess = cfg.on_success || {};
    const onFail = cfg.on_fail || {};
    const collect = (arr) => {
      if (Array.isArray(arr)) {
        for (const t of arr) if (typeof t === "string" && t) routingRunTargets.add(t);
      }
    };
    collect(onFinish.run);
    collect(onSuccess.run);
    collect(onFail.run);
  }
  for (const [checkId, checkConfig] of Object.entries(context2.config.checks || {})) {
    if (requestedChecksSet && !requestedChecksSet.has(checkId)) {
      if (context2.debug) {
        logger.info(
          `[PlanReady] Skipping check '${checkId}': not in expanded requested checks list`
        );
      }
      continue;
    }
    if (!requestedChecksSet && routingRunTargets.has(checkId)) {
      if (context2.debug) {
        logger.info(
          `[PlanReady] Skipping check '${checkId}': routing-run target (will be scheduled by on_*.run)`
        );
      }
      continue;
    }
    if (checkConfig.on && eventTrigger && !checkConfig.on.includes(eventTrigger)) {
      if (context2.debug) {
        logger.info(
          `[PlanReady] Skipping check '${checkId}': on=${JSON.stringify(checkConfig.on)}, event=${eventTrigger}`
        );
      }
      continue;
    }
    const checkTags = checkConfig.tags || [];
    const isTagged = checkTags.length > 0;
    if (tagFilter) {
      if (tagFilter.exclude && tagFilter.exclude.length > 0) {
        const hasExcludedTag = tagFilter.exclude.some((tag) => checkTags.includes(tag));
        if (hasExcludedTag) {
          if (context2.debug) {
            logger.info(`[PlanReady] Skipping check '${checkId}': excluded by tag filter`);
          }
          continue;
        }
      }
      if (tagFilter.include && tagFilter.include.length > 0) {
        const hasIncludedTag = tagFilter.include.some((tag) => checkTags.includes(tag));
        if (!hasIncludedTag && isTagged) {
          if (context2.debug) {
            logger.info(`[PlanReady] Skipping check '${checkId}': not included by tag filter`);
          }
          continue;
        }
      }
    } else {
      if (isTagged) {
        if (context2.debug) {
          logger.info(
            `[PlanReady] Skipping check '${checkId}': tagged but no tag filter specified`
          );
        }
        continue;
      }
    }
    filteredChecks[checkId] = checkConfig;
  }
  if (context2.debug) {
    const totalChecks = Object.keys(context2.config.checks || {}).length;
    const filteredCount = Object.keys(filteredChecks).length;
    logger.info(
      `[PlanReady] Filtered ${totalChecks} checks to ${filteredCount} based on event=${eventTrigger}`
    );
  }
  if (!context2.requestedChecks || context2.requestedChecks.length === 0) {
    const dependentsMap = /* @__PURE__ */ new Map();
    for (const [cid, cfg] of Object.entries(context2.config.checks || {})) {
      const deps = cfg.depends_on || [];
      const depList = Array.isArray(deps) ? deps : [deps];
      for (const raw of depList) {
        if (typeof raw !== "string") continue;
        const tokens = raw.includes("|") ? raw.split("|").map((s) => s.trim()).filter(Boolean) : [raw];
        for (const dep of tokens) {
          if (!dependentsMap.has(dep)) dependentsMap.set(dep, []);
          dependentsMap.get(dep).push(cid);
        }
      }
    }
    const queue = Object.keys(filteredChecks);
    const seenForward = new Set(queue);
    while (queue.length > 0) {
      const cur = queue.shift();
      const kids = dependentsMap.get(cur) || [];
      for (const child of kids) {
        if (seenForward.has(child)) continue;
        const cfg = context2.config.checks?.[child];
        if (!cfg) continue;
        if (cfg.on && eventTrigger && !cfg.on.includes(eventTrigger)) continue;
        const tags = cfg.tags || [];
        const isTagged = tags.length > 0;
        if (!tagFilter && isTagged) continue;
        if (tagFilter) {
          if (tagFilter.exclude && tagFilter.exclude.length > 0) {
            const hasExcluded = tagFilter.exclude.some((t) => tags.includes(t));
            if (hasExcluded) continue;
          }
          if (tagFilter.include && tagFilter.include.length > 0) {
            const hasIncluded = tagFilter.include.some((t) => tags.includes(t));
            if (!hasIncluded && isTagged) continue;
          }
        }
        filteredChecks[child] = cfg;
        seenForward.add(child);
        queue.push(child);
        if (context2.debug)
          logger.info(`[PlanReady] Added dependent '${child}' via forward-closure from '${cur}'`);
      }
    }
  }
  const areDependenciesSatisfied = (dependencies) => {
    for (const dep of dependencies) {
      if (dep.includes("|")) {
        const orOptions = dep.split("|").map((s) => s.trim()).filter(Boolean);
        const hasAtLeastOne = orOptions.some((opt) => filteredChecks[opt] !== void 0);
        if (!hasAtLeastOne) {
          return false;
        }
      } else {
        if (filteredChecks[dep] === void 0) {
          return false;
        }
      }
    }
    return true;
  };
  const finalChecks = {};
  for (const [checkId, checkConfig] of Object.entries(filteredChecks)) {
    const depRaw = checkConfig.depends_on;
    const dependencies = Array.isArray(depRaw) ? depRaw : typeof depRaw === "string" ? [depRaw] : [];
    if (dependencies.length > 0 && !tagFilter && !areDependenciesSatisfied(dependencies)) {
      if (context2.debug) {
        logger.info(
          `[PlanReady] Skipping check '${checkId}': unsatisfied dependencies ${JSON.stringify(dependencies)}`
        );
      }
      continue;
    }
    finalChecks[checkId] = checkConfig;
  }
  if (context2.debug && Object.keys(finalChecks).length !== Object.keys(filteredChecks).length) {
    logger.info(
      `[PlanReady] Removed ${Object.keys(filteredChecks).length - Object.keys(finalChecks).length} checks due to unsatisfied dependencies`
    );
  }
  const checkDependencies = {};
  for (const [checkId, checkConfig] of Object.entries(finalChecks)) {
    const depsRaw2 = checkConfig.depends_on;
    const depList = Array.isArray(depsRaw2) ? depsRaw2 : typeof depsRaw2 === "string" ? [depsRaw2] : [];
    const dependencies = depList.flatMap((d) => {
      if (typeof d === "string" && d.includes("|")) {
        const orOptions = d.split("|").map((s) => s.trim()).filter(Boolean).filter((opt) => finalChecks[opt] !== void 0);
        return orOptions;
      } else {
        if (tagFilter && finalChecks[d] === void 0) {
          if (context2.debug) {
            logger.info(
              `[PlanReady] Soft dependency '${d}' of check '${checkId}' filtered out by tags - check will run without it`
            );
          }
          return [];
        }
        return [d];
      }
    });
    checkDependencies[checkId] = dependencies;
  }
  let graph;
  try {
    graph = DependencyResolver.buildDependencyGraph(checkDependencies);
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    logger.error(`[PlanReady] Dependency validation failed: ${errorMsg}`);
    const validationIssue = {
      file: "system",
      line: 0,
      message: errorMsg,
      category: "logic",
      severity: "error",
      ruleId: "system/error"
    };
    context2.journal.commitEntry({
      sessionId: context2.sessionId,
      scope: [],
      checkId: "system",
      result: {
        issues: [validationIssue],
        output: void 0
      }
    });
    state.currentState = "Completed";
    return;
  }
  if (graph.hasCycles) {
    const cycleNodes = graph.cycleNodes?.join(" -> ") || "unknown";
    const errorMsg = `Dependency cycle detected: ${cycleNodes}`;
    logger.error(`[PlanReady] ${errorMsg}`);
    const cycleIssue = {
      file: "system",
      line: 0,
      message: errorMsg,
      category: "logic",
      severity: "error",
      ruleId: "system/error"
    };
    context2.journal.commitEntry({
      sessionId: context2.sessionId,
      scope: [],
      checkId: "system",
      result: {
        issues: [cycleIssue],
        output: void 0
      }
    });
    state.currentState = "Completed";
    return;
  }
  if (context2.debug) {
    logger.info(
      `[PlanReady] Graph built with ${graph.nodes.size} checks, ${graph.executionOrder.length} levels`
    );
  }
  context2.dependencyGraph = graph;
  state.wave = 0;
  transition("WavePlanning");
}
var init_plan_ready = __esm({
  "src/state-machine/states/plan-ready.ts"() {
    "use strict";
    init_dependency_resolver();
    init_logger();
  }
});

// src/state-machine/states/wave-planning.ts
async function handleWavePlanning(context2, state, transition) {
  if (context2.debug) {
    logger.info(`[WavePlanning] Planning wave ${state.wave}...`);
  }
  try {
    state.flags = state.flags || {};
    state.flags.forwardRunActive = false;
  } catch {
  }
  try {
    const flags = state.flags || {};
    logger.info(
      `[WavePlanning] Checking awaitingHumanInput flag: ${!!flags.awaitingHumanInput} (wave=${state.wave})`
    );
    if (flags.awaitingHumanInput) {
      logger.info("[WavePlanning] Awaiting human input \u2013 finishing run without further waves");
      state.levelQueue = [];
      state.eventQueue = [];
      transition("Completed");
      return;
    }
  } catch (e) {
    logger.warn(`[WavePlanning] Failed to check awaitingHumanInput flag: ${e}`);
  }
  if (!context2.dependencyGraph) {
    if (state.wave === 0 && state.levelQueue.length === 0) {
      throw new Error("Dependency graph not available");
    }
  }
  const bubbledEvents = context2._bubbledEvents || [];
  if (bubbledEvents.length > 0) {
    if (context2.debug) {
      logger.info(
        `[WavePlanning] Processing ${bubbledEvents.length} bubbled events from child workflows`
      );
    }
    for (const event of bubbledEvents) {
      state.eventQueue.push(event);
    }
    context2._bubbledEvents = [];
  }
  const forwardRunRequests = state.eventQueue.filter(
    (e) => e.type === "ForwardRunRequested"
  );
  if (forwardRunRequests.length > 0 && (state.levelQueue.length === 0 || forwardRunRequests.some((r) => r.origin === "goto" || r.origin === "goto_js"))) {
    if (state.levelQueue.length > 0) {
      if (context2.debug) {
        logger.info(
          `[WavePlanning] Preempting ${state.levelQueue.length} remaining levels due to goto forward-run request`
        );
      }
      state.levelQueue = [];
    }
    if (context2.debug) {
      logger.info(`[WavePlanning] Processing ${forwardRunRequests.length} forward run requests`);
    }
    state.eventQueue = state.eventQueue.filter((e) => e.type !== "ForwardRunRequested");
    const checksToRun = /* @__PURE__ */ new Set();
    if (!state.pendingRunScopes) state.pendingRunScopes = /* @__PURE__ */ new Map();
    const eventOverrides = /* @__PURE__ */ new Map();
    for (const request of forwardRunRequests) {
      const { target, gotoEvent } = request;
      const scopeKey = request.scope && Array.isArray(request.scope) ? JSON.stringify(request.scope) : "root";
      const dedupeKey = `${target}:${gotoEvent || "default"}:${state.wave}:${scopeKey}`;
      if (state.forwardRunGuards.has(dedupeKey)) {
        if (context2.debug) {
          logger.info(`[WavePlanning] Skipping duplicate forward run: ${target}`);
        }
        continue;
      }
      state.forwardRunGuards.add(dedupeKey);
      checksToRun.add(target);
      try {
        const scope = request.scope;
        if (scope && scope.length > 0) {
          const arr = state.pendingRunScopes.get(target) || [];
          const key = (s) => JSON.stringify(s);
          if (!arr.some((s) => key(s) === key(scope))) arr.push(scope);
          state.pendingRunScopes.set(target, arr);
        }
      } catch {
      }
      if (gotoEvent) {
        eventOverrides.set(target, gotoEvent);
      }
      const sourceCheck = request.sourceCheck;
      if (sourceCheck && request.origin === "run") {
        if (!state.allowedFailedDeps) {
          state.allowedFailedDeps = /* @__PURE__ */ new Map();
        }
        const allowedSet = state.allowedFailedDeps.get(target) || /* @__PURE__ */ new Set();
        allowedSet.add(sourceCheck);
        state.allowedFailedDeps.set(target, allowedSet);
        if (context2.debug) {
          logger.info(
            `[WavePlanning] Allowing ${target} to run despite failed dependency ${sourceCheck}`
          );
        }
      }
      const origin = request.origin;
      const dependencies = findTransitiveDependencies(target, context2);
      for (const dep of dependencies) {
        const stats = state.stats.get(dep);
        const hasSucceeded = !!stats && (stats.successfulRuns || 0) > 0;
        const hasRun = !!stats && (stats.totalRuns || 0) > 0;
        if (origin === "run" && hasRun) {
          continue;
        }
        if (!hasSucceeded) {
          checksToRun.add(dep);
        }
      }
      let shouldIncludeDependents = true;
      try {
        const origin2 = request.origin;
        const cfg = context2.config.checks?.[target];
        const targetType = String(cfg?.type || "").toLowerCase();
        const execCtx = context2.executionContext || {};
        const hasWebhook = !!execCtx.webhookContext;
        if (hasWebhook && (origin2 === "goto" || origin2 === "goto_js") && targetType === "human-input") {
          shouldIncludeDependents = false;
        }
      } catch {
      }
      if (shouldIncludeDependents) {
        const dependents = findTransitiveDependents(target, context2, gotoEvent);
        for (const dep of dependents) {
          checksToRun.add(dep);
        }
      }
    }
    if (checksToRun.size > 0) {
      const subgraphChecks = Array.from(checksToRun);
      const subDeps = {};
      for (const checkId of subgraphChecks) {
        const checkConfig = context2.config.checks?.[checkId];
        if (!checkConfig) continue;
        const deps = checkConfig.depends_on || [];
        const depList = Array.isArray(deps) ? deps : [deps];
        const expanded = depList.flatMap(
          (d) => typeof d === "string" && d.includes("|") ? d.split("|").map((s) => s.trim()).filter(Boolean) : [d]
        );
        subDeps[checkId] = expanded.filter((d) => checksToRun.has(d));
      }
      const subGraph = DependencyResolver.buildDependencyGraph(subDeps);
      if (subGraph.hasCycles) {
        const cycleNodes = subGraph.cycleNodes?.join(" -> ") || "unknown";
        const errorMsg = `Cycle detected in forward-run dependency subset: ${cycleNodes}`;
        logger.error(`[WavePlanning] ${errorMsg}`);
        const firstCycleCheck = subGraph.cycleNodes?.[0];
        if (firstCycleCheck) {
          const checkStats = {
            checkName: firstCycleCheck,
            totalRuns: 1,
            // Count as 1 execution attempt
            successfulRuns: 0,
            failedRuns: 1,
            skippedRuns: 0,
            skipped: false,
            totalDuration: 0,
            issuesFound: 0,
            issuesBySeverity: {
              critical: 0,
              error: 1,
              warning: 0,
              info: 0
            },
            errorMessage: errorMsg
          };
          state.stats.set(firstCycleCheck, checkStats);
        }
        transition("Completed");
        return;
      }
      state.levelQueue = [...subGraph.executionOrder];
      if (context2.debug) {
        const planned = subgraphChecks.join(", ");
        logger.info(
          `[WavePlanning] Forward-run planning: checks=[${planned}] levels=${state.levelQueue.length}`
        );
      }
      if (context2.debug) {
        logger.info(
          `[WavePlanning] Queued ${state.levelQueue.length} levels for ${checksToRun.size} checks (forward run)`
        );
      }
      state.wave++;
      state.currentWaveCompletions = /* @__PURE__ */ new Set();
      state.failedChecks = /* @__PURE__ */ new Set();
      state.flags.forwardRunRequested = false;
      try {
        state.flags.forwardRunActive = true;
        state.flags.waveKind = "forward";
      } catch {
      }
      transition("LevelDispatch");
      return;
    }
  }
  const waveRetryEvents = state.eventQueue.filter((e) => e.type === "WaveRetry");
  if (waveRetryEvents.length > 0 && state.levelQueue.length === 0 && !state.eventQueue.some((e) => e.type === "ForwardRunRequested")) {
    logger.info(`[WavePlanning] Processing wave retry requests (${waveRetryEvents.length} events)`);
    state.eventQueue = state.eventQueue.filter((e) => e.type !== "WaveRetry");
    const skippedIfChecks = /* @__PURE__ */ new Set();
    logger.info(`[WavePlanning] Scanning ${state.stats.size} stat entries for skipped-if checks`);
    for (const [name, stats] of state.stats.entries()) {
      logger.info(
        `[WavePlanning] Check ${name}: skipped=${stats.skipped}, skipReason=${stats.skipReason}`
      );
      if (stats.skipped === true && stats.skipReason === "if_condition") {
        skippedIfChecks.add(name);
        logger.info(`[WavePlanning] Found skipped-if check for retry: ${name}`);
      }
    }
    logger.info(`[WavePlanning] Total skipped-if checks: ${skippedIfChecks.size}`);
    if (skippedIfChecks.size === 0) {
      transition("Completed");
      return;
    }
    const checksToRun = Array.from(skippedIfChecks).filter(
      (id) => !context2.config.checks?.[id]?.forEach
    );
    const subDeps = {};
    for (const id of checksToRun) {
      const cfg = context2.config.checks?.[id];
      const rawDeps = cfg?.depends_on;
      const depsArray = Array.isArray(rawDeps) ? rawDeps : rawDeps ? [rawDeps] : [];
      const deps = depsArray.filter((d) => checksToRun.includes(d));
      subDeps[id] = deps;
    }
    const subGraph = DependencyResolver.buildDependencyGraph(subDeps);
    state.levelQueue = [...subGraph.executionOrder];
    if (context2.debug) {
      logger.info(
        `[WavePlanning] Wave retry queued ${checksToRun.length} skipped-if check(s) in ${state.levelQueue.length} level(s)`
      );
    }
    state.wave++;
    state.currentWaveCompletions = /* @__PURE__ */ new Set();
    state.failedChecks = /* @__PURE__ */ new Set();
    try {
      state.flags = state.flags || {};
      state.flags.forwardRunActive = true;
      state.flags.waveKind = "retry";
    } catch {
    }
    transition("LevelDispatch");
    return;
  }
  if (state.wave === 0 && state.levelQueue.length === 0) {
    if (!context2.dependencyGraph) {
      throw new Error("Dependency graph not available");
    }
    state.levelQueue = [...context2.dependencyGraph.executionOrder];
    if (context2.debug) {
      logger.info(
        `[WavePlanning] Queued ${state.levelQueue.length} levels for execution (initial wave)`
      );
    }
    state.wave++;
    state.currentWaveCompletions = /* @__PURE__ */ new Set();
    state.failedChecks = /* @__PURE__ */ new Set();
    try {
      state.flags = state.flags || {};
      state.flags.waveKind = "initial";
    } catch {
    }
  }
  if (state.levelQueue.length > 0) {
    transition("LevelDispatch");
  } else {
    if (state.eventQueue.length > 0) {
      if (context2.debug) {
        logger.warn(
          `[WavePlanning] Event queue not empty (${state.eventQueue.length} events) but no work scheduled`
        );
      }
    }
    if (context2.debug) {
      logger.info("[WavePlanning] All waves complete");
    }
    transition("Completed");
  }
}
function findTransitiveDependencies(target, context2) {
  const dependencies = /* @__PURE__ */ new Set();
  const checks = context2.config.checks || {};
  const visited = /* @__PURE__ */ new Set();
  const dfs = (checkId) => {
    if (visited.has(checkId)) return;
    visited.add(checkId);
    const checkConfig = checks[checkId];
    if (!checkConfig) return;
    const deps = checkConfig.depends_on || [];
    const depList = Array.isArray(deps) ? deps : [deps];
    for (const depId of depList) {
      if (typeof depId !== "string") continue;
      if (depId.includes("|")) {
        const orOptions = depId.split("|").map((s) => s.trim()).filter(Boolean);
        for (const opt of orOptions) {
          if (checks[opt]) {
            const optCfg = checks[opt];
            if (String(optCfg?.type || "").toLowerCase() === "memory" && String(optCfg?.operation || "").toLowerCase() === "set") {
              continue;
            }
            dependencies.add(opt);
            dfs(opt);
          }
        }
      } else {
        if (checks[depId]) {
          const dCfg = checks[depId];
          if (String(dCfg?.type || "").toLowerCase() === "memory" && String(dCfg?.operation || "").toLowerCase() === "set") {
            continue;
          }
          dependencies.add(depId);
          dfs(depId);
        }
      }
    }
  };
  dfs(target);
  return dependencies;
}
function findTransitiveDependents(target, context2, gotoEvent) {
  const dependents = /* @__PURE__ */ new Set();
  const checks = context2.config.checks || {};
  if (context2.debug) {
    logger.info(
      `[WavePlanning] findTransitiveDependents called for target=${target}, gotoEvent=${gotoEvent}`
    );
  }
  const dependsOn = (checkId, depId) => {
    const visited = /* @__PURE__ */ new Set();
    const dfs = (current) => {
      if (visited.has(current)) return false;
      visited.add(current);
      const checkConfig = checks[current];
      if (!checkConfig) return false;
      const deps = checkConfig.depends_on || [];
      const depList = Array.isArray(deps) ? deps : [deps];
      for (const dep of depList) {
        if (typeof dep !== "string") continue;
        if (dep.includes("|")) {
          const orOptions = dep.split("|").map((s) => s.trim());
          if (orOptions.includes(depId)) return true;
        } else {
          if (dep === depId) return true;
        }
      }
      for (const d of depList) {
        if (dfs(d)) return true;
      }
      return false;
    };
    return dfs(checkId);
  };
  for (const checkId of Object.keys(checks)) {
    if (checkId === target) continue;
    const checkConfig = checks[checkId];
    if (!checkConfig) continue;
    const isDep = dependsOn(checkId, target);
    if (context2.debug && isDep) {
      logger.info(`[WavePlanning] findTransitiveDependents: ${checkId} depends on ${target}`);
    }
    if (!isDep) continue;
    if (gotoEvent) {
      const triggers = checkConfig.on;
      if (Array.isArray(triggers) && triggers.length > 0) {
        if (!triggers.includes(gotoEvent)) {
          if (context2.debug) {
            logger.info(`[WavePlanning] Skipping ${checkId}: doesn't run for event ${gotoEvent}`);
          }
          continue;
        }
      }
    }
    dependents.add(checkId);
    if (context2.debug) {
      logger.info(`[WavePlanning] Added dependent: ${checkId}`);
    }
  }
  return dependents;
}
var init_wave_planning = __esm({
  "src/state-machine/states/wave-planning.ts"() {
    "use strict";
    init_logger();
    init_dependency_resolver();
  }
});

// src/telemetry/metrics.ts
var metrics_exports = {};
__export(metrics_exports, {
  addDiagramBlock: () => addDiagramBlock,
  addFailIfTriggered: () => addFailIfTriggered,
  addIssues: () => addIssues,
  decActiveCheck: () => decActiveCheck,
  getTestMetricsSnapshot: () => getTestMetricsSnapshot,
  incActiveCheck: () => incActiveCheck,
  recordCheckDuration: () => recordCheckDuration,
  recordForEachDuration: () => recordForEachDuration,
  recordProviderDuration: () => recordProviderDuration,
  resetTestMetricsSnapshot: () => resetTestMetricsSnapshot
});
function ensureInstruments() {
  if (initialized) return;
  try {
    checkDurationHist = meter.createHistogram("visor.check.duration_ms", {
      description: "Duration of a check execution in milliseconds",
      unit: "ms"
    });
    providerDurationHist = meter.createHistogram("visor.provider.duration_ms", {
      description: "Duration of provider execution in milliseconds",
      unit: "ms"
    });
    foreachDurationHist = meter.createHistogram("visor.foreach.item.duration_ms", {
      description: "Duration of a forEach item execution in milliseconds",
      unit: "ms"
    });
    issuesCounter = meter.createCounter("visor.check.issues", {
      description: "Number of issues produced by checks",
      unit: "1"
    });
    activeChecks = meter.createUpDownCounter("visor.run.active_checks", {
      description: "Number of checks actively running",
      unit: "1"
    });
    failIfCounter = meter.createCounter("visor.fail_if.triggered", {
      description: "Number of times fail_if condition triggered",
      unit: "1"
    });
    diagramBlocks = meter.createCounter("visor.diagram.blocks", {
      description: "Number of Mermaid diagram blocks emitted",
      unit: "1"
    });
    initialized = true;
  } catch {
  }
}
function recordCheckDuration(check, durationMs, group) {
  ensureInstruments();
  try {
    checkDurationHist?.record(durationMs, {
      "visor.check.id": check,
      "visor.check.group": group || "default"
    });
  } catch {
  }
}
function recordProviderDuration(check, providerType, durationMs) {
  ensureInstruments();
  try {
    providerDurationHist?.record(durationMs, {
      "visor.check.id": check,
      "visor.provider.type": providerType
    });
  } catch {
  }
}
function recordForEachDuration(check, index, total, durationMs) {
  ensureInstruments();
  try {
    foreachDurationHist?.record(durationMs, {
      "visor.check.id": check,
      "visor.foreach.index": index,
      "visor.foreach.total": total
    });
  } catch {
  }
}
function addIssues(check, severity, count = 1) {
  ensureInstruments();
  try {
    issuesCounter?.add(count, {
      "visor.check.id": check,
      severity
    });
  } catch {
  }
}
function incActiveCheck(check) {
  ensureInstruments();
  try {
    activeChecks?.add(1, { "visor.check.id": check });
  } catch {
  }
}
function decActiveCheck(check) {
  ensureInstruments();
  try {
    activeChecks?.add(-1, { "visor.check.id": check });
  } catch {
  }
}
function addFailIfTriggered(check, scope) {
  ensureInstruments();
  try {
    failIfCounter?.add(1, { "visor.check.id": check, scope });
  } catch {
  }
  if (TEST_ENABLED) TEST_SNAPSHOT.fail_if_triggered++;
}
function addDiagramBlock(origin) {
  ensureInstruments();
  try {
    diagramBlocks?.add(1, { origin });
  } catch {
  }
}
function getTestMetricsSnapshot() {
  return { ...TEST_SNAPSHOT };
}
function resetTestMetricsSnapshot() {
  Object.keys(TEST_SNAPSHOT).forEach((k) => TEST_SNAPSHOT[k] = 0);
}
var initialized, meter, TEST_ENABLED, TEST_SNAPSHOT, checkDurationHist, providerDurationHist, foreachDurationHist, issuesCounter, activeChecks, failIfCounter, diagramBlocks;
var init_metrics = __esm({
  "src/telemetry/metrics.ts"() {
    "use strict";
    init_lazy_otel();
    initialized = false;
    meter = metrics.getMeter("visor");
    TEST_ENABLED = process.env.VISOR_TEST_METRICS === "true";
    TEST_SNAPSHOT = { fail_if_triggered: 0 };
  }
});

// src/utils/sandbox.ts
function validateJsSyntax(code) {
  if (!code || typeof code !== "string") {
    return { valid: false, error: "Code must be a non-empty string" };
  }
  const trimmed = code.trim();
  if (trimmed.length === 0) {
    return { valid: false, error: "Code cannot be empty" };
  }
  const sandbox = createSecureSandbox();
  const looksLikeBlock = /\breturn\b/.test(trimmed) || /;/.test(trimmed) || /\n/.test(trimmed);
  const looksLikeIife = /\)\s*\(\s*\)\s*;?$/.test(trimmed);
  const body = looksLikeBlock ? looksLikeIife ? `return (
${trimmed}
);
` : `return (() => {
${trimmed}
})();
` : `return (
${trimmed}
);
`;
  const header = `const __lp = "[syntax-check]"; const log = (...a) => { try { console.log(__lp, ...a); } catch {} };
`;
  const fullCode = `${header}${body}`;
  try {
    sandbox.compile(fullCode);
    return { valid: true };
  } catch (e) {
    const msg = e instanceof Error ? e.message : String(e);
    return { valid: false, error: msg };
  }
}
function createSecureSandbox() {
  const globals = {
    ...import_sandboxjs.default.SAFE_GLOBALS,
    Math,
    JSON,
    // Provide console with limited surface. Use trampolines so that any test
    // spies (e.g., jest.spyOn(console, 'log')) see calls made inside the sandbox.
    console: {
      log: (...args) => {
        try {
          console.log(...args);
        } catch {
        }
      },
      warn: (...args) => {
        try {
          console.warn(...args);
        } catch {
        }
      },
      error: (...args) => {
        try {
          console.error(...args);
        } catch {
        }
      }
    }
  };
  const prototypeWhitelist = new Map(import_sandboxjs.default.SAFE_PROTOTYPES);
  const arrayMethods = /* @__PURE__ */ new Set([
    // Query/iteration
    "some",
    "every",
    "filter",
    "map",
    "reduce",
    "reduceRight",
    "find",
    "findIndex",
    "findLast",
    "findLastIndex",
    "includes",
    "indexOf",
    "lastIndexOf",
    "keys",
    "values",
    "entries",
    "forEach",
    // Nonmutating ES2023 additions
    "toReversed",
    "toSorted",
    "toSpliced",
    "with",
    "at",
    // Mutators and common ops
    "slice",
    "concat",
    "join",
    "push",
    "pop",
    "shift",
    "unshift",
    "sort",
    "reverse",
    "copyWithin",
    "fill",
    // Flattening
    "flat",
    "flatMap",
    // Meta
    "length"
  ]);
  prototypeWhitelist.set(Array.prototype, arrayMethods);
  const stringMethods = /* @__PURE__ */ new Set([
    "toLowerCase",
    "toUpperCase",
    "includes",
    "indexOf",
    "lastIndexOf",
    "startsWith",
    "endsWith",
    "slice",
    "substring",
    "substr",
    "trim",
    "trimStart",
    "trimEnd",
    "split",
    "replace",
    "replaceAll",
    "match",
    "matchAll",
    "charAt",
    "charCodeAt",
    "codePointAt",
    "normalize",
    "repeat",
    "padStart",
    "padEnd",
    "at",
    "length"
  ]);
  prototypeWhitelist.set(String.prototype, stringMethods);
  const objectMethods = /* @__PURE__ */ new Set([
    "hasOwnProperty",
    "propertyIsEnumerable",
    "toString",
    "valueOf"
  ]);
  prototypeWhitelist.set(Object.prototype, objectMethods);
  const mapMethods = /* @__PURE__ */ new Set([
    "get",
    "set",
    "has",
    "delete",
    "entries",
    "keys",
    "values",
    "forEach"
  ]);
  prototypeWhitelist.set(Map.prototype, mapMethods);
  const setMethods = /* @__PURE__ */ new Set([
    "add",
    "has",
    "delete",
    "entries",
    "keys",
    "values",
    "forEach"
  ]);
  prototypeWhitelist.set(Set.prototype, setMethods);
  const dateMethods = /* @__PURE__ */ new Set(["toISOString", "toJSON", "getTime"]);
  prototypeWhitelist.set(Date.prototype, dateMethods);
  const regexpMethods = /* @__PURE__ */ new Set(["test", "exec"]);
  prototypeWhitelist.set(RegExp.prototype, regexpMethods);
  return new import_sandboxjs.default({ globals, prototypeWhitelist });
}
function compileAndRun(sandbox, userCode, scope, opts = { injectLog: true, wrapFunction: true, logPrefix: "[sandbox]" }) {
  const inject = opts?.injectLog === true;
  let safePrefix = String(opts?.logPrefix ?? "[sandbox]");
  safePrefix = safePrefix.replace(/[\r\n\t\0]/g, "").replace(/[`$\\]/g, "").replace(/\$\{/g, "").slice(0, 64);
  const header = inject ? `const __lp = ${JSON.stringify(safePrefix)}; const log = (...a) => { try { console.log(__lp, ...a); } catch {} };
` : "";
  const src = String(userCode);
  const looksLikeBlock = /\breturn\b/.test(src) || /;/.test(src) || /\n/.test(src);
  const looksLikeIife = /\)\s*\(\s*\)\s*;?$/.test(src.trim());
  const body = opts.wrapFunction ? looksLikeBlock ? looksLikeIife ? `return (
${src}
);
` : `return (() => {
${src}
})();
` : `return (
${src}
);
` : `${src}`;
  const code = `${header}${body}`;
  let exec2;
  try {
    exec2 = sandbox.compile(code);
  } catch (e) {
    const msg = e instanceof Error ? e.message : String(e);
    throw new Error(`sandbox_compile_error: ${msg}`);
  }
  let out;
  try {
    out = exec2(scope);
  } catch (e) {
    const msg = e instanceof Error ? e.message : String(e);
    throw new Error(`sandbox_execution_error: ${msg}`);
  }
  if (out && typeof out.run === "function") {
    try {
      return out.run();
    } catch (e) {
      const msg = e instanceof Error ? e.message : String(e);
      throw new Error(`sandbox_runner_error: ${msg}`);
    }
  }
  return out;
}
var import_sandboxjs;
var init_sandbox = __esm({
  "src/utils/sandbox.ts"() {
    "use strict";
    import_sandboxjs = __toESM(require("@nyariv/sandboxjs"));
  }
});

// src/utils/author-permissions.ts
function getPermissionLevel(association) {
  if (!association) return PERMISSION_HIERARCHY.length;
  const index = PERMISSION_HIERARCHY.indexOf(association.toUpperCase());
  return index === -1 ? PERMISSION_HIERARCHY.length : index;
}
function hasMinPermission(authorAssociation, minPermission, isLocalMode = false) {
  if (isLocalMode) {
    return true;
  }
  const authorLevel = getPermissionLevel(authorAssociation);
  const minLevel = getPermissionLevel(minPermission);
  return authorLevel <= minLevel;
}
function isOwner(authorAssociation, isLocalMode = false) {
  if (isLocalMode) return true;
  return authorAssociation?.toUpperCase() === "OWNER";
}
function isMember(authorAssociation, isLocalMode = false) {
  if (isLocalMode) return true;
  return hasMinPermission(authorAssociation, "MEMBER", isLocalMode);
}
function isCollaborator(authorAssociation, isLocalMode = false) {
  if (isLocalMode) return true;
  return hasMinPermission(authorAssociation, "COLLABORATOR", isLocalMode);
}
function isContributor(authorAssociation, isLocalMode = false) {
  if (isLocalMode) return true;
  return hasMinPermission(authorAssociation, "CONTRIBUTOR", isLocalMode);
}
function isFirstTimer(authorAssociation, isLocalMode = false) {
  if (isLocalMode) return false;
  const assoc = authorAssociation?.toUpperCase();
  return assoc === "FIRST_TIME_CONTRIBUTOR" || assoc === "FIRST_TIMER";
}
function createPermissionHelpers(authorAssociation, isLocalMode = false) {
  return {
    hasMinPermission: (minPermission) => hasMinPermission(authorAssociation, minPermission, isLocalMode),
    isOwner: () => isOwner(authorAssociation, isLocalMode),
    isMember: () => isMember(authorAssociation, isLocalMode),
    isCollaborator: () => isCollaborator(authorAssociation, isLocalMode),
    isContributor: () => isContributor(authorAssociation, isLocalMode),
    isFirstTimer: () => isFirstTimer(authorAssociation, isLocalMode)
  };
}
function detectLocalMode() {
  return !process.env.GITHUB_ACTIONS;
}
function resolveAssociationFromEvent(eventContext, fallback) {
  try {
    const ec = eventContext || {};
    return ec?.comment?.author_association || ec?.issue?.author_association || ec?.pull_request?.author_association || fallback;
  } catch {
    return fallback;
  }
}
var PERMISSION_HIERARCHY;
var init_author_permissions = __esm({
  "src/utils/author-permissions.ts"() {
    "use strict";
    PERMISSION_HIERARCHY = [
      "OWNER",
      "MEMBER",
      "COLLABORATOR",
      "CONTRIBUTOR",
      "FIRST_TIME_CONTRIBUTOR",
      "FIRST_TIMER",
      "NONE"
    ];
  }
});

// src/memory-store.ts
var memory_store_exports = {};
__export(memory_store_exports, {
  MemoryStore: () => MemoryStore
});
var import_promises, import_path, MemoryStore;
var init_memory_store = __esm({
  "src/memory-store.ts"() {
    "use strict";
    import_promises = __toESM(require("fs/promises"));
    import_path = __toESM(require("path"));
    init_logger();
    MemoryStore = class _MemoryStore {
      static instance;
      data;
      // namespace -> key -> value
      config;
      initialized = false;
      constructor(config) {
        this.data = /* @__PURE__ */ new Map();
        this.config = this.normalizeConfig(config);
      }
      /**
       * Get singleton instance
       */
      static getInstance(config) {
        if (!_MemoryStore.instance) {
          _MemoryStore.instance = new _MemoryStore(config);
        } else if (config && !_MemoryStore.instance.initialized) {
          _MemoryStore.instance.config = _MemoryStore.instance.normalizeConfig(config);
        }
        return _MemoryStore.instance;
      }
      /**
       * Create a new isolated MemoryStore instance that does not affect the
       * process-wide singleton. Useful for nested workflows or tests where
       * state must not leak between runs.
       */
      static createIsolated(config) {
        return new _MemoryStore(config);
      }
      /**
       * Reset singleton instance (for testing)
       */
      static resetInstance() {
        _MemoryStore.instance = void 0;
      }
      /**
       * Initialize memory store (load from file if configured)
       */
      async initialize() {
        if (this.initialized) {
          return;
        }
        if (this.config.storage === "file" && this.config.auto_load && this.config.file) {
          try {
            await this.load();
            logger.debug(`Memory store loaded from ${this.config.file}`);
          } catch (error) {
            if (error.code !== "ENOENT") {
              logger.warn(
                `Failed to load memory store from ${this.config.file}: ${error instanceof Error ? error.message : "Unknown error"}`
              );
            }
          }
        }
        this.initialized = true;
      }
      /**
       * Normalize and apply defaults to config
       */
      normalizeConfig(config) {
        const storage = config?.storage || "memory";
        return {
          storage,
          format: config?.format || "json",
          file: config?.file,
          namespace: config?.namespace || "default",
          auto_load: config?.auto_load !== false,
          auto_save: config?.auto_save !== false
        };
      }
      /**
       * Get the default namespace
       */
      getDefaultNamespace() {
        return this.config.namespace || "default";
      }
      /**
       * Get a value from memory
       */
      get(key, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const nsData = this.data.get(ns);
        return nsData?.get(key);
      }
      /**
       * Check if a key exists in memory
       */
      has(key, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const nsData = this.data.get(ns);
        return nsData?.has(key) || false;
      }
      /**
       * Set a value in memory (override existing)
       */
      async set(key, value, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        if (!this.data.has(ns)) {
          this.data.set(ns, /* @__PURE__ */ new Map());
        }
        const nsData = this.data.get(ns);
        nsData.set(key, value);
        try {
          if (process.env.VISOR_DEBUG === "true" || process.env.JEST_WORKER_ID !== void 0) {
            if (ns === "fact-validation" && (key === "total_validations" || key === "all_valid")) {
              console.log("[MemoryStore] SET " + ns + "." + key + " = " + JSON.stringify(value));
            }
          }
        } catch {
        }
        try {
          if (process.env.VISOR_DEBUG === "true" || process.env.JEST_WORKER_ID !== void 0) {
            if (ns === "fact-validation" && (key === "total_validations" || key === "all_valid")) {
              console.log();
            }
          }
        } catch {
        }
        if (this.config.storage === "file" && this.config.auto_save) {
          await this.save();
        }
      }
      /**
       * Append a value to an array in memory
       * If key doesn't exist, creates a new array
       * If key exists but is not an array, converts it to an array
       */
      async append(key, value, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const existing = this.get(key, ns);
        let newValue;
        if (existing === void 0) {
          newValue = [value];
        } else if (Array.isArray(existing)) {
          newValue = [...existing, value];
        } else {
          newValue = [existing, value];
        }
        await this.set(key, newValue, ns);
      }
      /**
       * Increment a numeric value in memory
       * If key doesn't exist, initializes to 0 before incrementing
       * If key exists but is not a number, throws an error
       */
      async increment(key, amount = 1, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const existing = this.get(key, ns);
        let newValue;
        if (existing === void 0 || existing === null) {
          newValue = amount;
        } else if (typeof existing === "number") {
          newValue = existing + amount;
        } else {
          throw new Error(
            `Cannot increment non-numeric value at key '${key}' (type: ${typeof existing})`
          );
        }
        await this.set(key, newValue, ns);
        return newValue;
      }
      /**
       * Delete a key from memory
       */
      async delete(key, namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const nsData = this.data.get(ns);
        if (!nsData) {
          return false;
        }
        const deleted = nsData.delete(key);
        if (deleted && this.config.storage === "file" && this.config.auto_save) {
          await this.save();
        }
        return deleted;
      }
      /**
       * Clear all keys in a namespace (or all namespaces if none specified)
       */
      async clear(namespace) {
        if (namespace) {
          this.data.delete(namespace);
        } else {
          this.data.clear();
        }
        if (this.config.storage === "file" && this.config.auto_save) {
          await this.save();
        }
      }
      /**
       * List all keys in a namespace
       */
      list(namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const nsData = this.data.get(ns);
        return nsData ? Array.from(nsData.keys()) : [];
      }
      /**
       * List all namespaces
       */
      listNamespaces() {
        return Array.from(this.data.keys());
      }
      /**
       * Get all data in a namespace
       */
      getAll(namespace) {
        const ns = namespace || this.getDefaultNamespace();
        const nsData = this.data.get(ns);
        if (!nsData) {
          return {};
        }
        const result = {};
        for (const [key, value] of nsData.entries()) {
          result[key] = value;
        }
        return result;
      }
      /**
       * Load data from file
       */
      async load() {
        if (!this.config.file) {
          throw new Error("No file path configured for memory store");
        }
        const filePath = import_path.default.resolve(process.cwd(), this.config.file);
        const content = await import_promises.default.readFile(filePath, "utf-8");
        if (this.config.format === "json") {
          await this.loadFromJson(content);
        } else if (this.config.format === "csv") {
          await this.loadFromCsv(content);
        } else {
          throw new Error(`Unsupported format: ${this.config.format}`);
        }
      }
      /**
       * Save data to file
       */
      async save() {
        if (!this.config.file) {
          throw new Error("No file path configured for memory store");
        }
        const filePath = import_path.default.resolve(process.cwd(), this.config.file);
        const dir = import_path.default.dirname(filePath);
        await import_promises.default.mkdir(dir, { recursive: true });
        let content;
        if (this.config.format === "json") {
          content = this.saveToJson();
        } else if (this.config.format === "csv") {
          content = this.saveToCsv();
        } else {
          throw new Error(`Unsupported format: ${this.config.format}`);
        }
        await import_promises.default.writeFile(filePath, content, "utf-8");
      }
      /**
       * Load data from JSON format
       */
      async loadFromJson(content) {
        const data = JSON.parse(content);
        this.data.clear();
        for (const [namespace, nsData] of Object.entries(data)) {
          if (typeof nsData === "object" && nsData !== null && !Array.isArray(nsData)) {
            const nsMap = /* @__PURE__ */ new Map();
            for (const [key, value] of Object.entries(nsData)) {
              nsMap.set(key, value);
            }
            this.data.set(namespace, nsMap);
          }
        }
      }
      /**
       * Save data to JSON format
       */
      saveToJson() {
        const result = {};
        for (const [namespace, nsData] of this.data.entries()) {
          const nsObj = {};
          for (const [key, value] of nsData.entries()) {
            nsObj[key] = value;
          }
          result[namespace] = nsObj;
        }
        return JSON.stringify(result, null, 2);
      }
      /**
       * Load data from CSV format
       * CSV format: namespace,key,value,type
       */
      async loadFromCsv(content) {
        const lines = content.split("\n").filter((line) => line.trim());
        let startIndex = 0;
        if (lines[0]?.startsWith("namespace,")) {
          startIndex = 1;
        }
        this.data.clear();
        const arrays = /* @__PURE__ */ new Map();
        for (let i = startIndex; i < lines.length; i++) {
          const line = lines[i];
          const parts = this.parseCsvLine(line);
          if (parts.length < 3) {
            logger.warn(`Invalid CSV line ${i + 1}: ${line}`);
            continue;
          }
          const [namespace, key, valueStr, typeStr] = parts;
          const value = this.parseCsvValue(valueStr, typeStr);
          if (!this.data.has(namespace)) {
            this.data.set(namespace, /* @__PURE__ */ new Map());
            arrays.set(namespace, /* @__PURE__ */ new Map());
          }
          const nsData = this.data.get(namespace);
          const nsArrays = arrays.get(namespace);
          if (nsData.has(key)) {
            if (!nsArrays.has(key)) {
              const existingValue = nsData.get(key);
              nsArrays.set(key, [existingValue]);
            }
            nsArrays.get(key).push(value);
            nsData.set(key, nsArrays.get(key));
          } else {
            nsData.set(key, value);
          }
        }
      }
      /**
       * Save data to CSV format
       */
      saveToCsv() {
        const lines = ["namespace,key,value,type"];
        for (const [namespace, nsData] of this.data.entries()) {
          for (const [key, value] of nsData.entries()) {
            if (Array.isArray(value)) {
              for (const item of value) {
                lines.push(this.formatCsvLine(namespace, key, item));
              }
            } else {
              lines.push(this.formatCsvLine(namespace, key, value));
            }
          }
        }
        return lines.join("\n") + "\n";
      }
      /**
       * Parse a CSV line, handling quoted values with commas
       */
      parseCsvLine(line) {
        const parts = [];
        let current = "";
        let inQuotes = false;
        for (let i = 0; i < line.length; i++) {
          const char = line[i];
          if (char === '"') {
            if (inQuotes && line[i + 1] === '"') {
              current += '"';
              i++;
            } else {
              inQuotes = !inQuotes;
            }
          } else if (char === "," && !inQuotes) {
            parts.push(current);
            current = "";
          } else {
            current += char;
          }
        }
        parts.push(current);
        return parts;
      }
      /**
       * Format a CSV line with proper escaping
       */
      formatCsvLine(namespace, key, value) {
        const type = this.getValueType(value);
        const valueStr = this.formatCsvValue(value);
        return `${this.escapeCsv(namespace)},${this.escapeCsv(key)},${valueStr},${type}`;
      }
      /**
       * Escape a CSV value
       */
      escapeCsv(value) {
        if (value.includes(",") || value.includes('"') || value.includes("\n")) {
          return `"${value.replace(/"/g, '""')}"`;
        }
        return value;
      }
      /**
       * Format a value for CSV storage
       */
      formatCsvValue(value) {
        if (value === null) {
          return '""';
        }
        if (value === void 0) {
          return '""';
        }
        if (typeof value === "string") {
          return this.escapeCsv(value);
        }
        if (typeof value === "number" || typeof value === "boolean") {
          return this.escapeCsv(String(value));
        }
        return this.escapeCsv(JSON.stringify(value));
      }
      /**
       * Parse a CSV value based on its type
       */
      parseCsvValue(valueStr, typeStr) {
        if (!typeStr || typeStr === "string") {
          return valueStr;
        }
        if (typeStr === "number") {
          return Number(valueStr);
        }
        if (typeStr === "boolean") {
          return valueStr === "true";
        }
        if (typeStr === "object" || typeStr === "array") {
          try {
            return JSON.parse(valueStr);
          } catch {
            return valueStr;
          }
        }
        return valueStr;
      }
      /**
       * Get the type of a value for CSV storage
       */
      getValueType(value) {
        if (value === null || value === void 0) {
          return "string";
        }
        if (typeof value === "number") {
          return "number";
        }
        if (typeof value === "boolean") {
          return "boolean";
        }
        if (Array.isArray(value)) {
          return "array";
        }
        if (typeof value === "object") {
          return "object";
        }
        return "string";
      }
      /**
       * Get the current configuration
       */
      getConfig() {
        return { ...this.config };
      }
    };
  }
});

// src/failure-condition-evaluator.ts
var failure_condition_evaluator_exports = {};
__export(failure_condition_evaluator_exports, {
  FailureConditionEvaluator: () => FailureConditionEvaluator
});
var FailureConditionEvaluator;
var init_failure_condition_evaluator = __esm({
  "src/failure-condition-evaluator.ts"() {
    "use strict";
    init_trace_helpers();
    init_metrics();
    init_sandbox();
    init_author_permissions();
    init_memory_store();
    FailureConditionEvaluator = class _FailureConditionEvaluator {
      sandbox;
      constructor() {
      }
      /**
       * Create a secure sandbox with whitelisted functions and globals
       */
      createSecureSandbox() {
        return createSecureSandbox();
      }
      /**
       * Evaluate simple fail_if condition
       */
      async evaluateSimpleCondition(checkName, checkSchema, checkGroup, reviewSummary, expression, previousOutputs, authorAssociation) {
        const context2 = this.buildEvaluationContext(
          checkName,
          checkSchema,
          checkGroup,
          reviewSummary,
          previousOutputs,
          authorAssociation
        );
        try {
          try {
            const isObj = context2.output && typeof context2.output === "object";
            const keys = isObj ? Object.keys(context2.output).join(",") : typeof context2.output;
            let errorVal = void 0;
            if (isObj && context2.output.error !== void 0)
              errorVal = context2.output.error;
            (init_logger(), __toCommonJS(logger_exports)).logger.debug(
              `  fail_if: evaluating '${expression}' with output keys=${keys} error=${String(errorVal)}`
            );
          } catch {
          }
          const res = this.evaluateExpression(expression, context2);
          if (res === true) {
            try {
              addEvent("fail_if.triggered", {
                check: checkName,
                scope: "check",
                name: `${checkName}_fail_if`,
                expression,
                severity: "error"
              });
            } catch {
            }
            try {
              const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
              emitNdjsonSpanWithEvents2(
                "visor.fail_if",
                { check: checkName, scope: "check", name: `${checkName}_fail_if` },
                [
                  {
                    name: "fail_if.triggered",
                    attrs: {
                      check: checkName,
                      scope: "check",
                      name: `${checkName}_fail_if`,
                      expression,
                      severity: "error"
                    }
                  }
                ]
              );
            } catch {
            }
          }
          return res;
        } catch (error) {
          console.warn(`Failed to evaluate fail_if expression: ${error}`);
          return false;
        }
      }
      /**
       * Determine if the event is related to pull requests
       */
      determineIfPullRequest(eventType) {
        if (!eventType) return false;
        const prEvents = ["pr_opened", "pr_updated", "pr_closed", "pull_request"];
        return prEvents.includes(eventType) || eventType.startsWith("pr_");
      }
      /**
       * Determine if the event is related to issues
       */
      determineIfIssue(eventType) {
        if (!eventType) return false;
        const issueEvents = ["issue_opened", "issue_comment", "issues"];
        return issueEvents.includes(eventType) || eventType.startsWith("issue_");
      }
      /**
       * Evaluate if condition to determine whether a check should run
       */
      async evaluateIfCondition(checkName, expression, contextData) {
        const context2 = {
          // Check metadata
          checkName,
          // Git context
          branch: contextData?.branch || "unknown",
          baseBranch: contextData?.baseBranch || "main",
          filesChanged: contextData?.filesChanged || [],
          filesCount: contextData?.filesChanged?.length || 0,
          // GitHub event context
          event: {
            event_name: contextData?.event || "manual",
            action: void 0,
            // Would be populated from actual GitHub context
            repository: void 0
            // Would be populated from actual GitHub context
          },
          // Environment variables
          env: contextData?.environment || {},
          // Previous check results (unwrap output field like templates do)
          outputs: contextData?.previousResults ? (() => {
            const outputs = {};
            for (const [checkName2, result] of contextData.previousResults) {
              const summary = result;
              outputs[checkName2] = summary.output !== void 0 ? summary.output : summary;
            }
            return outputs;
          })() : {},
          // Workflow inputs (for workflows)
          inputs: contextData?.workflowInputs || {},
          // Output property: use provided output for guarantee evaluation, or empty for if conditions
          output: contextData?.output !== void 0 && contextData.output !== null && typeof contextData.output === "object" ? contextData.output : { issues: [] },
          // Author association (used by permission helpers)
          authorAssociation: contextData?.authorAssociation,
          // Utility metadata
          metadata: {
            checkName,
            schema: "",
            group: "",
            criticalIssues: 0,
            errorIssues: 0,
            warningIssues: 0,
            infoIssues: 0,
            totalIssues: 0,
            hasChanges: (contextData?.filesChanged?.length || 0) > 0,
            branch: contextData?.branch || "unknown",
            event: contextData?.event || "manual"
          }
        };
        try {
          const res = this.evaluateExpression(expression, context2);
          try {
            if (process.env.VISOR_DEBUG === "true") {
              const outputKeys = Object.keys(context2.outputs || {});
              console.error(
                `[if-eval] check=${checkName} expr="${expression}" result=${String(res)} outputKeys=[${outputKeys.join(",")}]`
              );
            }
          } catch {
          }
          return res;
        } catch (error) {
          console.warn(`Failed to evaluate if expression for check '${checkName}': ${error}`);
          return false;
        }
      }
      /**
       * Evaluate all failure conditions for a check result
       */
      async evaluateConditions(checkName, checkSchema, checkGroup, reviewSummary, globalConditions, checkConditions, previousOutputs, authorAssociation) {
        const context2 = this.buildEvaluationContext(
          checkName,
          checkSchema,
          checkGroup,
          reviewSummary,
          previousOutputs,
          authorAssociation
        );
        const results = [];
        if (globalConditions) {
          const globalResults = await this.evaluateConditionSet(globalConditions, context2, "global");
          results.push(...globalResults);
        }
        if (checkConditions) {
          const checkResults = await this.evaluateConditionSet(checkConditions, context2, "check");
          const overriddenConditions = new Set(Object.keys(checkConditions));
          const filteredResults = results.filter(
            (result) => !overriddenConditions.has(result.conditionName)
          );
          results.length = 0;
          results.push(...filteredResults, ...checkResults);
        }
        return results;
      }
      /**
       * Evaluate a set of failure conditions
       */
      async evaluateConditionSet(conditions, context2, source) {
        const results = [];
        for (const [conditionName, condition] of Object.entries(conditions)) {
          try {
            addEvent("fail_if.evaluated", {
              check: context2.checkName,
              scope: source,
              name: conditionName,
              expression: this.extractExpression(condition)
            });
          } catch {
          }
          try {
            const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
            emitNdjsonSpanWithEvents2(
              "visor.fail_if",
              { check: context2.checkName || "unknown", scope: source, name: conditionName },
              [
                {
                  name: "fail_if.evaluated",
                  attrs: {
                    check: context2.checkName,
                    scope: source,
                    name: conditionName,
                    expression: this.extractExpression(condition)
                  }
                }
              ]
            );
          } catch {
          }
          try {
            const result = await this.evaluateSingleCondition(conditionName, condition, context2);
            results.push(result);
            if (result.failed) {
              try {
                addEvent("fail_if.triggered", {
                  check: context2.checkName,
                  scope: source,
                  name: conditionName,
                  expression: result.expression,
                  severity: result.severity,
                  halt_execution: result.haltExecution
                });
              } catch {
              }
              try {
                addFailIfTriggered(context2.checkName || "unknown", source);
              } catch {
              }
            }
          } catch (error) {
            results.push({
              conditionName,
              failed: false,
              expression: this.extractExpression(condition),
              severity: "error",
              haltExecution: false,
              error: `Failed to evaluate ${source} condition '${conditionName}': ${error instanceof Error ? error.message : String(error)}`
            });
          }
        }
        return results;
      }
      /**
       * Evaluate a single failure condition
       */
      async evaluateSingleCondition(conditionName, condition, context2) {
        const expression = this.extractExpression(condition);
        const config = this.extractConditionConfig(condition);
        try {
          const failed = this.evaluateExpression(expression, context2);
          return {
            conditionName,
            failed,
            expression,
            message: config.message,
            severity: config.severity || "error",
            haltExecution: config.halt_execution || false
          };
        } catch (error) {
          throw new Error(
            `Expression evaluation error: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Secure expression evaluation using SandboxJS
       * Supports the same GitHub Actions-style functions as the previous implementation
       */
      evaluateExpression(condition, context2) {
        try {
          const normalize3 = (expr) => {
            const trimmed = expr.trim();
            if (!/[\n;]/.test(trimmed)) return trimmed;
            const parts = trimmed.split(/[\n;]+/).map((s) => s.trim()).filter((s) => s.length > 0 && !s.startsWith("//"));
            if (parts.length === 0) return "true";
            const lastRaw = parts.pop();
            const last = lastRaw.replace(/^return\s+/i, "").trim();
            if (parts.length === 0) return last;
            return `(${parts.join(", ")}, ${last})`;
          };
          const contains = (searchString, searchValue) => String(searchString).toLowerCase().includes(String(searchValue).toLowerCase());
          const startsWith = (searchString, searchValue) => String(searchString).toLowerCase().startsWith(String(searchValue).toLowerCase());
          const endsWith = (searchString, searchValue) => String(searchString).toLowerCase().endsWith(String(searchValue).toLowerCase());
          const length = (value) => {
            if (typeof value === "string" || Array.isArray(value)) {
              return value.length;
            }
            if (value && typeof value === "object") {
              return Object.keys(value).length;
            }
            return 0;
          };
          const always = () => true;
          const success = () => true;
          const failure = () => false;
          const log2 = (...args) => {
            console.log("\u{1F50D} Debug:", ...args);
          };
          const hasIssue = (issues2, field, value) => {
            if (!Array.isArray(issues2)) return false;
            return issues2.some((issue) => issue[field] === value);
          };
          const countIssues = (issues2, field, value) => {
            if (!Array.isArray(issues2)) return 0;
            return issues2.filter((issue) => issue[field] === value).length;
          };
          const hasFileMatching = (issues2, pattern) => {
            if (!Array.isArray(issues2)) return false;
            return issues2.some((issue) => issue.file?.includes(pattern));
          };
          const hasIssueWith = hasIssue;
          const hasFileWith = hasFileMatching;
          const permissionHelpers = createPermissionHelpers(
            context2.authorAssociation,
            detectLocalMode()
          );
          const hasMinPermission2 = permissionHelpers.hasMinPermission;
          const isOwner2 = permissionHelpers.isOwner;
          const isMember2 = permissionHelpers.isMember;
          const isCollaborator2 = permissionHelpers.isCollaborator;
          const isContributor2 = permissionHelpers.isContributor;
          const isFirstTimer2 = permissionHelpers.isFirstTimer;
          const output = context2.output || {};
          let issues = output.issues || [];
          if (typeof issues === "string") {
            try {
              issues = JSON.parse(issues);
            } catch {
              issues = [];
            }
          }
          if (!Array.isArray(issues)) {
            issues = [];
          }
          const metadata = context2.metadata || {
            checkName: context2.checkName || "",
            schema: context2.schema || "",
            group: context2.group || "",
            criticalIssues: issues.filter((i) => i.severity === "critical").length,
            errorIssues: issues.filter((i) => i.severity === "error").length,
            warningIssues: issues.filter((i) => i.severity === "warning").length,
            infoIssues: issues.filter((i) => i.severity === "info").length,
            totalIssues: issues.length,
            hasChanges: context2.hasChanges || false
          };
          const criticalIssues = metadata.criticalIssues;
          const errorIssues = metadata.errorIssues;
          const totalIssues = metadata.totalIssues;
          const warningIssues = metadata.warningIssues;
          const infoIssues = metadata.infoIssues;
          const checkName = context2.checkName || "";
          const schema = context2.schema || "";
          const group = context2.group || "";
          const branch = context2.branch || "unknown";
          const baseBranch = context2.baseBranch || "main";
          const filesChanged = context2.filesChanged || [];
          const filesCount = context2.filesCount || 0;
          const event = context2.event || "manual";
          const env = context2.env || {};
          const outputs = context2.outputs || {};
          const inputs = context2.inputs || {};
          const debugData = context2.debug || null;
          const memoryStore = MemoryStore.getInstance();
          const memoryAccessor = {
            get: (key, ns) => memoryStore.get(key, ns),
            has: (key, ns) => memoryStore.has(key, ns),
            list: (ns) => memoryStore.list(ns),
            getAll: (ns) => memoryStore.getAll(ns)
          };
          const scope = {
            // Primary context variables
            output,
            outputs,
            debug: debugData,
            // Memory accessor for fail_if expressions
            memory: memoryAccessor,
            // Legacy compatibility variables
            issues,
            metadata,
            criticalIssues,
            errorIssues,
            totalIssues,
            warningIssues,
            infoIssues,
            // If condition context
            checkName,
            schema,
            group,
            branch,
            baseBranch,
            filesChanged,
            filesCount,
            event,
            env,
            inputs,
            // Helper functions
            contains,
            startsWith,
            endsWith,
            length,
            always,
            success,
            failure,
            log: log2,
            hasIssue,
            countIssues,
            hasFileMatching,
            hasIssueWith,
            hasFileWith,
            // Permission helpers
            hasMinPermission: hasMinPermission2,
            isOwner: isOwner2,
            isMember: isMember2,
            isCollaborator: isCollaborator2,
            isContributor: isContributor2,
            isFirstTimer: isFirstTimer2
          };
          const raw = condition.trim();
          if (!this.sandbox) {
            this.sandbox = this.createSecureSandbox();
          }
          let result;
          try {
            let exec2;
            try {
              exec2 = this.sandbox.compile(`return (${raw});`);
            } catch {
              const normalizedExpr = normalize3(condition);
              exec2 = this.sandbox.compile(`return (${normalizedExpr});`);
            }
            result = exec2(scope).run();
          } catch (_primaryErr) {
            try {
              const vm = require("vm");
              const ctx = {
                // Scope vars
                output,
                outputs,
                debug: debugData,
                memory: memoryAccessor,
                issues,
                metadata,
                criticalIssues,
                errorIssues,
                totalIssues,
                warningIssues,
                infoIssues,
                checkName,
                schema,
                group,
                branch,
                baseBranch,
                filesChanged,
                filesCount,
                event,
                env,
                inputs,
                // Helpers
                contains,
                startsWith,
                endsWith,
                length,
                always,
                success,
                failure,
                log: log2,
                hasIssue,
                countIssues,
                hasFileMatching,
                hasIssueWith,
                hasFileWith,
                hasMinPermission: hasMinPermission2,
                isOwner: isOwner2,
                isMember: isMember2,
                isCollaborator: isCollaborator2,
                isContributor: isContributor2,
                isFirstTimer: isFirstTimer2,
                Math,
                JSON
              };
              const context3 = vm.createContext(ctx);
              let code = `(${raw})`;
              try {
                result = new vm.Script(code).runInContext(context3, { timeout: 50 });
              } catch {
                const normalizedExpr = normalize3(condition);
                code = `(${normalizedExpr})`;
                result = new vm.Script(code).runInContext(context3, { timeout: 50 });
              }
            } catch (vmErr) {
              console.error("\u274C Failed to evaluate expression:", condition, vmErr);
              throw vmErr;
            }
          }
          try {
            (init_logger(), __toCommonJS(logger_exports)).logger.debug(`  fail_if: result=${Boolean(result)}`);
          } catch {
          }
          return Boolean(result);
        } catch (error) {
          console.error("\u274C Failed to evaluate expression:", condition, error);
          throw error;
        }
      }
      /**
       * Extract the expression from a failure condition
       */
      extractExpression(condition) {
        if (typeof condition === "string") {
          return condition;
        }
        return condition.condition;
      }
      /**
       * Extract configuration from a failure condition
       */
      extractConditionConfig(condition) {
        if (typeof condition === "string") {
          return {};
        }
        return {
          message: condition.message,
          severity: condition.severity,
          halt_execution: condition.halt_execution
        };
      }
      /**
       * Build the evaluation context for expressions
       */
      buildEvaluationContext(checkName, checkSchema, checkGroup, reviewSummary, previousOutputs, authorAssociation) {
        const { issues, debug } = reviewSummary;
        const reviewSummaryWithOutput = reviewSummary;
        const {
          output: extractedOutput,
          // Exclude issues from otherFields since we handle it separately
          issues: _issues,
          // eslint-disable-line @typescript-eslint/no-unused-vars
          ...otherFields
        } = reviewSummaryWithOutput;
        const aggregatedOutput = {
          issues: (issues || []).map((issue) => ({
            file: issue.file,
            line: issue.line,
            endLine: issue.endLine,
            ruleId: issue.ruleId,
            message: issue.message,
            severity: issue.severity,
            category: issue.category,
            group: issue.group,
            schema: issue.schema,
            suggestion: issue.suggestion,
            replacement: issue.replacement
          })),
          // Include additional schema-specific data from reviewSummary
          ...otherFields
        };
        if (Array.isArray(extractedOutput)) {
          aggregatedOutput.items = extractedOutput;
          const anyError = extractedOutput.find(
            (it) => it && typeof it === "object" && it.error
          );
          if (anyError && anyError.error !== void 0) {
            aggregatedOutput.error = anyError.error;
          }
        } else if (extractedOutput && typeof extractedOutput === "object") {
          Object.assign(aggregatedOutput, extractedOutput);
        }
        try {
          const raw = reviewSummaryWithOutput.__raw;
          if (raw && typeof raw === "object") {
            Object.assign(aggregatedOutput, raw);
          }
        } catch {
        }
        try {
          if (typeof extractedOutput === "string") {
            const parsed = this.tryExtractJsonFromEnd(extractedOutput) ?? (() => {
              try {
                return JSON.parse(extractedOutput);
              } catch {
                return null;
              }
            })();
            if (parsed !== null) {
              if (Array.isArray(parsed)) {
                aggregatedOutput.items = parsed;
              } else if (typeof parsed === "object") {
                Object.assign(aggregatedOutput, parsed);
              }
            }
            const lower = extractedOutput.toLowerCase();
            const boolFrom = (key) => {
              const reTrue = new RegExp(
                `(?:^|[^a-z0-9_])${key}[^a-z0-9_]*[:=][^a-z0-9_]*true(?:[^a-z0-9_]|$)`
              );
              const reFalse = new RegExp(
                `(?:^|[^a-z0-9_])${key}[^a-z0-9_]*[:=][^a-z0-9_]*false(?:[^a-z0-9_]|$)`
              );
              if (reTrue.test(lower)) return true;
              if (reFalse.test(lower)) return false;
              return null;
            };
            const keys = ["error"];
            for (const k of keys) {
              const v = boolFrom(k);
              if (v !== null && aggregatedOutput[k] === void 0) {
                aggregatedOutput[k] = v;
              }
            }
          }
        } catch {
        }
        try {
          const rsAny = reviewSummaryWithOutput;
          const hasStructuredOutput = extractedOutput !== void 0 && extractedOutput !== null;
          if (!hasStructuredOutput && typeof rsAny?.content === "string") {
            const parsedFromContent = this.tryExtractJsonFromEnd(rsAny.content);
            if (parsedFromContent !== null && parsedFromContent !== void 0) {
              if (Array.isArray(parsedFromContent)) {
                aggregatedOutput.items = parsedFromContent;
              } else if (typeof parsedFromContent === "object") {
                Object.assign(aggregatedOutput, parsedFromContent);
              }
            }
          }
        } catch {
        }
        const memoryStore = MemoryStore.getInstance();
        const context2 = {
          output: aggregatedOutput,
          outputs: (() => {
            if (!previousOutputs) return {};
            const outputs = {};
            for (const [checkName2, result] of Object.entries(previousOutputs)) {
              const summary = result;
              outputs[checkName2] = summary.output !== void 0 ? summary.output : summary;
            }
            return outputs;
          })(),
          // Add memory accessor for fail_if expressions
          memory: {
            get: (key, ns) => memoryStore.get(key, ns),
            has: (key, ns) => memoryStore.has(key, ns),
            list: (ns) => memoryStore.list(ns),
            getAll: (ns) => memoryStore.getAll(ns)
          },
          // Add basic context info for failure conditions
          checkName,
          schema: checkSchema,
          group: checkGroup,
          authorAssociation
        };
        if (debug) {
          context2.debug = {
            errors: debug.errors || [],
            processingTime: debug.processingTime || 0,
            provider: debug.provider || "unknown",
            model: debug.model || "unknown"
          };
        }
        return context2;
      }
      // Minimal JSON-from-end extractor for fail_if context fallback
      tryExtractJsonFromEnd(text) {
        try {
          const lines = text.split("\n");
          for (let i = lines.length - 1; i >= 0; i--) {
            const t = lines[i].trim();
            if (t.startsWith("{") || t.startsWith("[")) {
              const candidate = lines.slice(i).join("\n").trim();
              if (candidate.startsWith("{") && candidate.endsWith("}") || candidate.startsWith("[") && candidate.endsWith("]")) {
                return JSON.parse(candidate);
              }
            }
          }
        } catch {
        }
        return null;
      }
      /**
       * Check if any failure condition requires halting execution
       */
      static shouldHaltExecution(results) {
        return results.some((result) => result.failed && result.haltExecution);
      }
      /**
       * Get all failed conditions
       */
      static getFailedConditions(results) {
        return results.filter((result) => result.failed);
      }
      /**
       * Group results by severity
       */
      static groupResultsBySeverity(results) {
        return {
          // Only 'error' severity now (no backward compatibility needed here as this is internal)
          error: results.filter((r) => r.severity === "error"),
          warning: results.filter((r) => r.severity === "warning"),
          info: results.filter((r) => r.severity === "info")
        };
      }
      /**
       * Format results for display
       */
      static formatResults(results) {
        const failed = _FailureConditionEvaluator.getFailedConditions(results);
        if (failed.length === 0) {
          return "\u2705 All failure conditions passed";
        }
        const grouped = _FailureConditionEvaluator.groupResultsBySeverity(failed);
        const sections = [];
        if (grouped.error.length > 0) {
          sections.push(`\u274C **Error severity conditions (${grouped.error.length}):**`);
          grouped.error.forEach((result) => {
            sections.push(`  - ${result.conditionName}: ${result.message || result.expression}`);
          });
        }
        if (grouped.warning.length > 0) {
          sections.push(`\u26A0\uFE0F **Warning conditions (${grouped.warning.length}):**`);
          grouped.warning.forEach((result) => {
            sections.push(`  - ${result.conditionName}: ${result.message || result.expression}`);
          });
        }
        if (grouped.info.length > 0) {
          sections.push(`\u2139\uFE0F **Info conditions (${grouped.info.length}):**`);
          grouped.info.forEach((result) => {
            sections.push(`  - ${result.conditionName}: ${result.message || result.expression}`);
          });
        }
        return sections.join("\n");
      }
    };
  }
});

// src/snapshot-store.ts
var snapshot_store_exports = {};
__export(snapshot_store_exports, {
  ContextView: () => ContextView,
  ExecutionJournal: () => ExecutionJournal
});
var ExecutionJournal, ContextView;
var init_snapshot_store = __esm({
  "src/snapshot-store.ts"() {
    "use strict";
    ExecutionJournal = class {
      commit = 0;
      entries = [];
      beginSnapshot() {
        return this.commit;
      }
      commitEntry(entry) {
        const committed = {
          sessionId: entry.sessionId,
          scope: entry.scope,
          checkId: entry.checkId,
          result: entry.result,
          event: entry.event,
          commitId: ++this.commit
        };
        this.entries.push(committed);
        return committed;
      }
      readVisible(sessionId, commitMax, event) {
        return this.entries.filter(
          (e) => e.sessionId === sessionId && e.commitId <= commitMax && (event ? e.event === event : true)
        );
      }
      // Lightweight helpers for debugging/metrics
      size() {
        return this.entries.length;
      }
    };
    ContextView = class {
      constructor(journal, sessionId, snapshotId, scope, event) {
        this.journal = journal;
        this.sessionId = sessionId;
        this.snapshotId = snapshotId;
        this.scope = scope;
        this.event = event;
      }
      /** Return the nearest result for a check in this scope (exact item  ancestor  latest). */
      get(checkId) {
        const visible = this.journal.readVisible(this.sessionId, this.snapshotId, this.event).filter((e) => e.checkId === checkId);
        if (visible.length === 0) return void 0;
        const exactMatches = visible.filter((e) => this.sameScope(e.scope, this.scope));
        if (exactMatches.length > 0) {
          return exactMatches[exactMatches.length - 1].result;
        }
        let best;
        for (const e of visible) {
          const dist = this.ancestorDistance(e.scope, this.scope);
          if (dist >= 0 && (best === void 0 || dist < best.dist)) {
            best = { entry: e, dist };
          }
        }
        if (best) return best.entry.result;
        return visible[visible.length - 1]?.result;
      }
      /** Return an aggregate (raw) result  the shallowest scope for this check. */
      getRaw(checkId) {
        const visible = this.journal.readVisible(this.sessionId, this.snapshotId, this.event).filter((e) => e.checkId === checkId);
        if (visible.length === 0) return void 0;
        let shallow = visible[0];
        for (const e of visible) {
          if (e.scope.length < shallow.scope.length) shallow = e;
        }
        return shallow.result;
      }
      /** All results for a check up to this snapshot. */
      getHistory(checkId) {
        return this.journal.readVisible(this.sessionId, this.snapshotId, this.event).filter((e) => e.checkId === checkId).map((e) => e.result);
      }
      sameScope(a, b) {
        if (a.length !== b.length) return false;
        for (let i = 0; i < a.length; i++) {
          if (a[i].check !== b[i].check || a[i].index !== b[i].index) return false;
        }
        return true;
      }
      // distance from ancestor to current; -1 if not ancestor
      ancestorDistance(ancestor, current) {
        if (ancestor.length > current.length) return -1;
        if (ancestor.length === 0 && current.length > 0) return -1;
        for (let i = 0; i < ancestor.length; i++) {
          if (ancestor[i].check !== current[i].check || ancestor[i].index !== current[i].index)
            return -1;
        }
        return current.length - ancestor.length;
      }
    };
  }
});

// src/state-machine/states/routing.ts
var routing_exports = {};
__export(routing_exports, {
  checkLoopBudget: () => checkLoopBudget,
  evaluateGoto: () => evaluateGoto,
  evaluateTransitions: () => evaluateTransitions,
  handleRouting: () => handleRouting
});
function hasMapFanoutDependents(context2, checkId) {
  const checks = context2.config.checks || {};
  const reduceProviders = /* @__PURE__ */ new Set(["log", "memory", "script", "workflow", "noop"]);
  for (const [cid, cfg] of Object.entries(checks)) {
    if (cid === checkId) continue;
    const rawDeps = cfg.depends_on || [];
    const depList = Array.isArray(rawDeps) ? rawDeps : [rawDeps];
    let depends = false;
    for (const dep of depList) {
      if (typeof dep !== "string") continue;
      if (dep.includes("|")) {
        const opts = dep.split("|").map((s) => s.trim()).filter(Boolean);
        if (opts.includes(checkId)) {
          depends = true;
          break;
        }
      } else if (dep === checkId) {
        depends = true;
        break;
      }
    }
    if (!depends) continue;
    const explicit = cfg.fanout;
    if (explicit === "map") return true;
    if (explicit === "reduce") continue;
    const providerType = context2.checks[cid]?.providerType || checks[cid]?.type || "";
    const inferred = reduceProviders.has(providerType) ? "reduce" : "map";
    if (inferred === "map") return true;
  }
  return false;
}
function classifyFailure(result) {
  const issues = result?.issues || [];
  if (!issues || issues.length === 0) return "none";
  let hasLogical = false;
  let hasExecution = false;
  for (const iss of issues) {
    const id = String(iss.ruleId || "");
    const msg = String(iss.message || "");
    if (id.endsWith("_fail_if") || id.includes("contract/guarantee_failed") || id.includes("contract/schema_validation_failed"))
      hasLogical = true;
    if (id.includes("/execution_error") || msg.includes("Command execution failed"))
      hasExecution = true;
    if (id.includes("forEach/execution_error") || msg.includes("sandbox_runner_error"))
      hasExecution = true;
  }
  if (hasLogical && !hasExecution) return "logical";
  if (hasExecution && !hasLogical) return "execution";
  return hasExecution ? "execution" : "logical";
}
function getCriticality(context2, checkId) {
  const cfg = context2.config.checks?.[checkId];
  return cfg && cfg.criticality || "policy";
}
function createMemoryHelpers() {
  const memoryStore = MemoryStore.getInstance();
  return {
    get: (key, ns) => memoryStore.get(key, ns),
    has: (key, ns) => memoryStore.has(key, ns),
    getAll: (ns) => memoryStore.getAll(ns),
    set: (key, value, ns) => {
      const nsName = ns || memoryStore.getDefaultNamespace();
      const data = memoryStore["data"];
      if (!data.has(nsName)) data.set(nsName, /* @__PURE__ */ new Map());
      data.get(nsName).set(key, value);
    },
    clear: (ns) => {
      const data = memoryStore["data"];
      if (ns) data.delete(ns);
      else data.clear();
    },
    increment: (key, amount = 1, ns) => {
      const nsName = ns || memoryStore.getDefaultNamespace();
      const data = memoryStore["data"];
      if (!data.has(nsName)) data.set(nsName, /* @__PURE__ */ new Map());
      const nsMap = data.get(nsName);
      const current = nsMap.get(key);
      const numCurrent = typeof current === "number" ? current : 0;
      const newValue = numCurrent + amount;
      nsMap.set(key, newValue);
      return newValue;
    }
  };
}
function getHistoryLimit() {
  const raw = process.env.VISOR_TEST_HISTORY_LIMIT || process.env.VISOR_OUTPUT_HISTORY_LIMIT;
  if (!raw) return void 0;
  const n = parseInt(raw, 10);
  return Number.isFinite(n) && n > 0 ? n : void 0;
}
function formatScopeLabel(scope) {
  if (!scope || scope.length === 0) return "";
  return scope.map((item) => `${item.check}:${item.index}`).join("|");
}
function recordRoutingEvent(args) {
  const attrs = {
    check_id: args.checkId,
    trigger: args.trigger,
    action: args.action
  };
  if (args.target) attrs.target = args.target;
  if (args.source) attrs.source = args.source;
  const scopeLabel = formatScopeLabel(args.scope);
  if (scopeLabel) attrs.scope = scopeLabel;
  if (args.gotoEvent) attrs.goto_event = args.gotoEvent;
  addEvent("visor.routing", attrs);
}
async function handleRouting(context2, state, transition, emitEvent, routingContext) {
  const { checkId, scope, result, checkConfig, success } = routingContext;
  logger.info(`[Routing] Evaluating routing for check: ${checkId}, success: ${success}`);
  const failureResult = await evaluateFailIf(checkId, result, checkConfig, context2, state);
  if (failureResult.haltExecution) {
    logger.error(
      `[Routing] HALTING EXECUTION due to critical failure in ${checkId}: ${failureResult.haltMessage}`
    );
    const haltIssue = {
      file: "system",
      line: 0,
      ruleId: `${checkId}_halt_execution`,
      message: `Execution halted: ${failureResult.haltMessage || "Critical failure condition met"}`,
      severity: "error",
      category: "logic"
    };
    result.issues = [...result.issues || [], haltIssue];
    emitEvent({
      type: "Shutdown",
      error: {
        message: failureResult.haltMessage || `Execution halted by check ${checkId}`,
        name: "HaltExecution"
      }
    });
    transition("Error");
    return true;
  }
  if (failureResult.failed) {
    if (context2.debug) {
      logger.info(`[Routing] fail_if/failure_conditions triggered for ${checkId}`);
    }
    await processOnFail(checkId, scope, result, checkConfig, context2, state, emitEvent);
  } else if (success) {
    await processOnSuccess(checkId, scope, result, checkConfig, context2, state, emitEvent);
  } else {
    await processOnFail(checkId, scope, result, checkConfig, context2, state, emitEvent);
  }
  const shouldProcessOnFinishHere = !!checkConfig.on_finish && (checkConfig.forEach !== true || !hasMapFanoutDependents(context2, checkId));
  if (checkConfig.on_finish) {
    logger.info(
      `[Routing] on_finish decision for ${checkId}: forEach=${!!checkConfig.forEach}, processHere=${shouldProcessOnFinishHere}`
    );
  }
  if (shouldProcessOnFinishHere) {
    await processOnFinish(checkId, scope, result, checkConfig, context2, state, emitEvent);
  }
  transition("WavePlanning");
  return false;
}
async function processOnFinish(checkId, scope, result, checkConfig, context2, state, emitEvent) {
  const onFinish = checkConfig.on_finish;
  if (!onFinish) {
    return;
  }
  logger.info(`Processing on_finish for ${checkId}`);
  let queuedForward = false;
  if (onFinish.run && onFinish.run.length > 0) {
    const currentCheckIsForEach = checkConfig.forEach === true;
    const forEachItems = currentCheckIsForEach ? result.forEachItems : void 0;
    const hasForEachItems = Array.isArray(forEachItems) && forEachItems.length > 0;
    for (const targetCheck of onFinish.run) {
      if (checkLoopBudget(context2, state, "on_finish", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_finish run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      const targetConfig = context2.config.checks?.[targetCheck];
      const fanoutMode = targetConfig?.fanout || "reduce";
      if (context2.debug) {
        logger.info(
          `[Routing] on_finish.run: scheduling ${targetCheck} with fanout=${fanoutMode}, hasForEachItems=${hasForEachItems}`
        );
      }
      if (fanoutMode === "map" && hasForEachItems) {
        for (let itemIndex = 0; itemIndex < forEachItems.length; itemIndex++) {
          state.routingLoopCount++;
          const itemScope = [
            { check: checkId, index: itemIndex }
          ];
          recordRoutingEvent({
            checkId,
            trigger: "on_finish",
            action: "run",
            target: targetCheck,
            source: "run",
            scope: itemScope
          });
          emitEvent({
            type: "ForwardRunRequested",
            target: targetCheck,
            scope: itemScope,
            origin: "run"
          });
          queuedForward = true;
        }
      } else {
        state.routingLoopCount++;
        recordRoutingEvent({
          checkId,
          trigger: "on_finish",
          action: "run",
          target: targetCheck,
          source: "run",
          scope: []
        });
        emitEvent({
          type: "ForwardRunRequested",
          target: targetCheck,
          scope: [],
          origin: "run"
        });
        queuedForward = true;
      }
    }
  }
  if (onFinish.run_js) {
    const dynamicTargets = await evaluateRunJs(
      onFinish.run_js,
      checkId,
      checkConfig,
      result,
      context2,
      state
    );
    for (const targetCheck of dynamicTargets) {
      if (checkLoopBudget(context2, state, "on_finish", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_finish run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      if (context2.debug) {
        logger.info(`[Routing] on_finish.run_js: scheduling ${targetCheck}`);
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_finish",
        action: "run",
        target: targetCheck,
        source: "run_js",
        scope
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: targetCheck,
        scope,
        origin: "run_js"
      });
      queuedForward = true;
    }
  }
  const finishTransTarget = await evaluateTransitions(
    onFinish.transitions,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (finishTransTarget !== void 0) {
    if (finishTransTarget) {
      if (checkLoopBudget(context2, state, "on_finish", "goto")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_finish goto`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_finish",
        action: "goto",
        target: finishTransTarget.to,
        source: "transitions",
        scope,
        gotoEvent: finishTransTarget.goto_event
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: finishTransTarget.to,
        scope,
        origin: "goto_js",
        gotoEvent: finishTransTarget.goto_event
      });
    }
    return;
  }
  const gotoTarget = await evaluateGoto(
    onFinish.goto_js,
    onFinish.goto,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (gotoTarget) {
    if (checkLoopBudget(context2, state, "on_finish", "goto")) {
      const errorIssue = {
        file: "system",
        line: 0,
        ruleId: `${checkId}/routing/loop_budget_exceeded`,
        message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_finish goto`,
        severity: "error",
        category: "logic"
      };
      result.issues = [...result.issues || [], errorIssue];
      return;
    }
    if (context2.debug) {
      logger.info(`[Routing] on_finish.goto: ${gotoTarget}`);
    }
    state.routingLoopCount++;
    recordRoutingEvent({
      checkId,
      trigger: "on_finish",
      action: "goto",
      target: gotoTarget,
      source: onFinish.goto_js ? "goto_js" : "goto",
      scope
    });
    emitEvent({
      type: "ForwardRunRequested",
      target: gotoTarget,
      scope,
      origin: "goto_js"
    });
    state.flags.forwardRunRequested = true;
  }
  if (queuedForward) {
    const guardKey = `waveRetry:on_finish:${checkId}:wave:${state.wave}`;
    if (!state.forwardRunGuards?.has(guardKey)) {
      state.forwardRunGuards?.add(guardKey);
      emitEvent({ type: "WaveRetry", reason: "on_finish" });
    }
  }
}
async function evaluateFailIf(checkId, result, checkConfig, context2, state) {
  const config = context2.config;
  const globalFailIf = config.fail_if;
  const checkFailIf = checkConfig.fail_if;
  const globalFailureConditions = config.failure_conditions;
  const checkFailureConditions = checkConfig.failure_conditions;
  if (!globalFailIf && !checkFailIf && !globalFailureConditions && !checkFailureConditions) {
    return { failed: false, haltExecution: false };
  }
  const evaluator = new FailureConditionEvaluator();
  const outputsRecord = {};
  for (const [key] of state.stats.entries()) {
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        context2.event
      );
      const journalResult = contextView.get(key);
      if (journalResult) {
        outputsRecord[key] = journalResult;
      }
    } catch {
      outputsRecord[key] = { issues: [] };
    }
  }
  const checkSchema = typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema || "";
  const checkGroup = checkConfig.group || "";
  let anyFailed = false;
  let shouldHalt = false;
  let haltMessage;
  if (globalFailIf) {
    try {
      const failed = await evaluator.evaluateSimpleCondition(
        checkId,
        checkSchema,
        checkGroup,
        result,
        globalFailIf,
        outputsRecord
      );
      if (failed) {
        logger.warn(`[Routing] Global fail_if triggered for ${checkId}: ${globalFailIf}`);
        const failIssue = {
          file: "system",
          line: 0,
          ruleId: "global_fail_if",
          message: `Global failure condition met: ${globalFailIf}`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], failIssue];
      }
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error);
      logger.error(`[Routing] Error evaluating global fail_if: ${msg}`);
    }
  }
  if (checkFailIf) {
    try {
      const failed = await evaluator.evaluateSimpleCondition(
        checkId,
        checkSchema,
        checkGroup,
        result,
        checkFailIf,
        outputsRecord
      );
      if (failed) {
        logger.warn(`[Routing] Check fail_if triggered for ${checkId}: ${checkFailIf}`);
        const failIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}_fail_if`,
          message: `Check failure condition met: ${checkFailIf}`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], failIssue];
        anyFailed = true;
      }
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error);
      logger.error(`[Routing] Error evaluating check fail_if: ${msg}`);
    }
  }
  if (globalFailureConditions || checkFailureConditions) {
    try {
      const conditionResults = await evaluator.evaluateConditions(
        checkId,
        checkSchema,
        checkGroup,
        result,
        globalFailureConditions,
        checkFailureConditions,
        outputsRecord
      );
      for (const condResult of conditionResults) {
        if (condResult.failed) {
          logger.warn(
            `[Routing] Failure condition '${condResult.conditionName}' triggered for ${checkId}: ${condResult.expression}`
          );
          const failIssue = {
            file: "system",
            line: 0,
            ruleId: `${checkId}_${condResult.conditionName}`,
            message: condResult.message || `Failure condition met: ${condResult.expression}`,
            severity: condResult.severity || "error",
            category: "logic"
          };
          result.issues = [...result.issues || [], failIssue];
          anyFailed = true;
          if (condResult.haltExecution) {
            shouldHalt = true;
            haltMessage = condResult.message || `Execution halted: condition '${condResult.conditionName}' triggered`;
            logger.error(
              `[Routing] HALT EXECUTION triggered by '${condResult.conditionName}' for ${checkId}`
            );
          }
        }
      }
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error);
      logger.error(`[Routing] Error evaluating failure_conditions: ${msg}`);
    }
  }
  return { failed: anyFailed, haltExecution: shouldHalt, haltMessage };
}
function checkLoopBudget(context2, state, origin, action) {
  const maxLoops = context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS;
  if (state.routingLoopCount >= maxLoops) {
    const msg = `Routing loop budget exceeded (max_loops=${maxLoops}) during ${origin} ${action}`;
    logger.error(`[Routing] ${msg}`);
    return true;
  }
  return false;
}
async function processOnSuccess(checkId, scope, result, checkConfig, context2, state, emitEvent) {
  const onSuccess = checkConfig.on_success;
  if (!onSuccess) {
    return;
  }
  if (context2.debug) {
    logger.info(`[Routing] Processing on_success for ${checkId}`);
  }
  if (onSuccess.run && onSuccess.run.length > 0) {
    const resForEachItems = result && result.forEachItems || void 0;
    const hasForEachItems = Array.isArray(resForEachItems) && resForEachItems.length > 0;
    for (const targetCheck of onSuccess.run) {
      if (checkLoopBudget(context2, state, "on_success", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_success run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      const targetConfig = context2.config.checks?.[targetCheck];
      const fanoutMode = targetConfig?.fanout || "reduce";
      if (context2.debug) {
        logger.info(
          `[Routing] on_success.run: scheduling ${targetCheck} with fanout=${fanoutMode}, hasForEachItems=${hasForEachItems}`
        );
      }
      if (fanoutMode === "map" && hasForEachItems) {
        for (let itemIndex = 0; itemIndex < resForEachItems.length; itemIndex++) {
          state.routingLoopCount++;
          const itemScope = [
            { check: checkId, index: itemIndex }
          ];
          recordRoutingEvent({
            checkId,
            trigger: "on_success",
            action: "run",
            target: targetCheck,
            source: "run",
            scope: itemScope
          });
          emitEvent({
            type: "ForwardRunRequested",
            target: targetCheck,
            scope: itemScope,
            origin: "run"
          });
        }
      } else {
        state.routingLoopCount++;
        recordRoutingEvent({
          checkId,
          trigger: "on_success",
          action: "run",
          target: targetCheck,
          source: "run",
          scope
        });
        emitEvent({
          type: "ForwardRunRequested",
          target: targetCheck,
          scope,
          origin: "run"
        });
      }
    }
  }
  if (onSuccess.run_js) {
    const dynamicTargets = await evaluateRunJs(
      onSuccess.run_js,
      checkId,
      checkConfig,
      result,
      context2,
      state
    );
    for (const targetCheck of dynamicTargets) {
      if (checkLoopBudget(context2, state, "on_success", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_success run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      if (context2.debug) {
        logger.info(`[Routing] on_success.run_js: scheduling ${targetCheck}`);
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_success",
        action: "run",
        target: targetCheck,
        source: "run_js",
        scope
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: targetCheck,
        scope,
        origin: "run_js"
      });
    }
  }
  const successTransTarget = await evaluateTransitions(
    onSuccess.transitions,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (successTransTarget !== void 0) {
    if (successTransTarget) {
      if (checkLoopBudget(context2, state, "on_success", "goto")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_success goto`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_success",
        action: "goto",
        target: successTransTarget.to,
        source: "transitions",
        scope,
        gotoEvent: successTransTarget.goto_event
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: successTransTarget.to,
        scope,
        origin: "goto_js",
        gotoEvent: successTransTarget.goto_event
      });
      state.flags.forwardRunRequested = true;
    }
    return;
  }
  const gotoTarget = await evaluateGoto(
    onSuccess.goto_js,
    onSuccess.goto,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (gotoTarget) {
    if (checkLoopBudget(context2, state, "on_success", "goto")) {
      const errorIssue = {
        file: "system",
        line: 0,
        ruleId: `${checkId}/routing/loop_budget_exceeded`,
        message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_success goto`,
        severity: "error",
        category: "logic"
      };
      result.issues = [...result.issues || [], errorIssue];
      return;
    }
    if (context2.debug) {
      logger.info(`[Routing] on_success.goto: ${gotoTarget}`);
    }
    state.routingLoopCount++;
    recordRoutingEvent({
      checkId,
      trigger: "on_success",
      action: "goto",
      target: gotoTarget,
      source: onSuccess.goto_js ? "goto_js" : "goto",
      scope,
      gotoEvent: onSuccess.goto_event
    });
    emitEvent({
      type: "ForwardRunRequested",
      target: gotoTarget,
      gotoEvent: onSuccess.goto_event,
      scope,
      origin: "goto_js"
    });
    state.flags.forwardRunRequested = true;
  }
}
async function processOnFail(checkId, scope, result, checkConfig, context2, state, emitEvent) {
  const defaults = context2.config.routing?.defaults?.on_fail || {};
  const onFail = checkConfig.on_fail ? { ...defaults, ...checkConfig.on_fail } : void 0;
  if (!onFail) {
    return;
  }
  if (context2.debug) {
    logger.info(`[Routing] Processing on_fail for ${checkId}`);
  }
  if (onFail.run && onFail.run.length > 0) {
    const resForEachItems = result && result.forEachItems || void 0;
    const hasForEachItems = Array.isArray(resForEachItems) && resForEachItems.length > 0;
    for (const targetCheck of onFail.run) {
      if (checkLoopBudget(context2, state, "on_fail", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_fail run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      const targetConfig = context2.config.checks?.[targetCheck];
      const fanoutMode = targetConfig?.fanout || "reduce";
      if (context2.debug) {
        logger.info(
          `[Routing] on_fail.run: scheduling ${targetCheck} with fanout=${fanoutMode}, hasForEachItems=${hasForEachItems}`
        );
      }
      if (hasForEachItems) {
        for (let itemIndex = 0; itemIndex < resForEachItems.length; itemIndex++) {
          const itemOut = resForEachItems[itemIndex];
          if (itemOut && typeof itemOut === "object" && itemOut.__failed !== true && fanoutMode !== "map") {
            continue;
          }
          state.routingLoopCount++;
          const itemScope = [
            { check: checkId, index: itemIndex }
          ];
          recordRoutingEvent({
            checkId,
            trigger: "on_fail",
            action: "run",
            target: targetCheck,
            source: "run",
            scope: itemScope
          });
          emitEvent({
            type: "ForwardRunRequested",
            target: targetCheck,
            scope: itemScope,
            origin: "run",
            sourceCheck: checkId
            // The failed check that triggered on_fail.run
          });
        }
      } else {
        state.routingLoopCount++;
        recordRoutingEvent({
          checkId,
          trigger: "on_fail",
          action: "run",
          target: targetCheck,
          source: "run",
          scope
        });
        emitEvent({
          type: "ForwardRunRequested",
          target: targetCheck,
          scope,
          origin: "run",
          sourceCheck: checkId
          // The failed check that triggered on_fail.run
        });
      }
    }
  }
  if (onFail.run_js) {
    const dynamicTargets = await evaluateRunJs(
      onFail.run_js,
      checkId,
      checkConfig,
      result,
      context2,
      state
    );
    for (const targetCheck of dynamicTargets) {
      if (checkLoopBudget(context2, state, "on_fail", "run")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_fail run`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      if (context2.debug) {
        logger.info(`[Routing] on_fail.run_js: scheduling ${targetCheck}`);
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_fail",
        action: "run",
        target: targetCheck,
        source: "run_js",
        scope
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: targetCheck,
        scope,
        origin: "run_js",
        sourceCheck: checkId
        // The failed check that triggered on_fail.run_js
      });
    }
  }
  if (onFail.retry && typeof onFail.retry.max === "number" && onFail.retry.max > 0) {
    const crit = getCriticality(context2, checkId);
    const failureKind = classifyFailure(result);
    if ((crit === "external" || crit === "internal") && failureKind === "logical") {
      if (context2.debug) {
        logger.info(
          `[Routing] on_fail.retry suppressed for ${checkId} (criticality=${crit}, failure=logical)`
        );
      }
    } else {
      const max = Math.max(0, onFail.retry.max || 0);
      if (!state.retryAttempts) state.retryAttempts = /* @__PURE__ */ new Map();
      const attemptsMap = state.retryAttempts;
      const makeKey = (sc) => {
        const keyScope = sc && sc.length > 0 ? JSON.stringify(sc) : "root";
        return `${checkId}::${keyScope}`;
      };
      const scheduleRetryForScope = (sc) => {
        const key = makeKey(sc);
        const used = attemptsMap.get(key) || 0;
        if (used >= max) return;
        attemptsMap.set(key, used + 1);
        state.routingLoopCount++;
        recordRoutingEvent({
          checkId,
          trigger: "on_fail",
          action: "retry",
          source: "retry",
          scope: sc || []
        });
        emitEvent({
          type: "ForwardRunRequested",
          target: checkId,
          scope: sc || [],
          origin: "run"
        });
      };
      const resForEachItems = result && result.forEachItems || void 0;
      const hasForEachItems = Array.isArray(resForEachItems) && resForEachItems.length > 0;
      if (hasForEachItems) {
        for (let i = 0; i < resForEachItems.length; i++) {
          const itemOut = resForEachItems[i];
          if (itemOut && typeof itemOut === "object" && itemOut.__failed === true) {
            const sc = [{ check: checkId, index: i }];
            scheduleRetryForScope(sc);
          }
        }
      } else {
        scheduleRetryForScope(scope);
      }
    }
  }
  const failTransTarget = await evaluateTransitions(
    onFail.transitions,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (failTransTarget !== void 0) {
    if (failTransTarget) {
      if (checkLoopBudget(context2, state, "on_fail", "goto")) {
        const errorIssue = {
          file: "system",
          line: 0,
          ruleId: `${checkId}/routing/loop_budget_exceeded`,
          message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? DEFAULT_MAX_LOOPS}) during on_fail goto`,
          severity: "error",
          category: "logic"
        };
        result.issues = [...result.issues || [], errorIssue];
        return;
      }
      state.routingLoopCount++;
      recordRoutingEvent({
        checkId,
        trigger: "on_fail",
        action: "goto",
        target: failTransTarget.to,
        source: "transitions",
        scope,
        gotoEvent: failTransTarget.goto_event
      });
      emitEvent({
        type: "ForwardRunRequested",
        target: failTransTarget.to,
        scope,
        origin: "goto_js",
        gotoEvent: failTransTarget.goto_event
      });
      state.flags.forwardRunRequested = true;
    }
    return;
  }
  const gotoTarget = await evaluateGoto(
    onFail.goto_js,
    onFail.goto,
    checkId,
    checkConfig,
    result,
    context2,
    state
  );
  if (gotoTarget) {
    if (checkLoopBudget(context2, state, "on_fail", "goto")) {
      const errorIssue = {
        file: "system",
        line: 0,
        ruleId: `${checkId}/routing/loop_budget_exceeded`,
        message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_fail goto`,
        severity: "error",
        category: "logic"
      };
      result.issues = [...result.issues || [], errorIssue];
      return;
    }
    if (context2.debug) {
      logger.info(`[Routing] on_fail.goto: ${gotoTarget}`);
    }
    state.routingLoopCount++;
    recordRoutingEvent({
      checkId,
      trigger: "on_fail",
      action: "goto",
      target: gotoTarget,
      source: onFail.goto_js ? "goto_js" : "goto",
      scope,
      gotoEvent: onFail.goto_event
    });
    emitEvent({
      type: "ForwardRunRequested",
      target: gotoTarget,
      gotoEvent: onFail.goto_event,
      scope,
      origin: "goto_js"
    });
    state.flags.forwardRunRequested = true;
  }
}
async function evaluateRunJs(runJs, checkId, checkConfig, result, context2, _state) {
  try {
    const sandbox = createSecureSandbox();
    const historyLimit = getHistoryLimit();
    const snapshotId = context2.journal.beginSnapshot();
    const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
      context2.journal,
      context2.sessionId,
      snapshotId,
      [],
      context2.event
    );
    const outputsRecord = {};
    const outputsHistory = {};
    const allEntries = context2.journal.readVisible(context2.sessionId, snapshotId, context2.event);
    const uniqueCheckIds = new Set(allEntries.map((e) => e.checkId));
    for (const checkIdFromJournal of uniqueCheckIds) {
      try {
        const journalResult = contextView.get(checkIdFromJournal);
        if (journalResult) {
          outputsRecord[checkIdFromJournal] = journalResult.output !== void 0 ? journalResult.output : journalResult;
        }
      } catch {
        outputsRecord[checkIdFromJournal] = { issues: [] };
      }
      try {
        const history = contextView.getHistory(checkIdFromJournal);
        if (history && history.length > 0) {
          const trimmed = historyLimit && history.length > historyLimit ? history.slice(history.length - historyLimit) : history;
          outputsHistory[checkIdFromJournal] = trimmed.map(
            (r) => r.output !== void 0 ? r.output : r
          );
        }
      } catch {
      }
    }
    outputsRecord.history = outputsHistory;
    let forEachMeta = void 0;
    try {
      const hist = outputsHistory[checkId] || [];
      const lastArr = hist.slice().reverse().find((x) => Array.isArray(x));
      if (checkConfig.forEach === true && Array.isArray(lastArr)) {
        forEachMeta = {
          is_parent: true,
          last_wave_size: lastArr.length,
          last_items: lastArr
        };
      }
    } catch {
    }
    const scopeObj = {
      step: {
        id: checkId,
        tags: checkConfig.tags || [],
        group: checkConfig.group
      },
      outputs: outputsRecord,
      outputs_history: outputsHistory,
      output: result?.output,
      memory: createMemoryHelpers(),
      event: {
        name: context2.event || "manual"
      },
      forEach: forEachMeta
    };
    const code = `
      const step = scope.step;
      const outputs = scope.outputs;
      const outputs_history = scope.outputs_history;
      const output = scope.output;
      const memory = scope.memory;
      const event = scope.event;
      const forEach = scope.forEach;
      const log = (...args) => console.log('\u{1F50D} Debug:', ...args);
      const __fn = () => {
        ${runJs}
      };
      const __res = __fn();
      return Array.isArray(__res) ? __res.filter(x => typeof x === 'string' && x) : [];
    `;
    try {
      const evalResult = compileAndRun(
        sandbox,
        code,
        { scope: scopeObj },
        { injectLog: false, wrapFunction: false }
      );
      return Array.isArray(evalResult) ? evalResult.filter(Boolean) : [];
    } catch (_e) {
      try {
        const vm = require("vm");
        const context3 = vm.createContext({ scope: scopeObj, console: { log: () => {
        } } });
        const src = `(() => { ${runJs}
 })()`;
        const val = new vm.Script(src).runInContext(context3, { timeout: 100 });
        return Array.isArray(val) ? val.filter((x) => typeof x === "string" && x) : [];
      } catch (_vmErr) {
        return [];
      }
    }
  } catch (error) {
    const msg = error instanceof Error ? error.message : String(error);
    logger.error(`[Routing] Error evaluating run_js: ${msg}`);
    return [];
  }
}
async function evaluateGoto(gotoJs, gotoStatic, checkId, checkConfig, result, context2, _state) {
  if (gotoJs) {
    try {
      const sandbox = createSecureSandbox();
      const historyLimit = getHistoryLimit();
      const snapshotId = context2.journal.beginSnapshot();
      const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        void 0
      );
      const outputsRecord = {};
      const outputsHistory = {};
      const allEntries = context2.journal.readVisible(context2.sessionId, snapshotId, void 0);
      const uniqueCheckIds = new Set(allEntries.map((e) => e.checkId));
      for (const checkIdFromJournal of uniqueCheckIds) {
        try {
          const journalResult = contextView.get(checkIdFromJournal);
          if (journalResult) {
            outputsRecord[checkIdFromJournal] = journalResult.output !== void 0 ? journalResult.output : journalResult;
          }
        } catch {
          outputsRecord[checkIdFromJournal] = { issues: [] };
        }
        try {
          const history = contextView.getHistory(checkIdFromJournal);
          if (history && history.length > 0) {
            const trimmed = historyLimit && history.length > historyLimit ? history.slice(history.length - historyLimit) : history;
            outputsHistory[checkIdFromJournal] = trimmed.map(
              (r) => r.output !== void 0 ? r.output : r
            );
          }
        } catch {
        }
      }
      outputsRecord.history = outputsHistory;
      let forEachMeta = void 0;
      try {
        const hist = outputsHistory[checkId] || [];
        const lastArr = hist.slice().reverse().find((x) => Array.isArray(x));
        if (checkConfig.forEach === true && Array.isArray(lastArr)) {
          forEachMeta = {
            is_parent: true,
            last_wave_size: lastArr.length,
            last_items: lastArr
          };
        }
      } catch {
      }
      const scopeObj = {
        step: {
          id: checkId,
          tags: checkConfig.tags || [],
          group: checkConfig.group
        },
        outputs: outputsRecord,
        outputs_history: outputsHistory,
        output: result?.output,
        memory: createMemoryHelpers(),
        event: {
          name: context2.event || "manual"
        },
        forEach: forEachMeta
      };
      if (context2.debug) {
        logger.info(
          `[Routing] evaluateGoto: checkId=${checkId}, outputs_history keys=${Object.keys(outputsHistory).join(",")}`
        );
        for (const [key, values] of Object.entries(outputsHistory)) {
          logger.info(`[Routing]   ${key}: ${values.length} items`);
        }
      }
      const code = `
        const step = scope.step;
        const outputs = scope.outputs;
        const outputs_history = scope.outputs_history;
        const output = scope.output;
        const memory = scope.memory;
        const event = scope.event;
        const forEach = scope.forEach;
        const log = (...args) => console.log('\u{1F50D} Debug:', ...args);
        ${gotoJs}
      `;
      try {
        const evalResult = compileAndRun(
          sandbox,
          code,
          { scope: scopeObj },
          { injectLog: false, wrapFunction: true }
        );
        if (context2.debug) {
          logger.info(`[Routing] evaluateGoto result: ${evalResult}`);
        }
        if (typeof evalResult === "string" && evalResult) {
          return evalResult;
        }
      } catch (_e) {
        try {
          const vm = require("vm");
          const contextObj = {
            step: scopeObj.step,
            outputs: scopeObj.outputs,
            outputs_history: scopeObj.outputs_history,
            output: scopeObj.output,
            memory: scopeObj.memory,
            event: scopeObj.event,
            forEach: scopeObj.forEach
          };
          const vmctx = vm.createContext(contextObj);
          const src = `(() => { ${gotoJs}
 })()`;
          const res = new vm.Script(src).runInContext(vmctx, { timeout: 100 });
          if (typeof res === "string" && res) return res;
        } catch (_vmErr) {
        }
      }
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error);
      logger.error(`[Routing] Error evaluating goto_js: ${msg}`);
      if (gotoStatic) {
        logger.info(`[Routing] Falling back to static goto: ${gotoStatic}`);
        return gotoStatic;
      }
    }
  }
  return gotoStatic || null;
}
async function evaluateTransitions(transitions, checkId, checkConfig, result, context2, _state) {
  if (!transitions || transitions.length === 0) return void 0;
  try {
    const sandbox = createSecureSandbox();
    const historyLimit = getHistoryLimit();
    const snapshotId = context2.journal.beginSnapshot();
    const ContextView2 = (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView;
    const view = new ContextView2(context2.journal, context2.sessionId, snapshotId, [], void 0);
    const outputsRecord = {};
    const outputsHistory = {};
    const allEntries = context2.journal.readVisible(context2.sessionId, snapshotId, void 0);
    const uniqueCheckIds = new Set(allEntries.map((e) => e.checkId));
    for (const cid of uniqueCheckIds) {
      try {
        const jr = view.get(cid);
        if (jr) outputsRecord[cid] = jr.output !== void 0 ? jr.output : jr;
      } catch {
      }
      try {
        const hist = view.getHistory(cid);
        if (hist && hist.length > 0) {
          const trimmed = historyLimit && hist.length > historyLimit ? hist.slice(hist.length - historyLimit) : hist;
          outputsHistory[cid] = trimmed.map((r) => r.output !== void 0 ? r.output : r);
        }
      } catch {
      }
    }
    outputsRecord.history = outputsHistory;
    const scopeObj = {
      step: { id: checkId, tags: checkConfig.tags || [], group: checkConfig.group },
      outputs: outputsRecord,
      outputs_history: outputsHistory,
      output: result?.output,
      memory: createMemoryHelpers(),
      event: { name: context2.event || "manual" }
    };
    for (const rule of transitions) {
      const helpers = `
        const any = (arr, pred) => Array.isArray(arr) && arr.some(x => pred(x));
        const all = (arr, pred) => Array.isArray(arr) && arr.every(x => pred(x));
        const none = (arr, pred) => Array.isArray(arr) && !arr.some(x => pred(x));
        const count = (arr, pred) => Array.isArray(arr) ? arr.filter(x => pred(x)).length : 0;
      `;
      const code = `
        ${helpers}
        const step = scope.step;
        const outputs = scope.outputs;
        const outputs_history = scope.outputs_history;
        const output = scope.output;
        const memory = scope.memory;
        const event = scope.event;
        const __eval = () => { return (${rule.when}); };
        return __eval();
      `;
      let matched;
      try {
        matched = compileAndRun(
          sandbox,
          code,
          { scope: scopeObj },
          { injectLog: false, wrapFunction: false }
        );
      } catch (_e) {
        try {
          const vm = require("vm");
          const helpersFns = {
            any: (arr, pred) => Array.isArray(arr) && arr.some(pred),
            all: (arr, pred) => Array.isArray(arr) && arr.every(pred),
            none: (arr, pred) => Array.isArray(arr) && !arr.some(pred),
            count: (arr, pred) => Array.isArray(arr) ? arr.filter(pred).length : 0
          };
          const context3 = vm.createContext({
            step: scopeObj.step,
            outputs: scopeObj.outputs,
            outputs_history: scopeObj.outputs_history,
            output: scopeObj.output,
            memory: scopeObj.memory,
            event: scopeObj.event,
            ...helpersFns
          });
          const res = new vm.Script(`(${rule.when})`).runInContext(context3, { timeout: 50 });
          matched = !!res;
        } catch (_vmErr) {
          matched = false;
        }
      }
      if (matched) {
        if (rule.to === null) return null;
        if (typeof rule.to === "string" && rule.to.length > 0) {
          return { to: rule.to, goto_event: rule.goto_event };
        }
        return null;
      }
    }
    return void 0;
  } catch (err) {
    logger.error(
      `[Routing] Error evaluating transitions: ${err instanceof Error ? err.message : String(err)}`
    );
    return void 0;
  }
}
var DEFAULT_MAX_LOOPS;
var init_routing = __esm({
  "src/state-machine/states/routing.ts"() {
    "use strict";
    init_logger();
    init_trace_helpers();
    init_failure_condition_evaluator();
    init_sandbox();
    init_memory_store();
    DEFAULT_MAX_LOOPS = 10;
  }
});

// src/utils/mermaid-telemetry.ts
function emitMermaidFromMarkdown(checkName, markdown, origin) {
  if (!markdown || typeof markdown !== "string") return 0;
  let m;
  let count = 0;
  MERMAID_RE.lastIndex = 0;
  while ((m = MERMAID_RE.exec(markdown)) != null) {
    const code = (m[1] || "").trim();
    if (code) {
      try {
        addEvent("diagram.block", { check: checkName, origin, code });
        addDiagramBlock(origin);
        if (process.env.VISOR_TRACE_REPORT === "true") {
          const outDir = process.env.VISOR_TRACE_DIR || path3.join(process.cwd(), "output", "traces");
          try {
            if (!fs3.existsSync(outDir)) fs3.mkdirSync(outDir, { recursive: true });
            const ts = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
            const jsonPath = path3.join(outDir, `${ts}.trace.json`);
            const htmlPath = path3.join(outDir, `${ts}.report.html`);
            let data = { spans: [] };
            if (fs3.existsSync(jsonPath)) {
              try {
                data = JSON.parse(fs3.readFileSync(jsonPath, "utf8"));
              } catch {
                data = { spans: [] };
              }
            }
            data.spans.push({
              events: [{ name: "diagram.block", attrs: { check: checkName, origin, code } }]
            });
            fs3.writeFileSync(jsonPath, JSON.stringify(data, null, 2), "utf8");
            if (!fs3.existsSync(htmlPath)) {
              fs3.writeFileSync(
                htmlPath,
                '<!doctype html><html><head><meta charset="utf-8"/><title>Visor Trace Report</title></head><body><h2>Visor Trace Report</h2></body></html>',
                "utf8"
              );
            }
          } catch {
          }
        }
        count++;
      } catch {
      }
    }
  }
  return count;
}
var fs3, path3, MERMAID_RE;
var init_mermaid_telemetry = __esm({
  "src/utils/mermaid-telemetry.ts"() {
    "use strict";
    init_trace_helpers();
    init_metrics();
    fs3 = __toESM(require("fs"));
    path3 = __toESM(require("path"));
    MERMAID_RE = /```mermaid\s*\n([\s\S]*?)\n```/gi;
  }
});

// src/state-machine/context/workflow-inputs.ts
function resolveWorkflowInputs(checkConfig, context2) {
  if (checkConfig?.workflowInputs) {
    return checkConfig.workflowInputs;
  }
  if (context2.config?.workflow_inputs) {
    return context2.config.workflow_inputs;
  }
  if (context2.executionContext?.workflowInputs) {
    return context2.executionContext.workflowInputs;
  }
  return void 0;
}
var init_workflow_inputs = __esm({
  "src/state-machine/context/workflow-inputs.ts"() {
    "use strict";
  }
});

// src/state-machine/dispatch/history-snapshot.ts
var history_snapshot_exports = {};
__export(history_snapshot_exports, {
  buildOutputHistoryFromJournal: () => buildOutputHistoryFromJournal
});
function getHistoryLimit2() {
  const raw = process.env.VISOR_TEST_HISTORY_LIMIT || process.env.VISOR_OUTPUT_HISTORY_LIMIT;
  if (!raw) return void 0;
  const n = parseInt(raw, 10);
  return Number.isFinite(n) && n > 0 ? n : void 0;
}
function buildOutputHistoryFromJournal(context2) {
  const outputHistory = /* @__PURE__ */ new Map();
  const limit = getHistoryLimit2();
  try {
    const snapshot = context2.journal.beginSnapshot();
    const allEntries = context2.journal.readVisible(context2.sessionId, snapshot, void 0);
    for (const entry of allEntries) {
      const checkId = entry.checkId;
      if (!outputHistory.has(checkId)) {
        outputHistory.set(checkId, []);
      }
      try {
        if (entry && typeof entry.result === "object" && entry.result.__skipped) {
          continue;
        }
      } catch {
      }
      const payload = entry.result.output !== void 0 ? entry.result.output : entry.result;
      try {
        if (payload && typeof payload === "object" && payload.forEachItems && Array.isArray(payload.forEachItems)) {
          continue;
        }
      } catch {
      }
      if (payload !== void 0) {
        const arr = outputHistory.get(checkId);
        arr.push(payload);
        if (limit && arr.length > limit) {
          arr.splice(0, arr.length - limit);
        }
      }
    }
  } catch (error) {
    logger.debug(`[LevelDispatch] Error building output history: ${error}`);
  }
  return outputHistory;
}
var init_history_snapshot = __esm({
  "src/state-machine/dispatch/history-snapshot.ts"() {
    "use strict";
    init_logger();
  }
});

// src/state-machine/dispatch/dependency-gating.ts
function buildDependencyResultsWithScope(checkId, checkConfig, context2, scope) {
  const dependencyResults = /* @__PURE__ */ new Map();
  const dependencies = checkConfig.depends_on || [];
  const depList = Array.isArray(dependencies) ? dependencies : [dependencies];
  const currentIndex = scope.length > 0 ? scope[scope.length - 1].index : void 0;
  for (const depId of depList) {
    if (!depId) continue;
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const visible = context2.journal.readVisible(
        context2.sessionId,
        snapshotId,
        context2.event
      );
      const sameScope = (a, b) => {
        if (a.length !== b.length) return false;
        for (let i = 0; i < a.length; i++)
          if (a[i].check !== b[i].check || a[i].index !== b[i].index) return false;
        return true;
      };
      const matches = visible.filter((e) => e.checkId === depId && sameScope(e.scope, scope));
      let journalResult = matches.length > 0 ? matches[matches.length - 1].result : void 0;
      if (journalResult && Array.isArray(journalResult.forEachItems) && currentIndex !== void 0) {
        const perItemSummary = journalResult.forEachItemResults && journalResult.forEachItemResults[currentIndex] || { issues: [] };
        const perItemOutput = journalResult.forEachItems[currentIndex];
        const combined = { ...perItemSummary, output: perItemOutput };
        dependencyResults.set(depId, combined);
        continue;
      }
      if (!journalResult) {
        try {
          const { ContextView: ContextView2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
          const rawContextView = new ContextView2(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            context2.event
          );
          const raw = rawContextView.get(depId);
          if (raw && Array.isArray(raw.forEachItems) && currentIndex !== void 0) {
            const perItemSummary = raw.forEachItemResults && raw.forEachItemResults[currentIndex] || { issues: [] };
            const perItemOutput = raw.forEachItems[currentIndex];
            journalResult = { ...perItemSummary, output: perItemOutput };
          }
        } catch {
        }
      }
      if (journalResult) {
        dependencyResults.set(depId, journalResult);
      }
    } catch {
    }
  }
  try {
    const snapshotId = context2.journal.beginSnapshot();
    const allEntries = context2.journal.readVisible(
      context2.sessionId,
      snapshotId,
      context2.event
    );
    const allCheckNames = Array.from(new Set(allEntries.map((e) => e.checkId)));
    for (const checkName of allCheckNames) {
      try {
        const { ContextView: ContextView2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
        const rawContextView = new ContextView2(
          context2.journal,
          context2.sessionId,
          snapshotId,
          scope,
          context2.event
        );
        const jr = rawContextView.get(checkName);
        if (jr) dependencyResults.set(checkName, jr);
      } catch {
      }
    }
    for (const checkName of allCheckNames) {
      const checkCfg = context2.config.checks?.[checkName];
      if (checkCfg?.forEach) {
        try {
          const { ContextView: ContextView2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
          const rawContextView = new ContextView2(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            context2.event
          );
          const rawResult = rawContextView.get(checkName);
          if (rawResult && rawResult.forEachItems) {
            const rawKey = `${checkName}-raw`;
            dependencyResults.set(rawKey, {
              issues: [],
              output: rawResult.forEachItems
            });
          }
        } catch {
        }
      }
    }
  } catch {
  }
  return dependencyResults;
}
var init_dependency_gating = __esm({
  "src/state-machine/dispatch/dependency-gating.ts"() {
    "use strict";
  }
});

// src/liquid-extensions.ts
var liquid_extensions_exports = {};
__export(liquid_extensions_exports, {
  ReadFileTag: () => ReadFileTag,
  configureLiquidWithExtensions: () => configureLiquidWithExtensions,
  createExtendedLiquid: () => createExtendedLiquid,
  sanitizeLabel: () => sanitizeLabel,
  sanitizeLabelList: () => sanitizeLabelList,
  withPermissionsContext: () => withPermissionsContext
});
function sanitizeLabel(value) {
  if (value == null) return "";
  const s = String(value);
  return s.replace(/[^A-Za-z0-9:\/\- ]/g, "").replace(/\/{2,}/g, "/").trim();
}
function sanitizeLabelList(labels) {
  if (!Array.isArray(labels)) return [];
  return labels.map((v) => sanitizeLabel(v)).filter((s) => s.length > 0);
}
async function withPermissionsContext(ctx, fn) {
  return await permissionsALS.run(ctx, fn);
}
function configureLiquidWithExtensions(liquid) {
  liquid.registerTag("readfile", ReadFileTag);
  liquid.registerFilter("parse_json", (value) => {
    if (typeof value !== "string") {
      return value;
    }
    try {
      return JSON.parse(value);
    } catch {
      return value;
    }
  });
  liquid.registerFilter("to_json", (value) => {
    try {
      return JSON.stringify(value);
    } catch {
      return "[Error: Unable to serialize to JSON]";
    }
  });
  liquid.registerFilter("base64", (value) => {
    if (value == null) return "";
    const str = String(value);
    return Buffer.from(str).toString("base64");
  });
  liquid.registerFilter("base64_decode", (value) => {
    if (value == null) return "";
    const str = String(value);
    try {
      return Buffer.from(str, "base64").toString("utf-8");
    } catch {
      return "[Error: Invalid base64 string]";
    }
  });
  liquid.registerFilter("safe_label", (value) => sanitizeLabel(value));
  liquid.registerFilter("safe_label_list", (value) => sanitizeLabelList(value));
  liquid.registerFilter("unescape_newlines", (value) => {
    if (value == null) return "";
    const s = String(value);
    return s.replace(/\\n/g, "\n").replace(/\\r/g, "\r").replace(/\\t/g, "	");
  });
  liquid.registerFilter("json_escape", (value) => {
    if (value == null) return "";
    const s = String(value);
    const jsonStr = JSON.stringify(s);
    return jsonStr.slice(1, -1);
  });
  liquid.registerFilter("shell_escape", (value) => {
    if (value == null) return "''";
    const s = String(value);
    return "'" + s.replace(/'/g, "'\\''") + "'";
  });
  liquid.registerFilter("escape_shell", (value) => {
    if (value == null) return "''";
    const s = String(value);
    return "'" + s.replace(/'/g, "'\\''") + "'";
  });
  liquid.registerFilter("shell_escape_double", (value) => {
    if (value == null) return '""';
    const s = String(value);
    const escaped = s.replace(/\\/g, "\\\\").replace(/\$/g, "\\$").replace(/`/g, "\\`").replace(/"/g, '\\"').replace(/!/g, "\\!");
    return '"' + escaped + '"';
  });
  const isLocal = detectLocalMode();
  const resolveAssoc = (val) => {
    if (typeof val === "string" && val.length > 0) return val;
    const store = permissionsALS.getStore();
    return store?.authorAssociation;
  };
  liquid.registerFilter("has_min_permission", (authorAssociation, level) => {
    return hasMinPermission(resolveAssoc(authorAssociation), level, isLocal);
  });
  liquid.registerFilter("is_owner", (authorAssociation) => {
    return isOwner(resolveAssoc(authorAssociation), isLocal);
  });
  liquid.registerFilter("is_member", (authorAssociation) => {
    return isMember(resolveAssoc(authorAssociation), isLocal);
  });
  liquid.registerFilter("is_collaborator", (authorAssociation) => {
    return isCollaborator(resolveAssoc(authorAssociation), isLocal);
  });
  liquid.registerFilter("is_contributor", (authorAssociation) => {
    return isContributor(resolveAssoc(authorAssociation), isLocal);
  });
  liquid.registerFilter("is_first_timer", (authorAssociation) => {
    return isFirstTimer(resolveAssoc(authorAssociation), isLocal);
  });
  const memoryStore = MemoryStore.getInstance();
  liquid.registerFilter("memory_get", (key, namespace) => {
    if (typeof key !== "string") {
      return void 0;
    }
    return memoryStore.get(key, namespace);
  });
  liquid.registerFilter("memory_has", (key, namespace) => {
    if (typeof key !== "string") {
      return false;
    }
    const has = memoryStore.has(key, namespace);
    try {
      if (process.env.VISOR_DEBUG === "true" && key === "fact_validation_issues") {
        console.error(
          `[liquid] memory_has('${key}', ns='${namespace || memoryStore.getDefaultNamespace()}') => ${String(
            has
          )}`
        );
      }
    } catch {
    }
    return has;
  });
  liquid.registerFilter("memory_list", (namespace) => {
    return memoryStore.list(namespace);
  });
  liquid.registerFilter("get", (obj, pathExpr) => {
    if (obj == null) return void 0;
    const path22 = typeof pathExpr === "string" ? pathExpr : String(pathExpr || "");
    if (!path22) return obj;
    const parts = path22.split(".");
    let cur = obj;
    for (const p of parts) {
      if (cur == null) return void 0;
      cur = cur[p];
    }
    return cur;
  });
  liquid.registerFilter("not_empty", (v) => {
    if (Array.isArray(v)) return v.length > 0;
    if (typeof v === "string") return v.length > 0;
    if (v && typeof v === "object") return Object.keys(v).length > 0;
    return false;
  });
  liquid.registerFilter("coalesce", (first, ...rest) => {
    const all = [first, ...rest];
    for (const v of all) {
      if (Array.isArray(v) && v.length > 0) return v;
      if (typeof v === "string" && v.length > 0) return v;
      if (v && typeof v === "object" && Object.keys(v).length > 0) return v;
    }
    return Array.isArray(first) ? [] : first ?? void 0;
  });
  liquid.registerFilter("where_exp", (items, varName, expr) => {
    const arr = Array.isArray(items) ? items : [];
    const name = typeof varName === "string" && varName.trim() ? varName.trim() : "i";
    const body = String(expr || "");
    try {
      const fn = new Function(
        name,
        "idx",
        "arr",
        `try { return (${body}); } catch { return false; }`
      );
      const out = [];
      for (let idx = 0; idx < arr.length; idx++) {
        const i = arr[idx];
        let ok = false;
        try {
          ok = !!fn(i, idx, arr);
        } catch {
          ok = false;
        }
        if (ok) out.push(i);
      }
      return out;
    } catch {
      return [];
    }
  });
  liquid.registerFilter(
    "chat_history",
    function(value, ...args) {
      try {
        const impl = this;
        const ctx = impl?.context;
        const allArgs = Array.isArray(args) ? args : [];
        if (allArgs.length === 0) {
          return [];
        }
        const positional = [];
        const options = {};
        for (const arg of allArgs) {
          if (Array.isArray(arg) && arg.length === 2 && typeof arg[0] === "string" && arg[0].length > 0) {
            options[arg[0]] = arg[1];
          } else {
            positional.push(arg);
          }
        }
        const stepArgs = positional;
        const steps = stepArgs.map((s) => String(s ?? "").trim()).filter((s) => s.length > 0);
        if (steps.length === 0) return [];
        const outputsHistoryVar = ctx?.get(["outputs_history"]) || {};
        const outputsVar = ctx?.get(["outputs"]) || {};
        const outputsHistory = outputsHistoryVar && Object.keys(outputsHistoryVar).length > 0 ? outputsHistoryVar : outputsVar?.history || {};
        const checksMeta = ctx?.get(["checks_meta"]) || ctx?.get(["event"])?.payload?.__checksMeta || void 0;
        const directionRaw = typeof options.direction === "string" ? options.direction.toLowerCase() : "";
        const direction = directionRaw === "desc" ? "desc" : "asc";
        const limit = typeof options.limit === "number" && options.limit > 0 ? Math.floor(options.limit) : void 0;
        const textCfg = options.text && typeof options.text === "object" ? options.text : {};
        const defaultField = typeof textCfg.default_field === "string" && textCfg.default_field.trim() ? textCfg.default_field.trim() : "text";
        const byStepText = {};
        if (textCfg.by_step && typeof textCfg.by_step === "object") {
          for (const [k, v] of Object.entries(textCfg.by_step)) {
            if (typeof v === "string" && v.trim()) {
              byStepText[k] = v.trim();
            }
          }
        }
        const rolesCfg = options.roles && typeof options.roles === "object" ? options.roles : {};
        const byTypeRole = {};
        if (rolesCfg.by_type && typeof rolesCfg.by_type === "object") {
          for (const [k, v] of Object.entries(rolesCfg.by_type)) {
            if (typeof v === "string" && v.trim()) {
              byTypeRole[k] = v.trim();
            }
          }
        }
        const byStepRole = {};
        if (rolesCfg.by_step && typeof rolesCfg.by_step === "object") {
          for (const [k, v] of Object.entries(rolesCfg.by_step)) {
            if (typeof v === "string" && v.trim()) {
              byStepRole[k] = v.trim();
            }
          }
        }
        if (typeof options.role_map === "string" && options.role_map.trim().length > 0) {
          const parts = String(options.role_map).split(",").map((p) => p.trim()).filter(Boolean);
          for (const part of parts) {
            const eqIdx = part.indexOf("=");
            if (eqIdx > 0) {
              const k = part.slice(0, eqIdx).trim();
              const v = part.slice(eqIdx + 1).trim();
              if (k && v) {
                byStepRole[k] = v;
              }
            }
          }
        }
        const defaultRole = typeof rolesCfg.default === "string" && rolesCfg.default.trim() ? rolesCfg.default.trim() : void 0;
        const getNested = (obj, path22) => {
          if (!obj || !path22) return void 0;
          const parts = path22.split(".");
          let cur = obj;
          for (const p of parts) {
            if (cur == null) return void 0;
            cur = cur[p];
          }
          return cur;
        };
        const normalizeText = (step, raw) => {
          try {
            const overrideField = byStepText[step];
            if (overrideField) {
              const val = getNested(raw, overrideField);
              if (val !== void 0 && val !== null) {
                const s = String(val);
                if (s.trim().length > 0) return s;
              }
            }
            if (raw && typeof raw === "object") {
              if (typeof raw.text === "string" && raw.text.trim().length > 0) {
                return raw.text;
              }
              if (typeof raw.content === "string" && raw.content.trim().length > 0) {
                return raw.content;
              }
              const dfVal = raw[defaultField];
              if (dfVal !== void 0 && dfVal !== null) {
                const s = String(dfVal);
                if (s.trim().length > 0) return s;
              }
            }
            if (typeof raw === "string") return raw;
            if (raw == null) return "";
            try {
              return JSON.stringify(raw);
            } catch {
              return String(raw);
            }
          } catch {
            if (typeof raw === "string") return raw;
            return "";
          }
        };
        const normalizeRole = (step) => {
          try {
            if (byStepRole[step]) return byStepRole[step];
            const meta = checksMeta ? checksMeta[step] : void 0;
            const type = meta?.type;
            if (type && byTypeRole[type]) return byTypeRole[type];
            if (type === "human-input") return "user";
            if (type === "ai") return "assistant";
            if (defaultRole) return defaultRole;
            if (type) {
              if (type === "human-input") return "user";
              if (type === "ai") return "assistant";
            }
          } catch {
          }
          return "assistant";
        };
        const messages = [];
        const tsBase = Date.now();
        let counter = 0;
        for (const step of steps) {
          const arr = outputsHistory?.[step];
          if (!Array.isArray(arr)) continue;
          for (const raw of arr) {
            let ts;
            if (raw && typeof raw === "object" && typeof raw.ts === "number") {
              ts = raw.ts;
            }
            if (!Number.isFinite(ts)) {
              ts = tsBase + counter++;
            }
            const text = normalizeText(step, raw);
            const role = normalizeRole(step);
            messages.push({ step, role, text, ts, raw });
          }
        }
        messages.sort((a, b) => a.ts - b.ts);
        if (direction === "desc") {
          messages.reverse();
        }
        if (limit && limit > 0 && messages.length > limit) {
          if (direction === "asc") {
            return messages.slice(messages.length - limit);
          }
          return messages.slice(0, limit);
        }
        return messages;
      } catch {
        return [];
      }
    }
  );
}
function createExtendedLiquid(options = {}) {
  const liquid = new import_liquidjs.Liquid({
    cache: false,
    strictFilters: false,
    strictVariables: false,
    ...options
  });
  configureLiquidWithExtensions(liquid);
  return liquid;
}
var import_liquidjs, import_async_hooks, import_promises2, import_path2, ReadFileTag, permissionsALS;
var init_liquid_extensions = __esm({
  "src/liquid-extensions.ts"() {
    "use strict";
    import_liquidjs = require("liquidjs");
    import_async_hooks = require("async_hooks");
    import_promises2 = __toESM(require("fs/promises"));
    import_path2 = __toESM(require("path"));
    init_author_permissions();
    init_memory_store();
    ReadFileTag = class extends import_liquidjs.Tag {
      filepath;
      constructor(token, remainTokens, liquid) {
        super(token, remainTokens, liquid);
        this.filepath = new import_liquidjs.Value(token.args, liquid);
      }
      *render(ctx, emitter) {
        const filePath = yield this.filepath.value(ctx, false);
        if (!filePath || typeof filePath !== "string") {
          emitter.write("[Error: Invalid file path]");
          return;
        }
        const projectRoot = process.cwd();
        const resolvedPath = import_path2.default.resolve(projectRoot, filePath.toString());
        if (!resolvedPath.startsWith(projectRoot)) {
          emitter.write("[Error: File path escapes project directory]");
          return;
        }
        try {
          const content = yield import_promises2.default.readFile(resolvedPath, "utf-8");
          emitter.write(content);
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : error?.code || "Unknown error";
          emitter.write(`[Error reading file: ${errorMessage}]`);
        }
      }
    };
    permissionsALS = new import_async_hooks.AsyncLocalStorage();
  }
});

// src/state-machine/dispatch/template-renderer.ts
async function renderTemplateContent(checkId, checkConfig, reviewSummary) {
  try {
    const { createExtendedLiquid: createExtendedLiquid2 } = await Promise.resolve().then(() => (init_liquid_extensions(), liquid_extensions_exports));
    const fs20 = await import("fs/promises");
    const path22 = await import("path");
    const schemaRaw = checkConfig.schema || "plain";
    const schema = typeof schemaRaw === "string" ? schemaRaw : "code-review";
    let templateContent;
    if (checkConfig.template && checkConfig.template.content) {
      templateContent = String(checkConfig.template.content);
    } else if (checkConfig.template && checkConfig.template.file) {
      const file = String(checkConfig.template.file);
      const resolved = path22.resolve(process.cwd(), file);
      templateContent = await fs20.readFile(resolved, "utf-8");
    } else if (schema && schema !== "plain") {
      const sanitized = String(schema).replace(/[^a-zA-Z0-9-]/g, "");
      if (sanitized) {
        const candidatePaths = [
          path22.join(__dirname, "output", sanitized, "template.liquid"),
          // bundled: dist/output/
          path22.join(__dirname, "..", "..", "output", sanitized, "template.liquid"),
          // source: output/
          path22.join(process.cwd(), "output", sanitized, "template.liquid"),
          // fallback: cwd/output/
          path22.join(process.cwd(), "dist", "output", sanitized, "template.liquid")
          // fallback: cwd/dist/output/
        ];
        for (const p of candidatePaths) {
          try {
            templateContent = await fs20.readFile(p, "utf-8");
            if (templateContent) break;
          } catch {
          }
        }
      }
    }
    if (!templateContent) return void 0;
    const liquid = createExtendedLiquid2({
      trimTagLeft: false,
      trimTagRight: false,
      trimOutputLeft: false,
      trimOutputRight: false,
      greedy: false
    });
    let output = reviewSummary.output;
    if (typeof output === "string") {
      const trimmed = output.trim();
      if (trimmed.startsWith("{") || trimmed.startsWith("[")) {
        try {
          output = JSON.parse(trimmed);
        } catch {
        }
      }
    }
    const templateData = {
      issues: reviewSummary.issues || [],
      checkName: checkId,
      output
    };
    const rendered = await liquid.parseAndRender(templateContent, templateData);
    return rendered.trim();
  } catch (error) {
    const msg = error instanceof Error ? error.message : String(error);
    logger.error(`[LevelDispatch] Failed to render template for ${checkId}: ${msg}`);
    return void 0;
  }
}
var init_template_renderer = __esm({
  "src/state-machine/dispatch/template-renderer.ts"() {
    "use strict";
    init_logger();
  }
});

// src/state-machine/dispatch/stats-manager.ts
function hasFatalIssues(result) {
  if (!result.issues) return false;
  return result.issues.some((issue) => {
    const ruleId = issue.ruleId || "";
    return ruleId.endsWith("/error") || ruleId.includes("/execution_error") || ruleId.endsWith("_fail_if");
  });
}
function updateStats(results, state, isForEachIteration = false) {
  for (const { checkId, result, error, duration } of results) {
    const existing = state.stats.get(checkId);
    const stats = existing || {
      checkName: checkId,
      totalRuns: 0,
      successfulRuns: 0,
      failedRuns: 0,
      skippedRuns: 0,
      skipped: false,
      totalDuration: 0,
      issuesFound: 0,
      issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
    };
    const skippedMarker = result.__skipped;
    if (skippedMarker) {
      stats.skipped = true;
      stats.skipReason = typeof skippedMarker === "string" ? skippedMarker : stats.skipReason || "if_condition";
      stats.totalRuns = 0;
      stats.successfulRuns = 0;
      stats.failedRuns = 0;
      stats.skippedRuns++;
      state.stats.set(checkId, stats);
      continue;
    }
    if (stats.skipped) {
      stats.skipped = false;
      stats.skippedRuns = 0;
      stats.skipReason = void 0;
      stats.skipCondition = void 0;
    }
    stats.totalRuns++;
    if (typeof duration === "number" && Number.isFinite(duration)) {
      stats.totalDuration += duration;
    }
    const hasExecutionFailure = !!error || hasFatalIssues(result);
    if (error) {
      stats.failedRuns++;
    } else if (hasExecutionFailure) {
      stats.failedRuns++;
      if (!isForEachIteration) {
        state.failedChecks = state.failedChecks || /* @__PURE__ */ new Set();
        state.failedChecks.add(checkId);
      }
    } else {
      stats.successfulRuns++;
    }
    if (result.issues) {
      stats.issuesFound += result.issues.length;
      for (const issue of result.issues) {
        if (issue.severity === "critical") stats.issuesBySeverity.critical++;
        else if (issue.severity === "error") stats.issuesBySeverity.error++;
        else if (issue.severity === "warning") stats.issuesBySeverity.warning++;
        else if (issue.severity === "info") stats.issuesBySeverity.info++;
      }
    }
    if (stats.outputsProduced === void 0) {
      const forEachItems = result.forEachItems;
      if (Array.isArray(forEachItems)) stats.outputsProduced = forEachItems.length;
      else if (result.output !== void 0) stats.outputsProduced = 1;
    }
    state.stats.set(checkId, stats);
  }
}
var init_stats_manager = __esm({
  "src/state-machine/dispatch/stats-manager.ts"() {
    "use strict";
  }
});

// src/providers/check-provider.interface.ts
var CheckProvider;
var init_check_provider_interface = __esm({
  "src/providers/check-provider.interface.ts"() {
    "use strict";
    CheckProvider = class {
    };
  }
});

// src/utils/tracer-init.ts
var tracer_init_exports = {};
__export(tracer_init_exports, {
  initializeTracer: () => initializeTracer
});
async function initializeTracer(sessionId, checkName) {
  try {
    let ProbeLib;
    try {
      ProbeLib = await import("@probelabs/probe");
    } catch {
      try {
        ProbeLib = require("@probelabs/probe");
      } catch {
        ProbeLib = {};
      }
    }
    const SimpleTelemetry = ProbeLib?.SimpleTelemetry;
    const SimpleAppTracer = ProbeLib?.SimpleAppTracer;
    if (SimpleTelemetry && SimpleAppTracer) {
      const sanitizedCheckName = checkName ? path5.basename(checkName) : "check";
      const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
      const traceDir = process.env.GITHUB_WORKSPACE ? path5.join(process.env.GITHUB_WORKSPACE, "debug-artifacts") : path5.join(process.cwd(), "debug-artifacts");
      if (!fs5.existsSync(traceDir)) {
        fs5.mkdirSync(traceDir, { recursive: true });
      }
      const traceFilePath = path5.join(traceDir, `trace-${sanitizedCheckName}-${timestamp}.jsonl`);
      const resolvedTracePath = path5.resolve(traceFilePath);
      const resolvedTraceDir = path5.resolve(traceDir);
      if (!resolvedTracePath.startsWith(resolvedTraceDir)) {
        console.error(
          `\u26A0\uFE0F Security: Attempted path traversal detected. Check name: ${checkName}, resolved path: ${resolvedTracePath}`
        );
        return null;
      }
      const telemetry = new SimpleTelemetry({
        enableFile: true,
        filePath: traceFilePath,
        enableConsole: false
      });
      const tracer = new SimpleAppTracer(telemetry, sessionId);
      if (typeof tracer.recordEvent !== "function") {
        tracer.recordEvent = (name, attributes) => {
          try {
            if (telemetry.record) {
              telemetry.record({ event: name, ...attributes });
            }
          } catch {
          }
        };
      }
      console.error(`\u{1F4CA} Simple tracing enabled, will save to: ${traceFilePath}`);
      if (process.env.GITHUB_ACTIONS) {
        console.log(`::notice title=AI Trace::Trace will be saved to ${traceFilePath}`);
        console.log(`::set-output name=trace-path::${traceFilePath}`);
      }
      return {
        tracer,
        telemetryConfig: telemetry,
        filePath: traceFilePath
      };
    }
    console.error("\u26A0\uFE0F Telemetry classes not available in ProbeAgent, skipping tracing");
    return null;
  } catch (error) {
    console.error("\u26A0\uFE0F Warning: Failed to initialize tracing:", error);
    return null;
  }
}
var path5, fs5;
var init_tracer_init = __esm({
  "src/utils/tracer-init.ts"() {
    "use strict";
    path5 = __toESM(require("path"));
    fs5 = __toESM(require("fs"));
  }
});

// src/session-registry.ts
var session_registry_exports = {};
__export(session_registry_exports, {
  SessionRegistry: () => SessionRegistry
});
var SessionRegistry;
var init_session_registry = __esm({
  "src/session-registry.ts"() {
    "use strict";
    SessionRegistry = class _SessionRegistry {
      static instance;
      sessions = /* @__PURE__ */ new Map();
      exitHandlerRegistered = false;
      constructor() {
        this.registerExitHandlers();
      }
      /**
       * Get the singleton instance of SessionRegistry
       */
      static getInstance() {
        if (!_SessionRegistry.instance) {
          _SessionRegistry.instance = new _SessionRegistry();
        }
        return _SessionRegistry.instance;
      }
      /**
       * Register a ProbeAgent session
       */
      registerSession(sessionId, agent) {
        console.error(`\u{1F504} Registering AI session: ${sessionId}`);
        this.sessions.set(sessionId, agent);
      }
      /**
       * Get an existing ProbeAgent session
       */
      getSession(sessionId) {
        const agent = this.sessions.get(sessionId);
        if (agent) {
          console.error(`\u267B\uFE0F  Reusing AI session: ${sessionId}`);
        }
        return agent;
      }
      /**
       * Remove a session from the registry
       */
      unregisterSession(sessionId) {
        if (this.sessions.has(sessionId)) {
          console.error(`\u{1F5D1}\uFE0F  Unregistering AI session: ${sessionId}`);
          const agent = this.sessions.get(sessionId);
          this.sessions.delete(sessionId);
          if (agent && typeof agent.cleanup === "function") {
            try {
              agent.cleanup();
            } catch (error) {
              console.error(`\u26A0\uFE0F  Warning: Failed to cleanup ProbeAgent: ${error}`);
            }
          }
        }
      }
      /**
       * Clear all sessions (useful for cleanup)
       */
      clearAllSessions() {
        console.error(`\u{1F9F9} Clearing all AI sessions (${this.sessions.size} sessions)`);
        for (const [, agent] of this.sessions.entries()) {
          if (agent && typeof agent.cleanup === "function") {
            try {
              agent.cleanup();
            } catch {
            }
          }
        }
        this.sessions.clear();
      }
      /**
       * Get all active session IDs
       */
      getActiveSessionIds() {
        return Array.from(this.sessions.keys());
      }
      /**
       * Check if a session exists
       */
      hasSession(sessionId) {
        return this.sessions.has(sessionId);
      }
      /**
       * Clone a session with a new session ID using ProbeAgent's official clone() method
       * This uses ProbeAgent's built-in cloning which automatically handles:
       * - Intelligent filtering of internal messages (schema reminders, tool prompts, etc.)
       * - Preserving system message for cache efficiency
       * - Deep copying conversation history
       * - Copying agent configuration
       */
      async cloneSession(sourceSessionId, newSessionId, checkName) {
        const sourceAgent = this.sessions.get(sourceSessionId);
        if (!sourceAgent) {
          console.error(`\u26A0\uFE0F  Cannot clone session: ${sourceSessionId} not found`);
          return void 0;
        }
        try {
          const clonedAgent = sourceAgent.clone({
            sessionId: newSessionId,
            stripInternalMessages: true,
            // Remove schema reminders, tool prompts, etc.
            keepSystemMessage: true,
            // Keep for cache efficiency
            deepCopy: true
            // Safe deep copy of history
          });
          if (sourceAgent.debug && checkName) {
            try {
              const { initializeTracer: initializeTracer2 } = await Promise.resolve().then(() => (init_tracer_init(), tracer_init_exports));
              const tracerResult = await initializeTracer2(newSessionId, checkName);
              if (tracerResult) {
                clonedAgent.tracer = tracerResult.tracer;
                clonedAgent._telemetryConfig = tracerResult.telemetryConfig;
                clonedAgent._traceFilePath = tracerResult.filePath;
              }
            } catch (traceError) {
              console.error(
                "\u26A0\uFE0F  Warning: Failed to initialize tracing for cloned session:",
                traceError
              );
            }
          }
          if (sourceAgent._mcpInitialized && typeof clonedAgent.initialize === "function") {
            try {
              await clonedAgent.initialize();
              console.error(`\u{1F527} Initialized MCP tools for cloned session`);
            } catch (initError) {
              console.error(`\u26A0\uFE0F  Warning: Failed to initialize cloned agent: ${initError}`);
            }
          }
          const historyLength = clonedAgent.history?.length || 0;
          console.error(
            `\u{1F4CB} Cloned session ${sourceSessionId} \u2192 ${newSessionId} using ProbeAgent.clone() (${historyLength} messages, internal messages filtered)`
          );
          this.registerSession(newSessionId, clonedAgent);
          return clonedAgent;
        } catch (error) {
          console.error(`\u26A0\uFE0F  Failed to clone session ${sourceSessionId}:`, error);
          return void 0;
        }
      }
      /**
       * Register process exit handlers to cleanup sessions on exit
       */
      registerExitHandlers() {
        if (this.exitHandlerRegistered) {
          return;
        }
        const cleanupAndExit = (signal) => {
          if (this.sessions.size > 0) {
            console.error(`
\u{1F9F9} [${signal}] Cleaning up ${this.sessions.size} active AI sessions...`);
            this.clearAllSessions();
          }
        };
        process.on("exit", () => {
          if (this.sessions.size > 0) {
            console.error(`\u{1F9F9} [exit] Cleaning up ${this.sessions.size} active AI sessions...`);
            for (const [, agent] of this.sessions.entries()) {
              if (agent && typeof agent.cleanup === "function") {
                try {
                  agent.cleanup();
                } catch {
                }
              }
            }
            this.sessions.clear();
          }
        });
        process.on("SIGINT", () => {
          cleanupAndExit("SIGINT");
          process.exit(0);
        });
        process.on("SIGTERM", () => {
          cleanupAndExit("SIGTERM");
          process.exit(0);
        });
        this.exitHandlerRegistered = true;
      }
    };
  }
});

// src/utils/diff-processor.ts
async function processDiffWithOutline(diffContent) {
  if (!diffContent || diffContent.trim().length === 0) {
    return diffContent;
  }
  try {
    const originalProbePath = process.env.PROBE_PATH;
    const fs20 = require("fs");
    const possiblePaths = [
      // Relative to current working directory (most common in production)
      path6.join(process.cwd(), "node_modules/@probelabs/probe/bin/probe-binary"),
      // Relative to __dirname (for unbundled development)
      path6.join(__dirname, "../..", "node_modules/@probelabs/probe/bin/probe-binary"),
      // Relative to dist directory (for bundled CLI)
      path6.join(__dirname, "node_modules/@probelabs/probe/bin/probe-binary")
    ];
    let probeBinaryPath;
    for (const candidatePath of possiblePaths) {
      if (fs20.existsSync(candidatePath)) {
        probeBinaryPath = candidatePath;
        break;
      }
    }
    if (!probeBinaryPath) {
      if (process.env.DEBUG === "1" || process.env.VERBOSE === "1") {
        console.error("Probe binary not found. Tried:", possiblePaths);
      }
      return diffContent;
    }
    process.env.PROBE_PATH = probeBinaryPath;
    const extractPromise = (0, import_probe.extract)({
      content: diffContent,
      format: "outline-diff",
      allowTests: true
      // Allow test files and test code blocks in extraction results
    });
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error("Extract timeout after 30s")), 3e4);
    });
    const result = await Promise.race([extractPromise, timeoutPromise]);
    if (originalProbePath !== void 0) {
      process.env.PROBE_PATH = originalProbePath;
    } else {
      delete process.env.PROBE_PATH;
    }
    return typeof result === "string" ? result : JSON.stringify(result);
  } catch (error) {
    if (process.env.DEBUG === "1" || process.env.VERBOSE === "1") {
      console.error("Failed to process diff with outline-diff format:", error);
    }
    return diffContent;
  }
}
var import_probe, path6;
var init_diff_processor = __esm({
  "src/utils/diff-processor.ts"() {
    "use strict";
    import_probe = require("@probelabs/probe");
    path6 = __toESM(require("path"));
  }
});

// src/utils/comment-metadata.ts
function parseVisorThreadMetadata(commentBody) {
  const headerRe = /<!--\s*visor:thread=(\{[\s\S]*?\})\s*-->/m;
  const match = headerRe.exec(commentBody);
  if (!match) {
    return null;
  }
  try {
    const metadata = JSON.parse(match[1]);
    return metadata && typeof metadata === "object" && !Array.isArray(metadata) ? metadata : null;
  } catch {
    return null;
  }
}
function shouldFilterVisorReviewComment(commentBody) {
  if (!commentBody) {
    return false;
  }
  if (commentBody.includes("visor-comment-id:pr-review-")) {
    return true;
  }
  const metadata = parseVisorThreadMetadata(commentBody);
  if (metadata && metadata.group === "review") {
    return true;
  }
  return false;
}
var init_comment_metadata = __esm({
  "src/utils/comment-metadata.ts"() {
    "use strict";
  }
});

// src/ai-review-service.ts
function log(...args) {
  logger.debug(args.join(" "));
}
function createProbeTracerAdapter(fallbackTracer) {
  const fallback = fallbackTracer && typeof fallbackTracer === "object" ? fallbackTracer : null;
  const emitEvent = (name, attrs) => {
    try {
      const span = trace.getActiveSpan();
      if (span && typeof span.addEvent === "function") {
        span.addEvent(name, attrs);
      }
    } catch {
    }
  };
  return {
    withSpan: async (name, fn, attrs) => withActiveSpan(name, attrs, async (span) => {
      if (fallback && typeof fallback.withSpan === "function") {
        return await fallback.withSpan(name, async () => fn(span), attrs);
      }
      return await fn(span);
    }),
    recordEvent: (name, attrs) => {
      emitEvent(name, attrs);
      if (fallback && typeof fallback.recordEvent === "function") {
        try {
          fallback.recordEvent(name, attrs);
        } catch {
        }
      }
    },
    addEvent: (name, attrs) => {
      emitEvent(name, attrs);
      if (fallback && typeof fallback.addEvent === "function") {
        try {
          fallback.addEvent(name, attrs);
        } catch {
        }
      } else if (fallback && typeof fallback.recordEvent === "function") {
        try {
          fallback.recordEvent(name, attrs);
        } catch {
        }
      }
    },
    recordDelegationEvent: (phase, attrs) => {
      emitEvent(`delegation.${phase}`, attrs);
      if (fallback && typeof fallback.recordDelegationEvent === "function") {
        try {
          fallback.recordDelegationEvent(phase, attrs);
        } catch {
        }
      }
    },
    recordMermaidValidationEvent: (phase, attrs) => {
      emitEvent(`mermaid.${phase}`, attrs);
      if (fallback && typeof fallback.recordMermaidValidationEvent === "function") {
        try {
          fallback.recordMermaidValidationEvent(phase, attrs);
        } catch {
        }
      }
    },
    recordJsonValidationEvent: (phase, attrs) => {
      emitEvent(`json.${phase}`, attrs);
      if (fallback && typeof fallback.recordJsonValidationEvent === "function") {
        try {
          fallback.recordJsonValidationEvent(phase, attrs);
        } catch {
        }
      }
    },
    createDelegationSpan: (sessionId, task) => {
      let fallbackSpan = null;
      if (fallback && typeof fallback.createDelegationSpan === "function") {
        try {
          fallbackSpan = fallback.createDelegationSpan(sessionId, task);
        } catch {
        }
      }
      let span = null;
      try {
        const tracer = trace.getTracer("visor");
        span = tracer.startSpan("probe.delegation", {
          attributes: {
            "delegation.session_id": sessionId,
            "delegation.task": task
          }
        });
      } catch {
      }
      if (!span && fallbackSpan) return fallbackSpan;
      if (!span) return null;
      return {
        setAttributes: (attrs) => {
          try {
            if (attrs) span.setAttributes(attrs);
          } catch {
          }
          if (fallbackSpan && typeof fallbackSpan.setAttributes === "function") {
            try {
              fallbackSpan.setAttributes(attrs);
            } catch {
            }
          }
        },
        setStatus: (status) => {
          try {
            span.setStatus(status);
          } catch {
          }
          if (fallbackSpan && typeof fallbackSpan.setStatus === "function") {
            try {
              fallbackSpan.setStatus(status);
            } catch {
            }
          }
        },
        end: () => {
          try {
            span.end();
          } catch {
          }
          if (fallbackSpan && typeof fallbackSpan.end === "function") {
            try {
              fallbackSpan.end();
            } catch {
            }
          }
        }
      };
    },
    flush: async () => {
      if (fallback && typeof fallback.flush === "function") {
        await fallback.flush();
      }
    },
    shutdown: async () => {
      if (fallback && typeof fallback.shutdown === "function") {
        await fallback.shutdown();
      }
    }
  };
}
var import_probe2, AIReviewService;
var init_ai_review_service = __esm({
  "src/ai-review-service.ts"() {
    "use strict";
    import_probe2 = require("@probelabs/probe");
    init_session_registry();
    init_logger();
    init_lazy_otel();
    init_trace_helpers();
    init_tracer_init();
    init_diff_processor();
    init_comment_metadata();
    AIReviewService = class {
      config;
      sessionRegistry;
      constructor(config = {}) {
        this.config = {
          timeout: 12e5,
          // Increased timeout to 20 minutes for AI responses
          ...config
        };
        this.sessionRegistry = SessionRegistry.getInstance();
        if (typeof this.config.debug === "undefined") {
          try {
            if (process.env.VISOR_PROVIDER_DEBUG === "true" || process.env.VISOR_DEBUG === "true") {
              this.config.debug = true;
            }
          } catch {
          }
        }
        const providerExplicit = typeof this.config.provider === "string" && this.config.provider.length > 0;
        if (!providerExplicit) {
          if (!this.config.apiKey) {
            if (process.env.CLAUDE_CODE_API_KEY) {
              this.config.apiKey = process.env.CLAUDE_CODE_API_KEY;
              this.config.provider = "claude-code";
            } else if (process.env.GOOGLE_API_KEY) {
              this.config.apiKey = process.env.GOOGLE_API_KEY;
              this.config.provider = "google";
            } else if (process.env.ANTHROPIC_API_KEY) {
              this.config.apiKey = process.env.ANTHROPIC_API_KEY;
              this.config.provider = "anthropic";
            } else if (process.env.OPENAI_API_KEY) {
              this.config.apiKey = process.env.OPENAI_API_KEY;
              this.config.provider = "openai";
            } else if (
              // Check for AWS Bedrock credentials
              process.env.AWS_ACCESS_KEY_ID && process.env.AWS_SECRET_ACCESS_KEY || process.env.AWS_BEDROCK_API_KEY
            ) {
              this.config.provider = "bedrock";
              this.config.apiKey = "AWS_CREDENTIALS";
            }
          }
        }
        if (!this.config.model && process.env.MODEL_NAME) {
          this.config.model = process.env.MODEL_NAME;
        }
      }
      // NOTE: per request, no additional redaction/encryption helpers are used.
      /**
       * Execute AI review using probe agent
       */
      async executeReview(prInfo, customPrompt, schema, checkName, sessionId) {
        const startTime = Date.now();
        const timestamp = (/* @__PURE__ */ new Date()).toISOString();
        const cfgAny = this.config;
        const skipTransport = cfgAny?.skip_transport_context === true;
        const skipPRContext = cfgAny?.skip_code_context === true || skipTransport && cfgAny?.skip_code_context !== false;
        const skipSlackContext = cfgAny?.skip_slack_context === true || skipTransport && cfgAny?.skip_slack_context !== false;
        const prompt = await this.buildCustomPrompt(prInfo, customPrompt, schema, {
          skipPRContext,
          skipSlackContext
        });
        log(`Executing AI review with ${this.config.provider} provider...`);
        log(`\u{1F527} Debug: Raw schema parameter: ${JSON.stringify(schema)} (type: ${typeof schema})`);
        log(`Schema type: ${schema || "none (no schema)"}`);
        let debugInfo;
        if (this.config.debug) {
          debugInfo = {
            prompt,
            rawResponse: "",
            provider: this.config.provider || "unknown",
            model: this.config.model || "default",
            apiKeySource: this.getApiKeySource(),
            processingTime: 0,
            promptLength: prompt.length,
            responseLength: 0,
            errors: [],
            jsonParseSuccess: false,
            timestamp,
            schemaName: typeof schema === "object" ? "custom" : schema,
            schema: void 0
            // Will be populated when schema is loaded
          };
        }
        if (this.config.model === "mock" || this.config.provider === "mock") {
          log("\u{1F3AD} Using mock AI model/provider for testing - skipping API key validation");
        } else {
          if (!this.config.apiKey) {
            try {
              if (this.config.provider === "google" && process.env.GOOGLE_API_KEY) {
                this.config.apiKey = process.env.GOOGLE_API_KEY;
              } else if (this.config.provider === "anthropic" && process.env.ANTHROPIC_API_KEY) {
                this.config.apiKey = process.env.ANTHROPIC_API_KEY;
              } else if (this.config.provider === "openai" && process.env.OPENAI_API_KEY) {
                this.config.apiKey = process.env.OPENAI_API_KEY;
              } else if (this.config.provider === "claude-code" && process.env.CLAUDE_CODE_API_KEY) {
                this.config.apiKey = process.env.CLAUDE_CODE_API_KEY;
              }
            } catch {
            }
          }
          if (!this.config.apiKey) {
            log("\u26A0\uFE0F No API key configured - ProbeAgent will attempt CLI fallback (claude-code/codex)");
            if (debugInfo) {
              debugInfo.errors = debugInfo.errors || [];
              debugInfo.errors.push("No API key configured - attempting CLI fallback");
            }
          }
        }
        try {
          const call = this.callProbeAgent(prompt, schema, debugInfo, checkName, sessionId);
          const timeoutMs = Math.max(0, this.config.timeout || 0);
          const {
            response,
            effectiveSchema,
            sessionId: usedSessionId
          } = timeoutMs > 0 ? await this.withTimeout(call, timeoutMs, "AI review") : await call;
          const processingTime = Date.now() - startTime;
          if (debugInfo) {
            debugInfo.rawResponse = response;
            debugInfo.responseLength = response.length;
            debugInfo.processingTime = processingTime;
          }
          const result = this.parseAIResponse(response, debugInfo, effectiveSchema);
          try {
            result.sessionId = usedSessionId;
          } catch {
          }
          if (debugInfo) {
            result.debug = debugInfo;
          }
          return result;
        } catch (error) {
          if (debugInfo) {
            debugInfo.errors = [error instanceof Error ? error.message : String(error)];
            debugInfo.processingTime = Date.now() - startTime;
            return {
              issues: [
                {
                  file: "system",
                  line: 0,
                  ruleId: "system/ai-execution-error",
                  message: error instanceof Error ? error.message : String(error),
                  severity: "error",
                  category: "logic"
                }
              ],
              debug: debugInfo
            };
          }
          throw error;
        }
      }
      /**
       * Execute AI review using session reuse - reuses an existing ProbeAgent session
       * @param sessionMode - 'clone' (default) clones history, 'append' shares history
       */
      async executeReviewWithSessionReuse(prInfo, customPrompt, parentSessionId, schema, checkName, sessionMode = "clone") {
        const startTime = Date.now();
        const timestamp = (/* @__PURE__ */ new Date()).toISOString();
        if (!this.config.apiKey) {
          try {
            if (this.config.provider === "google" && process.env.GOOGLE_API_KEY) {
              this.config.apiKey = process.env.GOOGLE_API_KEY;
            } else if (this.config.provider === "anthropic" && process.env.ANTHROPIC_API_KEY) {
              this.config.apiKey = process.env.ANTHROPIC_API_KEY;
            } else if (this.config.provider === "openai" && process.env.OPENAI_API_KEY) {
              this.config.apiKey = process.env.OPENAI_API_KEY;
            } else if (this.config.provider === "claude-code" && process.env.CLAUDE_CODE_API_KEY) {
              this.config.apiKey = process.env.CLAUDE_CODE_API_KEY;
            }
          } catch {
          }
        }
        const existingAgent = this.sessionRegistry.getSession(parentSessionId);
        if (!existingAgent) {
          throw new Error(
            `Session not found for reuse: ${parentSessionId}. Ensure the parent check completed successfully.`
          );
        }
        const cfgAny = this.config;
        const skipTransport = cfgAny?.skip_transport_context === true;
        const skipSlackContext = cfgAny?.skip_slack_context === true || skipTransport && cfgAny?.skip_slack_context !== false;
        const prompt = await this.buildCustomPrompt(prInfo, customPrompt, schema, {
          // When reusing sessions we always skip PR context, regardless of flags
          skipPRContext: true,
          skipSlackContext
        });
        let agentToUse;
        let currentSessionId;
        if (sessionMode === "clone") {
          currentSessionId = `${checkName}-session-${Date.now()}`;
          log(
            `\u{1F4CB} Cloning AI session ${parentSessionId} \u2192 ${currentSessionId} for ${checkName} check...`
          );
          const clonedAgent = await this.sessionRegistry.cloneSession(
            parentSessionId,
            currentSessionId,
            checkName
            // Pass checkName for tracing
          );
          if (!clonedAgent) {
            throw new Error(`Failed to clone session ${parentSessionId}`);
          }
          agentToUse = clonedAgent;
        } else {
          log(`\u{1F504} Appending to AI session ${parentSessionId} (shared history)...`);
          agentToUse = existingAgent;
          currentSessionId = parentSessionId;
        }
        log(`\u{1F527} Debug: Raw schema parameter: ${JSON.stringify(schema)} (type: ${typeof schema})`);
        log(`\u{1F4CB} Schema for this check: ${schema || "none (no schema)"}`);
        if (sessionMode === "clone") {
          log(`\u2705 Cloned agent will use NEW schema (${schema}) - parent schema does not persist`);
          log(`\u{1F504} Clone operation ensures fresh agent with copied history but new configuration`);
        } else {
          log(`\u{1F504} Append mode - using existing agent instance with shared history and configuration`);
        }
        let debugInfo;
        if (this.config.debug) {
          debugInfo = {
            prompt,
            rawResponse: "",
            provider: this.config.provider || "unknown",
            model: this.config.model || "default",
            apiKeySource: this.getApiKeySource(),
            processingTime: 0,
            promptLength: prompt.length,
            responseLength: 0,
            errors: [],
            jsonParseSuccess: false,
            timestamp,
            schemaName: typeof schema === "object" ? "custom" : schema,
            schema: void 0
            // Will be populated when schema is loaded
          };
        }
        try {
          const call = this.callProbeAgentWithExistingSession(
            agentToUse,
            prompt,
            schema,
            debugInfo,
            checkName
          );
          const timeoutMs = Math.max(0, this.config.timeout || 0);
          const { response, effectiveSchema } = timeoutMs > 0 ? await this.withTimeout(call, timeoutMs, "AI review (session)") : await call;
          const processingTime = Date.now() - startTime;
          if (debugInfo) {
            debugInfo.rawResponse = response;
            debugInfo.responseLength = response.length;
            debugInfo.processingTime = processingTime;
          }
          const result = this.parseAIResponse(response, debugInfo, effectiveSchema);
          try {
            result.sessionId = currentSessionId;
          } catch {
          }
          if (debugInfo) {
            result.debug = debugInfo;
          }
          if (sessionMode === "clone" && currentSessionId !== parentSessionId) {
            result.sessionId = currentSessionId;
          }
          return result;
        } catch (error) {
          if (debugInfo) {
            debugInfo.errors = [error instanceof Error ? error.message : String(error)];
            debugInfo.processingTime = Date.now() - startTime;
            return {
              issues: [
                {
                  file: "system",
                  line: 0,
                  ruleId: "system/ai-session-reuse-error",
                  message: error instanceof Error ? error.message : String(error),
                  severity: "error",
                  category: "logic"
                }
              ],
              debug: debugInfo
            };
          }
          throw error;
        }
      }
      /**
       * Promise timeout helper that rejects after ms if unresolved
       */
      async withTimeout(p, ms, label = "operation") {
        let timer;
        try {
          const timeout = new Promise((_, reject) => {
            timer = setTimeout(() => reject(new Error(`${label} timed out after ${ms}ms`)), ms);
          });
          return await Promise.race([p, timeout]);
        } finally {
          if (timer) clearTimeout(timer);
        }
      }
      /**
       * Register a new AI session in the session registry
       */
      registerSession(sessionId, agent) {
        this.sessionRegistry.registerSession(sessionId, agent);
      }
      /**
       * Cleanup a session from the registry
       */
      cleanupSession(sessionId) {
        this.sessionRegistry.unregisterSession(sessionId);
      }
      /**
       * Build a custom prompt for AI review with XML-formatted data
       */
      async buildCustomPrompt(prInfo, customInstructions, schema, options) {
        const skipPRContext = options?.skipPRContext === true;
        const skipSlackContext = options?.skipSlackContext === true;
        const isCodeReviewSchema = schema === "code-review";
        const prContext = skipPRContext ? "" : await this.formatPRContext(prInfo, isCodeReviewSchema);
        const slackContextXml = skipSlackContext === true ? "" : this.formatSlackContextFromPRInfo(prInfo);
        const isIssue = prInfo.isIssue === true;
        if (isIssue) {
          if (skipPRContext && !slackContextXml) {
            return `<instructions>
${customInstructions}
</instructions>`;
          }
          return `<review_request>
  <instructions>
${customInstructions}
  </instructions>

  <context>
${prContext}${slackContextXml}
  </context>

  <rules>
    <rule>Understand the issue context and requirements from the XML data structure</rule>
    <rule>Provide helpful, actionable guidance based on the issue details</rule>
    <rule>Be constructive and supportive in your analysis</rule>
    <rule>Consider project conventions and patterns when making recommendations</rule>
    <rule>Suggest practical solutions or next steps that address the specific concern</rule>
    <rule>Focus on addressing the specific concern raised in the issue</rule>
    <rule>Reference relevant XML elements like metadata, description, labels, assignees when providing context</rule>
  </rules>
</review_request>`;
        }
        if (isCodeReviewSchema) {
          const analysisType = prInfo.isIncremental ? "INCREMENTAL" : "FULL";
          if (skipPRContext && !slackContextXml) {
            return `<instructions>
${customInstructions}
</instructions>

<reminder>
  <rule>The code context and diff were provided in the previous message</rule>
  <rule>Focus on the new analysis instructions above</rule>
  <rule>Only analyze code that appears with + (additions) or - (deletions) in the diff sections</rule>
  <rule>STRICT OUTPUT POLICY: Report only actual problems, risks, or deficiencies</rule>
  <rule>SEVERITY ASSIGNMENT: Assign severity ONLY to problems introduced or left unresolved by this change</rule>
</reminder>`;
          }
          return `<review_request>
  <analysis_type>${analysisType}</analysis_type>

  <analysis_focus>
    ${analysisType === "INCREMENTAL" ? "You are analyzing a NEW COMMIT added to an existing PR. Focus on the changes in the commit_diff section for this specific commit." : "You are analyzing the COMPLETE PR. Review all changes in the full_diff section."}
  </analysis_focus>

  <instructions>
${customInstructions}
  </instructions>

  <context>
${prContext}${slackContextXml}
  </context>

  <rules>
    <rule>Only analyze code that appears with + (additions) or - (deletions) in the diff sections</rule>
    <rule>Ignore unchanged code unless directly relevant to understanding a change</rule>
    <rule>Line numbers in your response should match actual file line numbers from the diff</rule>
    <rule>Focus on real issues, not nitpicks or cosmetic concerns</rule>
    <rule>Provide actionable, specific feedback with clear remediation steps</rule>
    <rule>For INCREMENTAL analysis, ONLY review changes in commit_diff section</rule>
    <rule>For FULL analysis, review all changes in full_diff section</rule>
    <rule>Reference specific XML elements like files_summary, metadata when providing context</rule>
    <rule>STRICT OUTPUT POLICY: Report only actual problems, risks, or deficiencies. Do not write praise, congratulations, or celebratory text. Do not create issues that merely restate improvements or say "no action needed".</rule>
    <rule>SEVERITY ASSIGNMENT: Assign severity ONLY to problems introduced or left unresolved by this change (critical/error/warning/info as appropriate). Do NOT create issue entries solely to acknowledge improvements; if no problems exist, return zero issues.</rule>
  </rules>
</review_request>`;
        }
        if (skipPRContext && !slackContextXml) {
          return `<instructions>
${customInstructions}
</instructions>`;
        }
        return `<instructions>
${customInstructions}
</instructions>

<context>
${prContext}${slackContextXml}
</context>`;
      }
      // REMOVED: Built-in prompts - only use custom prompts from .visor.yaml
      // REMOVED: getFocusInstructions - only use custom prompts from .visor.yaml
      /**
       * Format PR or Issue context for the AI using XML structure
       */
      async formatPRContext(prInfo, isCodeReviewSchema) {
        const prContextInfo = prInfo;
        const isIssue = prContextInfo.isIssue === true;
        const isPRContext = prContextInfo.isPRContext === true;
        const isSlackMode = prContextInfo.slackConversation !== void 0;
        let includeCodeContext;
        if (isPRContext) {
          includeCodeContext = true;
        } else if (isSlackMode) {
          includeCodeContext = prContextInfo.includeCodeContext === true;
        } else {
          includeCodeContext = prContextInfo.includeCodeContext !== false;
        }
        if (isPRContext) {
          log("\u{1F50D} Including full code diffs in AI context (PR mode)");
        } else if (isSlackMode && !includeCodeContext) {
          log("\u{1F4AC} Slack mode: excluding code diffs (use includeCodeContext: true to enable)");
        } else if (!includeCodeContext) {
          log("\u{1F4CA} Including only file summary in AI context (no diffs)");
        } else {
          log("\u{1F50D} Including code diffs in AI context");
        }
        if (isIssue) {
          let context3 = `<issue>
  <!-- Core issue metadata including identification, status, and timeline information -->
  <metadata>
    <number>${prInfo.number}</number>
    <title>${this.escapeXml(prInfo.title)}</title>
    <author>${prInfo.author}</author>
    <state>${prInfo.eventContext?.issue?.state || "open"}</state>
    <created_at>${prInfo.eventContext?.issue?.created_at || ""}</created_at>
    <updated_at>${prInfo.eventContext?.issue?.updated_at || ""}</updated_at>
    <comments_count>${prInfo.eventContext?.issue?.comments || 0}</comments_count>
  </metadata>`;
          if (prInfo.body) {
            context3 += `
  <!-- Full issue description and body text provided by the issue author -->
  <description>
${this.escapeXml(prInfo.body)}
  </description>`;
          }
          const eventContext = prInfo;
          const labels = eventContext.eventContext?.issue?.labels;
          if (labels && labels.length > 0) {
            context3 += `
  <!-- Applied labels for issue categorization and organization -->
  <labels>`;
            labels.forEach((label) => {
              const labelName = typeof label === "string" ? label : label.name || "unknown";
              context3 += `
    <label>${this.escapeXml(labelName)}</label>`;
            });
            context3 += `
  </labels>`;
          }
          const assignees = prInfo.eventContext?.issue?.assignees;
          if (assignees && assignees.length > 0) {
            context3 += `
  <!-- Users assigned to work on this issue -->
  <assignees>`;
            assignees.forEach((assignee) => {
              const assigneeName = typeof assignee === "string" ? assignee : assignee.login || "unknown";
              context3 += `
    <assignee>${this.escapeXml(assigneeName)}</assignee>`;
            });
            context3 += `
  </assignees>`;
          }
          const milestone = prInfo.eventContext?.issue?.milestone;
          if (milestone) {
            context3 += `
  <!-- Associated project milestone information -->
  <milestone>
    <title>${this.escapeXml(milestone.title || "")}</title>
    <state>${milestone.state || "open"}</state>
    <due_on>${milestone.due_on || ""}</due_on>
  </milestone>`;
          }
          const triggeringComment2 = prInfo.eventContext?.comment;
          if (triggeringComment2) {
            context3 += `
  <!-- The comment that triggered this analysis -->
  <triggering_comment>
    <author>${this.escapeXml(triggeringComment2.user?.login || "unknown")}</author>
    <created_at>${triggeringComment2.created_at || ""}</created_at>
    <body>${this.escapeXml(triggeringComment2.body || "")}</body>
  </triggering_comment>`;
          }
          const issueComments = prInfo.comments;
          if (issueComments && issueComments.length > 0) {
            let historicalComments = triggeringComment2 ? issueComments.filter((c) => c.id !== triggeringComment2.id) : issueComments;
            if (isCodeReviewSchema) {
              historicalComments = historicalComments.filter(
                (c) => !shouldFilterVisorReviewComment(c.body)
              );
            }
            if (historicalComments.length > 0) {
              context3 += `
  <!-- Previous comments in chronological order (excluding triggering comment) -->
  <comment_history>`;
              historicalComments.forEach((comment) => {
                context3 += `
    <comment>
      <author>${this.escapeXml(comment.author || "unknown")}</author>
      <created_at>${comment.createdAt || ""}</created_at>
      <body>${this.escapeXml(comment.body || "")}</body>
    </comment>`;
              });
              context3 += `
  </comment_history>`;
            }
          }
          context3 += `
</issue>`;
          return context3;
        }
        let context2 = `<pull_request>
  <!-- Core pull request metadata including identification, branches, and change statistics -->
  <metadata>
    <number>${prInfo.number}</number>
    <title>${this.escapeXml(prInfo.title)}</title>
    <author>${prInfo.author}</author>
    <base_branch>${prInfo.base}</base_branch>
    <target_branch>${prInfo.head}</target_branch>
    <total_additions>${prInfo.totalAdditions}</total_additions>
    <total_deletions>${prInfo.totalDeletions}</total_deletions>
    <files_changed_count>${prInfo.files.length}</files_changed_count>
  </metadata>`;
        try {
          const firstFile = (prInfo.files || [])[0];
          if (firstFile && firstFile.filename) {
            context2 += `
  <raw_diff_header>
${this.escapeXml(`diff --git a/${firstFile.filename} b/${firstFile.filename}`)}
  </raw_diff_header>`;
          }
        } catch {
        }
        if (prInfo.body) {
          context2 += `
  <!-- Full pull request description provided by the author -->
  <description>
${this.escapeXml(prInfo.body)}
  </description>`;
        }
        if (includeCodeContext) {
          if (prInfo.fullDiff) {
            const processedFullDiff = await processDiffWithOutline(prInfo.fullDiff);
            context2 += `
  <!-- Complete unified diff showing all changes in the pull request (processed with outline-diff) -->
  <full_diff>
${this.escapeXml(processedFullDiff)}
  </full_diff>`;
          }
          if (prInfo.isIncremental) {
            if (prInfo.commitDiff && prInfo.commitDiff.length > 0) {
              const processedCommitDiff = await processDiffWithOutline(prInfo.commitDiff);
              context2 += `
  <!-- Diff of only the latest commit for incremental analysis (processed with outline-diff) -->
  <commit_diff>
${this.escapeXml(processedCommitDiff)}
  </commit_diff>`;
            } else {
              const processedFallbackDiff = prInfo.fullDiff ? await processDiffWithOutline(prInfo.fullDiff) : "";
              context2 += `
  <!-- Commit diff could not be retrieved - falling back to full diff analysis (processed with outline-diff) -->
  <commit_diff>
${this.escapeXml(processedFallbackDiff)}
  </commit_diff>`;
            }
          }
        } else {
          context2 += `
  <!-- Code diffs excluded to reduce token usage (no code-review schema detected or disabled by flag) -->`;
        }
        if (prInfo.files.length > 0) {
          context2 += `
  <!-- Summary of all files changed with statistics -->
  <files_summary>`;
          prInfo.files.forEach((file) => {
            context2 += `
    <file>
      <filename>${this.escapeXml(file.filename)}</filename>
      <status>${file.status}</status>
      <additions>${file.additions}</additions>
      <deletions>${file.deletions}</deletions>
    </file>`;
          });
          context2 += `
  </files_summary>`;
        }
        const triggeringComment = prInfo.eventContext?.comment;
        if (triggeringComment) {
          context2 += `
  <!-- The comment that triggered this analysis -->
  <triggering_comment>
    <author>${this.escapeXml(triggeringComment.user?.login || "unknown")}</author>
    <created_at>${triggeringComment.created_at || ""}</created_at>
    <body>${this.escapeXml(triggeringComment.body || "")}</body>
  </triggering_comment>`;
        }
        const prComments = prInfo.comments;
        if (prComments && prComments.length > 0) {
          let historicalComments = triggeringComment ? prComments.filter((c) => c.id !== triggeringComment.id) : prComments;
          if (isCodeReviewSchema) {
            historicalComments = historicalComments.filter(
              (c) => !shouldFilterVisorReviewComment(c.body)
            );
          }
          if (historicalComments.length > 0) {
            context2 += `
  <!-- Previous PR comments in chronological order (excluding triggering comment) -->
  <comment_history>`;
            historicalComments.forEach((comment) => {
              context2 += `
    <comment>
      <author>${this.escapeXml(comment.author || "unknown")}</author>
      <created_at>${comment.createdAt || ""}</created_at>
      <body>${this.escapeXml(comment.body || "")}</body>
    </comment>`;
            });
            context2 += `
  </comment_history>`;
          }
        }
        context2 += `
</pull_request>`;
        return context2;
      }
      /**
       * Format Slack conversation context (if attached to PRInfo) as XML
       */
      formatSlackContextFromPRInfo(prInfo) {
        try {
          const anyInfo = prInfo;
          const conv = anyInfo.slackConversation;
          if (!conv || typeof conv !== "object") return "";
          const transport = conv.transport || "slack";
          const thread = conv.thread || {};
          const messages = Array.isArray(conv.messages) ? conv.messages : [];
          const current = conv.current || {};
          const attrs = conv.attributes || {};
          let xml = `
<slack_context>
  <transport>${this.escapeXml(String(transport))}</transport>
  <thread>
    <id>${this.escapeXml(String(thread.id || ""))}</id>
    <url>${this.escapeXml(String(thread.url || ""))}</url>
  </thread>`;
          const attrKeys = Object.keys(attrs);
          if (attrKeys.length > 0) {
            xml += `
  <attributes>`;
            for (const k of attrKeys) {
              const v = attrs[k];
              xml += `
    <attribute>
      <key>${this.escapeXml(String(k))}</key>
      <value>${this.escapeXml(String(v ?? ""))}</value>
    </attribute>`;
            }
            xml += `
  </attributes>`;
          }
          if (messages.length > 0) {
            xml += `
  <messages>`;
            for (const m of messages) {
              xml += `
    <message>
      <role>${this.escapeXml(String(m.role || "user"))}</role>
      <user>${this.escapeXml(String(m.user || ""))}</user>
      <text>${this.escapeXml(String(m.text || ""))}</text>
      <timestamp>${this.escapeXml(String(m.timestamp || ""))}</timestamp>
      <origin>${this.escapeXml(String(m.origin || ""))}</origin>
    </message>`;
            }
            xml += `
  </messages>`;
          }
          xml += `
  <current>
    <role>${this.escapeXml(String(current.role || "user"))}</role>
    <user>${this.escapeXml(String(current.user || ""))}</user>
    <text>${this.escapeXml(String(current.text || ""))}</text>
    <timestamp>${this.escapeXml(String(current.timestamp || ""))}</timestamp>
    <origin>${this.escapeXml(String(current.origin || ""))}</origin>
  </current>
</slack_context>`;
          return xml;
        } catch {
          return "";
        }
      }
      /**
       * Build a normalized ConversationContext for GitHub (PR/issue + comments)
       * using the same contract as Slack's ConversationContext. This is exposed
       * to templates via the unified `conversation` object.
       */
      buildGitHubConversationFromPRInfo(prInfo) {
        try {
          const anyInfo = prInfo;
          const eventCtx = anyInfo.eventContext || {};
          const comments = anyInfo.comments || [];
          const repoOwner = eventCtx.repository?.owner?.login || process.env.GITHUB_REPOSITORY?.split("/")?.[0];
          const repoName = eventCtx.repository?.name || process.env.GITHUB_REPOSITORY?.split("/")?.[1];
          const number = prInfo.number;
          const threadId = repoOwner && repoName ? `${repoOwner}/${repoName}#${number}` : `github#${number}`;
          const threadUrl = eventCtx.issue?.html_url || eventCtx.pull_request?.html_url || (repoOwner && repoName ? `https://github.com/${repoOwner}/${repoName}/pull/${number}` : void 0);
          const messages = [];
          if (prInfo.body && prInfo.body.trim().length > 0) {
            messages.push({
              role: "user",
              user: prInfo.author || "unknown",
              text: prInfo.body,
              timestamp: eventCtx.pull_request?.created_at || eventCtx.issue?.created_at || "",
              origin: "github"
            });
          }
          for (const c of comments) {
            messages.push({
              role: "user",
              user: c.author || "unknown",
              text: c.body || "",
              timestamp: c.createdAt || "",
              origin: "github"
            });
          }
          const triggeringComment = eventCtx.comment;
          let current;
          if (triggeringComment) {
            current = {
              role: "user",
              user: triggeringComment.user && triggeringComment.user.login || "unknown",
              text: triggeringComment.body || "",
              timestamp: triggeringComment.created_at || "",
              origin: "github"
            };
          } else if (messages.length > 0) {
            current = messages[messages.length - 1];
          } else {
            current = {
              role: "user",
              user: prInfo.author || "unknown",
              text: prInfo.title || "",
              timestamp: "",
              origin: "github"
            };
          }
          const attributes = {};
          if (repoOwner) attributes.owner = repoOwner;
          if (repoName) attributes.repo = repoName;
          attributes.number = String(number);
          if (eventCtx.event_name) attributes.event_name = String(eventCtx.event_name);
          if (eventCtx.action) attributes.action = String(eventCtx.action);
          const ctx = {
            transport: "github",
            thread: { id: threadId, url: threadUrl },
            messages,
            current,
            attributes
          };
          return ctx;
        } catch {
          return void 0;
        }
      }
      /**
       * No longer escaping XML - returning text as-is
       */
      escapeXml(text) {
        return text;
      }
      /**
       * Call ProbeAgent with an existing session
       */
      async callProbeAgentWithExistingSession(agent, prompt, schema, debugInfo, _checkName) {
        if (this.config.model === "mock" || this.config.provider === "mock") {
          log("\u{1F3AD} Using mock AI model/provider for testing (session reuse)");
          const response = await this.generateMockResponse(prompt, _checkName, schema);
          return { response, effectiveSchema: typeof schema === "object" ? "custom" : schema };
        }
        log("\u{1F504} Reusing existing ProbeAgent session for AI review...");
        log(`\u{1F4DD} Prompt length: ${prompt.length} characters`);
        log(`\u2699\uFE0F Model: ${this.config.model || "default"}, Provider: ${this.config.provider || "auto"}`);
        try {
          log("\u{1F680} Calling existing ProbeAgent with answer()...");
          let schemaString = void 0;
          let effectiveSchema = typeof schema === "object" ? "custom" : schema;
          if (schema && schema !== "plain") {
            try {
              schemaString = await this.loadSchemaContent(schema);
              log(`\u{1F4CB} Loaded schema content for: ${schema}`);
              log(`\u{1F4C4} Raw schema JSON:
${schemaString}`);
            } catch (error) {
              log(`\u26A0\uFE0F Failed to load schema ${schema}, proceeding without schema:`, error);
              schemaString = void 0;
              effectiveSchema = void 0;
              if (debugInfo && debugInfo.errors) {
                debugInfo.errors.push(`Failed to load schema: ${error}`);
              }
            }
          } else if (schema === "plain") {
            log(`\u{1F4CB} Using plain schema - no JSON validation will be applied`);
          }
          const schemaOptions = schemaString ? { schema: schemaString } : void 0;
          if (debugInfo && schemaOptions) {
            debugInfo.schema = JSON.stringify(schemaOptions, null, 2);
          }
          if (schemaOptions) {
            log(`\u{1F3AF} Schema options passed to ProbeAgent.answer() (session reuse):`);
            log(JSON.stringify(schemaOptions, null, 2));
          }
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const provider = this.config.provider || "auto";
              const model = this.config.model || "default";
              let conversationHistory = [];
              try {
                const agentAny2 = agent;
                if (agentAny2.history) {
                  conversationHistory = agentAny2.history;
                } else if (agentAny2.messages) {
                  conversationHistory = agentAny2.messages;
                } else if (agentAny2._messages) {
                  conversationHistory = agentAny2._messages;
                }
              } catch {
              }
              const debugData = {
                timestamp,
                checkName: _checkName || "unknown",
                provider,
                model,
                schema: effectiveSchema,
                schemaOptions: schemaOptions || "none",
                sessionInfo: {
                  isSessionReuse: true,
                  historyMessageCount: conversationHistory.length
                },
                currentPromptLength: prompt.length,
                currentPrompt: prompt,
                conversationHistory
              };
              const debugJson = JSON.stringify(debugData, null, 2);
              let readableVersion = `=============================================================
`;
              readableVersion += `VISOR DEBUG REPORT - SESSION REUSE
`;
              readableVersion += `=============================================================
`;
              readableVersion += `Timestamp: ${timestamp}
`;
              readableVersion += `Check Name: ${_checkName || "unknown"}
`;
              readableVersion += `Provider: ${provider}
`;
              readableVersion += `Model: ${model}
`;
              readableVersion += `Schema: ${effectiveSchema}
`;
              readableVersion += `Schema Options: ${schemaOptions ? "provided" : "none"}
`;
              readableVersion += `History Messages: ${conversationHistory.length}
`;
              readableVersion += `=============================================================

`;
              if (schemaOptions) {
                readableVersion += `
${"=".repeat(60)}
`;
                readableVersion += `SCHEMA CONFIGURATION
`;
                readableVersion += `${"=".repeat(60)}
`;
                readableVersion += JSON.stringify(schemaOptions, null, 2);
                readableVersion += `
`;
              }
              if (conversationHistory.length > 0) {
                readableVersion += `
${"=".repeat(60)}
`;
                readableVersion += `CONVERSATION HISTORY (${conversationHistory.length} messages)
`;
                readableVersion += `${"=".repeat(60)}
`;
                conversationHistory.forEach((msg, index) => {
                  readableVersion += `
${"-".repeat(60)}
`;
                  readableVersion += `MESSAGE #${index + 1}
`;
                  readableVersion += `Role: ${msg.role || "unknown"}
`;
                  if (msg.content) {
                    const contentStr = typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content, null, 2);
                    readableVersion += `Length: ${contentStr.length} characters
`;
                    readableVersion += `${"-".repeat(60)}
`;
                    readableVersion += `${contentStr}
`;
                  }
                });
              }
              readableVersion += `
${"=".repeat(60)}
`;
              readableVersion += `CURRENT PROMPT (NEW MESSAGE)
`;
              readableVersion += `${"=".repeat(60)}
`;
              readableVersion += `Length: ${prompt.length} characters
`;
              readableVersion += `${"-".repeat(60)}
`;
              readableVersion += `${prompt}
`;
              readableVersion += `
${"=".repeat(60)}
`;
              readableVersion += `END OF DEBUG REPORT
`;
              readableVersion += `${"=".repeat(60)}
`;
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              if (!fs20.existsSync(debugArtifactsDir)) {
                fs20.mkdirSync(debugArtifactsDir, { recursive: true });
              }
              const debugFile = path22.join(
                debugArtifactsDir,
                `prompt-${_checkName || "unknown"}-${timestamp}.json`
              );
              fs20.writeFileSync(debugFile, debugJson, "utf-8");
              const readableFile = path22.join(
                debugArtifactsDir,
                `prompt-${_checkName || "unknown"}-${timestamp}.txt`
              );
              fs20.writeFileSync(readableFile, readableVersion, "utf-8");
              log(`
\u{1F4BE} Full debug info saved to:`);
              log(`   JSON: ${debugFile}`);
              log(`   TXT:  ${readableFile}`);
              log(`   - Includes: full conversation history, schema, current prompt`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save debug file: ${error}`);
            }
          }
          const agentAny = agent;
          agentAny.tracer = createProbeTracerAdapter(agentAny.tracer);
          let response;
          if (agentAny.tracer && typeof agentAny.tracer.withSpan === "function") {
            response = await agentAny.tracer.withSpan(
              "visor.ai_check_reuse",
              async () => {
                return await agent.answer(prompt, void 0, schemaOptions);
              },
              {
                "check.name": _checkName || "unknown",
                "check.mode": "session_reuse",
                "prompt.length": prompt.length,
                "schema.type": effectiveSchema || "none"
              }
            );
          } else {
            response = schemaOptions ? await agent.answer(prompt, void 0, schemaOptions) : await agent.answer(prompt);
          }
          log("\u2705 ProbeAgent session reuse completed successfully");
          log(`\u{1F4E4} Response length: ${response.length} characters`);
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const agentAny2 = agent;
              let fullHistory = [];
              if (agentAny2.history) {
                fullHistory = agentAny2.history;
              } else if (agentAny2.messages) {
                fullHistory = agentAny2.messages;
              } else if (agentAny2._messages) {
                fullHistory = agentAny2._messages;
              }
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              const sessionBase = path22.join(
                debugArtifactsDir,
                `session-${_checkName || "unknown"}-${timestamp}`
              );
              const sessionData = {
                timestamp,
                checkName: _checkName || "unknown",
                provider: this.config.provider || "auto",
                model: this.config.model || "default",
                schema: effectiveSchema,
                totalMessages: fullHistory.length
              };
              fs20.writeFileSync(sessionBase + ".json", JSON.stringify(sessionData, null, 2), "utf-8");
              let readable = `=============================================================
`;
              readable += `COMPLETE AI SESSION HISTORY (AFTER RESPONSE)
`;
              readable += `=============================================================
`;
              readable += `Timestamp: ${timestamp}
`;
              readable += `Check: ${_checkName || "unknown"}
`;
              readable += `Total Messages: ${fullHistory.length}
`;
              readable += `=============================================================

`;
              fullHistory.forEach((msg, idx) => {
                const role = msg.role || "unknown";
                const content = typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content, null, 2);
                readable += `
${"=".repeat(60)}
MESSAGE ${idx + 1}/${fullHistory.length}
Role: ${role}
${"=".repeat(60)}
`;
                readable += content + "\n";
              });
              fs20.writeFileSync(sessionBase + ".summary.txt", readable, "utf-8");
              log(`\u{1F4BE} Complete session history saved:`);
              log(`   - Contains ALL ${fullHistory.length} messages (prompts + responses)`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save complete session history: ${error}`);
            }
          }
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              const responseFile = path22.join(
                debugArtifactsDir,
                `response-${_checkName || "unknown"}-${timestamp}.txt`
              );
              let responseContent = `=============================================================
`;
              responseContent += `VISOR AI RESPONSE - SESSION REUSE
`;
              responseContent += `=============================================================
`;
              responseContent += `Timestamp: ${timestamp}
`;
              responseContent += `Check Name: ${_checkName || "unknown"}
`;
              responseContent += `Response Length: ${response.length} characters
`;
              responseContent += `=============================================================

`;
              responseContent += `${"=".repeat(60)}
`;
              responseContent += `AI RESPONSE
`;
              responseContent += `${"=".repeat(60)}
`;
              responseContent += response;
              responseContent += `
${"=".repeat(60)}
`;
              responseContent += `END OF RESPONSE
`;
              responseContent += `${"=".repeat(60)}
`;
              fs20.writeFileSync(responseFile, responseContent, "utf-8");
              log(`\u{1F4BE} Response saved to: ${responseFile}`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save response file: ${error}`);
            }
          }
          if (agentAny._traceFilePath && agentAny._telemetryConfig) {
            try {
              if (agentAny.tracer && typeof agentAny.tracer.flush === "function") {
                await agentAny.tracer.flush();
                log(`\u{1F504} Flushed tracer spans for cloned session`);
              }
              if (agentAny._telemetryConfig && typeof agentAny._telemetryConfig.shutdown === "function") {
                await agentAny._telemetryConfig.shutdown();
                log(`\u{1F4CA} OpenTelemetry trace saved to: ${agentAny._traceFilePath}`);
                if (process.env.GITHUB_ACTIONS) {
                  const fs20 = require("fs");
                  if (fs20.existsSync(agentAny._traceFilePath)) {
                    const stats = fs20.statSync(agentAny._traceFilePath);
                    console.log(
                      `::notice title=AI Trace Saved::${agentAny._traceFilePath} (${stats.size} bytes)`
                    );
                  }
                }
              } else if (agentAny.tracer && typeof agentAny.tracer.shutdown === "function") {
                await agentAny.tracer.shutdown();
                log(`\u{1F4CA} Trace saved to: ${agentAny._traceFilePath}`);
              }
            } catch (exportError) {
              logger.warn(`\u26A0\uFE0F  Warning: Failed to export trace for cloned session: ${exportError}`);
            }
          }
          return { response, effectiveSchema };
        } catch (error) {
          logger.error(
            `\u274C ProbeAgent session reuse failed: ${error instanceof Error ? error.message : "Unknown error"}`
          );
          throw new Error(
            `ProbeAgent session reuse failed: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Call ProbeAgent SDK with built-in schema validation
       */
      async callProbeAgent(prompt, schema, debugInfo, _checkName, providedSessionId) {
        const sessionId = providedSessionId || (() => {
          const timestamp = (/* @__PURE__ */ new Date()).toISOString();
          return `visor-${timestamp.replace(/[:.]/g, "-")}-${_checkName || "unknown"}`;
        })();
        if (this.config.model === "mock" || this.config.provider === "mock") {
          const inJest = !!process.env.JEST_WORKER_ID;
          log("\u{1F3AD} Using mock AI model/provider");
          if (!inJest) {
            const response = await this.generateMockResponse(prompt, _checkName, schema);
            return {
              response,
              effectiveSchema: typeof schema === "object" ? "custom" : schema,
              sessionId
            };
          }
        }
        log("\u{1F916} Creating ProbeAgent for AI review...");
        log(`\u{1F194} Session ID: ${sessionId}`);
        log(`\u{1F4DD} Prompt length: ${prompt.length} characters`);
        log(`\u2699\uFE0F Model: ${this.config.model || "default"}, Provider: ${this.config.provider || "auto"}`);
        const originalEnv = {
          CLAUDE_CODE_API_KEY: process.env.CLAUDE_CODE_API_KEY,
          GOOGLE_API_KEY: process.env.GOOGLE_API_KEY,
          ANTHROPIC_API_KEY: process.env.ANTHROPIC_API_KEY,
          OPENAI_API_KEY: process.env.OPENAI_API_KEY
        };
        try {
          if (this.config.provider === "claude-code" && this.config.apiKey) {
            process.env.CLAUDE_CODE_API_KEY = this.config.apiKey;
            process.env.ANTHROPIC_API_KEY = this.config.apiKey;
          } else if (this.config.provider === "google" && this.config.apiKey) {
            process.env.GOOGLE_API_KEY = this.config.apiKey;
          } else if (this.config.provider === "anthropic" && this.config.apiKey) {
            process.env.ANTHROPIC_API_KEY = this.config.apiKey;
          } else if (this.config.provider === "openai" && this.config.apiKey) {
            process.env.OPENAI_API_KEY = this.config.apiKey;
          } else if (this.config.provider === "bedrock") {
          }
          const explicitPromptType = (process.env.VISOR_PROMPT_TYPE || "").trim();
          let systemPrompt = this.config.systemPrompt;
          if (!systemPrompt && schema !== "code-review") {
            systemPrompt = "You are general assistant, follow user instructions.";
          }
          const options = {
            sessionId,
            // Prefer config promptType, then env override, else fallback to code-review when schema is set
            promptType: this.config.promptType && this.config.promptType.trim() ? this.config.promptType.trim() : explicitPromptType ? explicitPromptType : schema === "code-review" ? "code-review-template" : void 0,
            allowEdit: false,
            // We don't want the agent to modify files
            debug: this.config.debug || false,
            // Use systemPrompt (native in rc168+) with fallback to customPrompt for backward compat
            systemPrompt: systemPrompt || this.config.systemPrompt || this.config.customPrompt
          };
          let traceFilePath = "";
          let telemetryConfig = null;
          let probeFileTracer = null;
          if (this.config.debug) {
            const tracerResult = await initializeTracer(sessionId, _checkName);
            if (tracerResult) {
              probeFileTracer = tracerResult.tracer;
              telemetryConfig = tracerResult.telemetryConfig;
              traceFilePath = tracerResult.filePath;
            }
          }
          options.tracer = createProbeTracerAdapter(probeFileTracer);
          if (this.config.mcpServers && Object.keys(this.config.mcpServers).length > 0) {
            options.enableMcp = true;
            options.mcpConfig = { mcpServers: this.config.mcpServers };
          }
          if (this.config.enableDelegate !== void 0) {
            options.enableDelegate = this.config.enableDelegate;
          }
          if (this.config.retry) {
            options.retry = this.config.retry;
          }
          if (this.config.fallback) {
            options.fallback = this.config.fallback;
          }
          if (this.config.allowEdit !== void 0) {
            options.allowEdit = this.config.allowEdit;
          }
          if (this.config.allowedTools !== void 0) {
            options.allowedTools = this.config.allowedTools;
            log(`\u{1F527} Setting allowedTools: ${JSON.stringify(this.config.allowedTools)}`);
          }
          if (this.config.disableTools !== void 0) {
            options.disableTools = this.config.disableTools;
            log(`\u{1F527} Setting disableTools: ${this.config.disableTools}`);
          }
          if (this.config.allowBash !== void 0) {
            options.enableBash = this.config.allowBash;
          }
          if (this.config.bashConfig !== void 0) {
            options.bashConfig = this.config.bashConfig;
          }
          if (this.config.completionPrompt !== void 0) {
            options.completionPrompt = this.config.completionPrompt;
          }
          try {
            const cfgAny = this.config;
            const allowedFolders = cfgAny.allowedFolders;
            const preferredPath = cfgAny.workspacePath || (Array.isArray(allowedFolders) && allowedFolders.length > 0 ? allowedFolders[0] : void 0) || cfgAny.path;
            if (Array.isArray(allowedFolders) && allowedFolders.length > 0) {
              options.allowedFolders = allowedFolders;
              if (!options.path && preferredPath) {
                options.path = preferredPath;
              }
              log(`\u{1F5C2}\uFE0F ProbeAgent workspace config:`);
              log(`   path (cwd): ${options.path}`);
              log(`   allowedFolders[0]: ${allowedFolders[0]}`);
            } else if (preferredPath) {
              options.path = preferredPath;
              log(`\u{1F5C2}\uFE0F ProbeAgent path: ${preferredPath} (no allowedFolders)`);
            }
          } catch {
          }
          if (this.config.provider) {
            const providerOverride = this.config.provider === "claude-code" || this.config.provider === "bedrock" ? "anthropic" : this.config.provider === "anthropic" || this.config.provider === "openai" || this.config.provider === "google" ? this.config.provider : void 0;
            if (providerOverride) {
              options.provider = providerOverride;
            }
          }
          if (this.config.model) {
            options.model = this.config.model;
          }
          const agent = new import_probe2.ProbeAgent(options);
          if (typeof agent.initialize === "function") {
            await agent.initialize();
          }
          log("\u{1F680} Calling ProbeAgent...");
          let schemaString = void 0;
          let effectiveSchema = typeof schema === "object" ? "custom" : schema;
          if (schema && schema !== "plain") {
            try {
              schemaString = await this.loadSchemaContent(schema);
              log(`\u{1F4CB} Loaded schema content for: ${schema}`);
              log(`\u{1F4C4} Raw schema JSON:
${schemaString}`);
            } catch (error) {
              log(`\u26A0\uFE0F Failed to load schema ${schema}, proceeding without schema:`, error);
              schemaString = void 0;
              effectiveSchema = void 0;
              if (debugInfo && debugInfo.errors) {
                debugInfo.errors.push(`Failed to load schema: ${error}`);
              }
            }
          } else if (schema === "plain") {
            log(`\u{1F4CB} Using plain schema - no JSON validation will be applied`);
          }
          const schemaOptions = schemaString ? { schema: schemaString } : void 0;
          if (debugInfo && schemaOptions) {
            debugInfo.schema = JSON.stringify(schemaOptions, null, 2);
          }
          if (schemaOptions) {
            log(`\u{1F3AF} Schema options passed to ProbeAgent.answer():`);
            log(JSON.stringify(schemaOptions, null, 2));
          }
          const provider = this.config.provider || "auto";
          const model = this.config.model || "default";
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const os2 = require("os");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const debugData = {
                timestamp,
                checkName: _checkName || "unknown",
                provider,
                model,
                schema: effectiveSchema,
                schemaOptions: schemaOptions || "none",
                sessionInfo: {
                  isSessionReuse: false,
                  isNewSession: true
                },
                promptLength: prompt.length,
                prompt
              };
              const debugJson = JSON.stringify(debugData, null, 2);
              let readableVersion = `=============================================================
`;
              readableVersion += `VISOR DEBUG REPORT - NEW SESSION
`;
              readableVersion += `=============================================================
`;
              readableVersion += `Timestamp: ${timestamp}
`;
              readableVersion += `Check Name: ${_checkName || "unknown"}
`;
              readableVersion += `Provider: ${provider}
`;
              readableVersion += `Model: ${model}
`;
              readableVersion += `Schema: ${effectiveSchema}
`;
              readableVersion += `Schema Options: ${schemaOptions ? "provided" : "none"}
`;
              readableVersion += `Session Type: New Session (no history)
`;
              readableVersion += `=============================================================

`;
              if (schemaOptions) {
                readableVersion += `
${"=".repeat(60)}
`;
                readableVersion += `SCHEMA CONFIGURATION
`;
                readableVersion += `${"=".repeat(60)}
`;
                readableVersion += JSON.stringify(schemaOptions, null, 2);
                readableVersion += `
`;
              }
              readableVersion += `
${"=".repeat(60)}
`;
              readableVersion += `PROMPT
`;
              readableVersion += `${"=".repeat(60)}
`;
              readableVersion += `Length: ${prompt.length} characters
`;
              readableVersion += `${"-".repeat(60)}
`;
              readableVersion += `${prompt}
`;
              readableVersion += `
${"=".repeat(60)}
`;
              readableVersion += `END OF DEBUG REPORT
`;
              readableVersion += `${"=".repeat(60)}
`;
              const tempDir = os2.tmpdir();
              const promptFile = path22.join(tempDir, `visor-prompt-${timestamp}.txt`);
              fs20.writeFileSync(promptFile, prompt, "utf-8");
              log(`
\u{1F4BE} Prompt saved to: ${promptFile}`);
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              try {
                const base = path22.join(
                  debugArtifactsDir,
                  `prompt-${_checkName || "unknown"}-${timestamp}`
                );
                fs20.writeFileSync(base + ".json", debugJson, "utf-8");
                fs20.writeFileSync(base + ".summary.txt", readableVersion, "utf-8");
                log(`
\u{1F4BE} Full debug info saved to directory: ${debugArtifactsDir}`);
              } catch {
              }
              log(`
\u{1F4DD} To reproduce locally, run:`);
              let cliCommand = `npx @probelabs/probe@latest agent`;
              cliCommand += ` --provider ${provider}`;
              if (model !== "default") {
                cliCommand += ` --model ${model}`;
              }
              if (schema) {
                cliCommand += ` --schema output/${schema}/schema.json`;
              }
              cliCommand += ` "${promptFile}"`;
              log(`
$ ${cliCommand}
`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save prompt file: ${error}`);
            }
          }
          let response;
          const tracer = options.tracer;
          if (tracer && typeof tracer.withSpan === "function") {
            response = await tracer.withSpan(
              "visor.ai_check",
              async () => {
                return await agent.answer(prompt, void 0, schemaOptions);
              },
              {
                "check.name": _checkName || "unknown",
                "check.session_id": sessionId,
                "prompt.length": prompt.length,
                "schema.type": effectiveSchema || "none"
              }
            );
          } else {
            response = schemaOptions ? await agent.answer(prompt, void 0, schemaOptions) : await agent.answer(prompt);
          }
          log("\u2705 ProbeAgent completed successfully");
          log(`\u{1F4E4} Response length: ${response.length} characters`);
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const agentAny = agent;
              let fullHistory = [];
              if (agentAny.history) {
                fullHistory = agentAny.history;
              } else if (agentAny.messages) {
                fullHistory = agentAny.messages;
              } else if (agentAny._messages) {
                fullHistory = agentAny._messages;
              }
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              const sessionBase = path22.join(
                debugArtifactsDir,
                `session-${_checkName || "unknown"}-${timestamp}`
              );
              const sessionData = {
                timestamp,
                checkName: _checkName || "unknown",
                provider: this.config.provider || "auto",
                model: this.config.model || "default",
                schema: effectiveSchema,
                totalMessages: fullHistory.length
              };
              fs20.writeFileSync(sessionBase + ".json", JSON.stringify(sessionData, null, 2), "utf-8");
              let readable = `=============================================================
`;
              readable += `COMPLETE AI SESSION HISTORY (AFTER RESPONSE)
`;
              readable += `=============================================================
`;
              readable += `Timestamp: ${timestamp}
`;
              readable += `Check: ${_checkName || "unknown"}
`;
              readable += `Total Messages: ${fullHistory.length}
`;
              readable += `=============================================================

`;
              fullHistory.forEach((msg, idx) => {
                const role = msg.role || "unknown";
                const content = typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content, null, 2);
                readable += `
${"=".repeat(60)}
MESSAGE ${idx + 1}/${fullHistory.length}
Role: ${role}
${"=".repeat(60)}
`;
                readable += content + "\n";
              });
              fs20.writeFileSync(sessionBase + ".summary.txt", readable, "utf-8");
              log(`\u{1F4BE} Complete session history saved:`);
              log(`   - Contains ALL ${fullHistory.length} messages (prompts + responses)`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save complete session history: ${error}`);
            }
          }
          if (process.env.VISOR_DEBUG_AI_SESSIONS === "true") {
            try {
              const fs20 = require("fs");
              const path22 = require("path");
              const timestamp = (/* @__PURE__ */ new Date()).toISOString().replace(/[:.]/g, "-");
              const debugArtifactsDir = process.env.VISOR_DEBUG_ARTIFACTS || path22.join(process.cwd(), "debug-artifacts");
              const responseFile = path22.join(
                debugArtifactsDir,
                `response-${_checkName || "unknown"}-${timestamp}.txt`
              );
              let responseContent = `=============================================================
`;
              responseContent += `VISOR AI RESPONSE - NEW SESSION
`;
              responseContent += `=============================================================
`;
              responseContent += `Timestamp: ${timestamp}
`;
              responseContent += `Check Name: ${_checkName || "unknown"}
`;
              responseContent += `Response Length: ${response.length} characters
`;
              responseContent += `=============================================================

`;
              responseContent += `${"=".repeat(60)}
`;
              responseContent += `AI RESPONSE
`;
              responseContent += `${"=".repeat(60)}
`;
              responseContent += response;
              responseContent += `
${"=".repeat(60)}
`;
              responseContent += `END OF RESPONSE
`;
              responseContent += `${"=".repeat(60)}
`;
              fs20.writeFileSync(responseFile, responseContent, "utf-8");
              log(`\u{1F4BE} Response saved to: ${responseFile}`);
            } catch (error) {
              log(`\u26A0\uFE0F Could not save response file: ${error}`);
            }
          }
          if (traceFilePath && telemetryConfig) {
            try {
              const telemetry = telemetryConfig;
              const tracerWithMethods = tracer;
              if (tracerWithMethods && typeof tracerWithMethods.flush === "function") {
                await tracerWithMethods.flush();
                log(`\u{1F504} Flushed tracer spans`);
              }
              if (telemetry && typeof telemetry.shutdown === "function") {
                await telemetry.shutdown();
                log(`\u{1F4CA} OpenTelemetry trace saved to: ${traceFilePath}`);
                if (process.env.GITHUB_ACTIONS) {
                  const fs20 = require("fs");
                  if (fs20.existsSync(traceFilePath)) {
                    const stats = fs20.statSync(traceFilePath);
                    console.log(
                      `::notice title=AI Trace Saved::OpenTelemetry trace file size: ${stats.size} bytes`
                    );
                  }
                }
              } else if (tracerWithMethods && typeof tracerWithMethods.shutdown === "function") {
                await tracerWithMethods.shutdown();
                log(`\u{1F4CA} Trace saved to: ${traceFilePath}`);
              }
            } catch (exportError) {
              logger.warn(`\u26A0\uFE0F  Warning: Failed to export trace: ${exportError}`);
            }
          }
          if (_checkName) {
            this.registerSession(sessionId, agent);
            log(`\u{1F527} Debug: Registered AI session for potential reuse: ${sessionId}`);
          }
          return { response, effectiveSchema, sessionId };
        } catch (error) {
          console.error("\u274C ProbeAgent failed:", error);
          throw new Error(
            `ProbeAgent execution failed: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        } finally {
          Object.keys(originalEnv).forEach((key) => {
            if (originalEnv[key] === void 0) {
              delete process.env[key];
            } else {
              process.env[key] = originalEnv[key];
            }
          });
        }
      }
      /**
       * Load schema content from schema files or inline definitions
       */
      async loadSchemaContent(schema) {
        const fs20 = require("fs").promises;
        const path22 = require("path");
        if (typeof schema === "object" && schema !== null) {
          log("\u{1F4CB} Using inline schema object from configuration");
          return JSON.stringify(schema);
        }
        try {
          const parsed = JSON.parse(schema);
          if (typeof parsed === "object" && parsed !== null) {
            log("\u{1F4CB} Using inline schema JSON string");
            return schema;
          }
        } catch {
        }
        if ((schema.startsWith("./") || schema.includes(".json")) && !path22.isAbsolute(schema)) {
          if (schema.includes("..") || schema.includes("\0")) {
            throw new Error("Invalid schema path: path traversal not allowed");
          }
          try {
            const schemaPath = path22.resolve(process.cwd(), schema);
            log(`\u{1F4CB} Loading custom schema from file: ${schemaPath}`);
            const schemaContent = await fs20.readFile(schemaPath, "utf-8");
            return schemaContent.trim();
          } catch (error) {
            throw new Error(
              `Failed to load custom schema from ${schema}: ${error instanceof Error ? error.message : "Unknown error"}`
            );
          }
        }
        const sanitizedSchemaName = schema.replace(/[^a-zA-Z0-9-]/g, "");
        if (!sanitizedSchemaName || sanitizedSchemaName !== schema) {
          throw new Error("Invalid schema name");
        }
        const candidatePaths = [
          // GitHub Action bundle location
          path22.join(__dirname, "output", sanitizedSchemaName, "schema.json"),
          // Historical fallback when src/output was inadvertently bundled as output1/
          path22.join(__dirname, "output1", sanitizedSchemaName, "schema.json"),
          // Local dev (repo root)
          path22.join(process.cwd(), "output", sanitizedSchemaName, "schema.json")
        ];
        for (const schemaPath of candidatePaths) {
          try {
            const schemaContent = await fs20.readFile(schemaPath, "utf-8");
            return schemaContent.trim();
          } catch {
          }
        }
        const distPath = path22.join(__dirname, "output", sanitizedSchemaName, "schema.json");
        const distAltPath = path22.join(__dirname, "output1", sanitizedSchemaName, "schema.json");
        const cwdPath = path22.join(process.cwd(), "output", sanitizedSchemaName, "schema.json");
        throw new Error(
          `Failed to load schema '${sanitizedSchemaName}'. Tried: ${distPath}, ${distAltPath}, and ${cwdPath}. Ensure build copies 'output/' into dist (build:cli), or provide a custom schema file/path.`
        );
      }
      /**
       * Parse AI response JSON
       */
      parseAIResponse(response, debugInfo, _schema) {
        log("\u{1F50D} Parsing AI response...");
        log(`\u{1F4CA} Raw response length: ${response.length} characters`);
        if (response.length > 400) {
          log("\u{1F4CB} Response preview (first 200 chars):", response.substring(0, 200));
          log("\u{1F4CB} Response preview (last 200 chars):", response.substring(response.length - 200));
        } else {
          log("\u{1F4CB} Full response preview:", response);
        }
        try {
          let reviewData;
          if (_schema === "plain" || !_schema) {
            log(
              `\u{1F4CB} ${_schema === "plain" ? "Plain" : "No"} schema detected - treating raw response as text output`
            );
            const trimmed = typeof response === "string" ? response.trim() : "";
            const out = trimmed ? { text: trimmed } : {};
            return {
              issues: [],
              // Expose assistant-style content via output.text so downstream formatters
              // (Slack frontend, CLI "Assistant Response" section, templates) can render it.
              output: out,
              debug: debugInfo
            };
          }
          {
            log("\u{1F50D} Extracting JSON from AI response...");
            const sanitizedResponse = response.replace(/^\uFEFF/, "").replace(/[\u200B-\u200D\uFEFF\u00A0]/g, "").replace(/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]/g, "").trim();
            try {
              reviewData = JSON.parse(sanitizedResponse);
              log("\u2705 Successfully parsed direct JSON response");
              if (debugInfo) debugInfo.jsonParseSuccess = true;
            } catch (parseErr) {
              const errMsg = parseErr instanceof Error ? parseErr.message : String(parseErr);
              log(`\u{1F50D} Direct JSON parsing failed: ${errMsg}`);
              if (response.toLowerCase().includes("i cannot") || response.toLowerCase().includes("unable to")) {
                console.error("\u{1F6AB} AI refused to analyze - returning empty result");
                return {
                  issues: []
                };
              }
              log("\u{1F527} Treating response as plain text (no JSON extraction)");
              const trimmed = response.trim();
              return {
                issues: [],
                output: { text: trimmed },
                debug: debugInfo
              };
            }
          }
          const looksLikeTextOutput = reviewData && typeof reviewData === "object" && typeof reviewData.text === "string" && String(reviewData.text).trim().length > 0;
          const isCustomSchema = _schema === "custom" || _schema && (_schema.startsWith("./") || _schema.endsWith(".json")) || _schema && _schema !== "code-review" && !_schema.includes("output/") || !_schema && looksLikeTextOutput;
          const _debugSchemaLogging = this.config.debug === true || process.env.VISOR_DEBUG_AI_SESSIONS === "true";
          if (_debugSchemaLogging) {
            const details = {
              schema: _schema,
              isCustomSchema,
              isCustomLiteral: _schema === "custom",
              startsWithDotSlash: typeof _schema === "string" ? _schema.startsWith("./") : false,
              endsWithJson: typeof _schema === "string" ? _schema.endsWith(".json") : false,
              notCodeReview: _schema !== "code-review",
              noOutputPrefix: typeof _schema === "string" ? !_schema.includes("output/") : false
            };
            try {
              log(`\u{1F50D} Schema detection: ${JSON.stringify(details)}`);
            } catch {
              log(
                `\u{1F50D} Schema detection: _schema="${String(_schema)}", isCustomSchema=${isCustomSchema}`
              );
            }
          }
          if (isCustomSchema) {
            log("\u{1F4CB} Custom schema detected - preserving all fields from parsed JSON");
            log(`\u{1F4CA} Schema: ${_schema}`);
            try {
              log(`\u{1F4CA} Custom schema keys: ${Object.keys(reviewData).join(", ")}`);
            } catch {
            }
            const out = reviewData && typeof reviewData === "object" ? reviewData : {};
            const hasText = typeof out.text === "string" && String(out.text).trim().length > 0;
            if (!hasText) {
              let fallbackText = "";
              try {
                if (Array.isArray(reviewData?.issues) && reviewData.issues.length > 0) {
                  fallbackText = reviewData.issues.map((i) => i && (i.message || i.text || i.response)).filter((s) => typeof s === "string" && s.trim().length > 0).join("\n");
                }
              } catch {
              }
              if (!fallbackText && typeof response === "string" && response.trim()) {
                fallbackText = response.trim().slice(0, 6e4);
              }
              if (fallbackText) {
                out.text = fallbackText;
              }
            }
            const result2 = {
              // Keep issues empty for custom-schema rendering; consumers read from output.*
              issues: [],
              output: out
            };
            log(
              "\u2705 Successfully created ReviewSummary with custom schema output (with fallback text when needed)"
            );
            return result2;
          }
          log("\u{1F50D} Validating parsed review data...");
          log(`\u{1F4CA} Overall score: ${0}`);
          log(`\u{1F4CB} Total issues: ${reviewData.issues?.length || 0}`);
          log(
            `\u{1F6A8} Critical issues: ${reviewData.issues?.filter((i) => i.severity === "critical").length || 0}`
          );
          log(`\u{1F4AC} Comments count: ${Array.isArray(reviewData.issues) ? reviewData.issues.length : 0}`);
          const processedIssues = Array.isArray(reviewData.issues) ? reviewData.issues.map((issue, index) => {
            log(`\u{1F50D} Processing issue ${index + 1}:`, issue);
            return {
              file: issue.file || "unknown",
              line: issue.line || 1,
              endLine: issue.endLine,
              ruleId: issue.ruleId || `${issue.category || "general"}/unknown`,
              message: issue.message || "",
              severity: issue.severity,
              category: issue.category,
              suggestion: issue.suggestion,
              replacement: issue.replacement
            };
          }) : [];
          const result = {
            issues: processedIssues
          };
          const criticalCount = (result.issues || []).filter((i) => i.severity === "critical").length;
          if (criticalCount > 0) {
            log(`\u{1F6A8} Found ${criticalCount} critical severity issue(s)`);
          }
          log(`\u{1F4C8} Total issues: ${(result.issues || []).length}`);
          log("\u2705 Successfully created ReviewSummary");
          return result;
        } catch (error) {
          const detailed = this.config.debug === true || process.env.VISOR_DEBUG_AI_SESSIONS === "true";
          const message = error instanceof Error ? error.message : String(error);
          if (detailed) {
            logger.debug(`\u274C Failed to parse AI response: ${message}`);
            logger.debug("\u{1F4C4} FULL RAW RESPONSE:");
            logger.debug("=".repeat(80));
            logger.debug(response);
            logger.debug("=".repeat(80));
            logger.debug(`\u{1F4CF} Response length: ${response.length} characters`);
            if (error instanceof SyntaxError) {
              logger.debug("\u{1F50D} JSON parsing error - the response may not be valid JSON");
              logger.debug(`\u{1F50D} Error details: ${error.message}`);
              const errorMatch = error.message.match(/position (\d+)/);
              if (errorMatch) {
                const position = parseInt(errorMatch[1]);
                logger.debug(`\u{1F50D} Error at position ${position}:`);
                const start = Math.max(0, position - 50);
                const end = Math.min(response.length, position + 50);
                logger.debug(`\u{1F50D} Context: "${response.substring(start, end)}"`);
                logger.debug(`\u{1F50D} Response beginning: "${response.substring(0, 100)}"`);
              }
              if (response.includes("I cannot")) {
                logger.debug("\u{1F50D} Response appears to be a refusal/explanation rather than JSON");
              }
              if (response.includes("```")) {
                logger.debug("\u{1F50D} Response appears to contain markdown code blocks");
              }
              if (response.startsWith("<")) {
                logger.debug("\u{1F50D} Response appears to start with XML/HTML");
              }
            }
          } else {
            logger.error(`\u274C Failed to parse AI response: ${message}`);
          }
          throw new Error(
            `Invalid AI response format: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Generate mock response for testing
       */
      async generateMockResponse(_prompt, _checkName, _schema) {
        await new Promise((resolve9) => setTimeout(resolve9, 500));
        const name = (_checkName || "").toLowerCase();
        if (name.includes("extract-facts")) {
          const arr = Array.from({ length: 6 }, (_, i) => ({
            id: `fact-${i + 1}`,
            category: "Feature",
            claim: `claim-${i + 1}`,
            verifiable: true,
            refs: [{ path: "src/check-execution-engine.ts", lines: "6400-6460" }]
          }));
          return JSON.stringify(arr);
        }
        if (name.includes("validate-fact")) {
          const idMatch = _prompt.match(/Fact ID:\s*([\w\-]+)/i);
          const claimMatch = _prompt.match(/\*\*Claim:\*\*\s*(.+)/i);
          const attemptMatch = _prompt.match(/Attempt:\s*(\d+)/i);
          const factId = idMatch ? idMatch[1] : "fact-1";
          const claim = claimMatch ? claimMatch[1].trim() : "unknown-claim";
          const n = Number(factId.split("-")[1] || "0");
          const attempt = attemptMatch ? Number(attemptMatch[1]) : 0;
          const isValid = attempt >= 1 ? true : !(n >= 1 && n <= 3);
          return JSON.stringify({
            fact_id: factId,
            claim,
            is_valid: isValid,
            confidence: "high",
            evidence: isValid ? "verified" : "not found",
            correction: isValid ? null : `correct ${claim}`
          });
        }
        if (name.includes("issue-assistant") || name.includes("comment-assistant")) {
          const text = "### Assistant Reply";
          const intent = name.includes("issue") ? "issue_triage" : "comment_reply";
          return JSON.stringify({ text, intent });
        }
        const mockResponse = { content: JSON.stringify({ issues: [], summary: { totalIssues: 0 } }) };
        return JSON.stringify(mockResponse);
      }
      /**
       * Get the API key source for debugging (without revealing the key)
       */
      getApiKeySource() {
        if (process.env.CLAUDE_CODE_API_KEY && this.config.provider === "claude-code") {
          return "CLAUDE_CODE_API_KEY";
        }
        if (process.env.GOOGLE_API_KEY && this.config.provider === "google") {
          return "GOOGLE_API_KEY";
        }
        if (process.env.ANTHROPIC_API_KEY && this.config.provider === "anthropic") {
          return "ANTHROPIC_API_KEY";
        }
        if (process.env.OPENAI_API_KEY && this.config.provider === "openai") {
          return "OPENAI_API_KEY";
        }
        if (this.config.provider === "bedrock") {
          if (process.env.AWS_BEDROCK_API_KEY) {
            return "AWS_BEDROCK_API_KEY";
          }
          if (process.env.AWS_ACCESS_KEY_ID && process.env.AWS_SECRET_ACCESS_KEY) {
            return "AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY";
          }
        }
        return "unknown";
      }
    };
  }
});

// src/utils/env-resolver.ts
var EnvironmentResolver;
var init_env_resolver = __esm({
  "src/utils/env-resolver.ts"() {
    "use strict";
    EnvironmentResolver = class {
      /**
       * Resolves a single configuration value that may contain environment variable references
       */
      static resolveValue(value) {
        if (typeof value !== "string") {
          return value;
        }
        let resolved = value.replace(/\$\{\{\s*env\.([A-Z_][A-Z0-9_]*)\s*\}\}/g, (match, envVar) => {
          return process.env[envVar] || match;
        });
        resolved = resolved.replace(/\$\{([A-Z_][A-Z0-9_]*)\}/g, (match, envVar) => {
          return process.env[envVar] || match;
        });
        resolved = resolved.replace(/\$([A-Z_][A-Z0-9_]*)/g, (match, envVar) => {
          return process.env[envVar] || match;
        });
        return resolved;
      }
      /**
       * Resolves all environment variables in an EnvConfig object
       */
      static resolveEnvConfig(envConfig) {
        const resolved = {};
        for (const [key, value] of Object.entries(envConfig)) {
          resolved[key] = this.resolveValue(value);
        }
        return resolved;
      }
      /**
       * Applies environment configuration to the process environment
       * This allows checks to access their specific environment variables
       */
      static applyEnvConfig(envConfig) {
        const resolved = this.resolveEnvConfig(envConfig);
        for (const [key, value] of Object.entries(resolved)) {
          if (value !== void 0) {
            process.env[key] = String(value);
          }
        }
      }
      /**
       * Creates a temporary environment for a specific check execution
       * Returns a cleanup function to restore the original environment
       */
      static withTemporaryEnv(envConfig, callback) {
        const resolved = this.resolveEnvConfig(envConfig);
        const originalValues = {};
        for (const [key, value] of Object.entries(resolved)) {
          originalValues[key] = process.env[key];
          if (value !== void 0) {
            process.env[key] = String(value);
          }
        }
        try {
          const result = callback();
          if (result instanceof Promise) {
            return result.finally(() => {
              for (const [key, originalValue] of Object.entries(originalValues)) {
                if (originalValue === void 0) {
                  delete process.env[key];
                } else {
                  process.env[key] = originalValue;
                }
              }
            });
          }
          for (const [key, originalValue] of Object.entries(originalValues)) {
            if (originalValue === void 0) {
              delete process.env[key];
            } else {
              process.env[key] = originalValue;
            }
          }
          return result;
        } catch (error) {
          for (const [key, originalValue] of Object.entries(originalValues)) {
            if (originalValue === void 0) {
              delete process.env[key];
            } else {
              process.env[key] = originalValue;
            }
          }
          throw error;
        }
      }
      /**
       * Validates that all required environment variables are available
       */
      static validateRequiredEnvVars(envConfig, requiredVars) {
        const resolved = this.resolveEnvConfig(envConfig);
        const missing = [];
        for (const varName of requiredVars) {
          const value = resolved[varName] || process.env[varName];
          if (!value) {
            missing.push(varName);
          }
        }
        return missing;
      }
      /**
       * Resolves environment variables in HTTP headers
       * Each header value is processed through resolveValue to replace env var references
       */
      static resolveHeaders(headers) {
        const resolved = {};
        for (const [key, value] of Object.entries(headers)) {
          resolved[key] = String(this.resolveValue(value));
        }
        return resolved;
      }
      /**
       * Sanitizes headers for logging/telemetry by redacting sensitive values
       * Headers like Authorization, API keys, and cookies are replaced with [REDACTED]
       */
      static sanitizeHeaders(headers) {
        const sensitiveHeaders = ["authorization", "x-api-key", "cookie", "set-cookie"];
        const sanitized = {};
        for (const [key, value] of Object.entries(headers)) {
          if (sensitiveHeaders.includes(key.toLowerCase())) {
            sanitized[key] = "[REDACTED]";
          } else {
            sanitized[key] = value;
          }
        }
        return sanitized;
      }
    };
  }
});

// src/issue-filter.ts
var issue_filter_exports = {};
__export(issue_filter_exports, {
  IssueFilter: () => IssueFilter
});
var fs6, path7, IssueFilter;
var init_issue_filter = __esm({
  "src/issue-filter.ts"() {
    "use strict";
    fs6 = __toESM(require("fs"));
    path7 = __toESM(require("path"));
    IssueFilter = class {
      fileCache = /* @__PURE__ */ new Map();
      suppressionEnabled;
      constructor(suppressionEnabled = true) {
        this.suppressionEnabled = suppressionEnabled;
      }
      /**
       * Filter out issues that have suppression comments
       * @param issues Array of issues to filter
       * @param workingDir Working directory for resolving file paths
       * @returns Filtered array of issues with suppressed ones removed
       */
      filterIssues(issues, workingDir = process.cwd()) {
        if (!this.suppressionEnabled || !issues || issues.length === 0) {
          return issues;
        }
        const filteredIssues = [];
        const suppressedCount = {};
        for (const issue of issues) {
          if (this.shouldSuppressIssue(issue, workingDir)) {
            suppressedCount[issue.file] = (suppressedCount[issue.file] || 0) + 1;
          } else {
            filteredIssues.push(issue);
          }
        }
        const totalSuppressed = Object.values(suppressedCount).reduce((sum, count) => sum + count, 0);
        if (totalSuppressed > 0) {
          console.log(`\u{1F507} Suppressed ${totalSuppressed} issue(s) via visor-disable comments:`);
          for (const [file, count] of Object.entries(suppressedCount)) {
            console.log(`   - ${file}: ${count} issue(s)`);
          }
        }
        return filteredIssues;
      }
      /**
       * Check if an issue should be suppressed based on comments in the file
       */
      shouldSuppressIssue(issue, workingDir) {
        if (!issue.file || issue.file === "system" || issue.file === "webhook" || issue.line === 0) {
          return false;
        }
        const lines = this.getFileLines(issue.file, workingDir);
        if (!lines || lines.length === 0) {
          return false;
        }
        const firstFiveLines = lines.slice(0, 5).join("\n").toLowerCase();
        if (firstFiveLines.includes("visor-disable-file")) {
          return true;
        }
        const lineIndex = issue.line - 1;
        const startLine = Math.max(0, lineIndex - 2);
        const endLine = Math.min(lines.length - 1, lineIndex + 2);
        for (let i = startLine; i <= endLine; i++) {
          if (lines[i].toLowerCase().includes("visor-disable")) {
            return true;
          }
        }
        return false;
      }
      /**
       * Get file lines from cache or read from disk
       */
      getFileLines(filePath, workingDir) {
        if (this.fileCache.has(filePath)) {
          return this.fileCache.get(filePath);
        }
        try {
          const resolvedPath = path7.isAbsolute(filePath) ? filePath : path7.join(workingDir, filePath);
          if (!fs6.existsSync(resolvedPath)) {
            if (fs6.existsSync(filePath)) {
              const content2 = fs6.readFileSync(filePath, "utf8");
              const lines2 = content2.split("\n");
              this.fileCache.set(filePath, lines2);
              return lines2;
            }
            return null;
          }
          const content = fs6.readFileSync(resolvedPath, "utf8");
          const lines = content.split("\n");
          this.fileCache.set(filePath, lines);
          return lines;
        } catch {
          return null;
        }
      }
      /**
       * Clear the file cache (useful for testing or long-running processes)
       */
      clearCache() {
        this.fileCache.clear();
      }
    };
  }
});

// src/telemetry/state-capture.ts
var state_capture_exports = {};
__export(state_capture_exports, {
  captureCheckInputContext: () => captureCheckInputContext,
  captureCheckOutput: () => captureCheckOutput,
  captureConditionalEvaluation: () => captureConditionalEvaluation,
  captureForEachState: () => captureForEachState,
  captureLiquidEvaluation: () => captureLiquidEvaluation,
  captureProviderCall: () => captureProviderCall,
  captureRoutingDecision: () => captureRoutingDecision,
  captureStateSnapshot: () => captureStateSnapshot,
  captureTransformJS: () => captureTransformJS,
  sanitizeContextForTelemetry: () => sanitizeContextForTelemetry
});
function isSensitiveEnvVar(name) {
  return SENSITIVE_ENV_PATTERNS.some((pattern) => pattern.test(name));
}
function sanitizeContextForTelemetry(context2) {
  if (!context2 || typeof context2 !== "object") return context2;
  const sanitized = { ...context2 };
  if (sanitized.env && typeof sanitized.env === "object") {
    const sanitizedEnv = {};
    for (const [key, value] of Object.entries(sanitized.env)) {
      if (isSensitiveEnvVar(key)) {
        sanitizedEnv[key] = "[REDACTED]";
      } else {
        sanitizedEnv[key] = String(value);
      }
    }
    sanitized.env = sanitizedEnv;
  }
  return sanitized;
}
function safeSerialize(value, maxLength = MAX_ATTRIBUTE_LENGTH) {
  try {
    if (value === void 0 || value === null) return String(value);
    const seen = /* @__PURE__ */ new WeakSet();
    const json = JSON.stringify(value, (key, val) => {
      if (typeof val === "object" && val !== null) {
        if (seen.has(val)) return "[Circular]";
        seen.add(val);
      }
      if (typeof val === "string" && val.length > maxLength) {
        return val.substring(0, maxLength) + "...[truncated]";
      }
      return val;
    });
    if (json.length > maxLength) {
      return json.substring(0, maxLength) + "...[truncated]";
    }
    return json;
  } catch (err) {
    return `[Error serializing: ${err instanceof Error ? err.message : String(err)}]`;
  }
}
function captureCheckInputContext(span, context2) {
  try {
    const sanitizedContext = sanitizeContextForTelemetry(context2);
    const keys = Object.keys(sanitizedContext);
    span.setAttribute("visor.check.input.keys", keys.join(","));
    span.setAttribute("visor.check.input.count", keys.length);
    span.setAttribute("visor.check.input.context", safeSerialize(sanitizedContext));
    if (sanitizedContext.pr) {
      span.setAttribute("visor.check.input.pr", safeSerialize(sanitizedContext.pr, 1e3));
    }
    if (sanitizedContext.outputs) {
      span.setAttribute("visor.check.input.outputs", safeSerialize(sanitizedContext.outputs, 5e3));
    }
    if (sanitizedContext.env) {
      span.setAttribute(
        "visor.check.input.env_keys",
        Object.keys(sanitizedContext.env).join(",")
      );
    }
  } catch (err) {
    try {
      span.setAttribute("visor.check.input.error", String(err));
    } catch {
    }
  }
}
function captureCheckOutput(span, output) {
  try {
    span.setAttribute("visor.check.output.type", typeof output);
    if (Array.isArray(output)) {
      span.setAttribute("visor.check.output.length", output.length);
      const preview = output.slice(0, 10);
      span.setAttribute("visor.check.output.preview", safeSerialize(preview, 2e3));
    }
    span.setAttribute("visor.check.output", safeSerialize(output));
  } catch (err) {
    try {
      span.setAttribute("visor.check.output.error", String(err));
    } catch {
    }
  }
}
function captureForEachState(span, items, index, currentItem) {
  try {
    span.setAttribute("visor.foreach.total", items.length);
    span.setAttribute("visor.foreach.index", index);
    span.setAttribute("visor.foreach.current_item", safeSerialize(currentItem, 500));
    if (items.length <= MAX_ARRAY_ITEMS) {
      span.setAttribute("visor.foreach.items", safeSerialize(items));
    } else {
      span.setAttribute(
        "visor.foreach.items.preview",
        safeSerialize(items.slice(0, MAX_ARRAY_ITEMS))
      );
      span.setAttribute("visor.foreach.items.truncated", true);
    }
  } catch (err) {
    span.setAttribute("visor.foreach.error", String(err));
  }
}
function captureLiquidEvaluation(span, template, context2, result) {
  try {
    span.setAttribute("visor.liquid.template", template.substring(0, 1e3));
    span.setAttribute("visor.liquid.template.length", template.length);
    span.setAttribute("visor.liquid.result", result.substring(0, 2e3));
    span.setAttribute("visor.liquid.result.length", result.length);
    span.setAttribute("visor.liquid.context", safeSerialize(context2, 3e3));
  } catch (err) {
    span.setAttribute("visor.liquid.error", String(err));
  }
}
function captureTransformJS(span, code, input, output) {
  try {
    const codePreview = code.length > 2e3 ? code.substring(0, 2e3) + "...[truncated]" : code;
    span.setAttribute("visor.transform.code", codePreview);
    span.setAttribute("visor.transform.code.length", code.length);
    span.setAttribute("visor.transform.input", safeSerialize(input, 2e3));
    span.setAttribute("visor.transform.output", safeSerialize(output, 2e3));
  } catch (err) {
    span.setAttribute("visor.transform.error", String(err));
  }
}
function captureProviderCall(span, providerType, request, response) {
  try {
    span.setAttribute("visor.provider.type", providerType);
    const fullCapture = process.env.VISOR_TELEMETRY_FULL_CAPTURE === "true" || process.env.VISOR_TELEMETRY_FULL_CAPTURE === "1";
    if (request.model) span.setAttribute("visor.provider.request.model", String(request.model));
    if (request.prompt) {
      span.setAttribute("visor.provider.request.prompt.length", request.prompt.length);
      span.setAttribute("visor.provider.request.prompt.preview", request.prompt.substring(0, 500));
      if (fullCapture) {
        span.setAttribute("visor.provider.request.prompt", safeSerialize(request.prompt));
      }
    }
    if (response.content) {
      span.setAttribute("visor.provider.response.length", response.content.length);
      span.setAttribute("visor.provider.response.preview", response.content.substring(0, 500));
      if (fullCapture) {
        span.setAttribute("visor.provider.response.content", safeSerialize(response.content));
      }
    }
    if (response.tokens) {
      span.setAttribute("visor.provider.response.tokens", response.tokens);
    }
  } catch (err) {
    span.setAttribute("visor.provider.error", String(err));
  }
}
function captureConditionalEvaluation(span, condition, result, context2) {
  try {
    span.setAttribute("visor.condition.expression", condition.substring(0, 500));
    span.setAttribute("visor.condition.result", result);
    span.setAttribute("visor.condition.context", safeSerialize(context2, 2e3));
  } catch (err) {
    span.setAttribute("visor.condition.error", String(err));
  }
}
function captureRoutingDecision(span, action, target, condition) {
  try {
    span.setAttribute("visor.routing.action", action);
    span.setAttribute("visor.routing.target", Array.isArray(target) ? target.join(",") : target);
    if (condition) {
      span.setAttribute("visor.routing.condition", condition.substring(0, 500));
    }
  } catch (err) {
    span.setAttribute("visor.routing.error", String(err));
  }
}
function captureStateSnapshot(span, checkId, outputs, memory) {
  try {
    span.addEvent("state.snapshot", {
      "visor.snapshot.check_id": checkId,
      "visor.snapshot.outputs": safeSerialize(outputs, 5e3),
      "visor.snapshot.memory": safeSerialize(memory, 5e3),
      "visor.snapshot.timestamp": (/* @__PURE__ */ new Date()).toISOString()
    });
  } catch (err) {
    span.setAttribute("visor.snapshot.error", String(err));
  }
}
var MAX_ATTRIBUTE_LENGTH, MAX_ARRAY_ITEMS, SENSITIVE_ENV_PATTERNS;
var init_state_capture = __esm({
  "src/telemetry/state-capture.ts"() {
    "use strict";
    MAX_ATTRIBUTE_LENGTH = 1e4;
    MAX_ARRAY_ITEMS = 100;
    SENSITIVE_ENV_PATTERNS = [
      /api[_-]?key/i,
      /secret/i,
      /token/i,
      /password/i,
      /auth/i,
      /credential/i,
      /private[_-]?key/i,
      /^sk-/i,
      // OpenAI-style keys
      /^AIza/i
      // Google API keys
    ];
  }
});

// src/utils/command-executor.ts
var command_executor_exports = {};
__export(command_executor_exports, {
  CommandExecutor: () => CommandExecutor,
  commandExecutor: () => commandExecutor
});
var import_child_process, import_util, CommandExecutor, commandExecutor;
var init_command_executor = __esm({
  "src/utils/command-executor.ts"() {
    "use strict";
    import_child_process = require("child_process");
    import_util = require("util");
    init_logger();
    CommandExecutor = class _CommandExecutor {
      static instance;
      constructor() {
      }
      static getInstance() {
        if (!_CommandExecutor.instance) {
          _CommandExecutor.instance = new _CommandExecutor();
        }
        return _CommandExecutor.instance;
      }
      /**
       * Execute a shell command with optional stdin, environment, and timeout
       */
      async execute(command, options = {}) {
        const execAsync = (0, import_util.promisify)(import_child_process.exec);
        const timeout = options.timeout || 3e4;
        if (options.stdin) {
          return this.executeWithStdin(command, options);
        }
        try {
          const result = await execAsync(command, {
            cwd: options.cwd,
            env: options.env,
            timeout
          });
          return {
            stdout: result.stdout || "",
            stderr: result.stderr || "",
            exitCode: 0
          };
        } catch (error) {
          return this.handleExecutionError(error, timeout);
        }
      }
      /**
       * Execute command with stdin input
       */
      executeWithStdin(command, options) {
        return new Promise((resolve9, reject) => {
          const childProcess = (0, import_child_process.exec)(
            command,
            {
              cwd: options.cwd,
              env: options.env,
              timeout: options.timeout || 3e4
            },
            (error, stdout, stderr) => {
              if (error && error.killed && (error.code === "ETIMEDOUT" || error.signal === "SIGTERM")) {
                reject(new Error(`Command timed out after ${options.timeout || 3e4}ms`));
              } else {
                resolve9({
                  stdout: stdout || "",
                  stderr: stderr || "",
                  exitCode: error ? error.code || 1 : 0
                });
              }
            }
          );
          if (options.stdin && childProcess.stdin) {
            childProcess.stdin.write(options.stdin);
            childProcess.stdin.end();
          }
        });
      }
      /**
       * Handle execution errors consistently
       */
      handleExecutionError(error, timeout) {
        const execError = error;
        if (execError.killed && (execError.code === "ETIMEDOUT" || execError.signal === "SIGTERM")) {
          throw new Error(`Command timed out after ${timeout}ms`);
        }
        let exitCode = 1;
        if (execError.code) {
          exitCode = typeof execError.code === "string" ? parseInt(execError.code, 10) : execError.code;
        }
        return {
          stdout: execError.stdout || "",
          stderr: execError.stderr || "",
          exitCode
        };
      }
      /**
       * Build safe environment variables by merging process.env with custom env
       * Ensures all values are strings (no undefined)
       */
      buildEnvironment(baseEnv = process.env, ...customEnvs) {
        const result = {};
        for (const [key, value] of Object.entries(baseEnv)) {
          if (value !== void 0) {
            result[key] = value;
          }
        }
        for (const customEnv of customEnvs) {
          if (customEnv) {
            Object.assign(result, customEnv);
          }
        }
        return result;
      }
      /**
       * Log command execution for debugging
       */
      logExecution(command, options) {
        const debugInfo = [
          `Executing command: ${command}`,
          options.cwd ? `cwd: ${options.cwd}` : null,
          options.stdin ? "with stdin" : null,
          options.timeout ? `timeout: ${options.timeout}ms` : null,
          options.env ? `env vars: ${Object.keys(options.env).length}` : null
        ].filter(Boolean).join(", ");
        logger.debug(debugInfo);
      }
    };
    commandExecutor = CommandExecutor.getInstance();
  }
});

// src/providers/custom-tool-executor.ts
var import_ajv, CustomToolExecutor;
var init_custom_tool_executor = __esm({
  "src/providers/custom-tool-executor.ts"() {
    "use strict";
    init_liquid_extensions();
    init_sandbox();
    init_logger();
    init_command_executor();
    import_ajv = __toESM(require("ajv"));
    CustomToolExecutor = class {
      liquid;
      sandbox;
      tools;
      ajv;
      constructor(tools) {
        this.liquid = createExtendedLiquid({
          cache: false,
          strictFilters: false,
          strictVariables: false
        });
        this.tools = new Map(Object.entries(tools || {}));
        this.ajv = new import_ajv.default({ allErrors: true, verbose: true });
      }
      /**
       * Register a custom tool
       */
      registerTool(tool) {
        if (!tool.name) {
          throw new Error("Tool must have a name");
        }
        this.tools.set(tool.name, tool);
      }
      /**
       * Register multiple tools
       */
      registerTools(tools) {
        for (const [name, tool] of Object.entries(tools)) {
          tool.name = tool.name || name;
          this.registerTool(tool);
        }
      }
      /**
       * Get all registered tools
       */
      getTools() {
        return Array.from(this.tools.values());
      }
      /**
       * Get a specific tool by name
       */
      getTool(name) {
        return this.tools.get(name);
      }
      /**
       * Validate tool input against schema using ajv
       */
      validateInput(tool, input) {
        if (!tool.inputSchema) {
          return;
        }
        const validate = this.ajv.compile(tool.inputSchema);
        const valid = validate(input);
        if (!valid) {
          const errors = validate.errors?.map((err) => {
            if (err.instancePath) {
              return `${err.instancePath}: ${err.message}`;
            }
            return err.message;
          }).join(", ");
          throw new Error(`Input validation failed for tool '${tool.name}': ${errors}`);
        }
      }
      /**
       * Execute a custom tool
       */
      async execute(toolName, args, context2) {
        const tool = this.tools.get(toolName);
        if (!tool) {
          throw new Error(`Tool not found: ${toolName}`);
        }
        this.validateInput(tool, args);
        const templateContext = {
          ...context2,
          args,
          input: args
        };
        const command = await this.liquid.parseAndRender(tool.exec, templateContext);
        let stdin;
        if (tool.stdin) {
          stdin = await this.liquid.parseAndRender(tool.stdin, templateContext);
        }
        const env = commandExecutor.buildEnvironment(process.env, tool.env, context2?.env);
        const result = await commandExecutor.execute(command, {
          stdin,
          cwd: tool.cwd,
          env,
          timeout: tool.timeout || 3e4
        });
        if (result.exitCode !== 0) {
          const errorOutput = result.stderr || result.stdout || "Command failed";
          throw new Error(
            `Tool '${toolName}' execution failed with exit code ${result.exitCode}: ${errorOutput}`
          );
        }
        let output = result.stdout;
        if (tool.parseJson) {
          try {
            output = JSON.parse(result.stdout);
          } catch (e) {
            const err = e instanceof Error ? e : new Error(String(e));
            logger.warn(`Failed to parse tool output as JSON: ${err.message}`);
            if (!tool.transform && !tool.transform_js) {
              throw new Error(`Tool '${toolName}' output could not be parsed as JSON: ${err.message}`);
            }
          }
        }
        if (tool.transform) {
          const transformContext = {
            ...templateContext,
            output,
            stdout: result.stdout,
            stderr: result.stderr,
            exitCode: result.exitCode
          };
          const transformed = await this.liquid.parseAndRender(tool.transform, transformContext);
          if (typeof transformed === "string" && transformed.trim().startsWith("{")) {
            try {
              output = JSON.parse(transformed);
            } catch {
              output = transformed;
            }
          } else {
            output = transformed;
          }
        }
        if (tool.transform_js) {
          output = await this.applyJavaScriptTransform(tool.transform_js, output, {
            ...templateContext,
            stdout: result.stdout,
            stderr: result.stderr,
            exitCode: result.exitCode
          });
        }
        return output;
      }
      /**
       * Apply JavaScript transform to output
       */
      async applyJavaScriptTransform(transformJs, output, context2) {
        if (!this.sandbox) {
          this.sandbox = createSecureSandbox();
        }
        const code = `
      const output = ${JSON.stringify(output)};
      const context = ${JSON.stringify(context2)};
      const args = context.args || {};
      const pr = context.pr || {};
      const files = context.files || [];
      const outputs = context.outputs || {};
      const env = context.env || {};

      ${transformJs}
    `;
        try {
          return await compileAndRun(this.sandbox, code, { timeout: 5e3 });
        } catch (error) {
          logger.error(`JavaScript transform error: ${error}`);
          throw error;
        }
      }
      /**
       * Convert custom tools to MCP tool format
       */
      toMcpTools() {
        return Array.from(this.tools.values()).map((tool) => ({
          name: tool.name,
          description: tool.description,
          inputSchema: tool.inputSchema,
          handler: async (args) => {
            return this.execute(tool.name, args);
          }
        }));
      }
    };
  }
});

// src/workflow-registry.ts
var workflow_registry_exports = {};
__export(workflow_registry_exports, {
  WorkflowRegistry: () => WorkflowRegistry
});
var import_fs, path8, yaml, import_ajv2, import_ajv_formats, WorkflowRegistry;
var init_workflow_registry = __esm({
  "src/workflow-registry.ts"() {
    "use strict";
    import_fs = require("fs");
    path8 = __toESM(require("path"));
    yaml = __toESM(require("js-yaml"));
    init_logger();
    init_dependency_resolver();
    import_ajv2 = __toESM(require("ajv"));
    import_ajv_formats = __toESM(require("ajv-formats"));
    WorkflowRegistry = class _WorkflowRegistry {
      static instance;
      workflows = /* @__PURE__ */ new Map();
      ajv;
      constructor() {
        this.ajv = new import_ajv2.default({ allErrors: true, strict: false });
        (0, import_ajv_formats.default)(this.ajv);
      }
      /**
       * Get the singleton instance of the workflow registry
       */
      static getInstance() {
        if (!_WorkflowRegistry.instance) {
          _WorkflowRegistry.instance = new _WorkflowRegistry();
        }
        return _WorkflowRegistry.instance;
      }
      /**
       * Register a workflow definition
       */
      register(workflow, source = "inline", options) {
        const validation = this.validateWorkflow(workflow);
        if (!validation.valid) {
          return validation;
        }
        if (this.workflows.has(workflow.id) && !options?.override) {
          return {
            valid: false,
            errors: [
              {
                path: "id",
                message: `Workflow with ID '${workflow.id}' already exists`,
                value: workflow.id
              }
            ]
          };
        }
        this.workflows.set(workflow.id, {
          definition: workflow,
          source,
          registeredAt: /* @__PURE__ */ new Date(),
          usage: {
            count: 0
          }
        });
        logger.debug(`Registered workflow '${workflow.id}' from ${source}`);
        return { valid: true };
      }
      /**
       * Get a workflow by ID
       */
      get(id) {
        const entry = this.workflows.get(id);
        if (entry) {
          entry.usage = entry.usage || { count: 0 };
          entry.usage.count++;
          entry.usage.lastUsed = /* @__PURE__ */ new Date();
        }
        return entry?.definition;
      }
      /**
       * Check if a workflow exists
       */
      has(id) {
        return this.workflows.has(id);
      }
      /**
       * List all registered workflows
       */
      list() {
        return Array.from(this.workflows.values()).map((entry) => entry.definition);
      }
      /**
       * Get workflow metadata
       */
      getMetadata(id) {
        return this.workflows.get(id);
      }
      /**
       * Remove a workflow from the registry
       */
      unregister(id) {
        return this.workflows.delete(id);
      }
      /**
       * Clear all workflows
       */
      clear() {
        this.workflows.clear();
      }
      /**
       * Import workflows from a file or URL
       */
      async import(source, options) {
        const results = [];
        try {
          const content = await this.loadWorkflowContent(source, options?.basePath);
          const data = this.parseWorkflowContent(content, source);
          const workflows = Array.isArray(data) ? data : [data];
          for (const workflow of workflows) {
            if (options?.validate !== false) {
              const validation = this.validateWorkflow(workflow);
              if (!validation.valid) {
                results.push(validation);
                continue;
              }
              if (options?.validators) {
                for (const validator of options.validators) {
                  const customValidation = validator(workflow);
                  if (!customValidation.valid) {
                    results.push(customValidation);
                    continue;
                  }
                }
              }
            }
            const workflowWithoutTests = { ...workflow };
            delete workflowWithoutTests.tests;
            const result = this.register(workflowWithoutTests, source, { override: options?.override });
            results.push(result);
          }
        } catch (error) {
          results.push({
            valid: false,
            errors: [
              {
                path: "source",
                message: `Failed to import workflows from '${source}': ${error instanceof Error ? error.message : String(error)}`,
                value: source
              }
            ]
          });
        }
        return results;
      }
      /**
       * Import multiple workflow sources
       */
      async importMany(sources, options) {
        const results = /* @__PURE__ */ new Map();
        for (const source of sources) {
          const importResults = await this.import(source, options);
          results.set(source, importResults);
        }
        return results;
      }
      /**
       * Validate a workflow definition
       */
      validateWorkflow(workflow) {
        const errors = [];
        const warnings = [];
        if (!workflow.id) {
          errors.push({ path: "id", message: "Workflow ID is required" });
        }
        if (!workflow.name) {
          errors.push({ path: "name", message: "Workflow name is required" });
        }
        if (!workflow.steps || Object.keys(workflow.steps).length === 0) {
          errors.push({ path: "steps", message: "Workflow must have at least one step" });
        }
        if (workflow.inputs) {
          for (let i = 0; i < workflow.inputs.length; i++) {
            const input = workflow.inputs[i];
            if (!input.name) {
              errors.push({ path: `inputs[${i}].name`, message: "Input parameter name is required" });
            }
            if (!input.schema) {
              warnings.push({
                path: `inputs[${i}].schema`,
                message: "Input parameter schema is recommended"
              });
            }
          }
        }
        if (workflow.outputs) {
          for (let i = 0; i < workflow.outputs.length; i++) {
            const output = workflow.outputs[i];
            if (!output.name) {
              errors.push({ path: `outputs[${i}].name`, message: "Output parameter name is required" });
            }
            if (!output.value && !output.value_js) {
              errors.push({
                path: `outputs[${i}]`,
                message: "Output parameter must have either value or value_js"
              });
            }
          }
        }
        for (const [stepId, step] of Object.entries(workflow.steps || {})) {
          if (step.depends_on) {
            for (const dep of step.depends_on) {
              if (!workflow.steps[dep]) {
                errors.push({
                  path: `steps.${stepId}.depends_on`,
                  message: `Step '${stepId}' depends on non-existent step '${dep}'`,
                  value: dep
                });
              }
            }
          }
          if (step.inputs) {
            for (const [inputName, mapping] of Object.entries(step.inputs)) {
              if (typeof mapping === "object" && mapping !== null && "source" in mapping) {
                const typedMapping = mapping;
                if (typedMapping.source === "step" && !typedMapping.stepId) {
                  errors.push({
                    path: `steps.${stepId}.inputs.${inputName}`,
                    message: 'Step input mapping with source "step" must have stepId'
                  });
                }
                if (typedMapping.source === "param") {
                  const paramExists = workflow.inputs?.some((p) => p.name === typedMapping.value);
                  if (!paramExists) {
                    errors.push({
                      path: `steps.${stepId}.inputs.${inputName}`,
                      message: `Step input references non-existent parameter '${typedMapping.value}'`,
                      value: typedMapping.value
                    });
                  }
                }
              }
            }
          }
        }
        const circularDeps = this.detectCircularDependencies(workflow);
        if (circularDeps.length > 0) {
          errors.push({
            path: "steps",
            message: `Circular dependencies detected: ${circularDeps.join(" -> ")}`
          });
        }
        return {
          valid: errors.length === 0,
          errors: errors.length > 0 ? errors : void 0,
          warnings: warnings.length > 0 ? warnings : void 0
        };
      }
      /**
       * Validate input values against workflow input schema
       */
      validateInputs(workflow, inputs) {
        const errors = [];
        if (!workflow.inputs) {
          return { valid: true };
        }
        for (const param of workflow.inputs) {
          if (param.required !== false && !(param.name in inputs) && param.default === void 0) {
            errors.push({
              path: `inputs.${param.name}`,
              message: `Required input '${param.name}' is missing`
            });
          }
        }
        for (const param of workflow.inputs) {
          if (param.name in inputs && param.schema) {
            const value = inputs[param.name];
            const valid = this.validateAgainstSchema(value, param.schema);
            if (!valid.valid) {
              errors.push({
                path: `inputs.${param.name}`,
                message: valid.error || "Invalid input value",
                value
              });
            }
          }
        }
        return {
          valid: errors.length === 0,
          errors: errors.length > 0 ? errors : void 0
        };
      }
      /**
       * Load workflow content from file or URL
       */
      async loadWorkflowContent(source, basePath) {
        if (source.startsWith("http://") || source.startsWith("https://")) {
          const response = await fetch(source);
          if (!response.ok) {
            throw new Error(`Failed to fetch workflow from ${source}: ${response.statusText}`);
          }
          return await response.text();
        }
        const filePath = path8.isAbsolute(source) ? source : path8.resolve(basePath || process.cwd(), source);
        return await import_fs.promises.readFile(filePath, "utf-8");
      }
      /**
       * Parse workflow content (YAML or JSON)
       */
      parseWorkflowContent(content, source) {
        try {
          return JSON.parse(content);
        } catch {
          try {
            return yaml.load(content);
          } catch (error) {
            throw new Error(
              `Failed to parse workflow file ${source}: ${error instanceof Error ? error.message : String(error)}`
            );
          }
        }
      }
      /**
       * Detect circular dependencies in workflow steps using DependencyResolver
       */
      detectCircularDependencies(workflow) {
        const dependencies = {};
        for (const [stepId, step] of Object.entries(workflow.steps || {})) {
          const rawDeps = step.depends_on;
          dependencies[stepId] = Array.isArray(rawDeps) ? rawDeps : rawDeps ? [rawDeps] : [];
        }
        try {
          const graph = DependencyResolver.buildDependencyGraph(dependencies);
          if (graph.hasCycles && graph.cycleNodes) {
            return graph.cycleNodes;
          }
          return [];
        } catch {
          return [];
        }
      }
      /**
       * Validate a value against a JSON schema
       */
      validateAgainstSchema(value, schema) {
        try {
          const validate = this.ajv.compile(schema);
          const valid = validate(value);
          if (!valid) {
            const errors = validate.errors?.map((e) => `${e.instancePath || "/"}: ${e.message}`).join(", ");
            return { valid: false, error: errors };
          }
          return { valid: true };
        } catch (error) {
          return { valid: false, error: error instanceof Error ? error.message : String(error) };
        }
      }
    };
  }
});

// src/workflow-executor.ts
var import_liquidjs2, WorkflowExecutor;
var init_workflow_executor = __esm({
  "src/workflow-executor.ts"() {
    "use strict";
    init_check_provider_registry();
    init_dependency_resolver();
    init_logger();
    init_sandbox();
    import_liquidjs2 = require("liquidjs");
    WorkflowExecutor = class {
      providerRegistry = null;
      liquid;
      constructor() {
        this.liquid = new import_liquidjs2.Liquid();
      }
      /**
       * Lazy-load the provider registry to avoid circular dependency during initialization
       */
      getProviderRegistry() {
        if (!this.providerRegistry) {
          this.providerRegistry = CheckProviderRegistry.getInstance();
        }
        return this.providerRegistry;
      }
      /**
       * Execute a workflow
       */
      async execute(workflow, executionContext, runOptions) {
        const startTime = Date.now();
        executionContext.metadata = {
          startTime,
          status: "running"
        };
        try {
          const executionOrder = this.resolveExecutionOrder(workflow);
          logger.debug(`Workflow ${workflow.id} execution order: ${executionOrder.join(" -> ")}`);
          const stepResults = /* @__PURE__ */ new Map();
          const stepSummaries = [];
          for (const stepId of executionOrder) {
            const step = workflow.steps[stepId];
            if (step.if) {
              const shouldRun = this.evaluateCondition(step.if, {
                inputs: executionContext.inputs,
                outputs: Object.fromEntries(stepResults),
                pr: runOptions.prInfo
              });
              if (!shouldRun) {
                logger.info(`Skipping step '${stepId}' due to condition: ${step.if}`);
                stepSummaries.push({
                  stepId,
                  status: "skipped"
                });
                continue;
              }
            }
            const stepConfig = await this.prepareStepConfig(
              step,
              stepId,
              executionContext,
              stepResults,
              workflow
            );
            try {
              logger.info(`Executing workflow step '${stepId}'`);
              const stepContext = {
                ...runOptions.context,
                workflowInputs: executionContext.inputs
              };
              const result = await this.executeStep(
                stepConfig,
                runOptions.prInfo,
                stepResults,
                stepContext
              );
              stepResults.set(stepId, result);
              stepSummaries.push({
                stepId,
                status: "success",
                issues: result.issues,
                output: result.output
              });
            } catch (error) {
              const errorMessage = error instanceof Error ? error.message : String(error);
              logger.error(`Step '${stepId}' failed: ${errorMessage}`);
              stepSummaries.push({
                stepId,
                status: "failed",
                output: { error: errorMessage }
              });
              if (!runOptions.options?.continueOnError) {
                throw new Error(`Workflow step '${stepId}' failed: ${errorMessage}`);
              }
            }
          }
          const outputs = await this.computeOutputs(
            workflow,
            executionContext,
            stepResults,
            runOptions.prInfo
          );
          executionContext.outputs = outputs;
          const aggregated = this.aggregateResults(stepResults);
          const endTime = Date.now();
          executionContext.metadata.endTime = endTime;
          executionContext.metadata.duration = endTime - startTime;
          executionContext.metadata.status = "completed";
          return {
            success: true,
            score: aggregated.score,
            confidence: aggregated.confidence,
            issues: aggregated.issues,
            comments: aggregated.comments,
            output: outputs,
            status: "completed",
            duration: endTime - startTime,
            stepSummaries
          };
        } catch (error) {
          const endTime = Date.now();
          executionContext.metadata.endTime = endTime;
          executionContext.metadata.duration = endTime - startTime;
          executionContext.metadata.status = "failed";
          executionContext.metadata.error = error instanceof Error ? error.message : String(error);
          return {
            success: false,
            status: "failed",
            duration: endTime - startTime,
            error: error instanceof Error ? error.message : String(error)
          };
        }
      }
      /**
       * Resolve step execution order based on dependencies
       */
      resolveExecutionOrder(workflow) {
        const dependencies = {};
        for (const [stepId, step] of Object.entries(workflow.steps)) {
          const rawDeps = step.depends_on;
          dependencies[stepId] = Array.isArray(rawDeps) ? rawDeps : rawDeps ? [rawDeps] : [];
        }
        const graph = DependencyResolver.buildDependencyGraph(dependencies);
        if (graph.hasCycles) {
          throw new Error(
            `Circular dependency detected in workflow steps: ${graph.cycleNodes?.join(" -> ")}`
          );
        }
        const order = [];
        for (const group of graph.executionOrder) {
          order.push(...group.parallel);
        }
        return order;
      }
      /**
       * Prepare step configuration with input mappings
       */
      async prepareStepConfig(step, stepId, executionContext, stepResults, workflow) {
        const config = {
          ...step,
          type: step.type || "ai",
          checkName: `${executionContext.instanceId}:${stepId}`
        };
        if (step.inputs) {
          for (const [inputName, mapping] of Object.entries(step.inputs)) {
            const value = await this.resolveInputMapping(
              mapping,
              executionContext,
              stepResults,
              workflow
            );
            config[inputName] = value;
          }
        }
        return config;
      }
      /**
       * Resolve input mapping to actual value
       */
      async resolveInputMapping(mapping, executionContext, stepResults, _workflow) {
        if (typeof mapping === "string") {
          return executionContext.inputs[mapping];
        }
        if (typeof mapping === "object" && mapping !== null && "source" in mapping) {
          const typedMapping = mapping;
          switch (typedMapping.source) {
            case "param":
              return executionContext.inputs[String(typedMapping.value)];
            case "step":
              if (!typedMapping.stepId) {
                throw new Error("Step input mapping requires stepId");
              }
              const stepResult = stepResults.get(typedMapping.stepId);
              if (!stepResult) {
                throw new Error(`Step '${typedMapping.stepId}' has not been executed yet`);
              }
              const output = stepResult.output;
              if (typedMapping.outputParam && output) {
                return output[typedMapping.outputParam];
              }
              return output;
            case "constant":
              return typedMapping.value;
            case "expression":
              if (!typedMapping.expression) {
                throw new Error("Expression mapping requires expression field");
              }
              const sandbox = createSecureSandbox();
              return compileAndRun(
                sandbox,
                typedMapping.expression,
                {
                  inputs: executionContext.inputs,
                  outputs: Object.fromEntries(stepResults),
                  steps: Object.fromEntries(
                    Array.from(stepResults.entries()).map(([id, result]) => [
                      id,
                      result.output
                    ])
                  )
                },
                { injectLog: true, logPrefix: "workflow.input.expression" }
              );
            default:
              throw new Error(`Unknown input mapping source: ${typedMapping.source}`);
          }
        }
        if (typeof mapping === "object" && mapping !== null && "template" in mapping) {
          const typedMapping = mapping;
          if (typedMapping.template) {
            return await this.liquid.parseAndRender(typedMapping.template, {
              inputs: executionContext.inputs,
              outputs: Object.fromEntries(stepResults)
            });
          }
        }
        return mapping;
      }
      /**
       * Execute a single step
       */
      async executeStep(config, prInfo, dependencyResults, context2) {
        const provider = await this.getProviderRegistry().getProvider(config.type);
        if (!provider) {
          throw new Error(`Provider '${config.type}' not found`);
        }
        return await provider.execute(prInfo, config, dependencyResults, context2);
      }
      /**
       * Compute workflow outputs
       */
      async computeOutputs(workflow, executionContext, stepResults, prInfo) {
        const outputs = {};
        if (!workflow.outputs) {
          return outputs;
        }
        for (const output of workflow.outputs) {
          if (output.value_js) {
            const sandbox = createSecureSandbox();
            outputs[output.name] = compileAndRun(
              sandbox,
              output.value_js,
              {
                inputs: executionContext.inputs,
                steps: Object.fromEntries(
                  Array.from(stepResults.entries()).map(([id, result]) => [id, result.output])
                ),
                outputs: Object.fromEntries(stepResults),
                pr: prInfo
              },
              { injectLog: true, logPrefix: `workflow.output.${output.name}` }
            );
          } else if (output.value) {
            outputs[output.name] = await this.liquid.parseAndRender(output.value, {
              inputs: executionContext.inputs,
              steps: Object.fromEntries(
                Array.from(stepResults.entries()).map(([id, result]) => [id, result.output])
              ),
              outputs: Object.fromEntries(stepResults),
              pr: prInfo
            });
          }
        }
        return outputs;
      }
      /**
       * Aggregate results from all steps
       */
      aggregateResults(stepResults) {
        let totalScore = 0;
        let scoreCount = 0;
        const allIssues = [];
        const allComments = [];
        let minConfidence = "high";
        for (const result of stepResults.values()) {
          const extResult = result;
          if (typeof extResult.score === "number") {
            totalScore += extResult.score;
            scoreCount++;
          }
          if (result.issues) {
            allIssues.push(...result.issues);
          }
          if (extResult.comments) {
            allComments.push(...extResult.comments);
          }
          if (extResult.confidence) {
            if (extResult.confidence === "low" || extResult.confidence === "medium" && minConfidence === "high") {
              minConfidence = extResult.confidence;
            }
          }
        }
        return {
          score: scoreCount > 0 ? Math.round(totalScore / scoreCount) : 0,
          confidence: minConfidence,
          issues: allIssues,
          comments: allComments
        };
      }
      /**
       * Evaluate a condition expression
       */
      evaluateCondition(condition, context2) {
        try {
          const sandbox = createSecureSandbox();
          const result = compileAndRun(sandbox, condition, context2, {
            injectLog: true,
            logPrefix: "workflow.condition"
          });
          return Boolean(result);
        } catch (error) {
          logger.warn(`Failed to evaluate condition '${condition}': ${error}`);
          return false;
        }
      }
    };
  }
});

// src/state-machine/workflow-projection.ts
var workflow_projection_exports = {};
__export(workflow_projection_exports, {
  buildWorkflowScope: () => buildWorkflowScope,
  extractParentScope: () => extractParentScope,
  getWorkflowIdFromScope: () => getWorkflowIdFromScope,
  isWorkflowStep: () => isWorkflowStep,
  projectWorkflowToGraph: () => projectWorkflowToGraph,
  validateWorkflowDepth: () => validateWorkflowDepth
});
function projectWorkflowToGraph(workflow, workflowInputs, _parentCheckId) {
  if (!workflow.steps || Object.keys(workflow.steps).length === 0) {
    throw new Error(`Workflow '${workflow.id}' has no steps`);
  }
  const checks = {};
  const checksMetadata = {};
  for (const [stepId, step] of Object.entries(workflow.steps)) {
    const scopedCheckId = stepId;
    checks[scopedCheckId] = {
      type: step.type || "ai",
      ...step,
      // Store workflow inputs in the check config so they're accessible
      workflowInputs,
      // Mark this as a workflow step
      _workflowStep: true,
      _workflowId: workflow.id,
      _stepId: stepId
    };
    checksMetadata[scopedCheckId] = {
      tags: step.tags || workflow.tags || [],
      triggers: step.on || workflow.on || [],
      group: step.group,
      providerType: step.type || "ai",
      // Normalize depends_on to array (supports string | string[])
      dependencies: (Array.isArray(step.depends_on) ? step.depends_on : step.depends_on ? [step.depends_on] : []).map((dep) => dep)
    };
  }
  const config = {
    checks,
    version: "1.0",
    output: {
      pr_comment: {
        format: "table",
        group_by: "check",
        collapse: false
      }
    }
  };
  if (logger.isDebugEnabled?.()) {
    logger.debug(
      `[WorkflowProjection] Projected workflow '${workflow.id}' with ${Object.keys(checks).length} steps`
    );
  }
  return { config, checks: checksMetadata };
}
function validateWorkflowDepth(currentDepth, maxDepth, workflowId) {
  if (currentDepth >= maxDepth) {
    throw new Error(
      `Workflow nesting depth limit exceeded (${maxDepth}) for workflow '${workflowId}'. This may indicate a circular workflow reference or excessive nesting.`
    );
  }
}
function buildWorkflowScope(parentScope, workflowCheckId, stepId, foreachIndex) {
  const scope = parentScope ? [...parentScope] : [];
  scope.push({
    check: `${workflowCheckId}:${stepId}`,
    index: foreachIndex ?? 0
  });
  return scope;
}
function extractParentScope(scopedCheckId) {
  const lastColonIndex = scopedCheckId.lastIndexOf(":");
  if (lastColonIndex === -1) {
    return null;
  }
  return {
    parentCheckId: scopedCheckId.substring(0, lastColonIndex),
    stepId: scopedCheckId.substring(lastColonIndex + 1)
  };
}
function isWorkflowStep(checkId) {
  return checkId.includes(":");
}
function getWorkflowIdFromScope(scopedCheckId) {
  const parts = scopedCheckId.split(":");
  if (parts.length >= 2) {
    return parts[0];
  }
  return null;
}
var init_workflow_projection = __esm({
  "src/state-machine/workflow-projection.ts"() {
    "use strict";
    init_logger();
  }
});

// src/utils/config-merger.ts
var config_merger_exports = {};
__export(config_merger_exports, {
  ConfigMerger: () => ConfigMerger
});
var ConfigMerger;
var init_config_merger = __esm({
  "src/utils/config-merger.ts"() {
    "use strict";
    ConfigMerger = class {
      /**
       * Merge two configurations with child overriding parent
       * @param parent - Base configuration
       * @param child - Configuration to merge on top
       * @returns Merged configuration
       */
      merge(parent, child) {
        const result = this.deepCopy(parent);
        if (child.version !== void 0) result.version = child.version;
        if (child.ai_model !== void 0) result.ai_model = child.ai_model;
        if (child.ai_provider !== void 0) result.ai_provider = child.ai_provider;
        if (child.max_parallelism !== void 0) result.max_parallelism = child.max_parallelism;
        if (child.fail_fast !== void 0) result.fail_fast = child.fail_fast;
        if (child.fail_if !== void 0) result.fail_if = child.fail_if;
        if (child.failure_conditions !== void 0)
          result.failure_conditions = child.failure_conditions;
        if (child.env) {
          result.env = this.mergeObjects(parent.env || {}, child.env);
        }
        if (child.output) {
          result.output = this.mergeOutputConfig(parent.output, child.output);
        }
        if (child.checks) {
          result.checks = this.mergeChecks(parent.checks || {}, child.checks);
        }
        if (child.steps) {
          const parentSteps = parent.steps || {};
          const childSteps = child.steps || {};
          result.steps = this.mergeChecks(parentSteps, childSteps);
        }
        if (child.tools) {
          result.tools = this.mergeObjects(parent.tools || {}, child.tools);
        }
        if (child.imports) {
          const parentImports = parent.imports || [];
          const childImports = child.imports || [];
          result.imports = [.../* @__PURE__ */ new Set([...parentImports, ...childImports])];
        }
        return result;
      }
      /**
       * Deep copy an object
       */
      deepCopy(obj) {
        if (obj === null || obj === void 0) {
          return obj;
        }
        if (obj instanceof Date) {
          return new Date(obj.getTime());
        }
        if (obj instanceof Array) {
          const copy = [];
          for (const item of obj) {
            copy.push(this.deepCopy(item));
          }
          return copy;
        }
        if (obj instanceof Object) {
          const copy = {};
          for (const key in obj) {
            if (Object.prototype.hasOwnProperty.call(obj, key)) {
              copy[key] = this.deepCopy(obj[key]);
            }
          }
          return copy;
        }
        return obj;
      }
      /**
       * Merge two objects (child overrides parent)
       */
      mergeObjects(parent, child) {
        const result = { ...parent };
        for (const key in child) {
          if (Object.prototype.hasOwnProperty.call(child, key)) {
            const parentValue = parent[key];
            const childValue = child[key];
            if (childValue === null || childValue === void 0) {
              delete result[key];
            } else if (typeof parentValue === "object" && typeof childValue === "object" && !Array.isArray(parentValue) && !Array.isArray(childValue) && parentValue !== null && childValue !== null) {
              result[key] = this.mergeObjects(
                parentValue,
                childValue
              );
            } else {
              result[key] = this.deepCopy(childValue);
            }
          }
        }
        return result;
      }
      /**
       * Merge output configurations
       */
      mergeOutputConfig(parent, child) {
        if (!child) return parent;
        if (!parent) return child;
        const result = this.deepCopy(parent);
        if (child.pr_comment) {
          result.pr_comment = this.mergeObjects(
            parent.pr_comment || {},
            child.pr_comment
          );
        }
        if (child.file_comment !== void 0) {
          if (child.file_comment === null) {
            delete result.file_comment;
          } else {
            result.file_comment = this.mergeObjects(
              parent.file_comment || {},
              child.file_comment
            );
          }
        }
        if (child.github_checks !== void 0) {
          if (child.github_checks === null) {
            delete result.github_checks;
          } else {
            result.github_checks = this.mergeObjects(
              parent.github_checks || {},
              child.github_checks
            );
          }
        }
        return result;
      }
      /**
       * Merge check configurations with special handling
       */
      mergeChecks(parent, child) {
        const result = {};
        for (const [checkName, checkConfig] of Object.entries(parent)) {
          result[checkName] = this.deepCopy(checkConfig);
        }
        for (const [checkName, childConfig] of Object.entries(child)) {
          const parentConfig = parent[checkName];
          if (!parentConfig) {
            const copiedConfig = this.deepCopy(childConfig);
            if (!copiedConfig.type) {
              copiedConfig.type = "ai";
            }
            if (!copiedConfig.on) {
              copiedConfig.on = ["manual"];
            }
            if (copiedConfig.appendPrompt !== void 0) {
              if (!copiedConfig.prompt) {
                copiedConfig.prompt = copiedConfig.appendPrompt;
              } else {
                copiedConfig.prompt = copiedConfig.prompt + "\n\n" + copiedConfig.appendPrompt;
              }
              delete copiedConfig.appendPrompt;
            }
            result[checkName] = copiedConfig;
          } else {
            result[checkName] = this.mergeCheckConfig(parentConfig, childConfig);
          }
        }
        return result;
      }
      /**
       * Merge individual check configurations
       */
      mergeCheckConfig(parent, child) {
        const result = this.deepCopy(parent);
        if (child.type !== void 0) result.type = child.type;
        if (!result.type) {
          result.type = "ai";
        }
        if (child.prompt !== void 0) result.prompt = child.prompt;
        if (child.appendPrompt !== void 0) {
          if (result.prompt) {
            result.prompt = result.prompt + "\n\n" + child.appendPrompt;
          } else {
            result.prompt = child.appendPrompt;
          }
          delete result.appendPrompt;
        }
        if (child.exec !== void 0) result.exec = child.exec;
        if (child.stdin !== void 0) result.stdin = child.stdin;
        if (child.url !== void 0) result.url = child.url;
        if (child.focus !== void 0) result.focus = child.focus;
        if (child.command !== void 0) result.command = child.command;
        if (child.ai_model !== void 0) result.ai_model = child.ai_model;
        if (child.ai_provider !== void 0) result.ai_provider = child.ai_provider;
        if (child.group !== void 0) result.group = child.group;
        if (child.schema !== void 0) result.schema = child.schema;
        if (child.if !== void 0) result.if = child.if;
        if (child.reuse_ai_session !== void 0) result.reuse_ai_session = child.reuse_ai_session;
        if (child.fail_if !== void 0) result.fail_if = child.fail_if;
        if (child.failure_conditions !== void 0)
          result.failure_conditions = child.failure_conditions;
        if (child.on !== void 0) {
          if (Array.isArray(child.on) && child.on.length === 0) {
            result.on = [];
          } else {
            result.on = [...child.on];
          }
        }
        if (!result.on) {
          result.on = ["manual"];
        }
        if (child.triggers !== void 0) {
          result.triggers = child.triggers ? [...child.triggers] : void 0;
        }
        if (child.depends_on !== void 0) {
          result.depends_on = child.depends_on ? [...child.depends_on] : void 0;
        }
        if (child.env) {
          result.env = this.mergeObjects(
            parent.env || {},
            child.env
          );
        }
        if (child.ai) {
          result.ai = this.mergeObjects(
            parent.ai || {},
            child.ai
          );
        }
        if (child.template) {
          result.template = this.mergeObjects(
            parent.template || {},
            child.template
          );
        }
        return result;
      }
      /**
       * Check if a check is disabled (has empty 'on' array)
       */
      isCheckDisabled(check) {
        return Array.isArray(check.on) && check.on.length === 0;
      }
      /**
       * Remove disabled checks from the configuration
       */
      removeDisabledChecks(config) {
        if (!config.checks) return config;
        const result = this.deepCopy(config);
        const enabledChecks = {};
        for (const [checkName, checkConfig] of Object.entries(result.checks)) {
          if (!this.isCheckDisabled(checkConfig)) {
            enabledChecks[checkName] = checkConfig;
          } else {
            console.log(`\u2139\uFE0F  Check '${checkName}' is disabled (empty 'on' array)`);
          }
        }
        result.checks = enabledChecks;
        return result;
      }
    };
  }
});

// src/utils/config-loader.ts
var fs8, path9, yaml2, ConfigLoader;
var init_config_loader = __esm({
  "src/utils/config-loader.ts"() {
    "use strict";
    fs8 = __toESM(require("fs"));
    path9 = __toESM(require("path"));
    yaml2 = __toESM(require("js-yaml"));
    ConfigLoader = class {
      constructor(options = {}) {
        this.options = options;
        this.options = {
          allowRemote: true,
          cacheTTL: 5 * 60 * 1e3,
          // 5 minutes
          timeout: 30 * 1e3,
          // 30 seconds
          maxDepth: 10,
          allowedRemotePatterns: [],
          // Empty by default for security
          projectRoot: this.findProjectRoot(),
          ...options
        };
      }
      cache = /* @__PURE__ */ new Map();
      loadedConfigs = /* @__PURE__ */ new Set();
      /**
       * Determine the source type from a string
       */
      getSourceType(source) {
        if (source === "default") {
          return "default" /* DEFAULT */;
        }
        if (source.startsWith("http://") || source.startsWith("https://")) {
          return "remote" /* REMOTE */;
        }
        return "local" /* LOCAL */;
      }
      /**
       * Fetch configuration from any source
       */
      async fetchConfig(source, currentDepth = 0) {
        if (currentDepth >= (this.options.maxDepth || 10)) {
          throw new Error(
            `Maximum extends depth (${this.options.maxDepth}) exceeded. Check for circular dependencies.`
          );
        }
        const normalizedSource = this.normalizeSource(source);
        if (this.loadedConfigs.has(normalizedSource)) {
          throw new Error(
            `Circular dependency detected: ${normalizedSource} is already in the extends chain`
          );
        }
        const sourceType = this.getSourceType(source);
        try {
          this.loadedConfigs.add(normalizedSource);
          switch (sourceType) {
            case "default" /* DEFAULT */:
              return await this.fetchDefaultConfig();
            case "remote" /* REMOTE */:
              if (!this.options.allowRemote) {
                throw new Error(
                  "Remote extends are disabled. Enable with --allow-remote-extends or remove VISOR_NO_REMOTE_EXTENDS environment variable."
                );
              }
              return await this.fetchRemoteConfig(source);
            case "local" /* LOCAL */:
              return await this.fetchLocalConfig(source);
            default:
              throw new Error(`Unknown configuration source: ${source}`);
          }
        } finally {
          this.loadedConfigs.delete(normalizedSource);
        }
      }
      /**
       * Normalize source path/URL for comparison
       */
      normalizeSource(source) {
        const sourceType = this.getSourceType(source);
        switch (sourceType) {
          case "default" /* DEFAULT */:
            return "default";
          case "remote" /* REMOTE */:
            return source.toLowerCase();
          case "local" /* LOCAL */:
            const basePath = this.options.baseDir || process.cwd();
            return path9.resolve(basePath, source);
          default:
            return source;
        }
      }
      /**
       * Load configuration from local file system
       */
      async fetchLocalConfig(filePath) {
        const basePath = this.options.baseDir || process.cwd();
        const resolvedPath = path9.resolve(basePath, filePath);
        this.validateLocalPath(resolvedPath);
        try {
          const content = fs8.readFileSync(resolvedPath, "utf8");
          const config = yaml2.load(content);
          if (!config || typeof config !== "object") {
            throw new Error(`Invalid YAML in configuration file: ${resolvedPath}`);
          }
          if (config.include && !config.extends) {
            const inc = config.include;
            config.extends = Array.isArray(inc) ? inc : [inc];
            delete config.include;
          }
          const previousBaseDir = this.options.baseDir;
          this.options.baseDir = path9.dirname(resolvedPath);
          try {
            if (config.extends) {
              const processedConfig = await this.processExtends(config);
              return processedConfig;
            }
            return config;
          } finally {
            this.options.baseDir = previousBaseDir;
          }
        } catch (error) {
          if (error && (error.code === "ENOENT" || error.code === "ENOTDIR")) {
            throw new Error(`Configuration file not found: ${resolvedPath}`);
          }
          if (error instanceof Error) {
            throw new Error(`Failed to load configuration from ${resolvedPath}: ${error.message}`);
          }
          throw error;
        }
      }
      /**
       * Fetch configuration from remote URL
       */
      async fetchRemoteConfig(url) {
        if (!url.startsWith("http://") && !url.startsWith("https://")) {
          throw new Error(`Invalid URL: ${url}. Only HTTP and HTTPS protocols are supported.`);
        }
        this.validateRemoteURL(url);
        const cacheEntry = this.cache.get(url);
        if (cacheEntry && Date.now() - cacheEntry.timestamp < cacheEntry.ttl) {
          const outputFormat2 = process.env.VISOR_OUTPUT_FORMAT;
          const logFn2 = outputFormat2 === "json" || outputFormat2 === "sarif" ? console.error : console.log;
          logFn2(`\u{1F4E6} Using cached configuration from: ${url}`);
          return cacheEntry.config;
        }
        const outputFormat = process.env.VISOR_OUTPUT_FORMAT;
        const logFn = outputFormat === "json" || outputFormat === "sarif" ? console.error : console.log;
        logFn(`\u2B07\uFE0F  Fetching remote configuration from: ${url}`);
        const controller = new AbortController();
        const timeoutMs = this.options.timeout ?? 3e4;
        const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
        try {
          const response = await fetch(url, {
            signal: controller.signal,
            headers: {
              "User-Agent": "Visor/1.0"
            }
          });
          if (!response.ok) {
            throw new Error(`Failed to fetch config: ${response.status} ${response.statusText}`);
          }
          const content = await response.text();
          const config = yaml2.load(content);
          if (!config || typeof config !== "object") {
            throw new Error(`Invalid YAML in remote configuration: ${url}`);
          }
          this.cache.set(url, {
            config,
            timestamp: Date.now(),
            ttl: this.options.cacheTTL || 5 * 60 * 1e3
          });
          if (config.extends) {
            return await this.processExtends(config);
          }
          return config;
        } catch (error) {
          if (error instanceof Error) {
            if (error.name === "AbortError") {
              throw new Error(`Timeout fetching configuration from ${url} (${timeoutMs}ms)`);
            }
            throw new Error(`Failed to fetch remote configuration from ${url}: ${error.message}`);
          }
          throw error;
        } finally {
          clearTimeout(timeoutId);
        }
      }
      /**
       * Load bundled default configuration
       */
      async fetchDefaultConfig() {
        const possiblePaths = [
          // Only support new non-dot filename
          path9.join(__dirname, "defaults", "visor.yaml"),
          // When running from source
          path9.join(__dirname, "..", "..", "defaults", "visor.yaml"),
          // Try via package root
          this.findPackageRoot() ? path9.join(this.findPackageRoot(), "defaults", "visor.yaml") : "",
          // GitHub Action environment variable
          process.env.GITHUB_ACTION_PATH ? path9.join(process.env.GITHUB_ACTION_PATH, "defaults", "visor.yaml") : "",
          process.env.GITHUB_ACTION_PATH ? path9.join(process.env.GITHUB_ACTION_PATH, "dist", "defaults", "visor.yaml") : ""
        ].filter((p) => p);
        let defaultConfigPath;
        for (const possiblePath of possiblePaths) {
          if (fs8.existsSync(possiblePath)) {
            defaultConfigPath = possiblePath;
            break;
          }
        }
        if (defaultConfigPath) {
          console.error(`\u{1F4E6} Loading bundled default configuration from ${defaultConfigPath}`);
          const content = fs8.readFileSync(defaultConfigPath, "utf8");
          let config = yaml2.load(content);
          if (!config || typeof config !== "object") {
            throw new Error("Invalid default configuration");
          }
          if (config.include && !config.extends) {
            const inc = config.include;
            config.extends = Array.isArray(inc) ? inc : [inc];
            delete config.include;
          }
          config = this.normalizeStepsAndChecks(config);
          if (config.extends) {
            const previousBaseDir = this.options.baseDir;
            try {
              this.options.baseDir = path9.dirname(defaultConfigPath);
              return await this.processExtends(config);
            } finally {
              this.options.baseDir = previousBaseDir;
            }
          }
          return config;
        }
        console.warn("\u26A0\uFE0F  Bundled default configuration not found, using minimal defaults");
        return {
          version: "1.0",
          checks: {},
          output: {
            pr_comment: {
              format: "markdown",
              group_by: "check",
              collapse: true
            }
          }
        };
      }
      /**
       * Process extends directive in a configuration
       */
      async processExtends(config) {
        if (!config.extends) {
          return config;
        }
        const extends_ = Array.isArray(config.extends) ? config.extends : [config.extends];
        const { extends: _extendsField, ...configWithoutExtends } = config;
        const parentConfigs = [];
        for (const source of extends_) {
          const parentConfig = await this.fetchConfig(source, this.loadedConfigs.size);
          parentConfigs.push(parentConfig);
        }
        const { ConfigMerger: ConfigMerger2 } = await Promise.resolve().then(() => (init_config_merger(), config_merger_exports));
        const merger = new ConfigMerger2();
        let mergedParents = {};
        for (const parentConfig of parentConfigs) {
          mergedParents = merger.merge(mergedParents, parentConfig);
        }
        return merger.merge(mergedParents, configWithoutExtends);
      }
      /**
       * Find project root directory (for security validation)
       */
      findProjectRoot() {
        try {
          const { execSync } = require("child_process");
          const gitRoot = execSync("git rev-parse --show-toplevel", { encoding: "utf8" }).trim();
          if (gitRoot) return gitRoot;
        } catch {
        }
        const packageRoot = this.findPackageRoot();
        if (packageRoot) return packageRoot;
        return process.cwd();
      }
      /**
       * Validate remote URL against allowlist
       */
      validateRemoteURL(url) {
        const allowedPatterns = this.options.allowedRemotePatterns || [];
        if (allowedPatterns.length === 0) {
          return;
        }
        const isAllowed = allowedPatterns.some((pattern) => url.startsWith(pattern));
        if (!isAllowed) {
          throw new Error(
            `Security error: URL ${url} is not in the allowed list. Allowed patterns: ${allowedPatterns.join(", ")}`
          );
        }
      }
      /**
       * Validate local path against traversal attacks
       */
      validateLocalPath(resolvedPath) {
        const projectRoot = this.options.projectRoot || process.cwd();
        const normalizedPath = path9.normalize(resolvedPath);
        const normalizedRoot = path9.normalize(projectRoot);
        if (!normalizedPath.startsWith(normalizedRoot)) {
          throw new Error(
            `Security error: Path traversal detected. Cannot access files outside project root: ${projectRoot}`
          );
        }
        const sensitivePatterns = [
          "/etc/passwd",
          "/etc/shadow",
          "/.ssh/",
          "/.aws/",
          "/.env",
          "/private/"
        ];
        const lowerPath = normalizedPath.toLowerCase();
        for (const pattern of sensitivePatterns) {
          if (lowerPath.includes(pattern)) {
            throw new Error(`Security error: Cannot access potentially sensitive file: ${pattern}`);
          }
        }
      }
      /**
       * Find package root directory
       */
      findPackageRoot() {
        let currentDir = __dirname;
        const root = path9.parse(currentDir).root;
        while (currentDir !== root) {
          const packageJsonPath = path9.join(currentDir, "package.json");
          if (fs8.existsSync(packageJsonPath)) {
            try {
              const packageJson = JSON.parse(fs8.readFileSync(packageJsonPath, "utf8"));
              if (packageJson.name === "@probelabs/visor") {
                return currentDir;
              }
            } catch {
            }
          }
          currentDir = path9.dirname(currentDir);
        }
        return null;
      }
      /**
       * Clear the configuration cache
       */
      clearCache() {
        this.cache.clear();
      }
      /**
       * Reset the loaded configs tracking (for testing)
       */
      reset() {
        this.loadedConfigs.clear();
        this.clearCache();
      }
      /**
       * Normalize 'checks' and 'steps' keys for backward compatibility
       * Ensures both keys are present and contain the same data
       */
      normalizeStepsAndChecks(config) {
        if (config.steps && config.checks) {
          const merged = { ...config.checks, ...config.steps };
          config.checks = merged;
          config.steps = merged;
        } else if (config.steps && !config.checks) {
          config.checks = config.steps;
        } else if (config.checks && !config.steps) {
          config.steps = config.checks;
        }
        return config;
      }
    };
  }
});

// src/generated/config-schema.ts
var config_schema_exports = {};
__export(config_schema_exports, {
  configSchema: () => configSchema,
  default: () => config_schema_default
});
var configSchema, config_schema_default;
var init_config_schema = __esm({
  "src/generated/config-schema.ts"() {
    "use strict";
    configSchema = {
      $schema: "http://json-schema.org/draft-07/schema#",
      $ref: "#/definitions/VisorConfigSchema",
      definitions: {
        VisorConfigSchema: {
          type: "object",
          additionalProperties: false,
          properties: {
            hooks: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E"
            },
            version: {
              type: "string",
              description: "Configuration version"
            },
            extends: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                }
              ],
              description: 'Extends from other configurations - can be file path, HTTP(S) URL, or "default"'
            },
            include: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                }
              ],
              description: "Alias for extends - include from other configurations (backward compatibility)"
            },
            tools: {
              $ref: "#/definitions/Record%3Cstring%2CCustomToolDefinition%3E",
              description: "Custom tool definitions that can be used in MCP blocks"
            },
            imports: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Import workflow definitions from external files or URLs"
            },
            inputs: {
              type: "array",
              items: {
                $ref: "#/definitions/WorkflowInput"
              },
              description: "Workflow inputs (for standalone reusable workflows)"
            },
            outputs: {
              type: "array",
              items: {
                $ref: "#/definitions/WorkflowOutput"
              },
              description: "Workflow outputs (for standalone reusable workflows)"
            },
            steps: {
              $ref: "#/definitions/Record%3Cstring%2CCheckConfig%3E",
              description: "Step configurations (recommended)"
            },
            checks: {
              $ref: "#/definitions/Record%3Cstring%2CCheckConfig%3E",
              description: "Check configurations (legacy, use 'steps' instead) - always populated after normalization"
            },
            output: {
              $ref: "#/definitions/OutputConfig",
              description: "Output configuration (optional - defaults provided)"
            },
            http_server: {
              $ref: "#/definitions/HttpServerConfig",
              description: "HTTP server configuration for receiving webhooks"
            },
            memory: {
              $ref: "#/definitions/MemoryConfig",
              description: "Memory storage configuration"
            },
            env: {
              $ref: "#/definitions/EnvConfig",
              description: "Global environment variables"
            },
            ai_model: {
              type: "string",
              description: "Global AI model setting"
            },
            ai_provider: {
              type: "string",
              description: "Global AI provider setting"
            },
            ai_mcp_servers: {
              $ref: "#/definitions/Record%3Cstring%2CMcpServerConfig%3E",
              description: "Global MCP servers configuration for AI checks"
            },
            max_parallelism: {
              type: "number",
              description: "Maximum number of checks to run in parallel (default: 3)"
            },
            fail_fast: {
              type: "boolean",
              description: "Stop execution when any check fails (default: false)"
            },
            fail_if: {
              type: "string",
              description: "Simple global fail condition - fails if expression evaluates to true"
            },
            failure_conditions: {
              $ref: "#/definitions/FailureConditions",
              description: "Global failure conditions - optional (deprecated, use fail_if)"
            },
            tag_filter: {
              $ref: "#/definitions/TagFilter",
              description: "Tag filter for selective check execution"
            },
            routing: {
              $ref: "#/definitions/RoutingDefaults",
              description: "Optional routing defaults for retry/goto/run policies"
            },
            limits: {
              $ref: "#/definitions/LimitsConfig",
              description: "Global execution limits"
            },
            frontends: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  name: {
                    type: "string",
                    description: "Frontend name, e.g., 'ndjson-sink', 'github'"
                  },
                  config: {
                    description: "Frontend-specific configuration"
                  }
                },
                required: ["name"],
                additionalProperties: false
              },
              description: "Optional integrations: event-driven frontends (e.g., ndjson-sink, github)"
            },
            workspace: {
              $ref: "#/definitions/WorkspaceConfig",
              description: "Workspace isolation configuration for sandboxed execution"
            },
            slack: {
              $ref: "#/definitions/SlackConfig",
              description: "Slack configuration"
            }
          },
          required: ["version"],
          patternProperties: {
            "^x-": {}
          }
        },
        "Record<string,unknown>": {
          type: "object",
          additionalProperties: {}
        },
        "Record<string,CustomToolDefinition>": {
          type: "object",
          additionalProperties: {
            $ref: "#/definitions/CustomToolDefinition"
          }
        },
        CustomToolDefinition: {
          type: "object",
          properties: {
            name: {
              type: "string",
              description: "Tool name - used to reference the tool in MCP blocks"
            },
            description: {
              type: "string",
              description: "Description of what the tool does"
            },
            inputSchema: {
              type: "object",
              properties: {
                type: {
                  type: "string",
                  const: "object"
                },
                properties: {
                  $ref: "#/definitions/Record%3Cstring%2Cunknown%3E"
                },
                required: {
                  type: "array",
                  items: {
                    type: "string"
                  }
                },
                additionalProperties: {
                  type: "boolean"
                }
              },
              required: ["type"],
              additionalProperties: false,
              description: "Input schema for the tool (JSON Schema format)",
              patternProperties: {
                "^x-": {}
              }
            },
            exec: {
              type: "string",
              description: "Command to execute - supports Liquid template"
            },
            stdin: {
              type: "string",
              description: "Optional stdin input - supports Liquid template"
            },
            transform: {
              type: "string",
              description: "Transform the raw output - supports Liquid template"
            },
            transform_js: {
              type: "string",
              description: "Transform the output using JavaScript - alternative to transform"
            },
            cwd: {
              type: "string",
              description: "Working directory for command execution"
            },
            env: {
              $ref: "#/definitions/Record%3Cstring%2Cstring%3E",
              description: "Environment variables for the command"
            },
            timeout: {
              type: "number",
              description: "Timeout in milliseconds"
            },
            parseJson: {
              type: "boolean",
              description: "Whether to parse output as JSON automatically"
            },
            outputSchema: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Expected output schema for validation"
            }
          },
          required: ["name", "exec"],
          additionalProperties: false,
          description: "Custom tool definition for use in MCP blocks",
          patternProperties: {
            "^x-": {}
          }
        },
        "Record<string,string>": {
          type: "object",
          additionalProperties: {
            type: "string"
          }
        },
        WorkflowInput: {
          type: "object",
          properties: {
            name: {
              type: "string",
              description: "Input parameter name"
            },
            schema: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "JSON Schema for the input"
            },
            required: {
              type: "boolean",
              description: "Whether this input is required"
            },
            default: {
              description: "Default value if not provided"
            },
            description: {
              type: "string",
              description: "Human-readable description"
            }
          },
          required: ["name"],
          additionalProperties: false,
          description: "Workflow input definition for standalone reusable workflows",
          patternProperties: {
            "^x-": {}
          }
        },
        WorkflowOutput: {
          type: "object",
          properties: {
            name: {
              type: "string",
              description: "Output name"
            },
            description: {
              type: "string",
              description: "Human-readable description"
            },
            value: {
              type: "string",
              description: "Value using Liquid template syntax (references step outputs)"
            },
            value_js: {
              type: "string",
              description: "Value using JavaScript expression (alternative to value)"
            }
          },
          required: ["name"],
          additionalProperties: false,
          description: "Workflow output definition for standalone reusable workflows",
          patternProperties: {
            "^x-": {}
          }
        },
        "Record<string,CheckConfig>": {
          type: "object",
          additionalProperties: {
            $ref: "#/definitions/CheckConfig"
          }
        },
        CheckConfig: {
          type: "object",
          properties: {
            type: {
              $ref: "#/definitions/ConfigCheckType",
              description: "Type of check to perform (defaults to 'ai' if not specified)"
            },
            prompt: {
              type: "string",
              description: "AI prompt for the check - can be inline string or file path (auto-detected) - required for AI checks"
            },
            appendPrompt: {
              type: "string",
              description: "Additional prompt to append when extending configurations - merged with parent prompt"
            },
            exec: {
              type: "string",
              description: "Command execution with Liquid template support - required for command checks"
            },
            stdin: {
              type: "string",
              description: "Stdin input for tools with Liquid template support - optional for tool checks"
            },
            url: {
              type: "string",
              description: "HTTP URL - required for http output checks"
            },
            body: {
              type: "string",
              description: "HTTP body template (Liquid) - required for http output checks"
            },
            method: {
              type: "string",
              description: "HTTP method (defaults to POST)"
            },
            headers: {
              $ref: "#/definitions/Record%3Cstring%2Cstring%3E",
              description: "HTTP headers"
            },
            endpoint: {
              type: "string",
              description: "HTTP endpoint path - required for http_input checks"
            },
            transform: {
              type: "string",
              description: "Transform template for http_input data (Liquid) - optional"
            },
            transform_js: {
              type: "string",
              description: "Transform using JavaScript expressions (evaluated in secure sandbox) - optional"
            },
            content: {
              type: "string",
              description: "Script content to execute for script checks"
            },
            schedule: {
              type: "string",
              description: 'Cron schedule expression (e.g., "0 2 * * *") - optional for any check type'
            },
            focus: {
              type: "string",
              description: "Focus area for the check (security/performance/style/architecture/all) - optional"
            },
            command: {
              type: "string",
              description: 'Command that triggers this check (e.g., "review", "security-scan") - optional'
            },
            on: {
              type: "array",
              items: {
                $ref: "#/definitions/EventTrigger"
              },
              description: "Events that trigger this check (defaults to ['manual'] if not specified)"
            },
            triggers: {
              type: "array",
              items: {
                type: "string"
              },
              description: "File patterns that trigger this check (optional)"
            },
            ai: {
              $ref: "#/definitions/AIProviderConfig",
              description: "AI provider configuration (optional)"
            },
            ai_model: {
              type: "string",
              description: "AI model to use for this check - overrides global setting"
            },
            ai_provider: {
              type: "string",
              description: "AI provider to use for this check - overrides global setting"
            },
            ai_persona: {
              type: "string",
              description: "Optional persona hint, prepended to the prompt as 'Persona: <value>'"
            },
            ai_prompt_type: {
              type: "string",
              description: "Probe promptType for this check (underscore style)"
            },
            ai_system_prompt: {
              type: "string",
              description: "System prompt for this check (underscore style)"
            },
            ai_custom_prompt: {
              type: "string",
              description: "Legacy customPrompt (underscore style) \u2014 deprecated, use ai_system_prompt"
            },
            ai_mcp_servers: {
              $ref: "#/definitions/Record%3Cstring%2CMcpServerConfig%3E",
              description: "MCP servers for this AI check - overrides global setting"
            },
            ai_custom_tools: {
              type: "array",
              items: {
                type: "string"
              },
              description: "List of custom tool names to expose to this AI check via ephemeral SSE MCP server"
            },
            claude_code: {
              $ref: "#/definitions/ClaudeCodeConfig",
              description: "Claude Code configuration (for claude-code type checks)"
            },
            env: {
              $ref: "#/definitions/EnvConfig",
              description: "Environment variables for this check"
            },
            timeout: {
              type: "number",
              description: "Timeout in milliseconds for command execution (default: 60000, i.e., 60 seconds)"
            },
            depends_on: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                }
              ],
              description: "Check IDs that this check depends on (optional). Accepts single string or array."
            },
            group: {
              type: "string",
              description: 'Group name for comment separation (e.g., "code-review", "pr-overview") - optional'
            },
            schema: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  $ref: "#/definitions/Record%3Cstring%2Cunknown%3E"
                }
              ],
              description: 'Schema type for template rendering (e.g., "code-review", "markdown") or inline JSON schema object - optional'
            },
            output_schema: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Optional JSON Schema to validate the produced output. If omitted and `schema` is an object, the engine will treat that object as the output_schema for validation purposes while still using string schemas (e.g., 'code-review') for template selection."
            },
            template: {
              $ref: "#/definitions/CustomTemplateConfig",
              description: "Custom template configuration - optional"
            },
            if: {
              type: "string",
              description: "Condition to determine if check should run - runs if expression evaluates to true"
            },
            reuse_ai_session: {
              type: ["string", "boolean"],
              description: "Check name to reuse AI session from, or true to use first dependency (only works with depends_on)"
            },
            session_mode: {
              type: "string",
              enum: ["clone", "append"],
              description: "How to reuse AI session: 'clone' (default, copy history) or 'append' (share history)"
            },
            fail_if: {
              type: "string",
              description: "Simple fail condition - fails check if expression evaluates to true"
            },
            failure_conditions: {
              $ref: "#/definitions/FailureConditions",
              description: "Check-specific failure conditions - optional (deprecated, use fail_if)"
            },
            tags: {
              type: "array",
              items: {
                type: "string"
              },
              description: 'Tags for categorizing and filtering checks (e.g., ["local", "fast", "security"])'
            },
            criticality: {
              type: "string",
              enum: ["external", "internal", "policy", "info"],
              description: "Operational criticality of this step. Drives default safety policies (contracts, retries, loop budgets) at load time. Behavior can still be overridden explicitly per step via on_*, fail_if, assume/guarantee, etc.\n\n- 'external': interacts with external systems (side effects). Highest safety.\n- 'internal': modifies CI/config/state but not prod. High safety.\n- 'policy': organizational checks (linting, style, doc). Moderate safety.\n- 'info': informational checks. Lowest safety."
            },
            continue_on_failure: {
              type: "boolean",
              description: "Allow dependents to run even if this step fails. Defaults to false (dependents are gated when this step fails). Similar to GitHub Actions' continue-on-error."
            },
            forEach: {
              type: "boolean",
              description: "Process output as array and run dependent checks for each item"
            },
            fanout: {
              type: "string",
              enum: ["map", "reduce"],
              description: "Control scheduling behavior when this check is triggered via routing (run/goto) from a forEach scope.\n- 'map': schedule once per item (fan-out) using item scopes.\n- 'reduce': schedule a single run at the parent scope (aggregation). If unset, the current default is a single run (reduce) for backward compatibility."
            },
            reduce: {
              type: "boolean",
              description: "Alias for fanout: 'reduce'"
            },
            on_init: {
              $ref: "#/definitions/OnInitConfig",
              description: "Init routing configuration for this check (runs before execution/preprocessing)"
            },
            on_fail: {
              $ref: "#/definitions/OnFailConfig",
              description: "Failure routing configuration for this check (retry/goto/run)"
            },
            on_success: {
              $ref: "#/definitions/OnSuccessConfig",
              description: "Success routing configuration for this check (post-actions and optional goto)"
            },
            on_finish: {
              $ref: "#/definitions/OnFinishConfig",
              description: "Finish routing configuration for forEach checks (runs after ALL iterations complete)"
            },
            assume: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                }
              ],
              description: "Preconditions that must hold before executing the check. If any expression evaluates to false, the check is skipped (skipReason='assume')."
            },
            guarantee: {
              anyOf: [
                {
                  type: "string"
                },
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                }
              ],
              description: 'Postconditions that should hold after executing the check. Expressions are evaluated against the produced result/output; violations are recorded as error issues with ruleId "contract/guarantee_failed".'
            },
            max_runs: {
              type: "number",
              description: "Hard cap on how many times this check may execute within a single engine run. Overrides global limits.max_runs_per_check. Set to 0 or negative to disable for this step."
            },
            message: {
              type: "string",
              description: "Message template for log checks"
            },
            level: {
              type: "string",
              enum: ["debug", "info", "warn", "error"],
              description: "Log level for log checks"
            },
            include_pr_context: {
              type: "boolean",
              description: "Include PR context in log output"
            },
            include_dependencies: {
              type: "boolean",
              description: "Include dependency summaries in log output"
            },
            include_metadata: {
              type: "boolean",
              description: "Include execution metadata in log output"
            },
            output_format: {
              type: "string",
              enum: ["json", "text"],
              description: "Output parsing hint for command provider (optional) When set to 'json', command stdout is expected to be JSON. When 'text', treat as plain text. Note: command provider attempts JSON parsing heuristically; this flag mainly suppresses schema warnings and may be used by providers to alter parsing behavior in the future."
            },
            operation: {
              type: "string",
              enum: ["get", "set", "append", "increment", "delete", "clear", "list"],
              description: "Memory operation to perform. Use `type: 'script'` for custom JavaScript."
            },
            key: {
              type: "string",
              description: "Key for memory operation"
            },
            value: {
              description: "Value for set/append operations"
            },
            value_js: {
              type: "string",
              description: "JavaScript expression to compute value dynamically"
            },
            namespace: {
              type: "string",
              description: "Override namespace for this check"
            },
            op: {
              type: "string",
              description: "GitHub operation to perform (e.g., 'labels.add', 'labels.remove', 'comment.create')"
            },
            values: {
              anyOf: [
                {
                  type: "array",
                  items: {
                    type: "string"
                  }
                },
                {
                  type: "string"
                }
              ],
              description: "Values for GitHub operations (can be array or single value)"
            },
            transport: {
              type: "string",
              enum: ["stdio", "sse", "http"],
              description: "Transport type for MCP: stdio (default), sse (legacy), or http (streamable HTTP)"
            },
            methodArgs: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Arguments to pass to the MCP method (supports Liquid templates)"
            },
            argsTransform: {
              type: "string",
              description: "Transform template for method arguments (Liquid)"
            },
            sessionId: {
              type: "string",
              description: "Session ID for HTTP transport (optional, server may generate one)"
            },
            command_args: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Command arguments (for stdio transport in MCP checks)"
            },
            workingDirectory: {
              type: "string",
              description: "Working directory (for stdio transport in MCP checks)"
            },
            placeholder: {
              type: "string",
              description: "Placeholder text to show in input field"
            },
            allow_empty: {
              type: "boolean",
              description: "Allow empty input (default: false)"
            },
            multiline: {
              type: "boolean",
              description: "Support multiline input (default: false)"
            },
            default: {
              type: "string",
              description: "Default value if timeout occurs or empty input when allow_empty is true"
            },
            workflow: {
              type: "string",
              description: "Workflow ID or path to workflow file"
            },
            args: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Arguments/inputs for the workflow"
            },
            overrides: {
              $ref: "#/definitions/Record%3Cstring%2CPartial%3Cinterface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182%3E%3E",
              description: "Override specific step configurations in the workflow"
            },
            output_mapping: {
              $ref: "#/definitions/Record%3Cstring%2Cstring%3E",
              description: "Map workflow outputs to check outputs"
            },
            workflow_inputs: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Alias for args - workflow inputs (backward compatibility)"
            },
            config: {
              type: "string",
              description: "Config file path - alternative to workflow ID (loads a Visor config file as workflow)"
            },
            workflow_overrides: {
              $ref: "#/definitions/Record%3Cstring%2CPartial%3Cinterface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182%3E%3E",
              description: "Alias for overrides - workflow step overrides (backward compatibility)"
            },
            ref: {
              type: "string",
              description: "Git reference to checkout (branch, tag, commit SHA) - supports templates"
            },
            repository: {
              type: "string",
              description: "Repository URL or owner/repo format (defaults to current repository)"
            },
            token: {
              type: "string",
              description: "GitHub token for private repositories (defaults to GITHUB_TOKEN env)"
            },
            fetch_depth: {
              type: "number",
              description: "Number of commits to fetch (0 for full history, default: 1)"
            },
            fetch_tags: {
              type: "boolean",
              description: "Whether to fetch tags (default: false)"
            },
            submodules: {
              anyOf: [
                {
                  type: "boolean"
                },
                {
                  type: "string",
                  const: "recursive"
                }
              ],
              description: "Checkout submodules: false, true, or 'recursive'"
            },
            working_directory: {
              type: "string",
              description: "Working directory for the checkout (defaults to temp directory)"
            },
            use_worktree: {
              type: "boolean",
              description: "Use git worktree for efficient parallel checkouts (default: true)"
            },
            clean: {
              type: "boolean",
              description: "Clean the working directory before checkout (default: true)"
            },
            sparse_checkout: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Sparse checkout paths - only checkout specific directories/files"
            },
            lfs: {
              type: "boolean",
              description: "Enable Git LFS (Large File Storage)"
            },
            clone_timeout_ms: {
              type: "number",
              description: "Timeout in ms for cloning the bare repository (default: 300000 = 5 min)"
            },
            cleanup_on_failure: {
              type: "boolean",
              description: "Clean up worktree on failure (default: true)"
            },
            persist_worktree: {
              type: "boolean",
              description: "Keep worktree after workflow completion (default: false)"
            }
          },
          additionalProperties: false,
          description: "Configuration for a single check",
          patternProperties: {
            "^x-": {}
          }
        },
        ConfigCheckType: {
          type: "string",
          enum: [
            "ai",
            "command",
            "script",
            "http",
            "http_input",
            "http_client",
            "noop",
            "log",
            "memory",
            "github",
            "claude-code",
            "mcp",
            "human-input",
            "workflow",
            "git-checkout"
          ],
          description: "Valid check types in configuration"
        },
        EventTrigger: {
          type: "string",
          enum: [
            "pr_opened",
            "pr_updated",
            "pr_closed",
            "issue_opened",
            "issue_comment",
            "manual",
            "schedule",
            "webhook_received"
          ],
          description: "Valid event triggers for checks"
        },
        AIProviderConfig: {
          type: "object",
          properties: {
            provider: {
              type: "string",
              enum: ["google", "anthropic", "openai", "bedrock", "mock"],
              description: "AI provider to use"
            },
            model: {
              type: "string",
              description: "Model name to use"
            },
            apiKey: {
              type: "string",
              description: "API key (usually from environment variables)"
            },
            timeout: {
              type: "number",
              description: "Request timeout in milliseconds"
            },
            debug: {
              type: "boolean",
              description: "Enable debug mode"
            },
            prompt_type: {
              type: "string",
              description: "Probe promptType to use (e.g., engineer, code-review, architect)"
            },
            system_prompt: {
              type: "string",
              description: "System prompt (baseline preamble). Replaces legacy custom_prompt."
            },
            custom_prompt: {
              type: "string",
              description: "Probe customPrompt (baseline/system prompt) \u2014 deprecated, use system_prompt"
            },
            skip_code_context: {
              type: "boolean",
              description: "Skip adding code context (diffs, files, PR info) to the prompt"
            },
            skip_slack_context: {
              type: "boolean",
              description: "Skip adding Slack conversation context to the prompt (when running under Slack)"
            },
            skip_transport_context: {
              type: "boolean",
              description: "Skip adding transport-specific context (e.g., GitHub PR/issue XML, Slack conversation XML) to the prompt. When true, this behaves like setting both skip_code_context and skip_slack_context to true, unless those are explicitly overridden."
            },
            mcpServers: {
              $ref: "#/definitions/Record%3Cstring%2CMcpServerConfig%3E",
              description: "MCP servers configuration"
            },
            enableDelegate: {
              type: "boolean",
              description: "Enable the delegate tool for task distribution to subagents"
            },
            retry: {
              $ref: "#/definitions/AIRetryConfig",
              description: "Retry configuration for this provider"
            },
            fallback: {
              $ref: "#/definitions/AIFallbackConfig",
              description: "Fallback configuration for provider failures"
            },
            allowEdit: {
              type: "boolean",
              description: "Enable Edit and Create tools for file modification (disabled by default for security)"
            },
            allowedTools: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Filter allowed tools - supports whitelist, exclusion (!prefix), or raw AI mode (empty array)"
            },
            disableTools: {
              type: "boolean",
              description: "Disable all tools for raw AI mode (alternative to allowedTools: [])"
            },
            allowBash: {
              type: "boolean",
              description: "Enable bash command execution (shorthand for bashConfig.enabled)"
            },
            bashConfig: {
              $ref: "#/definitions/BashConfig",
              description: "Advanced bash command execution configuration"
            },
            completion_prompt: {
              type: "string",
              description: "Completion prompt for post-completion validation/review (runs after attempt_completion)"
            }
          },
          additionalProperties: false,
          description: "AI provider configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        "Record<string,McpServerConfig>": {
          type: "object",
          additionalProperties: {
            $ref: "#/definitions/McpServerConfig"
          }
        },
        McpServerConfig: {
          type: "object",
          properties: {
            command: {
              type: "string",
              description: "Command to execute for the MCP server"
            },
            args: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Arguments to pass to the command"
            },
            env: {
              $ref: "#/definitions/Record%3Cstring%2Cstring%3E",
              description: "Environment variables for the MCP server"
            }
          },
          required: ["command"],
          additionalProperties: false,
          description: "MCP Server configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        AIRetryConfig: {
          type: "object",
          properties: {
            maxRetries: {
              type: "number",
              description: "Maximum retry attempts (0-50)"
            },
            initialDelay: {
              type: "number",
              description: "Initial delay in milliseconds (0-60000)"
            },
            maxDelay: {
              type: "number",
              description: "Maximum delay cap in milliseconds (0-300000)"
            },
            backoffFactor: {
              type: "number",
              description: "Exponential backoff multiplier (1-10)"
            },
            retryableErrors: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Custom error patterns to retry on"
            }
          },
          additionalProperties: false,
          description: "Retry configuration for AI provider calls",
          patternProperties: {
            "^x-": {}
          }
        },
        AIFallbackConfig: {
          type: "object",
          properties: {
            strategy: {
              type: "string",
              enum: ["same-model", "same-provider", "any", "custom"],
              description: "Fallback strategy: 'same-model', 'same-provider', 'any', or 'custom'"
            },
            providers: {
              type: "array",
              items: {
                $ref: "#/definitions/AIFallbackProviderConfig"
              },
              description: "Array of fallback provider configurations"
            },
            maxTotalAttempts: {
              type: "number",
              description: "Maximum total attempts across all providers"
            },
            auto: {
              type: "boolean",
              description: "Enable automatic fallback using available environment variables"
            }
          },
          additionalProperties: false,
          description: "Fallback configuration for AI providers",
          patternProperties: {
            "^x-": {}
          }
        },
        AIFallbackProviderConfig: {
          type: "object",
          properties: {
            provider: {
              type: "string",
              enum: ["google", "anthropic", "openai", "bedrock"],
              description: "AI provider to use"
            },
            model: {
              type: "string",
              description: "Model name to use"
            },
            apiKey: {
              type: "string",
              description: "API key for this provider"
            },
            maxRetries: {
              type: "number",
              description: "Per-provider retry override"
            },
            region: {
              type: "string",
              description: "AWS region (for Bedrock)"
            },
            accessKeyId: {
              type: "string",
              description: "AWS access key ID (for Bedrock)"
            },
            secretAccessKey: {
              type: "string",
              description: "AWS secret access key (for Bedrock)"
            }
          },
          required: ["provider", "model"],
          additionalProperties: false,
          description: "Fallback provider configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        BashConfig: {
          type: "object",
          properties: {
            allow: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Array of permitted command patterns (e.g., ['ls', 'git status'])"
            },
            deny: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Array of blocked command patterns (e.g., ['rm -rf', 'sudo'])"
            },
            noDefaultAllow: {
              type: "boolean",
              description: "Disable default safe command list (use with caution)"
            },
            noDefaultDeny: {
              type: "boolean",
              description: "Disable default dangerous command blocklist (use with extreme caution)"
            },
            timeout: {
              type: "number",
              description: "Execution timeout in milliseconds"
            },
            workingDirectory: {
              type: "string",
              description: "Default working directory for command execution"
            }
          },
          additionalProperties: false,
          description: "Bash command execution configuration for ProbeAgent Note: Use 'allowBash: true' in AIProviderConfig to enable bash execution",
          patternProperties: {
            "^x-": {}
          }
        },
        ClaudeCodeConfig: {
          type: "object",
          properties: {
            allowedTools: {
              type: "array",
              items: {
                type: "string"
              },
              description: "List of allowed tools for Claude Code to use"
            },
            maxTurns: {
              type: "number",
              description: "Maximum number of turns in conversation"
            },
            systemPrompt: {
              type: "string",
              description: "System prompt for Claude Code"
            },
            mcpServers: {
              $ref: "#/definitions/Record%3Cstring%2CMcpServerConfig%3E",
              description: "MCP servers configuration"
            },
            subagent: {
              type: "string",
              description: "Path to subagent script"
            },
            enableDelegate: {
              type: "boolean",
              description: "Enable the delegate tool for task distribution to subagents"
            },
            hooks: {
              type: "object",
              properties: {
                onStart: {
                  type: "string",
                  description: "Called when check starts"
                },
                onEnd: {
                  type: "string",
                  description: "Called when check ends"
                },
                onError: {
                  type: "string",
                  description: "Called when check encounters an error"
                }
              },
              additionalProperties: false,
              description: "Event hooks for lifecycle management",
              patternProperties: {
                "^x-": {}
              }
            }
          },
          additionalProperties: false,
          description: "Claude Code configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        EnvConfig: {
          type: "object",
          additionalProperties: {
            type: ["string", "number", "boolean"]
          },
          description: "Environment variable reference configuration"
        },
        CustomTemplateConfig: {
          type: "object",
          properties: {
            file: {
              type: "string",
              description: "Path to custom template file (relative to config file or absolute)"
            },
            content: {
              type: "string",
              description: "Raw template content as string"
            }
          },
          additionalProperties: false,
          description: "Custom template configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        FailureConditions: {
          type: "object",
          additionalProperties: {
            $ref: "#/definitions/FailureCondition"
          },
          description: "Collection of failure conditions"
        },
        FailureCondition: {
          anyOf: [
            {
              $ref: "#/definitions/SimpleFailureCondition"
            },
            {
              $ref: "#/definitions/ComplexFailureCondition"
            }
          ],
          description: "Failure condition - can be a simple expression string or complex object"
        },
        SimpleFailureCondition: {
          type: "string",
          description: "Simple failure condition - just an expression string"
        },
        ComplexFailureCondition: {
          type: "object",
          properties: {
            condition: {
              type: "string",
              description: "Expression to evaluate using Function Constructor"
            },
            message: {
              type: "string",
              description: "Human-readable message when condition is met"
            },
            severity: {
              $ref: "#/definitions/FailureConditionSeverity",
              description: "Severity level of the failure"
            },
            halt_execution: {
              type: "boolean",
              description: "Whether this condition should halt execution"
            }
          },
          required: ["condition"],
          additionalProperties: false,
          description: "Complex failure condition with additional metadata",
          patternProperties: {
            "^x-": {}
          }
        },
        FailureConditionSeverity: {
          type: "string",
          enum: ["error", "warning", "info"],
          description: "Failure condition severity levels"
        },
        OnInitConfig: {
          type: "object",
          properties: {
            run: {
              type: "array",
              items: {
                $ref: "#/definitions/OnInitRunItem"
              },
              description: "Items to run before this check executes"
            },
            run_js: {
              type: "string",
              description: "Dynamic init items: JS expression returning OnInitRunItem[]"
            },
            transitions: {
              type: "array",
              items: {
                $ref: "#/definitions/TransitionRule"
              },
              description: "Declarative transitions (optional, for advanced use cases)"
            }
          },
          additionalProperties: false,
          description: "Init routing configuration per check Runs BEFORE the check executes (preprocessing/setup)",
          patternProperties: {
            "^x-": {}
          }
        },
        OnInitRunItem: {
          anyOf: [
            {
              $ref: "#/definitions/OnInitToolInvocation"
            },
            {
              $ref: "#/definitions/OnInitStepInvocation"
            },
            {
              $ref: "#/definitions/OnInitWorkflowInvocation"
            },
            {
              type: "string"
            }
          ],
          description: "Unified on_init run item - can be tool, step, workflow, or plain string"
        },
        OnInitToolInvocation: {
          type: "object",
          properties: {
            tool: {
              type: "string",
              description: "Tool name (must exist in tools: section)"
            },
            with: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Arguments to pass to the tool (Liquid templates supported)"
            },
            as: {
              type: "string",
              description: "Custom output name (defaults to tool name)"
            }
          },
          required: ["tool"],
          additionalProperties: false,
          description: "Invoke a custom tool (from tools: section)",
          patternProperties: {
            "^x-": {}
          }
        },
        OnInitStepInvocation: {
          type: "object",
          properties: {
            step: {
              type: "string",
              description: "Step name (must exist in steps: section)"
            },
            with: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Arguments to pass to the step (Liquid templates supported)"
            },
            as: {
              type: "string",
              description: "Custom output name (defaults to step name)"
            }
          },
          required: ["step"],
          additionalProperties: false,
          description: "Invoke a helper step (regular check)",
          patternProperties: {
            "^x-": {}
          }
        },
        OnInitWorkflowInvocation: {
          type: "object",
          properties: {
            workflow: {
              type: "string",
              description: "Workflow ID or path"
            },
            with: {
              $ref: "#/definitions/Record%3Cstring%2Cunknown%3E",
              description: "Workflow inputs (Liquid templates supported)"
            },
            as: {
              type: "string",
              description: "Custom output name (defaults to workflow name)"
            },
            overrides: {
              $ref: "#/definitions/Record%3Cstring%2CPartial%3Cinterface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182%3E%3E",
              description: "Step overrides"
            },
            output_mapping: {
              $ref: "#/definitions/Record%3Cstring%2Cstring%3E",
              description: "Output mapping"
            }
          },
          required: ["workflow"],
          additionalProperties: false,
          description: "Invoke a reusable workflow",
          patternProperties: {
            "^x-": {}
          }
        },
        "Record<string,Partial<interface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182>>": {
          type: "object",
          additionalProperties: {
            $ref: "#/definitions/Partial%3Cinterface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182%3E"
          }
        },
        "Partial<interface-src_types_config.ts-11359-23582-src_types_config.ts-0-41182>": {
          type: "object",
          additionalProperties: false
        },
        TransitionRule: {
          type: "object",
          properties: {
            when: {
              type: "string",
              description: "JavaScript expression evaluated in the same sandbox as goto_js; truthy enables the rule."
            },
            to: {
              type: ["string", "null"],
              description: "Target step ID, or null to explicitly prevent goto."
            },
            goto_event: {
              $ref: "#/definitions/EventTrigger",
              description: "Optional event override when performing goto."
            }
          },
          required: ["when"],
          additionalProperties: false,
          description: "Declarative transition rule for on_* blocks.",
          patternProperties: {
            "^x-": {}
          }
        },
        OnFailConfig: {
          type: "object",
          properties: {
            retry: {
              $ref: "#/definitions/RetryPolicy",
              description: "Retry policy"
            },
            run: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Remediation steps to run before reattempt"
            },
            goto: {
              type: "string",
              description: "Jump back to an ancestor step (by id)"
            },
            goto_event: {
              $ref: "#/definitions/EventTrigger",
              description: "Simulate a different event when performing goto (e.g., 'pr_updated')"
            },
            goto_js: {
              type: "string",
              description: "Dynamic goto: JS expression returning step id or null"
            },
            run_js: {
              type: "string",
              description: "Dynamic remediation list: JS expression returning string[]"
            },
            transitions: {
              type: "array",
              items: {
                $ref: "#/definitions/TransitionRule"
              },
              description: "Declarative transitions. Evaluated in order; first matching rule wins. If a rule's `to` is null, no goto occurs. When omitted or none match, the engine falls back to goto_js/goto for backward compatibility."
            }
          },
          additionalProperties: false,
          description: "Failure routing configuration per check",
          patternProperties: {
            "^x-": {}
          }
        },
        RetryPolicy: {
          type: "object",
          properties: {
            max: {
              type: "number",
              description: "Maximum retry attempts (excluding the first attempt)"
            },
            backoff: {
              $ref: "#/definitions/BackoffPolicy",
              description: "Backoff policy"
            }
          },
          additionalProperties: false,
          description: "Retry policy for a step",
          patternProperties: {
            "^x-": {}
          }
        },
        BackoffPolicy: {
          type: "object",
          properties: {
            mode: {
              type: "string",
              enum: ["fixed", "exponential"],
              description: "Backoff mode"
            },
            delay_ms: {
              type: "number",
              description: "Initial delay in milliseconds"
            }
          },
          additionalProperties: false,
          description: "Backoff policy for retries",
          patternProperties: {
            "^x-": {}
          }
        },
        OnSuccessConfig: {
          type: "object",
          properties: {
            run: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Post-success steps to run"
            },
            goto: {
              type: "string",
              description: "Optional jump back to ancestor step (by id)"
            },
            goto_event: {
              $ref: "#/definitions/EventTrigger",
              description: "Simulate a different event when performing goto (e.g., 'pr_updated')"
            },
            goto_js: {
              type: "string",
              description: "Dynamic goto: JS expression returning step id or null"
            },
            run_js: {
              type: "string",
              description: "Dynamic post-success steps: JS expression returning string[]"
            },
            transitions: {
              type: "array",
              items: {
                $ref: "#/definitions/TransitionRule"
              },
              description: "Declarative transitions (see OnFailConfig.transitions)."
            }
          },
          additionalProperties: false,
          description: "Success routing configuration per check",
          patternProperties: {
            "^x-": {}
          }
        },
        OnFinishConfig: {
          type: "object",
          properties: {
            run: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Post-finish steps to run"
            },
            goto: {
              type: "string",
              description: "Optional jump back to ancestor step (by id)"
            },
            goto_event: {
              $ref: "#/definitions/EventTrigger",
              description: "Simulate a different event when performing goto (e.g., 'pr_updated')"
            },
            goto_js: {
              type: "string",
              description: "Dynamic goto: JS expression returning step id or null"
            },
            run_js: {
              type: "string",
              description: "Dynamic post-finish steps: JS expression returning string[]"
            },
            transitions: {
              type: "array",
              items: {
                $ref: "#/definitions/TransitionRule"
              },
              description: "Declarative transitions (see OnFailConfig.transitions)."
            }
          },
          additionalProperties: false,
          description: "Finish routing configuration for forEach checks Runs once after ALL iterations of forEach and ALL dependent checks complete",
          patternProperties: {
            "^x-": {}
          }
        },
        OutputConfig: {
          type: "object",
          properties: {
            pr_comment: {
              $ref: "#/definitions/PrCommentOutput",
              description: "PR comment configuration"
            },
            file_comment: {
              $ref: "#/definitions/FileCommentOutput",
              description: "File comment configuration (optional)"
            },
            github_checks: {
              $ref: "#/definitions/GitHubCheckOutput",
              description: "GitHub check runs configuration (optional)"
            },
            suppressionEnabled: {
              type: "boolean",
              description: "Whether to enable issue suppression via visor-disable comments (default: true)"
            }
          },
          required: ["pr_comment"],
          additionalProperties: false,
          description: "Output configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        PrCommentOutput: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Whether PR comments are enabled"
            },
            format: {
              $ref: "#/definitions/ConfigOutputFormat",
              description: "Format of the output"
            },
            group_by: {
              $ref: "#/definitions/GroupByOption",
              description: "How to group the results"
            },
            collapse: {
              type: "boolean",
              description: "Whether to collapse sections by default"
            },
            debug: {
              $ref: "#/definitions/DebugConfig",
              description: "Debug mode configuration (optional)"
            }
          },
          required: ["format", "group_by", "collapse"],
          additionalProperties: false,
          description: "PR comment output configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        ConfigOutputFormat: {
          type: "string",
          enum: ["table", "json", "markdown", "sarif"],
          description: "Valid output formats"
        },
        GroupByOption: {
          type: "string",
          enum: ["check", "file", "severity", "group"],
          description: "Valid grouping options"
        },
        DebugConfig: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Enable debug mode"
            },
            includePrompts: {
              type: "boolean",
              description: "Include AI prompts in debug output"
            },
            includeRawResponses: {
              type: "boolean",
              description: "Include raw AI responses in debug output"
            },
            includeTiming: {
              type: "boolean",
              description: "Include timing information"
            },
            includeProviderInfo: {
              type: "boolean",
              description: "Include provider information"
            }
          },
          required: [
            "enabled",
            "includePrompts",
            "includeRawResponses",
            "includeTiming",
            "includeProviderInfo"
          ],
          additionalProperties: false,
          description: "Debug mode configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        FileCommentOutput: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Whether file comments are enabled"
            },
            inline: {
              type: "boolean",
              description: "Whether to show inline comments"
            }
          },
          required: ["enabled", "inline"],
          additionalProperties: false,
          description: "File comment output configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        GitHubCheckOutput: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Whether GitHub check runs are enabled"
            },
            per_check: {
              type: "boolean",
              description: "Whether to create individual check runs per configured check"
            },
            name_prefix: {
              type: "string",
              description: "Custom name prefix for check runs"
            }
          },
          required: ["enabled", "per_check"],
          additionalProperties: false,
          description: "GitHub Check Runs output configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        HttpServerConfig: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Whether HTTP server is enabled"
            },
            port: {
              type: "number",
              description: "Port to listen on"
            },
            host: {
              type: "string",
              description: "Host/IP to bind to (defaults to 0.0.0.0)"
            },
            tls: {
              $ref: "#/definitions/TlsConfig",
              description: "TLS/SSL configuration for HTTPS"
            },
            auth: {
              $ref: "#/definitions/HttpAuthConfig",
              description: "Authentication configuration"
            },
            endpoints: {
              type: "array",
              items: {
                $ref: "#/definitions/HttpEndpointConfig"
              },
              description: "HTTP endpoints configuration"
            }
          },
          required: ["enabled", "port"],
          additionalProperties: false,
          description: "HTTP server configuration for receiving webhooks",
          patternProperties: {
            "^x-": {}
          }
        },
        TlsConfig: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Enable TLS/HTTPS"
            },
            cert: {
              type: "string",
              description: "Path to TLS certificate file or certificate content"
            },
            key: {
              type: "string",
              description: "Path to TLS key file or key content"
            },
            ca: {
              type: "string",
              description: "Path to CA certificate file or CA content (optional)"
            },
            rejectUnauthorized: {
              type: "boolean",
              description: "Reject unauthorized connections (default: true)"
            }
          },
          required: ["enabled"],
          additionalProperties: false,
          description: "TLS/SSL configuration for HTTPS server",
          patternProperties: {
            "^x-": {}
          }
        },
        HttpAuthConfig: {
          type: "object",
          properties: {
            type: {
              type: "string",
              enum: ["bearer_token", "hmac", "basic", "none"],
              description: "Authentication type"
            },
            secret: {
              type: "string",
              description: "Secret or token for authentication"
            },
            username: {
              type: "string",
              description: "Username for basic auth"
            },
            password: {
              type: "string",
              description: "Password for basic auth"
            }
          },
          required: ["type"],
          additionalProperties: false,
          description: "HTTP server authentication configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        HttpEndpointConfig: {
          type: "object",
          properties: {
            path: {
              type: "string",
              description: "Path for the webhook endpoint"
            },
            transform: {
              type: "string",
              description: "Optional transform template (Liquid) for the received data"
            },
            name: {
              type: "string",
              description: "Optional name/ID for this endpoint"
            }
          },
          required: ["path"],
          additionalProperties: false,
          description: "HTTP server endpoint configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        MemoryConfig: {
          type: "object",
          properties: {
            storage: {
              type: "string",
              enum: ["memory", "file"],
              description: 'Storage mode: "memory" (in-memory, default) or "file" (persistent)'
            },
            format: {
              type: "string",
              enum: ["json", "csv"],
              description: "Storage format (only for file storage, default: json)"
            },
            file: {
              type: "string",
              description: "File path (required if storage: file)"
            },
            namespace: {
              type: "string",
              description: 'Default namespace (default: "default")'
            },
            auto_load: {
              type: "boolean",
              description: "Auto-load on startup (default: true if storage: file)"
            },
            auto_save: {
              type: "boolean",
              description: "Auto-save after operations (default: true if storage: file)"
            }
          },
          additionalProperties: false,
          description: "Memory storage configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        TagFilter: {
          type: "object",
          properties: {
            include: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Tags that checks must have to be included (ANY match)"
            },
            exclude: {
              type: "array",
              items: {
                type: "string"
              },
              description: "Tags that will exclude checks if present (ANY match)"
            }
          },
          additionalProperties: false,
          description: "Tag filter configuration for selective check execution",
          patternProperties: {
            "^x-": {}
          }
        },
        RoutingDefaults: {
          type: "object",
          properties: {
            max_loops: {
              type: "number",
              description: "Per-scope cap on routing transitions (success + failure)"
            },
            defaults: {
              type: "object",
              properties: {
                on_fail: {
                  $ref: "#/definitions/OnFailConfig"
                }
              },
              additionalProperties: false,
              description: "Default policies applied to checks (step-level overrides take precedence)",
              patternProperties: {
                "^x-": {}
              }
            }
          },
          additionalProperties: false,
          description: "Global routing defaults",
          patternProperties: {
            "^x-": {}
          }
        },
        LimitsConfig: {
          type: "object",
          properties: {
            max_runs_per_check: {
              type: "number",
              description: "Maximum number of executions per check within a single engine run. Applies to each distinct scope independently for forEach item executions. Set to 0 or negative to disable. Default: 50."
            },
            max_workflow_depth: {
              type: "number",
              description: "Maximum nesting depth for workflows executed by the state machine engine. Nested workflows are invoked by the workflow provider; this limit prevents accidental infinite recursion. Default: 3."
            }
          },
          additionalProperties: false,
          description: "Global engine limits",
          patternProperties: {
            "^x-": {}
          }
        },
        WorkspaceConfig: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Enable workspace isolation (default: true when config present)"
            },
            base_path: {
              type: "string",
              description: "Base path for workspaces (default: /tmp/visor-workspaces)"
            },
            name: {
              type: "string",
              description: "Workspace directory name (defaults to session id)"
            },
            main_project_name: {
              type: "string",
              description: "Main project folder name inside the workspace (defaults to original directory name)"
            },
            cleanup_on_exit: {
              type: "boolean",
              description: "Clean up workspace on exit (default: true)"
            },
            include_main_project: {
              type: "boolean",
              description: "Include main project worktree in AI allowed folders (default: false)"
            }
          },
          additionalProperties: false,
          description: "Workspace isolation configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        SlackConfig: {
          type: "object",
          properties: {
            version: {
              type: "string",
              description: "Slack API version"
            },
            mentions: {
              type: "string",
              description: "Mention handling: 'all', 'direct', etc."
            },
            threads: {
              type: "string",
              description: "Thread handling: 'required', 'optional', etc."
            },
            show_raw_output: {
              type: "boolean",
              description: "Show raw output in Slack responses"
            },
            telemetry: {
              $ref: "#/definitions/SlackTelemetryConfig",
              description: "Append telemetry identifiers to Slack replies."
            }
          },
          additionalProperties: false,
          description: "Slack configuration",
          patternProperties: {
            "^x-": {}
          }
        },
        SlackTelemetryConfig: {
          type: "object",
          properties: {
            enabled: {
              type: "boolean",
              description: "Enable telemetry ID suffix in Slack messages"
            }
          },
          additionalProperties: false,
          patternProperties: {
            "^x-": {}
          }
        }
      }
    };
    config_schema_default = configSchema;
  }
});

// src/config.ts
var config_exports = {};
__export(config_exports, {
  ConfigManager: () => ConfigManager,
  VALID_EVENT_TRIGGERS: () => VALID_EVENT_TRIGGERS
});
var yaml3, fs9, path10, import_simple_git, import_ajv3, import_ajv_formats2, VALID_EVENT_TRIGGERS, ConfigManager, __ajvValidate, __ajvErrors;
var init_config = __esm({
  "src/config.ts"() {
    "use strict";
    yaml3 = __toESM(require("js-yaml"));
    fs9 = __toESM(require("fs"));
    path10 = __toESM(require("path"));
    init_logger();
    import_simple_git = __toESM(require("simple-git"));
    init_config_loader();
    init_config_merger();
    import_ajv3 = __toESM(require("ajv"));
    import_ajv_formats2 = __toESM(require("ajv-formats"));
    init_sandbox();
    VALID_EVENT_TRIGGERS = [
      "pr_opened",
      "pr_updated",
      "pr_closed",
      "issue_opened",
      "issue_comment",
      "manual",
      "schedule",
      "webhook_received"
    ];
    ConfigManager = class {
      validCheckTypes = [
        "ai",
        "claude-code",
        "mcp",
        "command",
        "script",
        "http",
        "http_input",
        "http_client",
        "memory",
        "noop",
        "log",
        "github",
        "human-input",
        "workflow",
        "git-checkout"
      ];
      validEventTriggers = [...VALID_EVENT_TRIGGERS];
      validOutputFormats = ["table", "json", "markdown", "sarif"];
      validGroupByOptions = ["check", "file", "severity", "group"];
      /**
       * Load configuration from a file
       */
      async loadConfig(configPath, options = {}) {
        const { validate = true, mergeDefaults = true, allowedRemotePatterns } = options;
        const resolvedPath = path10.isAbsolute(configPath) ? configPath : path10.resolve(process.cwd(), configPath);
        try {
          let configContent;
          try {
            configContent = fs9.readFileSync(resolvedPath, "utf8");
          } catch (readErr) {
            if (readErr && (readErr.code === "ENOENT" || readErr.code === "ENOTDIR")) {
              throw new Error(`Configuration file not found: ${resolvedPath}`);
            }
            throw new Error(
              `Failed to read configuration file ${resolvedPath}: ${readErr?.message || String(readErr)}`
            );
          }
          let parsedConfig;
          try {
            parsedConfig = yaml3.load(configContent);
          } catch (yamlError) {
            const errorMessage = yamlError instanceof Error ? yamlError.message : String(yamlError);
            throw new Error(`Invalid YAML syntax in ${resolvedPath}: ${errorMessage}`);
          }
          if (!parsedConfig || typeof parsedConfig !== "object") {
            throw new Error("Configuration file must contain a valid YAML object");
          }
          const extendsValue = parsedConfig.extends || parsedConfig.include;
          if (extendsValue) {
            const loaderOptions = {
              baseDir: path10.dirname(resolvedPath),
              allowRemote: this.isRemoteExtendsAllowed(),
              maxDepth: 10,
              allowedRemotePatterns
            };
            const loader = new ConfigLoader(loaderOptions);
            const merger = new ConfigMerger();
            const extends_ = Array.isArray(extendsValue) ? extendsValue : [extendsValue];
            const { extends: _, include: __, ...configWithoutExtends } = parsedConfig;
            let mergedConfig = {};
            for (const source of extends_) {
              console.log(`\u{1F4E6} Extending from: ${source}`);
              const parentConfig = await loader.fetchConfig(source);
              mergedConfig = merger.merge(mergedConfig, parentConfig);
            }
            parsedConfig = merger.merge(mergedConfig, configWithoutExtends);
            parsedConfig = merger.removeDisabledChecks(parsedConfig);
          }
          if (parsedConfig.id && typeof parsedConfig.id === "string") {
            parsedConfig = await this.convertWorkflowToConfig(parsedConfig, path10.dirname(resolvedPath));
          }
          parsedConfig = this.normalizeStepsAndChecks(parsedConfig, !!extendsValue);
          await this.loadWorkflows(parsedConfig, path10.dirname(resolvedPath));
          if (validate) {
            this.validateConfig(parsedConfig);
          }
          let finalConfig = parsedConfig;
          if (mergeDefaults) {
            finalConfig = this.mergeWithDefaults(parsedConfig);
          }
          return finalConfig;
        } catch (error) {
          if (error instanceof Error) {
            if (error.message.includes("not found") || error.message.includes("Invalid YAML") || error.message.includes("extends") || error.message.includes("EACCES") || error.message.includes("EISDIR")) {
              throw error;
            }
            if (error.message.includes("ENOENT")) {
              throw new Error(`Configuration file not found: ${resolvedPath}`);
            }
            if (error.message.includes("EPERM")) {
              throw new Error(`Permission denied reading configuration file: ${resolvedPath}`);
            }
            throw new Error(`Failed to read configuration file ${resolvedPath}: ${error.message}`);
          }
          throw error;
        }
      }
      /**
       * Load configuration from an in-memory object (used by the test runner to
       * handle co-located config + tests without writing temp files).
       */
      async loadConfigFromObject(obj, options = {}) {
        const { validate = true, mergeDefaults = true, allowedRemotePatterns, baseDir } = options;
        try {
          let parsedConfig = JSON.parse(JSON.stringify(obj || {}));
          if (!parsedConfig || typeof parsedConfig !== "object") {
            throw new Error("Configuration must be a YAML/JSON object");
          }
          const extendsValue = parsedConfig.extends || parsedConfig.include;
          if (extendsValue) {
            const loaderOptions = {
              baseDir: baseDir || process.cwd(),
              allowRemote: this.isRemoteExtendsAllowed(),
              maxDepth: 10,
              allowedRemotePatterns
            };
            const loader = new ConfigLoader(loaderOptions);
            const extends_ = Array.isArray(extendsValue) ? extendsValue : [extendsValue];
            const { extends: _, include: __, ...configWithoutExtends } = parsedConfig;
            let mergedConfig = {};
            for (const source of extends_) {
              console.log(`\u{1F4E6} Extending from: ${source}`);
              const parentConfig = await loader.fetchConfig(String(source));
              mergedConfig = new ConfigMerger().merge(mergedConfig, parentConfig);
            }
            parsedConfig = new ConfigMerger().merge(mergedConfig, configWithoutExtends);
            parsedConfig = new ConfigMerger().removeDisabledChecks(parsedConfig);
          }
          if (parsedConfig.id && typeof parsedConfig.id === "string") {
            parsedConfig = await this.convertWorkflowToConfig(parsedConfig, baseDir || process.cwd());
          }
          parsedConfig = this.normalizeStepsAndChecks(parsedConfig, !!extendsValue);
          await this.loadWorkflows(parsedConfig, baseDir || process.cwd());
          if (validate) this.validateConfig(parsedConfig);
          let finalConfig = parsedConfig;
          if (mergeDefaults) finalConfig = this.mergeWithDefaults(parsedConfig);
          return finalConfig;
        } catch (error) {
          if (error instanceof Error) throw new Error(`Failed to load configuration: ${error.message}`);
          throw error;
        }
      }
      /**
       * Find and load configuration from default locations
       */
      async findAndLoadConfig(options = {}) {
        const gitRoot = await this.findGitRepositoryRoot();
        const searchDirs = [gitRoot, process.cwd()].filter(Boolean);
        for (const baseDir of searchDirs) {
          const candidates = ["visor.yaml", "visor.yml", ".visor.yaml", ".visor.yml"].map(
            (p) => path10.join(baseDir, p)
          );
          for (const p of candidates) {
            try {
              const st = fs9.statSync(p);
              if (!st.isFile()) continue;
              const isLegacy = path10.basename(p).startsWith(".");
              if (isLegacy) {
                if (process.env.VISOR_STRICT_CONFIG_NAME === "true") {
                  const rel = path10.relative(baseDir, p);
                  throw new Error(
                    `Legacy config detected: ${rel}. Please rename to visor.yaml (or visor.yml).`
                  );
                }
                return this.loadConfig(p, options);
              }
              return this.loadConfig(p, options);
            } catch (e) {
              if (e && e.code === "ENOENT") continue;
              if (e) throw e;
            }
          }
        }
        const bundledConfig = this.loadBundledDefaultConfig();
        if (bundledConfig) {
          return bundledConfig;
        }
        return this.getDefaultConfig();
      }
      /**
       * Find the git repository root directory
       */
      async findGitRepositoryRoot() {
        try {
          const git = (0, import_simple_git.default)();
          const isRepo = await git.checkIsRepo();
          if (!isRepo) {
            return null;
          }
          const rootDir = await git.revparse(["--show-toplevel"]);
          return rootDir.trim();
        } catch {
          return null;
        }
      }
      /**
       * Get default configuration
       */
      async getDefaultConfig() {
        return {
          version: "1.0",
          steps: {},
          checks: {},
          // Keep for backward compatibility
          max_parallelism: 3,
          output: {
            pr_comment: {
              format: "markdown",
              group_by: "check",
              collapse: true
            }
          }
        };
      }
      /**
       * Load bundled default configuration from the package
       */
      loadBundledDefaultConfig() {
        try {
          const possiblePaths = [];
          if (typeof __dirname !== "undefined") {
            possiblePaths.push(
              path10.join(__dirname, "defaults", "visor.yaml"),
              path10.join(__dirname, "..", "defaults", "visor.yaml")
            );
          }
          const pkgRoot = this.findPackageRoot();
          if (pkgRoot) {
            possiblePaths.push(path10.join(pkgRoot, "defaults", "visor.yaml"));
          }
          if (process.env.GITHUB_ACTION_PATH) {
            possiblePaths.push(
              path10.join(process.env.GITHUB_ACTION_PATH, "defaults", "visor.yaml"),
              path10.join(process.env.GITHUB_ACTION_PATH, "dist", "defaults", "visor.yaml")
            );
          }
          let bundledConfigPath;
          for (const possiblePath of possiblePaths) {
            if (fs9.existsSync(possiblePath)) {
              bundledConfigPath = possiblePath;
              break;
            }
          }
          if (bundledConfigPath) {
            console.error(`\u{1F4E6} Loading bundled default configuration from ${bundledConfigPath}`);
            const readAndParse = (p) => {
              const raw = fs9.readFileSync(p, "utf8");
              const obj = yaml3.load(raw);
              if (!obj || typeof obj !== "object") return {};
              if (obj.include && !obj.extends) {
                const inc = obj.include;
                obj.extends = Array.isArray(inc) ? inc : [inc];
                delete obj.include;
              }
              return obj;
            };
            const baseDir = path10.dirname(bundledConfigPath);
            const merger = new (init_config_merger(), __toCommonJS(config_merger_exports)).ConfigMerger();
            const loadWithExtendsSync = (p) => {
              const current = readAndParse(p);
              const extVal = current.extends || current.include;
              if (current.extends !== void 0) delete current.extends;
              if (current.include !== void 0) delete current.include;
              if (!extVal) return current;
              const list = Array.isArray(extVal) ? extVal : [extVal];
              let acc = {};
              for (const src of list) {
                const rel = typeof src === "string" ? src : String(src);
                const abs = path10.isAbsolute(rel) ? rel : path10.resolve(baseDir, rel);
                const parentCfg = loadWithExtendsSync(abs);
                acc = merger.merge(acc, parentCfg);
              }
              return merger.merge(acc, current);
            };
            let parsedConfig = loadWithExtendsSync(bundledConfigPath);
            parsedConfig = this.normalizeStepsAndChecks(parsedConfig);
            this.validateConfig(parsedConfig);
            return this.mergeWithDefaults(parsedConfig);
          }
        } catch (error) {
          console.warn(
            "Failed to load bundled default config:",
            error instanceof Error ? error.message : String(error)
          );
        }
        return null;
      }
      /**
       * Find the root directory of the Visor package
       */
      findPackageRoot() {
        let currentDir = __dirname;
        while (currentDir !== path10.dirname(currentDir)) {
          const packageJsonPath = path10.join(currentDir, "package.json");
          if (fs9.existsSync(packageJsonPath)) {
            try {
              const packageJson = JSON.parse(fs9.readFileSync(packageJsonPath, "utf8"));
              if (packageJson.name === "@probelabs/visor") {
                return currentDir;
              }
            } catch {
            }
          }
          currentDir = path10.dirname(currentDir);
        }
        return null;
      }
      /**
       * Convert a workflow definition file to a visor config
       * When a workflow YAML is run standalone, register the workflow and use its tests as checks
       */
      async convertWorkflowToConfig(workflowData, basePath) {
        const { WorkflowRegistry: WorkflowRegistry2 } = await Promise.resolve().then(() => (init_workflow_registry(), workflow_registry_exports));
        const registry = WorkflowRegistry2.getInstance();
        const workflowId = workflowData.id;
        logger.info(`Detected standalone workflow file: ${workflowId}`);
        if (workflowData.imports && Array.isArray(workflowData.imports)) {
          for (const source of workflowData.imports) {
            try {
              const results = await registry.import(source, { basePath, validate: true });
              for (const result2 of results) {
                if (!result2.valid && result2.errors) {
                  const errors = result2.errors.map((e) => `  ${e.path}: ${e.message}`).join("\n");
                  throw new Error(`Failed to import workflow from '${source}':
${errors}`);
                }
              }
              logger.info(`Imported workflows from: ${source}`);
            } catch (err) {
              const errMsg = err instanceof Error ? err.message : String(err);
              if (errMsg.includes("already exists")) {
                logger.debug(`Workflow from '${source}' already imported, skipping`);
              } else {
                throw err;
              }
            }
          }
        }
        const tests = workflowData.tests || {};
        const workflowDefinition = { ...workflowData };
        delete workflowDefinition.tests;
        delete workflowDefinition.imports;
        const result = registry.register(workflowDefinition, "standalone", { override: true });
        if (!result.valid && result.errors) {
          const errors = result.errors.map((e) => `  ${e.path}: ${e.message}`).join("\n");
          throw new Error(`Failed to register workflow '${workflowId}':
${errors}`);
        }
        logger.info(`Registered workflow '${workflowId}' for standalone execution`);
        const workflowSteps = workflowData.steps || {};
        const visorConfig = {
          version: "1.0",
          steps: workflowSteps,
          checks: workflowSteps,
          tests
          // Preserve test harness config (may be empty if stripped by test runner)
        };
        if (workflowData.outputs) {
          visorConfig.outputs = workflowData.outputs;
        }
        if (workflowData.inputs) {
          visorConfig.inputs = workflowData.inputs;
        }
        logger.debug(
          `Standalone workflow config has ${Object.keys(workflowSteps).length} workflow steps as checks`
        );
        logger.debug(`Workflow step names: ${Object.keys(workflowSteps).join(", ")}`);
        logger.debug(`Config keys after conversion: ${Object.keys(visorConfig).join(", ")}`);
        return visorConfig;
      }
      /**
       * Load and register workflows from configuration
       */
      async loadWorkflows(config, basePath) {
        if (!config.imports || config.imports.length === 0) {
          return;
        }
        const { WorkflowRegistry: WorkflowRegistry2 } = await Promise.resolve().then(() => (init_workflow_registry(), workflow_registry_exports));
        const registry = WorkflowRegistry2.getInstance();
        for (const source of config.imports) {
          const results = await registry.import(source, { basePath, validate: true });
          for (const result of results) {
            if (!result.valid && result.errors) {
              const errors = result.errors.map((e) => `  ${e.path}: ${e.message}`).join("\n");
              throw new Error(`Failed to import workflow from '${source}':
${errors}`);
            }
          }
          logger.info(`Imported workflows from: ${source}`);
        }
      }
      /**
       * Normalize 'checks' and 'steps' keys for backward compatibility
       * Ensures both keys are present and contain the same data
       */
      normalizeStepsAndChecks(config, preferChecks = false) {
        if (config.steps && config.checks) {
          if (preferChecks) {
            const merged = { ...config.steps, ...config.checks };
            config.steps = merged;
            config.checks = merged;
          } else {
            config.checks = config.steps;
            config.steps = config.steps;
          }
        } else if (config.steps && !config.checks) {
          config.checks = config.steps;
        } else if (config.checks && !config.steps) {
          config.steps = config.checks;
        }
        return config;
      }
      /**
       * Merge configuration with CLI options
       */
      mergeWithCliOptions(config, cliOptions) {
        const mergedConfig = { ...config };
        if (cliOptions.maxParallelism !== void 0) {
          mergedConfig.max_parallelism = cliOptions.maxParallelism;
        }
        if (cliOptions.failFast !== void 0) {
          mergedConfig.fail_fast = cliOptions.failFast;
        }
        return {
          config: mergedConfig,
          cliChecks: cliOptions.checks || [],
          cliOutput: cliOptions.output || "table"
        };
      }
      /**
       * Load configuration with environment variable overrides
       */
      async loadConfigWithEnvOverrides() {
        const environmentOverrides = {};
        if (process.env.VISOR_CONFIG_PATH) {
          environmentOverrides.configPath = process.env.VISOR_CONFIG_PATH;
        }
        if (process.env.VISOR_OUTPUT_FORMAT) {
          environmentOverrides.outputFormat = process.env.VISOR_OUTPUT_FORMAT;
        }
        let config;
        if (environmentOverrides.configPath) {
          try {
            config = await this.loadConfig(environmentOverrides.configPath);
          } catch {
            config = await this.findAndLoadConfig();
          }
        } else {
          config = await this.findAndLoadConfig();
        }
        return { config, environmentOverrides };
      }
      /**
       * Validate configuration against schema
       * @param config The config to validate
       * @param strict If true, treat warnings as errors (default: false)
       */
      validateConfig(config, strict = false) {
        const errors = [];
        const warnings = [];
        this.validateWithAjvSchema(config, errors, warnings);
        if (!config.version) {
          errors.push({
            field: "version",
            message: "Missing required field: version"
          });
        }
        if (!config.checks && !config.steps) {
          errors.push({
            field: "checks/steps",
            message: 'Missing required field: either "checks" or "steps" must be defined. "steps" is recommended for new configurations.'
          });
        }
        const checksToValidate = config.checks || config.steps;
        if (checksToValidate) {
          for (const [checkName, checkConfig] of Object.entries(checksToValidate)) {
            if (!checkConfig.type) {
              checkConfig.type = "ai";
            }
            this.validateCheckConfig(checkName, checkConfig, errors, config, warnings);
            if (checkConfig.ai_mcp_servers) {
              this.validateMcpServersObject(
                checkConfig.ai_mcp_servers,
                `checks.${checkName}.ai_mcp_servers`,
                errors,
                warnings
              );
            }
            if (checkConfig.ai?.mcpServers) {
              this.validateMcpServersObject(
                checkConfig.ai.mcpServers,
                `checks.${checkName}.ai.mcpServers`,
                errors,
                warnings
              );
            }
            if (checkConfig.ai_mcp_servers && checkConfig.ai?.mcpServers) {
              const lower = Object.keys(checkConfig.ai_mcp_servers);
              const higher = Object.keys(checkConfig.ai.mcpServers);
              const overridden = lower.filter((k) => higher.includes(k));
              warnings.push({
                field: `checks.${checkName}.ai.mcpServers`,
                message: overridden.length > 0 ? `Both ai_mcp_servers and ai.mcpServers are set; ai.mcpServers overrides these servers: ${overridden.join(
                  ", "
                )}` : "Both ai_mcp_servers and ai.mcpServers are set; ai.mcpServers takes precedence for this check."
              });
            }
            try {
              const anyCheck = checkConfig;
              const aiObj = anyCheck.ai || void 0;
              const hasBareMcpAtCheck = Object.prototype.hasOwnProperty.call(anyCheck, "mcpServers");
              const hasAiMcp = aiObj && Object.prototype.hasOwnProperty.call(aiObj, "mcpServers");
              const hasClaudeCodeMcp = anyCheck.claude_code && typeof anyCheck.claude_code === "object" && Object.prototype.hasOwnProperty.call(
                anyCheck.claude_code,
                "mcpServers"
              );
              if (checkConfig.type === "ai") {
                if (hasBareMcpAtCheck) {
                  warnings.push({
                    field: `checks.${checkName}.mcpServers`,
                    message: "'mcpServers' at the check root is ignored for type 'ai'. Use 'ai.mcpServers' or 'ai_mcp_servers' instead.",
                    value: anyCheck.mcpServers
                  });
                }
                if (hasClaudeCodeMcp) {
                  warnings.push({
                    field: `checks.${checkName}.claude_code.mcpServers`,
                    message: "'claude_code.mcpServers' is ignored for type 'ai'. Use 'ai.mcpServers' or 'ai_mcp_servers' instead."
                  });
                }
              }
              if (checkConfig.type === "claude-code") {
                if (hasAiMcp || checkConfig.ai_mcp_servers) {
                  warnings.push({
                    field: hasAiMcp ? `checks.${checkName}.ai.mcpServers` : `checks.${checkName}.ai_mcp_servers`,
                    message: "For type 'claude-code', MCP must be configured under 'claude_code.mcpServers'. 'ai.mcpServers' and 'ai_mcp_servers' are ignored for this check."
                  });
                }
              }
            } catch {
            }
          }
        }
        if (config.ai_mcp_servers) {
          this.validateMcpServersObject(config.ai_mcp_servers, "ai_mcp_servers", errors, warnings);
        }
        if (config.output) {
          this.validateOutputConfig(config.output, errors);
        }
        if (config.http_server) {
          this.validateHttpServerConfig(
            config.http_server,
            errors
          );
        }
        if (config.max_parallelism !== void 0) {
          if (typeof config.max_parallelism !== "number" || config.max_parallelism < 1 || !Number.isInteger(config.max_parallelism)) {
            errors.push({
              field: "max_parallelism",
              message: "max_parallelism must be a positive integer (minimum 1)",
              value: config.max_parallelism
            });
          }
        }
        if (config.tag_filter) {
          this.validateTagFilter(config.tag_filter, errors);
        }
        if (strict && warnings.length > 0) {
          errors.push(...warnings);
        }
        if (errors.length > 0) {
          throw new Error(errors[0].message);
        }
        if (!strict && warnings.length > 0) {
          for (const w of warnings) {
            logger.warn(`\u26A0\uFE0F  Config warning [${w.field}]: ${w.message}`);
          }
        }
      }
      /**
       * Validate individual check configuration
       */
      validateCheckConfig(checkName, checkConfig, errors, config, _warnings) {
        if (!checkConfig.type) {
          checkConfig.type = "ai";
        }
        if (checkConfig.type === "logger") {
          checkConfig.type = "log";
        }
        if (!this.validCheckTypes.includes(checkConfig.type)) {
          errors.push({
            field: `checks.${checkName}.type`,
            message: `Invalid check type "${checkConfig.type}". Must be: ${this.validCheckTypes.join(", ")}`,
            value: checkConfig.type
          });
        }
        if (checkConfig.type === "ai" && !checkConfig.prompt) {
          errors.push({
            field: `checks.${checkName}.prompt`,
            message: `Invalid check configuration for "${checkName}": missing prompt (required for AI checks)`
          });
        }
        try {
          const externalTypes = /* @__PURE__ */ new Set(["github", "http", "http_client", "http_input", "workflow"]);
          if (externalTypes.has(checkConfig.type) && !checkConfig.criticality) {
            errors.push({
              field: `checks.${checkName}.criticality`,
              message: `Missing required criticality for step "${checkName}" (type: ${checkConfig.type}). Set criticality: 'external' or 'internal' to enable safe defaults for side-effecting steps.`
            });
          }
        } catch {
        }
        try {
          const crit = checkConfig.criticality || "policy";
          const isCritical = crit === "external" || crit === "internal";
          if (isCritical) {
            const hasAssume = typeof checkConfig.assume === "string" || Array.isArray(checkConfig.assume) && checkConfig.assume.length > 0;
            const hasIf = typeof checkConfig.if === "string" && checkConfig.if.trim().length > 0;
            if (!hasAssume && !hasIf) {
              errors.push({
                field: `checks.${checkName}.assume`,
                message: `Critical step "${checkName}" (criticality: ${crit}) requires a precondition: set 'assume:' (preferred) or 'if:' to guard execution.`
              });
            }
            const outputProviders = /* @__PURE__ */ new Set([
              "ai",
              "script",
              "command",
              "http",
              "http_client",
              "http_input"
            ]);
            if (outputProviders.has(checkConfig.type)) {
              const hasSchema = typeof checkConfig.schema !== "undefined";
              const hasGuarantee = typeof checkConfig.guarantee === "string" && checkConfig.guarantee.trim().length > 0;
              if (!hasSchema && !hasGuarantee) {
                errors.push({
                  field: `checks.${checkName}.schema/guarantee`,
                  message: `Critical step "${checkName}" (type: ${checkConfig.type}) requires an output contract: provide 'schema:' (renderer name or JSON Schema) or 'guarantee:' expression.`
                });
              }
            }
          }
        } catch {
        }
        if (checkConfig.type === "command" && !checkConfig.exec) {
          errors.push({
            field: `checks.${checkName}.exec`,
            message: `Invalid check configuration for "${checkName}": missing exec field (required for command checks)`
          });
        }
        if (checkConfig.type === "http") {
          if (!checkConfig.url) {
            errors.push({
              field: `checks.${checkName}.url`,
              message: `Invalid check configuration for "${checkName}": missing url field (required for http checks)`
            });
          }
          if (!checkConfig.body) {
            errors.push({
              field: `checks.${checkName}.body`,
              message: `Invalid check configuration for "${checkName}": missing body field (required for http checks)`
            });
          }
        }
        if (checkConfig.type === "http_input" && !checkConfig.endpoint) {
          errors.push({
            field: `checks.${checkName}.endpoint`,
            message: `Invalid check configuration for "${checkName}": missing endpoint field (required for http_input checks)`
          });
        }
        try {
          const hasObjSchema = checkConfig?.schema && typeof checkConfig.schema === "object";
          const hasOutputSchema = checkConfig?.output_schema && typeof checkConfig.output_schema === "object";
          if (hasObjSchema && hasOutputSchema) {
            (_warnings || errors).push({
              field: `checks.${checkName}.schema`,
              message: `Both 'schema' (object) and 'output_schema' are set; 'schema' will be used for validation. 'output_schema' is deprecated.`
            });
          }
        } catch {
        }
        if (checkConfig.type === "http_client" && !checkConfig.url) {
          errors.push({
            field: `checks.${checkName}.url`,
            message: `Invalid check configuration for "${checkName}": missing url field (required for http_client checks)`
          });
        }
        if (checkConfig.schedule) {
          const cronParts = checkConfig.schedule.split(" ");
          if (cronParts.length < 5 || cronParts.length > 6) {
            errors.push({
              field: `checks.${checkName}.schedule`,
              message: `Invalid cron expression for "${checkName}": ${checkConfig.schedule}`,
              value: checkConfig.schedule
            });
          }
        }
        if (checkConfig.on) {
          if (!Array.isArray(checkConfig.on)) {
            errors.push({
              field: `checks.${checkName}.on`,
              message: `Invalid check configuration for "${checkName}": 'on' field must be an array`
            });
          } else {
            for (const event of checkConfig.on) {
              if (!this.validEventTriggers.includes(event)) {
                errors.push({
                  field: `checks.${checkName}.on`,
                  message: `Invalid event "${event}". Must be one of: ${this.validEventTriggers.join(", ")}`,
                  value: event
                });
              }
            }
          }
        }
        if (checkConfig.reuse_ai_session !== void 0) {
          const reuseValue = checkConfig.reuse_ai_session;
          const isString = typeof reuseValue === "string";
          const isBoolean = typeof reuseValue === "boolean";
          const isSelf = reuseValue === "self";
          if (!isString && !isBoolean) {
            errors.push({
              field: `checks.${checkName}.reuse_ai_session`,
              message: `Invalid reuse_ai_session value for "${checkName}": must be string (check name) or boolean`,
              value: reuseValue
            });
          } else if (isString && !isSelf) {
            const targetCheckName = reuseValue;
            if (!config?.checks || !config.checks[targetCheckName]) {
              errors.push({
                field: `checks.${checkName}.reuse_ai_session`,
                message: `Check "${checkName}" references non-existent check "${targetCheckName}" for session reuse`,
                value: reuseValue
              });
            }
          } else if (reuseValue === true) {
            if (!checkConfig.depends_on || !Array.isArray(checkConfig.depends_on) || checkConfig.depends_on.length === 0) {
              errors.push({
                field: `checks.${checkName}.reuse_ai_session`,
                message: `Check "${checkName}" has reuse_ai_session=true but missing or empty depends_on. Session reuse requires dependency on another check.`,
                value: reuseValue
              });
            }
          }
        }
        if (checkConfig.session_mode !== void 0) {
          if (checkConfig.session_mode !== "clone" && checkConfig.session_mode !== "append") {
            errors.push({
              field: `checks.${checkName}.session_mode`,
              message: `Invalid session_mode value for "${checkName}": must be 'clone' or 'append'`,
              value: checkConfig.session_mode
            });
          }
          if (!checkConfig.reuse_ai_session) {
            errors.push({
              field: `checks.${checkName}.session_mode`,
              message: `Check "${checkName}" has session_mode but no reuse_ai_session. session_mode requires reuse_ai_session to be set.`,
              value: checkConfig.session_mode
            });
          }
        }
        if (checkConfig.tags !== void 0) {
          if (!Array.isArray(checkConfig.tags)) {
            errors.push({
              field: `checks.${checkName}.tags`,
              message: `Invalid tags value for "${checkName}": must be an array of strings`,
              value: checkConfig.tags
            });
          } else {
            const validTagPattern = /^[a-zA-Z0-9][a-zA-Z0-9-_]*$/;
            checkConfig.tags.forEach((tag, index) => {
              if (typeof tag !== "string") {
                errors.push({
                  field: `checks.${checkName}.tags[${index}]`,
                  message: `Invalid tag at index ${index} for "${checkName}": must be a string`,
                  value: tag
                });
              } else if (!validTagPattern.test(tag)) {
                errors.push({
                  field: `checks.${checkName}.tags[${index}]`,
                  message: `Invalid tag "${tag}" for "${checkName}": tags must be alphanumeric with hyphens or underscores (start with alphanumeric)`,
                  value: tag
                });
              }
            });
          }
        }
        if (checkConfig.on_finish !== void 0) {
          if (!checkConfig.forEach) {
            errors.push({
              field: `checks.${checkName}.on_finish`,
              message: `Check "${checkName}" has on_finish but forEach is not true. on_finish is only valid on forEach checks.`,
              value: checkConfig.on_finish
            });
          }
        }
        try {
          const transformJs = checkConfig.transform_js;
          if (typeof transformJs === "string" && transformJs.trim().length > 0) {
            const result = validateJsSyntax(transformJs);
            if (!result.valid) {
              errors.push({
                field: `checks.${checkName}.transform_js`,
                message: `JavaScript syntax error in "${checkName}" transform_js: ${result.error}`,
                value: transformJs.slice(0, 100) + (transformJs.length > 100 ? "..." : "")
              });
            }
          }
          if (checkConfig.type === "script") {
            const content = checkConfig.content;
            if (typeof content === "string" && content.trim().length > 0) {
              const result = validateJsSyntax(content);
              if (!result.valid) {
                errors.push({
                  field: `checks.${checkName}.content`,
                  message: `JavaScript syntax error in "${checkName}" script: ${result.error}`,
                  value: content.slice(0, 100) + (content.length > 100 ? "..." : "")
                });
              }
            }
          }
        } catch {
        }
      }
      /**
       * Validate MCP servers object shape and values (basic shape only)
       */
      validateMcpServersObject(mcpServers, fieldPrefix, errors, _warnings) {
        if (typeof mcpServers !== "object" || mcpServers === null) {
          errors.push({
            field: fieldPrefix,
            message: `${fieldPrefix} must be an object mapping server names to { command, args?, env? }`,
            value: mcpServers
          });
          return;
        }
        for (const [serverName, cfg] of Object.entries(mcpServers)) {
          const pathStr = `${fieldPrefix}.${serverName}`;
          if (!cfg || typeof cfg !== "object") {
            errors.push({ field: pathStr, message: `${pathStr} must be an object`, value: cfg });
            continue;
          }
          const { command, args, env } = cfg;
          if (typeof command !== "string" || command.trim() === "") {
            errors.push({
              field: `${pathStr}.command`,
              message: `${pathStr}.command must be a non-empty string`,
              value: command
            });
          }
          if (args !== void 0 && !Array.isArray(args)) {
            errors.push({
              field: `${pathStr}.args`,
              message: `${pathStr}.args must be an array of strings`,
              value: args
            });
          }
          if (env !== void 0) {
            if (typeof env !== "object" || env === null) {
              errors.push({
                field: `${pathStr}.env`,
                message: `${pathStr}.env must be an object of string values`,
                value: env
              });
            } else {
              for (const [k, v] of Object.entries(env)) {
                if (typeof v !== "string") {
                  errors.push({
                    field: `${pathStr}.env.${k}`,
                    message: `${pathStr}.env.${k} must be a string`,
                    value: v
                  });
                }
              }
            }
          }
        }
      }
      /**
       * Validate configuration using generated JSON Schema via Ajv, if available.
       * Adds to errors/warnings but does not throw directly.
       */
      validateWithAjvSchema(config, errors, warnings) {
        try {
          if (!__ajvValidate) {
            try {
              const jsonPath = path10.resolve(__dirname, "generated", "config-schema.json");
              const jsonSchema = require(jsonPath);
              if (jsonSchema) {
                const ajv = new import_ajv3.default({ allErrors: true, allowUnionTypes: true, strict: false });
                (0, import_ajv_formats2.default)(ajv);
                const validate = ajv.compile(jsonSchema);
                __ajvValidate = (data) => validate(data);
                __ajvErrors = () => validate.errors;
              }
            } catch {
            }
            if (!__ajvValidate) {
              try {
                const mod = (init_config_schema(), __toCommonJS(config_schema_exports));
                const schema = mod?.configSchema || mod?.default || mod;
                if (schema) {
                  const ajv = new import_ajv3.default({ allErrors: true, allowUnionTypes: true, strict: false });
                  (0, import_ajv_formats2.default)(ajv);
                  const validate = ajv.compile(schema);
                  __ajvValidate = (data) => validate(data);
                  __ajvErrors = () => validate.errors;
                } else {
                  return;
                }
              } catch {
                return;
              }
            }
          }
          const ok = __ajvValidate(config);
          const errs = __ajvErrors ? __ajvErrors() : null;
          if (!ok && Array.isArray(errs)) {
            for (const e of errs) {
              const pathStr = e.instancePath ? e.instancePath.replace(/^\//, "").replace(/\//g, ".") : "";
              const msg = e.message || "Invalid configuration";
              if (e.keyword === "additionalProperties") {
                const addl = e.params && e.params.additionalProperty || "unknown";
                const fullField = pathStr ? `${pathStr}.${addl}` : addl;
                const topLevel = !pathStr;
                if (topLevel && (addl === "tests" || addl === "slack")) {
                  continue;
                }
                warnings.push({
                  field: fullField || "config",
                  message: topLevel ? `Unknown top-level key '${addl}' will be ignored.` : `Unknown key '${addl}' will be ignored`
                });
              } else {
                logger.debug(`Ajv note [${pathStr || "config"}]: ${msg}`);
              }
            }
          }
        } catch (err) {
          logger.debug(`Ajv validation skipped: ${err instanceof Error ? err.message : String(err)}`);
        }
      }
      // Unknown-key warnings are fully handled by Ajv using the generated schema
      // Unknown-key hints are produced by Ajv (additionalProperties=false)
      /**
       * Validate tag filter configuration
       */
      validateTagFilter(tagFilter, errors) {
        const validTagPattern = /^[a-zA-Z0-9][a-zA-Z0-9-_]*$/;
        if (tagFilter.include !== void 0) {
          if (!Array.isArray(tagFilter.include)) {
            errors.push({
              field: "tag_filter.include",
              message: "tag_filter.include must be an array of strings",
              value: tagFilter.include
            });
          } else {
            tagFilter.include.forEach((tag, index) => {
              if (typeof tag !== "string") {
                errors.push({
                  field: `tag_filter.include[${index}]`,
                  message: `Invalid tag at index ${index}: must be a string`,
                  value: tag
                });
              } else if (!validTagPattern.test(tag)) {
                errors.push({
                  field: `tag_filter.include[${index}]`,
                  message: `Invalid tag "${tag}": tags must be alphanumeric with hyphens or underscores`,
                  value: tag
                });
              }
            });
          }
        }
        if (tagFilter.exclude !== void 0) {
          if (!Array.isArray(tagFilter.exclude)) {
            errors.push({
              field: "tag_filter.exclude",
              message: "tag_filter.exclude must be an array of strings",
              value: tagFilter.exclude
            });
          } else {
            tagFilter.exclude.forEach((tag, index) => {
              if (typeof tag !== "string") {
                errors.push({
                  field: `tag_filter.exclude[${index}]`,
                  message: `Invalid tag at index ${index}: must be a string`,
                  value: tag
                });
              } else if (!validTagPattern.test(tag)) {
                errors.push({
                  field: `tag_filter.exclude[${index}]`,
                  message: `Invalid tag "${tag}": tags must be alphanumeric with hyphens or underscores`,
                  value: tag
                });
              }
            });
          }
        }
      }
      /**
       * Validate HTTP server configuration
       */
      validateHttpServerConfig(httpServerConfig, errors) {
        if (typeof httpServerConfig.enabled !== "boolean") {
          errors.push({
            field: "http_server.enabled",
            message: "http_server.enabled must be a boolean",
            value: httpServerConfig.enabled
          });
        }
        if (httpServerConfig.enabled === true) {
          if (typeof httpServerConfig.port !== "number" || httpServerConfig.port < 1 || httpServerConfig.port > 65535) {
            errors.push({
              field: "http_server.port",
              message: "http_server.port must be a number between 1 and 65535",
              value: httpServerConfig.port
            });
          }
          if (httpServerConfig.auth) {
            const auth = httpServerConfig.auth;
            const validAuthTypes = ["bearer_token", "hmac", "basic", "none"];
            if (!auth.type || !validAuthTypes.includes(auth.type)) {
              errors.push({
                field: "http_server.auth.type",
                message: `Invalid auth type. Must be one of: ${validAuthTypes.join(", ")}`,
                value: auth.type
              });
            }
          }
          if (httpServerConfig.tls && typeof httpServerConfig.tls === "object") {
            const tls = httpServerConfig.tls;
            if (tls.enabled === true) {
              if (!tls.cert) {
                errors.push({
                  field: "http_server.tls.cert",
                  message: "TLS certificate is required when TLS is enabled"
                });
              }
              if (!tls.key) {
                errors.push({
                  field: "http_server.tls.key",
                  message: "TLS key is required when TLS is enabled"
                });
              }
            }
          }
          if (httpServerConfig.endpoints && Array.isArray(httpServerConfig.endpoints)) {
            for (let i = 0; i < httpServerConfig.endpoints.length; i++) {
              const endpoint = httpServerConfig.endpoints[i];
              if (!endpoint.path || typeof endpoint.path !== "string") {
                errors.push({
                  field: `http_server.endpoints[${i}].path`,
                  message: "Endpoint path must be a string",
                  value: endpoint.path
                });
              }
            }
          }
        }
      }
      /**
       * Validate output configuration
       */
      validateOutputConfig(outputConfig, errors) {
        if (outputConfig.pr_comment) {
          const prComment = outputConfig.pr_comment;
          if (typeof prComment.format === "string" && !this.validOutputFormats.includes(prComment.format)) {
            errors.push({
              field: "output.pr_comment.format",
              message: `Invalid output format "${prComment.format}". Must be one of: ${this.validOutputFormats.join(", ")}`,
              value: prComment.format
            });
          }
          if (typeof prComment.group_by === "string" && !this.validGroupByOptions.includes(prComment.group_by)) {
            errors.push({
              field: "output.pr_comment.group_by",
              message: `Invalid group_by option "${prComment.group_by}". Must be one of: ${this.validGroupByOptions.join(", ")}`,
              value: prComment.group_by
            });
          }
        }
      }
      /**
       * Check if remote extends are allowed
       */
      isRemoteExtendsAllowed() {
        if (process.env.VISOR_NO_REMOTE_EXTENDS === "true" || process.env.VISOR_NO_REMOTE_EXTENDS === "1") {
          return false;
        }
        return true;
      }
      /**
       * Merge configuration with default values
       */
      mergeWithDefaults(config) {
        const defaultConfig = {
          version: "1.0",
          checks: {},
          max_parallelism: 3,
          output: {
            pr_comment: {
              format: "markdown",
              group_by: "check",
              collapse: true
            }
          }
        };
        const merged = { ...defaultConfig, ...config };
        if (merged.output) {
          merged.output.pr_comment = {
            ...defaultConfig.output.pr_comment,
            ...merged.output.pr_comment
          };
        } else {
          merged.output = defaultConfig.output;
        }
        return merged;
      }
    };
    __ajvValidate = null;
    __ajvErrors = null;
  }
});

// src/providers/workflow-check-provider.ts
var workflow_check_provider_exports = {};
__export(workflow_check_provider_exports, {
  WorkflowCheckProvider: () => WorkflowCheckProvider
});
var import_liquidjs3, WorkflowCheckProvider;
var init_workflow_check_provider = __esm({
  "src/providers/workflow-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_workflow_registry();
    init_workflow_executor();
    init_logger();
    init_sandbox();
    init_human_id();
    import_liquidjs3 = require("liquidjs");
    WorkflowCheckProvider = class extends CheckProvider {
      registry;
      executor;
      liquid;
      constructor() {
        super();
        this.registry = WorkflowRegistry.getInstance();
        this.executor = new WorkflowExecutor();
        this.liquid = new import_liquidjs3.Liquid();
      }
      getName() {
        return "workflow";
      }
      getDescription() {
        return "Executes reusable workflow definitions as checks";
      }
      async validateConfig(config) {
        const cfg = config;
        if (!cfg.workflow && !cfg.config) {
          logger.error('Workflow provider requires either "workflow" (id) or "config" (path)');
          return false;
        }
        if (cfg.workflow) {
          if (!this.registry.has(cfg.workflow)) {
            logger.error(`Workflow '${cfg.workflow}' not found in registry`);
            return false;
          }
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, context2) {
        const cfg = config;
        const isConfigPathMode = !!cfg.config && !cfg.workflow;
        const stepName = config.checkName || cfg.workflow || cfg.config || "workflow";
        let workflow;
        let workflowId = cfg.workflow;
        if (isConfigPathMode) {
          const parentCwd = context2?._parentContext?.originalWorkingDirectory || context2?._parentContext?.workingDirectory || context2?.originalWorkingDirectory || context2?.workingDirectory || process.cwd();
          workflow = await this.loadWorkflowFromConfigPath(String(cfg.config), parentCwd);
          workflowId = workflow.id;
          logger.info(`Executing workflow from config '${cfg.config}' as '${workflowId}'`);
        } else {
          workflowId = String(cfg.workflow);
          workflow = this.registry.get(workflowId);
          if (!workflow) {
            throw new Error(`Workflow '${workflowId}' not found in registry`);
          }
          logger.info(`Executing workflow '${workflowId}'`);
        }
        const inputs = await this.prepareInputs(workflow, config, prInfo, dependencyResults);
        try {
          const inputsCapture = Object.entries(inputs).map(([k, v]) => `${k}: ${typeof v === "string" ? v : JSON.stringify(v)}`).join("\n\n");
          context2?.hooks?.onPromptCaptured?.({
            step: String(stepName),
            provider: "workflow",
            prompt: inputsCapture
          });
        } catch {
        }
        const validation = this.registry.validateInputs(workflow, inputs);
        if (!validation.valid) {
          const errors = validation.errors?.map((e) => `${e.path}: ${e.message}`).join(", ");
          throw new Error(`Invalid workflow inputs: ${errors}`);
        }
        try {
          const mock = context2?.hooks?.mockForStep?.(String(stepName));
          if (mock !== void 0) {
            const ms = mock;
            const issuesArr = Array.isArray(ms?.issues) ? ms.issues : [];
            const out = ms && typeof ms === "object" && "output" in ms ? ms.output : ms;
            const summary2 = {
              issues: issuesArr,
              output: out,
              ...typeof ms?.content === "string" ? { content: String(ms.content) } : {}
            };
            return summary2;
          }
        } catch {
        }
        const modifiedWorkflow = this.applyOverrides(workflow, config);
        const engineMode = context2?._engineMode;
        if (engineMode === "state-machine") {
          logger.info(`[WorkflowProvider] Delegating workflow '${workflowId}' to state machine engine`);
          return await this.executeViaStateMachine(
            modifiedWorkflow,
            inputs,
            config,
            prInfo,
            dependencyResults,
            context2
          );
        }
        const executionContext = {
          instanceId: `${workflowId}-${Date.now()}`,
          parentCheckId: config.checkName,
          inputs,
          stepResults: /* @__PURE__ */ new Map()
        };
        const result = await this.executor.execute(modifiedWorkflow, executionContext, {
          prInfo,
          dependencyResults,
          context: context2
        });
        const outputs = this.mapOutputs(result, config.output_mapping);
        const summary = {
          issues: result.issues || []
        };
        summary.score = result.score || 0;
        summary.confidence = result.confidence || "medium";
        summary.comments = result.comments || [];
        summary.output = outputs;
        summary.content = this.formatWorkflowResult(workflow, result, outputs);
        return summary;
      }
      getSupportedConfigKeys() {
        return [
          "workflow",
          "config",
          "args",
          "overrides",
          "output_mapping",
          "timeout",
          "env",
          "checkName"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [];
      }
      /**
       * Prepare inputs for workflow execution
       */
      async prepareInputs(workflow, config, prInfo, dependencyResults) {
        const inputs = {};
        if (workflow.inputs) {
          for (const param of workflow.inputs) {
            if (param.default !== void 0) {
              inputs[param.name] = param.default;
            }
          }
        }
        const eventContext = config.eventContext || {};
        logger.debug(`[WorkflowProvider] prepareInputs for ${workflow.id}`);
        logger.debug(
          `[WorkflowProvider] eventContext keys: ${Object.keys(eventContext).join(", ") || "none"}`
        );
        logger.debug(
          `[WorkflowProvider] eventContext.slack: ${eventContext.slack ? "present" : "absent"}`
        );
        logger.debug(
          `[WorkflowProvider] eventContext.conversation: ${eventContext.conversation ? "present" : "absent"}`
        );
        const slack = (() => {
          try {
            const anyCtx = eventContext;
            const slackCtx = anyCtx?.slack;
            if (slackCtx && typeof slackCtx === "object") return slackCtx;
          } catch {
          }
          return void 0;
        })();
        const conversation = (() => {
          try {
            const anyCtx = eventContext;
            if (anyCtx?.slack?.conversation) return anyCtx.slack.conversation;
            if (anyCtx?.github?.conversation) return anyCtx.github.conversation;
            if (anyCtx?.conversation) return anyCtx.conversation;
          } catch {
          }
          return void 0;
        })();
        logger.debug(`[WorkflowProvider] slack extracted: ${slack ? "present" : "absent"}`);
        logger.debug(
          `[WorkflowProvider] conversation extracted: ${conversation ? "present" : "absent"}`
        );
        if (conversation) {
          logger.debug(
            `[WorkflowProvider] conversation.messages count: ${Array.isArray(conversation.messages) ? conversation.messages.length : 0}`
          );
        }
        const outputHistory = config.__outputHistory;
        const outputs_history = {};
        if (outputHistory) {
          for (const [k, v] of outputHistory.entries()) {
            outputs_history[k] = v;
          }
        }
        const outputsMap = {};
        logger.debug(
          `[WorkflowProvider] dependencyResults: ${dependencyResults ? dependencyResults.size : "undefined"} entries`
        );
        if (dependencyResults) {
          for (const [key, result] of dependencyResults.entries()) {
            const extracted = result.output ?? result;
            outputsMap[key] = extracted;
            const extractedKeys = extracted && typeof extracted === "object" ? Object.keys(extracted).join(", ") : "not-object";
            logger.debug(`[WorkflowProvider] outputs['${key}']: keys=[${extractedKeys}]`);
          }
        }
        const parentInputs = config.workflowInputs || {};
        const templateContext = {
          pr: prInfo,
          outputs: outputsMap,
          env: process.env,
          slack,
          conversation,
          outputs_history,
          // Include parent workflow inputs for templates like {{ inputs.question }}
          inputs: parentInputs
        };
        const userInputs = config.args || config.workflow_inputs;
        if (userInputs) {
          for (const [key, value] of Object.entries(userInputs)) {
            if (typeof value === "string") {
              if (value.includes("{{") || value.includes("{%")) {
                inputs[key] = await this.liquid.parseAndRender(value, templateContext);
                if (key === "text" || key === "question" || key === "context") {
                  const rendered = String(inputs[key]);
                  logger.info(
                    `[WorkflowProvider] Rendered '${key}' input (${rendered.length} chars): ${rendered.substring(0, 500)}${rendered.length > 500 ? "..." : ""}`
                  );
                }
              } else {
                inputs[key] = value;
              }
            } else if (typeof value === "object" && value !== null && "expression" in value) {
              const exprValue = value;
              const sandbox = createSecureSandbox();
              inputs[key] = compileAndRun(sandbox, exprValue.expression, templateContext, {
                injectLog: true,
                logPrefix: `workflow.input.${key}`
              });
            } else {
              inputs[key] = value;
              if (Array.isArray(value)) {
                logger.debug(`[WorkflowProvider] Input '${key}' is array with ${value.length} items`);
              } else if (typeof value === "object") {
                logger.debug(
                  `[WorkflowProvider] Input '${key}' is object with keys: ${Object.keys(value).join(", ")}`
                );
              }
            }
          }
        }
        const inputSummary = Object.entries(inputs).map(([k, v]) => `${k}:${Array.isArray(v) ? `array[${v.length}]` : typeof v}`).join(", ");
        logger.debug(`[WorkflowProvider] Final inputs: ${inputSummary}`);
        return inputs;
      }
      /**
       * Apply overrides to workflow steps
       */
      applyOverrides(workflow, config) {
        const overrideConfig = config.overrides || config.workflow_overrides;
        if (!overrideConfig) {
          return workflow;
        }
        const modified = JSON.parse(JSON.stringify(workflow));
        for (const [stepId, overrides] of Object.entries(overrideConfig)) {
          if (modified.steps[stepId]) {
            modified.steps[stepId] = {
              ...modified.steps[stepId],
              ...overrides
            };
          } else {
            logger.warn(`Cannot override non-existent step '${stepId}' in workflow '${workflow.id}'`);
          }
        }
        return modified;
      }
      /**
       * Map workflow outputs to check outputs
       */
      mapOutputs(result, outputMapping) {
        if (!outputMapping) {
          return result.output || {};
        }
        const mapped = {};
        const workflowOutputs = result.output || {};
        for (const [checkOutput, workflowOutput] of Object.entries(outputMapping)) {
          if (workflowOutput in workflowOutputs) {
            mapped[checkOutput] = workflowOutputs[workflowOutput];
          } else if (workflowOutput.includes(".")) {
            const parts = workflowOutput.split(".");
            let value = workflowOutputs;
            for (const part of parts) {
              value = value?.[part];
              if (value === void 0) break;
            }
            mapped[checkOutput] = value;
          }
        }
        return mapped;
      }
      /**
       * Format workflow execution result for display
       */
      /**
       * Execute workflow via state machine engine (M3: nested workflows)
       */
      async executeViaStateMachine(workflow, inputs, config, prInfo, dependencyResults, context2) {
        const {
          projectWorkflowToGraph: projectWorkflowToGraph2,
          validateWorkflowDepth: validateWorkflowDepth2
        } = (init_workflow_projection(), __toCommonJS(workflow_projection_exports));
        const { StateMachineRunner: StateMachineRunner2 } = (init_runner(), __toCommonJS(runner_exports));
        const { ExecutionJournal: ExecutionJournal2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
        const { MemoryStore: MemoryStore2 } = (init_memory_store(), __toCommonJS(memory_store_exports));
        const parentContext = context2?._parentContext;
        const parentState = context2?._parentState;
        const currentDepth = parentState?.flags?.currentWorkflowDepth || 0;
        const maxDepth = parentState?.flags?.maxWorkflowDepth ?? parentContext?.config?.limits?.max_workflow_depth ?? 3;
        validateWorkflowDepth2(currentDepth, maxDepth, workflow.id);
        const { config: workflowConfig, checks: checksMetadata } = projectWorkflowToGraph2(
          workflow,
          inputs,
          config.checkName || workflow.id
        );
        const parentMemoryCfg = parentContext?.memory && parentContext.memory.getConfig && parentContext.memory.getConfig() || parentContext?.config?.memory;
        const childJournal = new ExecutionJournal2();
        const childMemory = MemoryStore2.createIsolated(parentMemoryCfg);
        try {
          await childMemory.initialize();
        } catch {
        }
        const parentWorkspace = parentContext?.workspace;
        logger.info(`[WorkflowProvider] Workspace propagation for nested workflow '${workflow.id}':`);
        logger.info(`[WorkflowProvider]   parentContext exists: ${!!parentContext}`);
        logger.info(`[WorkflowProvider]   parentContext.workspace exists: ${!!parentWorkspace}`);
        if (parentWorkspace) {
          logger.info(
            `[WorkflowProvider]   parentWorkspace.isEnabled(): ${parentWorkspace.isEnabled?.() ?? "N/A"}`
          );
          const projectCount = parentWorkspace.listProjects?.()?.length ?? "N/A";
          logger.info(`[WorkflowProvider]   parentWorkspace project count: ${projectCount}`);
        } else {
          logger.warn(
            `[WorkflowProvider]   NO WORKSPACE from parent - nested checkouts won't be added to workspace!`
          );
        }
        const childContext = {
          mode: "state-machine",
          config: workflowConfig,
          checks: checksMetadata,
          journal: childJournal,
          memory: childMemory,
          // For nested workflows we continue to execute inside the same logical
          // working directory as the parent run. When workspace isolation is
          // enabled on the parent engine, its WorkspaceManager is also propagated
          // so that nested checks (AI, git-checkout, etc.) see the same isolated
          // workspace and project symlinks instead of falling back to the Visor
          // repository root.
          workingDirectory: parentContext?.workingDirectory || process.cwd(),
          originalWorkingDirectory: parentContext?.originalWorkingDirectory || parentContext?.workingDirectory || process.cwd(),
          workspace: parentWorkspace,
          // Always use a fresh session for nested workflows to isolate history
          sessionId: generateHumanId(),
          event: parentContext?.event || prInfo.eventType,
          debug: parentContext?.debug || false,
          maxParallelism: parentContext?.maxParallelism,
          failFast: parentContext?.failFast,
          // Propagate execution hooks (mocks, octokit, etc.) into the child so
          // nested steps can be mocked/observed by the YAML test runner.
          executionContext: parentContext?.executionContext,
          // Ensure all workflow steps are considered requested to avoid tag/event filtering surprises
          requestedChecks: Object.keys(checksMetadata)
        };
        const runner = new StateMachineRunner2(childContext);
        const childState = runner.getState();
        childState.flags.currentWorkflowDepth = currentDepth + 1;
        childState.flags.maxWorkflowDepth = maxDepth;
        childState.parentContext = parentContext;
        childState.parentScope = parentState?.parentScope;
        logger.info(
          `[WorkflowProvider] Executing nested workflow '${workflow.id}' at depth ${currentDepth + 1}`
        );
        const result = await runner.run();
        const bubbledEvents = childContext._bubbledEvents || [];
        if (bubbledEvents.length > 0 && parentContext) {
          if (parentContext.debug) {
            logger.info(`[WorkflowProvider] Bubbling ${bubbledEvents.length} events to parent context`);
          }
          if (!parentContext._bubbledEvents) {
            parentContext._bubbledEvents = [];
          }
          parentContext._bubbledEvents.push(...bubbledEvents);
        }
        const allIssues = [];
        let totalScore = 0;
        let scoreCount = 0;
        for (const stepResult of Object.values(result.results)) {
          const typedResult = stepResult;
          if (typedResult.issues) {
            allIssues.push(...typedResult.issues);
          }
          if (typedResult.score) {
            totalScore += typedResult.score;
            scoreCount++;
          }
        }
        const outputs = await this.computeWorkflowOutputsFromState(
          workflow,
          inputs,
          result.results,
          prInfo
        );
        const mappedOutputs = this.mapOutputs(
          { output: outputs },
          config.output_mapping
        );
        const summary = {
          issues: allIssues
        };
        summary.score = scoreCount > 0 ? Math.round(totalScore / scoreCount) : 0;
        summary.confidence = "medium";
        summary.output = mappedOutputs;
        summary.content = this.formatWorkflowResultFromStateMachine(
          workflow,
          result,
          mappedOutputs
        );
        return summary;
      }
      /**
       * Compute workflow outputs from state machine execution results
       */
      async computeWorkflowOutputsFromState(workflow, inputs, groupedResults, prInfo) {
        const outputs = {};
        if (!workflow.outputs) {
          return outputs;
        }
        const sandbox = createSecureSandbox();
        const flat = {};
        try {
          for (const arr of Object.values(groupedResults || {})) {
            for (const item of arr || []) {
              if (!item) continue;
              const name = item.checkName || item.name;
              if (typeof name === "string" && name) {
                flat[name] = { output: item.output, issues: item.issues };
              }
            }
          }
        } catch {
        }
        const outputsMap = Object.fromEntries(
          Object.entries(flat).map(([id, result]) => [id, result.output])
        );
        for (const output of workflow.outputs) {
          if (output.value_js) {
            outputs[output.name] = compileAndRun(
              sandbox,
              output.value_js,
              {
                inputs,
                outputs: outputsMap,
                // Keep 'steps' as alias for backwards compatibility
                steps: outputsMap,
                pr: prInfo
              },
              { injectLog: true, logPrefix: `workflow.output.${output.name}` }
            );
          } else if (output.value) {
            outputs[output.name] = await this.liquid.parseAndRender(output.value, {
              inputs,
              outputs: outputsMap,
              // Keep 'steps' as alias for backwards compatibility
              steps: outputsMap,
              pr: prInfo
            });
          }
        }
        return outputs;
      }
      /**
       * Format workflow result from state machine execution
       */
      formatWorkflowResultFromStateMachine(workflow, result, outputs) {
        const lines = [];
        lines.push(`Workflow: ${workflow.name}`);
        if (workflow.description) {
          lines.push(`Description: ${workflow.description}`);
        }
        lines.push("");
        lines.push("Execution Summary (State Machine):");
        lines.push(`- Total Steps: ${Object.keys(result.results || {}).length}`);
        lines.push(`- Duration: ${result.statistics?.totalDuration || 0}ms`);
        if (Object.keys(outputs).length > 0) {
          lines.push("");
          lines.push("Outputs:");
          for (const [key, value] of Object.entries(outputs)) {
            const formatted = typeof value === "object" ? JSON.stringify(value, null, 2) : String(value);
            lines.push(`- ${key}: ${formatted}`);
          }
        }
        return lines.join("\n");
      }
      formatWorkflowResult(workflow, result, outputs) {
        const lines = [];
        lines.push(`Workflow: ${workflow.name}`);
        if (workflow.description) {
          lines.push(`Description: ${workflow.description}`);
        }
        lines.push("");
        lines.push("Execution Summary:");
        lines.push(`- Status: ${result.status || "completed"}`);
        lines.push(`- Score: ${result.score || 0}`);
        lines.push(`- Issues Found: ${result.issues?.length || 0}`);
        if (result.duration) {
          lines.push(`- Duration: ${result.duration}ms`);
        }
        if (Object.keys(outputs).length > 0) {
          lines.push("");
          lines.push("Outputs:");
          for (const [key, value] of Object.entries(outputs)) {
            const formatted = typeof value === "object" ? JSON.stringify(value, null, 2) : String(value);
            lines.push(`- ${key}: ${formatted}`);
          }
        }
        if (result.stepSummaries && result.stepSummaries.length > 0) {
          lines.push("");
          lines.push("Step Results:");
          for (const summary of result.stepSummaries) {
            lines.push(
              `- ${summary.stepId}: ${summary.status} (${summary.issues?.length || 0} issues)`
            );
          }
        }
        return lines.join("\n");
      }
      /**
       * Load a Visor config file (with steps/checks) and wrap it as a WorkflowDefinition
       * so it can be executed by the state machine as a nested workflow.
       */
      async loadWorkflowFromConfigPath(sourcePath, baseDir) {
        const path22 = require("path");
        const fs20 = require("fs");
        const yaml4 = require("js-yaml");
        const resolved = path22.isAbsolute(sourcePath) ? sourcePath : path22.resolve(baseDir, sourcePath);
        if (!fs20.existsSync(resolved)) {
          throw new Error(`Workflow config not found at: ${resolved}`);
        }
        const rawContent = fs20.readFileSync(resolved, "utf8");
        const rawData = yaml4.load(rawContent);
        if (rawData.imports && Array.isArray(rawData.imports)) {
          const configDir = path22.dirname(resolved);
          for (const source of rawData.imports) {
            try {
              const results = await this.registry.import(source, {
                basePath: configDir,
                validate: true
              });
              for (const result of results) {
                if (!result.valid && result.errors) {
                  const errors = result.errors.map((e) => `  ${e.path}: ${e.message}`).join("\n");
                  throw new Error(`Failed to import workflow from '${source}':
${errors}`);
                }
              }
              logger.info(`Imported workflows from: ${source}`);
            } catch (err) {
              if (err.message?.includes("already exists")) {
                logger.debug(`Workflow from '${source}' already imported, skipping`);
              } else {
                throw err;
              }
            }
          }
        }
        const { ConfigManager: ConfigManager2 } = (init_config(), __toCommonJS(config_exports));
        const mgr = new ConfigManager2();
        const loaded = await mgr.loadConfig(resolved, { validate: false, mergeDefaults: false });
        const steps = loaded.steps || loaded.checks || {};
        if (!steps || Object.keys(steps).length === 0) {
          throw new Error(`Config '${resolved}' does not contain any steps to execute as a workflow`);
        }
        const id = path22.basename(resolved).replace(/\.(ya?ml)$/i, "");
        const name = loaded.name || `Workflow from ${path22.basename(resolved)}`;
        const workflowDef = {
          id,
          name,
          version: loaded.version || "1.0",
          steps,
          description: loaded.description,
          // Inherit optional triggers if present (not required)
          on: loaded.on,
          // Carry over optional inputs/outputs if present so callers can consume them
          inputs: loaded.inputs,
          outputs: loaded.outputs
        };
        return workflowDef;
      }
    };
  }
});

// src/providers/workflow-tool-executor.ts
function workflowInputsToJsonSchema(inputs) {
  if (!inputs || inputs.length === 0) {
    return {
      type: "object",
      properties: {},
      required: []
    };
  }
  const properties = {};
  const required = [];
  for (const input of inputs) {
    const propSchema = {};
    if (input.schema) {
      propSchema.type = input.schema.type || "string";
      if (input.schema.description) propSchema.description = input.schema.description;
      if (input.schema.enum) propSchema.enum = input.schema.enum;
      if (input.schema.default !== void 0) propSchema.default = input.schema.default;
      if (input.schema.minimum !== void 0) propSchema.minimum = input.schema.minimum;
      if (input.schema.maximum !== void 0) propSchema.maximum = input.schema.maximum;
      if (input.schema.minLength !== void 0) propSchema.minLength = input.schema.minLength;
      if (input.schema.maxLength !== void 0) propSchema.maxLength = input.schema.maxLength;
      if (input.schema.pattern) propSchema.pattern = input.schema.pattern;
      if (input.schema.format) propSchema.format = input.schema.format;
      if (input.schema.properties) propSchema.properties = input.schema.properties;
      if (input.schema.items) propSchema.items = input.schema.items;
      if (input.schema.additionalProperties !== void 0) {
        propSchema.additionalProperties = input.schema.additionalProperties;
      }
    } else {
      propSchema.type = "string";
    }
    if (!propSchema.description && input.description) {
      propSchema.description = input.description;
    }
    if (propSchema.default === void 0 && input.default !== void 0) {
      propSchema.default = input.default;
    }
    properties[input.name] = propSchema;
    if (input.required !== false && input.default === void 0) {
      required.push(input.name);
    }
  }
  return {
    type: "object",
    properties,
    required: required.length > 0 ? required : void 0
  };
}
function createWorkflowToolDefinition(workflow, argsOverrides) {
  const baseSchema = workflowInputsToJsonSchema(workflow.inputs);
  let inputSchema = baseSchema;
  if (argsOverrides && baseSchema && typeof baseSchema === "object") {
    const baseProperties = baseSchema.properties;
    const baseRequired = baseSchema.required;
    const filteredProperties = baseProperties ? { ...baseProperties } : {};
    for (const key of Object.keys(argsOverrides)) {
      delete filteredProperties[key];
    }
    const filteredRequired = baseRequired ? baseRequired.filter((r) => !argsOverrides[r]) : void 0;
    inputSchema = {
      ...baseSchema,
      properties: filteredProperties,
      required: filteredRequired && filteredRequired.length > 0 ? filteredRequired : void 0
    };
  }
  return {
    name: workflow.id,
    description: workflow.description || `Execute the ${workflow.name} workflow`,
    inputSchema,
    // Workflow tools don't have an exec command - they're executed specially
    exec: "",
    // Marker properties
    __isWorkflowTool: true,
    __workflowId: workflow.id,
    __argsOverrides: argsOverrides
  };
}
function isWorkflowTool(tool) {
  return tool.__isWorkflowTool === true;
}
function isWorkflowToolReference(item) {
  return typeof item === "object" && item !== null && "workflow" in item;
}
async function executeWorkflowAsTool(workflowId, args, context2, argsOverrides) {
  const registry = WorkflowRegistry.getInstance();
  const workflow = registry.get(workflowId);
  if (!workflow) {
    throw new Error(`Workflow '${workflowId}' not found in registry`);
  }
  logger.debug(`[WorkflowToolExecutor] Executing workflow '${workflowId}' as tool`);
  const mergedArgs = {
    ...args,
    ...argsOverrides
  };
  const { WorkflowCheckProvider: WorkflowCheckProvider2 } = await Promise.resolve().then(() => (init_workflow_check_provider(), workflow_check_provider_exports));
  const provider = new WorkflowCheckProvider2();
  const checkConfig = {
    type: "workflow",
    workflow: workflowId,
    args: mergedArgs,
    checkName: `workflow-tool-${workflowId}`
  };
  const result = await provider.execute(
    context2.prInfo,
    checkConfig,
    context2.outputs,
    context2.executionContext
  );
  const output = result.output;
  if (output !== void 0) {
    return output;
  }
  if (result.content) {
    return result.content;
  }
  return result;
}
function resolveWorkflowToolFromItem(item) {
  const registry = WorkflowRegistry.getInstance();
  if (typeof item === "string") {
    if (registry.has(item)) {
      const workflow = registry.get(item);
      return createWorkflowToolDefinition(workflow);
    }
    return void 0;
  }
  if (isWorkflowToolReference(item)) {
    const workflow = registry.get(item.workflow);
    if (!workflow) {
      logger.warn(`[WorkflowToolExecutor] Workflow '${item.workflow}' not found in registry`);
      return void 0;
    }
    return createWorkflowToolDefinition(workflow, item.args);
  }
  return void 0;
}
var init_workflow_tool_executor = __esm({
  "src/providers/workflow-tool-executor.ts"() {
    "use strict";
    init_workflow_registry();
    init_logger();
  }
});

// src/providers/mcp-custom-sse-server.ts
var import_http, import_events, CustomToolsSSEServer;
var init_mcp_custom_sse_server = __esm({
  "src/providers/mcp-custom-sse-server.ts"() {
    "use strict";
    init_custom_tool_executor();
    init_logger();
    import_http = __toESM(require("http"));
    import_events = require("events");
    init_workflow_tool_executor();
    CustomToolsSSEServer = class {
      server = null;
      port = 0;
      connections = /* @__PURE__ */ new Set();
      toolExecutor;
      sessionId;
      debug;
      eventBus;
      messageQueue = /* @__PURE__ */ new Map();
      tools;
      workflowContext;
      constructor(tools, sessionId, debug = false, workflowContext) {
        this.sessionId = sessionId;
        this.debug = debug;
        this.eventBus = new import_events.EventEmitter();
        this.tools = tools;
        this.workflowContext = workflowContext;
        const toolsRecord = {};
        const workflowToolNames = [];
        for (const [name, tool] of tools.entries()) {
          if (!isWorkflowTool(tool)) {
            toolsRecord[name] = tool;
          } else {
            workflowToolNames.push(name);
          }
        }
        if (workflowToolNames.length > 0 && !workflowContext) {
          logger.warn(
            `[CustomToolsSSEServer:${sessionId}] ${workflowToolNames.length} workflow tool(s) registered but no workflowContext provided. Tools [${workflowToolNames.join(", ")}] will fail at runtime. Pass workflowContext to enable workflow tool execution.`
          );
        }
        this.toolExecutor = new CustomToolExecutor(toolsRecord);
        if (this.debug) {
          const workflowToolCount = workflowToolNames.length;
          const regularToolCount = tools.size - workflowToolCount;
          logger.debug(
            `[CustomToolsSSEServer:${sessionId}] Initialized with ${regularToolCount} regular tools and ${workflowToolCount} workflow tools`
          );
        }
      }
      /**
       * Start the SSE server on an ephemeral port
       * Returns the actual bound port number
       */
      async start() {
        return new Promise((resolve9, reject) => {
          try {
            this.server = import_http.default.createServer((req, res) => {
              this.handleRequest(req, res).catch((error) => {
                logger.error(
                  `[CustomToolsSSEServer:${this.sessionId}] Request handler error: ${error}`
                );
              });
            });
            this.server.on("error", (error) => {
              if (error.code === "EADDRINUSE") {
                if (this.debug) {
                  logger.debug(
                    `[CustomToolsSSEServer:${this.sessionId}] Port ${this.port} in use, retrying with new port`
                  );
                }
                reject(new Error(`Port ${this.port} already in use`));
              } else {
                reject(error);
              }
            });
            this.server.listen(0, "localhost", () => {
              const address = this.server.address();
              if (!address || typeof address === "string") {
                reject(new Error("Failed to bind to port"));
                return;
              }
              this.port = address.port;
              if (this.debug) {
                logger.debug(
                  `[CustomToolsSSEServer:${this.sessionId}] Started on http://localhost:${this.port}/sse`
                );
              }
              resolve9(this.port);
            });
          } catch (error) {
            reject(error);
          }
        });
      }
      /**
       * Stop the server and cleanup resources
       */
      async stop() {
        if (this.debug) {
          logger.debug(`[CustomToolsSSEServer:${this.sessionId}] Stopping server...`);
        }
        for (const connection of this.connections) {
          try {
            connection.response.end();
          } catch (error) {
            if (this.debug) {
              logger.debug(
                `[CustomToolsSSEServer:${this.sessionId}] Error closing connection: ${error}`
              );
            }
          }
        }
        this.connections.clear();
        if (this.server) {
          await new Promise((resolve9, reject) => {
            const timeout = setTimeout(() => {
              if (this.debug) {
                logger.debug(
                  `[CustomToolsSSEServer:${this.sessionId}] Force closing server after timeout`
                );
              }
              this.server?.close(() => resolve9());
            }, 5e3);
            this.server.close((error) => {
              clearTimeout(timeout);
              if (error) {
                reject(error);
              } else {
                resolve9();
              }
            });
          });
          this.server = null;
        }
        if (this.debug) {
          logger.debug(`[CustomToolsSSEServer:${this.sessionId}] Server stopped`);
        }
      }
      /**
       * Get the SSE endpoint URL
       */
      getUrl() {
        if (!this.port) {
          throw new Error("Server not started");
        }
        return `http://localhost:${this.port}/sse`;
      }
      /**
       * Handle incoming HTTP requests
       */
      async handleRequest(req, res) {
        const url = new URL(req.url || "/", `http://localhost:${this.port}`);
        if (req.method === "OPTIONS") {
          this.handleCORS(res);
          res.writeHead(204);
          res.end();
          return;
        }
        if (req.method === "GET" && url.pathname === "/sse") {
          this.handleSSEConnection(req, res);
          return;
        }
        if (req.method === "POST" && url.pathname === "/sse") {
          await this.handleLegacySSEPost(req, res);
          return;
        }
        if (req.method === "POST" && url.pathname === "/message") {
          await this.handleMessage(req, res);
          return;
        }
        res.writeHead(404, { "Content-Type": "application/json" });
        res.end(JSON.stringify({ error: "Not found" }));
      }
      /**
       * Handle legacy POST /sse pattern (connection + message in one request)
       * This maintains backward compatibility with tests
       */
      async handleLegacySSEPost(req, res) {
        this.handleCORS(res);
        res.writeHead(200, {
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-cache",
          Connection: "keep-alive"
        });
        const connectionId = `conn-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`;
        const connection = {
          response: res,
          id: connectionId
        };
        this.connections.add(connection);
        if (this.debug) {
          logger.debug(
            `[CustomToolsSSEServer:${this.sessionId}] Legacy SSE POST connection: ${connectionId}`
          );
        }
        let body = "";
        req.on("data", (chunk) => {
          body += chunk.toString();
        });
        req.on("end", async () => {
          try {
            if (body.trim()) {
              const message = JSON.parse(body);
              await this.handleMCPMessage(connection, message);
            }
          } catch (error) {
            const errorMsg = error instanceof Error ? error.message : "Unknown error";
            if (this.debug) {
              logger.error(
                `[CustomToolsSSEServer:${this.sessionId}] Error in legacy SSE POST: ${errorMsg}`
              );
            }
            this.sendErrorResponse(connection, null, -32700, "Parse error", { error: errorMsg });
          }
        });
        req.on("close", () => {
          this.connections.delete(connection);
        });
      }
      /**
       * Handle SSE connection establishment (GET /sse)
       */
      handleSSEConnection(req, res) {
        this.handleCORS(res);
        res.writeHead(200, {
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-cache",
          Connection: "keep-alive"
        });
        const connectionId = `conn-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`;
        const connection = {
          response: res,
          id: connectionId
        };
        this.connections.add(connection);
        if (this.debug) {
          logger.debug(`[CustomToolsSSEServer:${this.sessionId}] New SSE connection: ${connectionId}`);
        }
        this.sendSSE(
          connection,
          "endpoint",
          `http://localhost:${this.port}/message?sessionId=${connectionId}`
        );
        req.on("close", () => {
          if (this.debug) {
            logger.debug(`[CustomToolsSSEServer:${this.sessionId}] Connection closed: ${connectionId}`);
          }
          this.connections.delete(connection);
        });
      }
      /**
       * Handle MCP message (POST /message)
       */
      async handleMessage(req, res) {
        const url = new URL(req.url || "/", `http://localhost:${this.port}`);
        const sessionId = url.searchParams.get("sessionId");
        let connection;
        for (const conn of this.connections) {
          if (conn.id === sessionId) {
            connection = conn;
            break;
          }
        }
        if (!connection) {
          connection = this.connections.values().next().value;
        }
        if (!connection) {
          res.writeHead(400, { "Content-Type": "application/json" });
          res.end(JSON.stringify({ error: "No active SSE connection" }));
          return;
        }
        let body = "";
        req.on("data", (chunk) => {
          body += chunk.toString();
        });
        req.on("end", async () => {
          try {
            const message = JSON.parse(body);
            if (this.debug) {
              logger.debug(
                `[CustomToolsSSEServer:${this.sessionId}] Received message: ${JSON.stringify(message)}`
              );
            }
            await this.handleMCPMessage(connection, message);
            this.handleCORS(res);
            res.writeHead(202, { "Content-Type": "application/json" });
            res.end(JSON.stringify({ status: "accepted" }));
          } catch (error) {
            const errorMsg = error instanceof Error ? error.message : "Unknown error";
            if (this.debug) {
              logger.error(
                `[CustomToolsSSEServer:${this.sessionId}] Error parsing message: ${errorMsg}`
              );
            }
            this.sendErrorResponse(connection, null, -32700, "Parse error", { error: errorMsg });
            res.writeHead(400, { "Content-Type": "application/json" });
            res.end(JSON.stringify({ error: "Parse error", details: errorMsg }));
          }
        });
      }
      /**
       * Handle CORS headers
       */
      handleCORS(res) {
        res.setHeader("Access-Control-Allow-Origin", "*");
        res.setHeader("Access-Control-Allow-Methods", "GET, POST, OPTIONS");
        res.setHeader("Access-Control-Allow-Headers", "Content-Type");
      }
      /**
       * Send SSE message to client
       */
      sendSSE(connection, event, data) {
        try {
          const dataStr = typeof data === "string" ? data : JSON.stringify(data);
          connection.response.write(`event: ${event}
`);
          connection.response.write(`data: ${dataStr}

`);
        } catch (error) {
          if (this.debug) {
            logger.error(`[CustomToolsSSEServer:${this.sessionId}] Error sending SSE: ${error}`);
          }
        }
      }
      /**
       * Handle MCP protocol messages
       */
      async handleMCPMessage(connection, message) {
        if (this.debug) {
          logger.debug(
            `[CustomToolsSSEServer:${this.sessionId}] Received MCP message: ${JSON.stringify(message)}`
          );
        }
        if (message.method === "tools/list") {
          const response = await this.handleToolsList(message.id);
          this.sendSSE(connection, "message", response);
          return;
        }
        if (message.method === "tools/call") {
          const request = message;
          const response = await this.handleToolCall(
            request.id,
            request.params.name,
            request.params.arguments
          );
          this.sendSSE(connection, "message", response);
          return;
        }
        if (message.method === "initialize") {
          const response = {
            jsonrpc: "2.0",
            id: message.id,
            result: {
              protocolVersion: "2024-11-05",
              capabilities: {
                tools: {}
              },
              serverInfo: {
                name: "visor-custom-tools",
                version: "1.0.0"
              }
            }
          };
          this.sendSSE(connection, "message", response);
          return;
        }
        if (message.method === "notifications/initialized") {
          return;
        }
        this.sendErrorResponse(connection, message.id, -32601, "Method not found");
      }
      /**
       * Handle tools/list MCP request
       */
      async handleToolsList(id) {
        const allTools = Array.from(this.tools.values());
        if (this.debug) {
          logger.debug(
            `[CustomToolsSSEServer:${this.sessionId}] Listing ${allTools.length} tools: ${allTools.map((t) => t.name).join(", ")}`
          );
        }
        return {
          jsonrpc: "2.0",
          id,
          result: {
            tools: allTools.map((tool) => ({
              name: tool.name,
              description: tool.description || `Execute ${tool.name}`,
              inputSchema: tool.inputSchema || {
                type: "object",
                properties: {},
                required: []
              }
            }))
          }
        };
      }
      /**
       * Handle tools/call MCP request
       */
      async handleToolCall(id, toolName, args) {
        try {
          if (this.debug) {
            logger.debug(
              `[CustomToolsSSEServer:${this.sessionId}] Executing tool: ${toolName} with args: ${JSON.stringify(args)}`
            );
          }
          let result;
          const tool = this.tools.get(toolName);
          if (tool && isWorkflowTool(tool)) {
            if (!this.workflowContext) {
              throw new Error(
                `Workflow tool '${toolName}' requires workflow context but none was provided`
              );
            }
            if (this.debug) {
              logger.debug(
                `[CustomToolsSSEServer:${this.sessionId}] Executing workflow tool: ${toolName}`
              );
            }
            const workflowTool = tool;
            result = await executeWorkflowAsTool(
              workflowTool.__workflowId,
              args,
              this.workflowContext,
              workflowTool.__argsOverrides
            );
          } else {
            result = await this.toolExecutor.execute(toolName, args);
          }
          const resultText = typeof result === "string" ? result : JSON.stringify(result, null, 2);
          if (this.debug) {
            logger.debug(
              `[CustomToolsSSEServer:${this.sessionId}] Tool execution completed: ${toolName}`
            );
          }
          return {
            jsonrpc: "2.0",
            id,
            result: {
              content: [
                {
                  type: "text",
                  text: resultText
                }
              ]
            }
          };
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : "Unknown error";
          logger.error(
            `[CustomToolsSSEServer:${this.sessionId}] Tool execution failed: ${toolName} - ${errorMsg}`
          );
          return {
            jsonrpc: "2.0",
            id,
            error: {
              code: -32603,
              message: "Internal error",
              data: {
                tool: toolName,
                error: errorMsg
              }
            }
          };
        }
      }
      /**
       * Send error response via SSE
       */
      sendErrorResponse(connection, id, code, message, data) {
        const errorResponse = {
          jsonrpc: "2.0",
          id: id ?? "error",
          error: {
            code,
            message,
            data
          }
        };
        this.sendSSE(connection, "message", errorResponse);
      }
    };
  }
});

// src/providers/ai-check-provider.ts
var import_promises3, import_path3, AICheckProvider;
var init_ai_check_provider = __esm({
  "src/providers/ai-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_ai_review_service();
    init_env_resolver();
    init_issue_filter();
    init_liquid_extensions();
    import_promises3 = __toESM(require("fs/promises"));
    import_path3 = __toESM(require("path"));
    init_lazy_otel();
    init_state_capture();
    init_mcp_custom_sse_server();
    init_logger();
    init_workflow_tool_executor();
    AICheckProvider = class extends CheckProvider {
      aiReviewService;
      liquidEngine;
      constructor() {
        super();
        this.aiReviewService = new AIReviewService();
        this.liquidEngine = createExtendedLiquid();
      }
      getName() {
        return "ai";
      }
      getDescription() {
        return "AI-powered code review using Google Gemini, Anthropic Claude, OpenAI GPT, or AWS Bedrock models";
      }
      /** Lightweight debug helper to avoid importing logger here */
      logDebug(msg) {
        try {
          if (process.env.VISOR_DEBUG === "true") {
            console.debug(msg);
          }
        } catch {
        }
      }
      /** Detect Slack webhook payload and build a lightweight slack context for templates */
      buildSlackEventContext(context2, config, prInfo) {
        try {
          const aiCfg = config?.ai || {};
          if (aiCfg.skip_slack_context === true) return {};
          const webhook = context2?.webhookContext;
          const map = webhook?.webhookData;
          if (!map || !(map instanceof Map)) return {};
          const first = Array.from(map.values())[0];
          if (!first || typeof first !== "object") return {};
          const ev = first.event;
          const conv = first.slack_conversation;
          if (!ev && !conv) return {};
          if (conv && prInfo) {
            try {
              prInfo.slackConversation = conv;
            } catch {
            }
          }
          return { slack: { event: ev, conversation: conv } };
        } catch {
          return {};
        }
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "ai") {
          return false;
        }
        const prompt = cfg.prompt || cfg.focus;
        if (typeof prompt !== "string") {
          return false;
        }
        if (cfg.ai) {
          if (cfg.ai.provider && !["google", "anthropic", "openai", "bedrock", "mock"].includes(cfg.ai.provider)) {
            return false;
          }
          if (cfg.ai.mcpServers) {
            if (!this.validateMcpServers(cfg.ai.mcpServers)) {
              return false;
            }
          }
        }
        const checkLevelMcpServers = cfg.ai_mcp_servers;
        if (checkLevelMcpServers) {
          if (!this.validateMcpServers(checkLevelMcpServers)) {
            return false;
          }
        }
        return true;
      }
      /**
       * Validate MCP servers configuration
       */
      validateMcpServers(mcpServers) {
        if (typeof mcpServers !== "object" || mcpServers === null) {
          return false;
        }
        for (const serverConfig of Object.values(mcpServers)) {
          if (!serverConfig || typeof serverConfig !== "object") {
            return false;
          }
          const config = serverConfig;
          if (typeof config.command !== "string") {
            return false;
          }
          if (config.args !== void 0 && !Array.isArray(config.args)) {
            return false;
          }
        }
        return true;
      }
      /**
       * Group files by their file extension for template context
       */
      groupFilesByExtension(files) {
        const grouped = {};
        files.forEach((file) => {
          const parts = file.filename.split(".");
          const ext = parts.length > 1 ? parts.pop()?.toLowerCase() || "noext" : "noext";
          if (!grouped[ext]) {
            grouped[ext] = [];
          }
          grouped[ext].push(file);
        });
        return grouped;
      }
      /**
       * Process prompt configuration to resolve final prompt string
       */
      async processPrompt(promptConfig, prInfo, eventContext, dependencyResults, outputHistory, args, workflowInputs) {
        let promptContent;
        if (await this.isFilePath(promptConfig)) {
          promptContent = await this.loadPromptFromFile(promptConfig);
        } else {
          promptContent = promptConfig;
        }
        return await this.renderPromptTemplate(
          promptContent,
          prInfo,
          eventContext,
          dependencyResults,
          outputHistory,
          args,
          workflowInputs
        );
      }
      /**
       * Detect if a string is likely a file path and if the file exists
       */
      async isFilePath(str) {
        if (!str || str.trim() !== str || str.length > 512) {
          return false;
        }
        if (/\s{2,}/.test(str) || // Multiple consecutive spaces
        /\n/.test(str) || // Contains newlines
        /^(please|analyze|review|check|find|identify|look|search)/i.test(str.trim()) || // Starts with command words
        str.split(" ").length > 8) {
          return false;
        }
        if (!/[\/\\]/.test(str)) {
          if (/\b(the|and|or|but|for|with|by|from|in|on|at|as)\b/i.test(str)) {
            return false;
          }
        }
        const hasFileExtension = /\.[a-zA-Z0-9]{1,10}$/i.test(str);
        const hasPathSeparators = /[\/\\]/.test(str);
        const isRelativePath = /^\.{1,2}\//.test(str);
        const isAbsolutePath = import_path3.default.isAbsolute(str);
        const hasTypicalFileChars = /^[a-zA-Z0-9._\-\/\\:~]+$/.test(str);
        if (!(hasFileExtension || isRelativePath || isAbsolutePath || hasPathSeparators)) {
          return false;
        }
        if (!hasTypicalFileChars) {
          return false;
        }
        try {
          let resolvedPath;
          if (import_path3.default.isAbsolute(str)) {
            resolvedPath = import_path3.default.normalize(str);
          } else {
            resolvedPath = import_path3.default.resolve(process.cwd(), str);
          }
          const fs20 = require("fs").promises;
          try {
            const stat = await fs20.stat(resolvedPath);
            return stat.isFile();
          } catch {
            return hasFileExtension && (isRelativePath || isAbsolutePath || hasPathSeparators);
          }
        } catch {
          return false;
        }
      }
      /**
       * Load prompt content from file with security validation
       */
      async loadPromptFromFile(promptPath) {
        if (!promptPath.endsWith(".liquid")) {
          throw new Error("Prompt file must have .liquid extension");
        }
        let resolvedPath;
        if (import_path3.default.isAbsolute(promptPath)) {
          resolvedPath = promptPath;
        } else {
          resolvedPath = import_path3.default.resolve(process.cwd(), promptPath);
        }
        if (!import_path3.default.isAbsolute(promptPath)) {
          const normalizedPath = import_path3.default.normalize(resolvedPath);
          const currentDir = import_path3.default.resolve(process.cwd());
          if (!normalizedPath.startsWith(currentDir)) {
            throw new Error("Invalid prompt file path: path traversal detected");
          }
        }
        if (promptPath.includes("../..")) {
          throw new Error("Invalid prompt file path: path traversal detected");
        }
        try {
          const promptContent = await import_promises3.default.readFile(resolvedPath, "utf-8");
          return promptContent;
        } catch (error) {
          throw new Error(
            `Failed to load prompt from ${resolvedPath}: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Render Liquid template in prompt with comprehensive event context
       */
      async renderPromptTemplate(promptContent, prInfo, eventContext, dependencyResults, outputHistory, args, workflowInputs) {
        const outputsRaw = {};
        if (dependencyResults) {
          for (const [k, v] of dependencyResults.entries()) {
            if (typeof k !== "string") continue;
            if (k.endsWith("-raw")) {
              const name = k.slice(0, -4);
              const summary = v;
              outputsRaw[name] = summary.output !== void 0 ? summary.output : summary;
            }
          }
        }
        const templateContext = {
          // PR Information
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            body: prInfo.body,
            author: prInfo.author,
            baseBranch: prInfo.base,
            headBranch: prInfo.head,
            isIncremental: prInfo.isIncremental,
            filesChanged: prInfo.files?.map((f) => f.filename) || [],
            totalAdditions: prInfo.files?.reduce((sum, f) => sum + f.additions, 0) || 0,
            totalDeletions: prInfo.files?.reduce((sum, f) => sum + f.deletions, 0) || 0,
            totalChanges: prInfo.files?.reduce((sum, f) => sum + f.changes, 0) || 0,
            base: prInfo.base,
            head: prInfo.head
          },
          // File Details
          files: prInfo.files || [],
          description: prInfo.body || "",
          // GitHub / webhook Event Context
          event: eventContext ? {
            name: eventContext.event_name || "unknown",
            action: eventContext.action,
            isPullRequest: !prInfo.isIssue,
            // Set based on whether this is a PR or an issue
            // Repository Info
            repository: eventContext.repository ? {
              owner: eventContext.repository?.owner?.login,
              name: eventContext.repository?.name,
              fullName: eventContext.repository ? `${eventContext.repository?.owner?.login}/${eventContext.repository?.name}` : void 0
            } : void 0,
            // Comment Data (for comment events)
            comment: eventContext.comment ? {
              body: eventContext.comment?.body,
              author: eventContext.comment?.user?.login
            } : void 0,
            // Issue Data (for issue events)
            issue: eventContext.issue ? {
              number: eventContext.issue?.number,
              title: eventContext.issue?.title,
              body: eventContext.issue?.body,
              state: eventContext.issue?.state,
              author: eventContext.issue?.user?.login,
              labels: eventContext.issue?.labels || [],
              assignees: eventContext?.issue?.assignees?.map((a) => a.login) || [],
              createdAt: eventContext.issue?.created_at,
              updatedAt: eventContext.issue?.updated_at,
              isPullRequest: !!eventContext.issue?.pull_request
            } : void 0,
            // Pull Request Event Data
            pullRequest: eventContext.pull_request ? {
              number: eventContext.pull_request?.number,
              state: eventContext.pull_request?.state,
              draft: eventContext.pull_request?.draft,
              headSha: eventContext.pull_request?.head?.sha,
              headRef: eventContext.pull_request?.head?.ref,
              baseSha: eventContext.pull_request?.base?.sha,
              baseRef: eventContext.pull_request?.base?.ref
            } : void 0,
            // Raw event payload for advanced use cases
            payload: eventContext
          } : void 0,
          // Slack conversation context (if provided via eventContext.slack)
          slack: (() => {
            try {
              const anyCtx = eventContext;
              const slack = anyCtx?.slack;
              if (slack && typeof slack === "object") return slack;
            } catch {
            }
            return void 0;
          })(),
          // Unified conversation context across transports (Slack & GitHub)
          conversation: (() => {
            try {
              const anyCtx = eventContext;
              if (anyCtx?.slack?.conversation) return anyCtx.slack.conversation;
              if (anyCtx?.github?.conversation) return anyCtx.github.conversation;
              if (anyCtx?.conversation) return anyCtx.conversation;
            } catch {
            }
            return void 0;
          })(),
          // Utility data for templates
          utils: {
            // Date/time helpers
            now: (/* @__PURE__ */ new Date()).toISOString(),
            today: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
            // Dynamic file grouping by extension
            filesByExtension: this.groupFilesByExtension(prInfo.files || []),
            // File status categorizations
            addedFiles: (prInfo.files || []).filter((f) => f.status === "added"),
            modifiedFiles: (prInfo.files || []).filter((f) => f.status === "modified"),
            removedFiles: (prInfo.files || []).filter((f) => f.status === "removed"),
            renamedFiles: (prInfo.files || []).filter((f) => f.status === "renamed"),
            // Change analysis
            hasLargeChanges: (prInfo.files || []).some((f) => f.changes > 50),
            totalFiles: (prInfo.files || []).length
          },
          // Checks metadata for helpers like chat_history
          checks_meta: (() => {
            try {
              return eventContext?.__checksMeta || void 0;
            } catch {
              return void 0;
            }
          })(),
          // Previous check outputs (dependency results)
          // Expose raw output directly if available, otherwise expose the result as-is
          outputs: dependencyResults ? Object.fromEntries(
            Array.from(dependencyResults.entries()).map(([checkName, result]) => [
              checkName,
              (() => {
                const summary = result;
                return summary.output !== void 0 ? summary.output : summary;
              })()
            ])
          ) : {},
          // Alias for consistency with other providers
          outputs_history: (() => {
            const hist = {};
            if (outputHistory) {
              for (const [k, v] of outputHistory.entries()) hist[k] = v;
            }
            return hist;
          })(),
          // Stage-scoped history slice calculated from baseline captured by the flow runner.
          outputs_history_stage: (() => {
            const stage = {};
            try {
              const base = eventContext?.__stageHistoryBase;
              if (!outputHistory || !base) return stage;
              for (const [k, v] of outputHistory.entries()) {
                const start = base[k] || 0;
                const arr = Array.isArray(v) ? v : [];
                stage[k] = arr.slice(start);
              }
            } catch {
            }
            return stage;
          })(),
          // New: outputs_raw exposes aggregate values (e.g., full arrays for forEach parents)
          outputs_raw: outputsRaw,
          // Custom arguments from on_init 'with' directive
          args: args || {},
          // Workflow inputs (for nested workflow steps to access parent inputs like {{ inputs.context }})
          inputs: workflowInputs || {}
        };
        try {
          if (process.env.VISOR_DEBUG === "true") {
            const outKeys = Object.keys(templateContext.outputs || {}).join(", ");
            const histKeys = Object.keys(templateContext.outputs_history || {}).join(", ");
            const inputsKeys = Object.keys(templateContext.inputs || {}).join(", ");
            console.error(
              `[prompt-ctx] outputs.keys=${outKeys} hist.keys=${histKeys} inputs.keys=${inputsKeys}`
            );
            const projects = templateContext.inputs?.projects;
            if (projects) {
              console.error(
                `[prompt-ctx] inputs.projects has ${Array.isArray(projects) ? projects.length : "N/A"} items`
              );
            }
          }
        } catch {
        }
        try {
          return await this.liquidEngine.parseAndRender(promptContent, templateContext);
        } catch (error) {
          const err = error || {};
          const lines = String(promptContent || "").split(/\r?\n/);
          const lineNum = Number(err.line || err?.token?.line || err?.location?.line || 0);
          const colNum = Number(err.col || err?.token?.col || err?.location?.col || 0);
          let snippet = "";
          if (lineNum > 0) {
            const start = Math.max(1, lineNum - 3);
            const end = Math.max(lineNum + 2, lineNum);
            const width = String(end).length;
            for (let i = start; i <= Math.min(end, lines.length); i++) {
              const ln = `${String(i).padStart(width, " ")} | ${lines[i - 1] ?? ""}`;
              snippet += ln + "\n";
              if (i === lineNum) {
                const caretPad = " ".repeat(Math.max(0, colNum > 1 ? colNum - 1 : 0) + width + 3);
                snippet += caretPad + "^\n";
              }
            }
          } else {
            const preview = lines.slice(0, 20).map((l, i) => `${(i + 1).toString().padStart(3, " ")} | ${l}`).join("\n");
            snippet = preview + "\n";
          }
          const msg = `Failed to render prompt template: ${error instanceof Error ? error.message : "Unknown error"}`;
          try {
            console.error("\n[prompt-error] " + msg + "\n" + snippet);
          } catch {
          }
          throw new Error(msg);
        }
      }
      /**
       * Render Liquid templates in schema definitions
       * Supports dynamic enum values and other template-driven schema properties
       */
      async renderSchema(schema, prInfo, _eventContext, dependencyResults, outputHistory, args, workflowInputs) {
        if (!schema) return schema;
        let schemaStr;
        if (typeof schema === "string") {
          if (!schema.includes("{{") && !schema.includes("{%")) {
            return schema;
          }
          schemaStr = schema;
        } else {
          schemaStr = JSON.stringify(schema);
          if (!schemaStr.includes("{{") && !schemaStr.includes("{%")) {
            return schema;
          }
        }
        const outputsRaw = {};
        if (dependencyResults) {
          for (const [k, v] of dependencyResults.entries()) {
            if (typeof k !== "string") continue;
            if (k.endsWith("-raw")) {
              const name = k.slice(0, -4);
              const summary = v;
              outputsRaw[name] = summary.output !== void 0 ? summary.output : summary;
            }
          }
        }
        const templateContext = {
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            body: prInfo.body,
            author: prInfo.author,
            baseBranch: prInfo.base,
            headBranch: prInfo.head,
            isIncremental: prInfo.isIncremental,
            filesChanged: prInfo.files?.map((f) => f.filename) || [],
            totalAdditions: prInfo.files?.reduce((sum, f) => sum + f.additions, 0) || 0,
            totalDeletions: prInfo.files?.reduce((sum, f) => sum + f.deletions, 0) || 0,
            totalChanges: prInfo.files?.reduce((sum, f) => sum + f.changes, 0) || 0,
            base: prInfo.base,
            head: prInfo.head
          },
          files: prInfo.files || [],
          description: prInfo.body || "",
          outputs: dependencyResults ? Object.fromEntries(
            Array.from(dependencyResults.entries()).map(([checkName, result]) => [
              checkName,
              (() => {
                const summary = result;
                return summary.output !== void 0 ? summary.output : summary;
              })()
            ])
          ) : {},
          outputs_history: (() => {
            const hist = {};
            if (outputHistory) {
              for (const [k, v] of outputHistory.entries()) hist[k] = v;
            }
            return hist;
          })(),
          outputs_raw: outputsRaw,
          args: args || {},
          inputs: workflowInputs || {}
        };
        try {
          if (process.env.VISOR_DEBUG === "true") {
            logger.debug(`[schema-render] Rendering schema with Liquid templates`);
            logger.debug(
              `[schema-render] inputs.projects count: ${Array.isArray(templateContext.inputs?.projects) ? templateContext.inputs.projects.length : "N/A"}`
            );
          }
          const renderedStr = await this.liquidEngine.parseAndRender(schemaStr, templateContext);
          try {
            const parsed = JSON.parse(renderedStr);
            if (process.env.VISOR_DEBUG === "true") {
              logger.debug(`[schema-render] Successfully rendered schema`);
            }
            return parsed;
          } catch (parseError) {
            const errorMsg = parseError instanceof Error ? parseError.message : String(parseError);
            const preview = renderedStr.length > 2e3 ? renderedStr.substring(0, 2e3) + "...[truncated]" : renderedStr;
            logger.error(`[schema-render] JSON_PARSE_ERROR: Failed to parse rendered schema as JSON`);
            logger.error(`[schema-render] Parse error: ${errorMsg}`);
            logger.error(`[schema-render] Original schema type: ${typeof schema}`);
            logger.error(`[schema-render] Rendered output (${renderedStr.length} chars):
${preview}`);
            throw new Error(
              `Schema template rendered invalid JSON: ${errorMsg}. Check Liquid template syntax. Rendered output starts with: "${renderedStr.substring(0, 100)}..."`
            );
          }
        } catch (error) {
          if (error instanceof Error && error.message.includes("Schema template rendered invalid JSON")) {
            throw error;
          }
          const errorMsg = error instanceof Error ? error.message : "Unknown error";
          logger.error(`[schema-render] LIQUID_RENDER_ERROR: Failed to render schema template`);
          logger.error(`[schema-render] Error: ${errorMsg}`);
          logger.error(
            `[schema-render] Original schema: ${schemaStr.substring(0, 500)}${schemaStr.length > 500 ? "...[truncated]" : ""}`
          );
          throw new Error(
            `Schema Liquid template error: ${errorMsg}. Check template syntax in schema definition.`
          );
        }
      }
      async execute(prInfo, config, _dependencyResults, sessionInfo) {
        if (config.env) {
          const result = EnvironmentResolver.withTemporaryEnv(config.env, () => {
            return this.executeWithConfig(prInfo, config, _dependencyResults, sessionInfo);
          });
          if (result instanceof Promise) {
            return result;
          }
          return result;
        }
        return this.executeWithConfig(prInfo, config, _dependencyResults, sessionInfo);
      }
      async executeWithConfig(prInfo, config, _dependencyResults, sessionInfo) {
        try {
          if (process.env.VISOR_DEBUG === "true") {
            console.error(`[ai-exec] step=${String(config.checkName || "unknown")}`);
          }
        } catch {
        }
        const aiConfig = {};
        if (config.ai) {
          const aiAny2 = config.ai;
          const skipTransport = aiAny2.skip_transport_context === true;
          if (aiAny2.apiKey !== void 0) {
            aiConfig.apiKey = aiAny2.apiKey;
          }
          if (aiAny2.model !== void 0) {
            aiConfig.model = aiAny2.model;
          }
          if (aiAny2.timeout !== void 0) {
            aiConfig.timeout = aiAny2.timeout;
          }
          if (aiAny2.provider !== void 0) {
            aiConfig.provider = aiAny2.provider;
          }
          if (aiAny2.debug !== void 0) {
            aiConfig.debug = aiAny2.debug;
          }
          if (aiAny2.enableDelegate !== void 0) {
            aiConfig.enableDelegate = aiAny2.enableDelegate;
          }
          if (aiAny2.allowEdit !== void 0) {
            aiConfig.allowEdit = aiAny2.allowEdit;
          }
          if (aiAny2.allowedTools !== void 0) {
            aiConfig.allowedTools = aiAny2.allowedTools;
            this.logDebug(
              `[AI Provider] Read allowedTools from YAML: ${JSON.stringify(aiAny2.allowedTools)}`
            );
          }
          if (aiAny2.disableTools !== void 0) {
            aiConfig.disableTools = aiAny2.disableTools;
            this.logDebug(`[AI Provider] Read disableTools from YAML: ${aiAny2.disableTools}`);
          }
          if (aiAny2.allowBash !== void 0) {
            aiConfig.allowBash = aiAny2.allowBash;
          }
          if (aiAny2.bashConfig !== void 0) {
            aiConfig.bashConfig = aiAny2.bashConfig;
          }
          if (aiAny2.completion_prompt !== void 0) {
            aiConfig.completionPrompt = aiAny2.completion_prompt;
          }
          if (aiAny2.skip_code_context !== void 0) {
            aiConfig.skip_code_context = aiAny2.skip_code_context;
          } else if (skipTransport) {
            aiConfig.skip_code_context = true;
          }
          if (aiAny2.skip_slack_context !== void 0) {
            aiConfig.skip_slack_context = aiAny2.skip_slack_context;
          } else if (skipTransport) {
            aiConfig.skip_slack_context = true;
          }
          if (aiAny2.retry !== void 0) {
            aiConfig.retry = aiAny2.retry;
          }
          if (aiAny2.fallback !== void 0) {
            aiConfig.fallback = aiAny2.fallback;
          }
        }
        try {
          const ctxAny = sessionInfo;
          const parentCtx = ctxAny?._parentContext;
          const workspace = parentCtx?.workspace;
          logger.debug(
            `[AI Provider] Workspace detection for check '${config.checkName || "unknown"}':`
          );
          logger.debug(`[AI Provider]   sessionInfo exists: ${!!sessionInfo}`);
          logger.debug(`[AI Provider]   _parentContext exists: ${!!parentCtx}`);
          logger.debug(`[AI Provider]   workspace exists: ${!!workspace}`);
          if (workspace) {
            logger.debug(
              `[AI Provider]   workspace.isEnabled exists: ${typeof workspace.isEnabled === "function"}`
            );
            logger.debug(
              `[AI Provider]   workspace.isEnabled(): ${typeof workspace.isEnabled === "function" ? workspace.isEnabled() : "N/A"}`
            );
            const projectCount = typeof workspace.listProjects === "function" ? workspace.listProjects()?.length : "N/A";
            logger.debug(`[AI Provider]   workspace.listProjects() count: ${projectCount}`);
          }
          if (workspace && typeof workspace.isEnabled === "function" && workspace.isEnabled()) {
            const folders = [];
            let workspaceRoot;
            let mainProjectPath;
            try {
              const info = workspace.getWorkspaceInfo?.();
              if (info && typeof info.workspacePath === "string") {
                workspaceRoot = info.workspacePath;
                mainProjectPath = info.mainProjectPath;
                folders.push(info.workspacePath);
              }
            } catch {
            }
            const projectPaths = [];
            try {
              const projects = workspace.listProjects?.() || [];
              for (const proj of projects) {
                if (proj && typeof proj.path === "string") {
                  folders.push(proj.path);
                  projectPaths.push(proj.path);
                }
              }
            } catch {
            }
            const workspaceCfg = parentCtx?.config?.workspace;
            const includeMainProject = workspaceCfg?.include_main_project === true || process.env.VISOR_WORKSPACE_INCLUDE_MAIN_PROJECT === "true";
            if (includeMainProject && mainProjectPath) {
              folders.push(mainProjectPath);
              logger.debug(`[AI Provider] Including main project (enabled): ${mainProjectPath}`);
            } else if (mainProjectPath) {
              logger.debug(`[AI Provider] Excluding main project (disabled): ${mainProjectPath}`);
            }
            const unique = Array.from(new Set(folders.filter((p) => typeof p === "string" && p)));
            if (unique.length > 0 && workspaceRoot) {
              if (unique[0] !== workspaceRoot) {
                logger.warn(
                  `[AI Provider] allowedFolders[0] is not workspaceRoot; tooling defaults may be mis-scoped`
                );
              }
              aiConfig.allowedFolders = unique;
              const aiCwd = workspaceRoot;
              aiConfig.path = aiCwd;
              aiConfig.cwd = aiCwd;
              aiConfig.workspacePath = aiCwd;
              logger.debug(`[AI Provider] Workspace isolation enabled:`);
              logger.debug(`[AI Provider]   cwd (workspaceRoot): ${aiCwd}`);
              logger.debug(`[AI Provider]   workspaceRoot: ${workspaceRoot}`);
              logger.debug(`[AI Provider]   allowedFolders: ${JSON.stringify(unique)}`);
            }
          } else if (parentCtx && typeof parentCtx.workingDirectory === "string") {
            if (!aiConfig.allowedFolders) {
              aiConfig.allowedFolders = [parentCtx.workingDirectory];
            }
            if (!aiConfig.path) {
              aiConfig.path = parentCtx.workingDirectory;
              aiConfig.cwd = parentCtx.workingDirectory;
            }
          }
        } catch {
        }
        if (config.ai_model !== void 0) {
          aiConfig.model = config.ai_model;
        }
        if (config.ai_provider !== void 0) {
          aiConfig.provider = config.ai_provider;
        }
        const customPrompt = config.prompt;
        if (!customPrompt) {
          throw new Error(
            `No prompt defined for check. All checks must have prompts defined in .visor.yaml configuration.`
          );
        }
        const mcpServers = {};
        const globalConfig = config;
        if (globalConfig.ai_mcp_servers) {
          Object.assign(mcpServers, globalConfig.ai_mcp_servers);
        }
        if (config.ai_mcp_servers) {
          Object.assign(mcpServers, config.ai_mcp_servers);
        }
        if (config.ai?.mcpServers) {
          Object.assign(mcpServers, config.ai.mcpServers);
        }
        let customToolsServer = null;
        let customToolsToLoad = [];
        let customToolsServerName = null;
        const legacyCustomTools = this.getCustomToolsForAI(config);
        if (legacyCustomTools.length > 0) {
          customToolsToLoad = legacyCustomTools;
          customToolsServerName = "__custom_tools__";
        }
        for (const [serverName, serverConfig] of Object.entries(mcpServers)) {
          if (serverConfig.tools && Array.isArray(serverConfig.tools)) {
            customToolsToLoad = serverConfig.tools;
            customToolsServerName = serverName;
            break;
          }
        }
        if (customToolsToLoad.length > 0 && customToolsServerName && !config.ai?.disableTools) {
          try {
            const customTools = this.loadCustomTools(customToolsToLoad, config);
            if (customTools.size > 0) {
              const sessionId = config.checkName || `ai-check-${Date.now()}`;
              const debug = aiConfig.debug || process.env.VISOR_DEBUG === "true";
              const workflowContext = {
                prInfo,
                outputs: _dependencyResults,
                executionContext: sessionInfo
              };
              customToolsServer = new CustomToolsSSEServer(
                customTools,
                sessionId,
                debug,
                workflowContext
              );
              const port = await customToolsServer.start();
              if (debug) {
                logger.debug(
                  `[AICheckProvider] Started custom tools SSE server '${customToolsServerName}' on port ${port} for ${customTools.size} tools`
                );
              }
              mcpServers[customToolsServerName] = {
                command: "",
                args: [],
                url: `http://localhost:${port}/sse`,
                transport: "sse"
              };
            }
          } catch (error) {
            logger.error(
              `[AICheckProvider] Failed to start custom tools SSE server '${customToolsServerName}': ${error instanceof Error ? error.message : "Unknown error"}`
            );
          }
        }
        if (Object.keys(mcpServers).length > 0 && !config.ai?.disableTools) {
          aiConfig.mcpServers = mcpServers;
        } else if (config.ai?.disableTools) {
        }
        const templateContext = {
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            author: prInfo.author,
            branch: prInfo.head,
            base: prInfo.base
          },
          files: prInfo.files,
          outputs: _dependencyResults ? Object.fromEntries(
            Array.from(_dependencyResults.entries()).map(([checkName, result]) => [
              checkName,
              result.output !== void 0 ? result.output : result
            ])
          ) : {},
          args: sessionInfo?.args || {}
        };
        try {
          const span = trace.getSpan(context.active());
          if (span) {
            captureCheckInputContext(span, templateContext);
          }
        } catch {
        }
        try {
          const checkId = config.checkName || config.id || "unknown";
          const ctxJson = JSON.stringify(sanitizeContextForTelemetry(templateContext));
          const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
          emitNdjsonSpanWithEvents2(
            "visor.check",
            { "visor.check.id": checkId, "visor.check.input.context": ctxJson },
            []
          );
        } catch {
        }
        const baseEventContext = config.eventContext || {};
        const checksMeta = config.checksMeta;
        const slackCtx = this.buildSlackEventContext(
          sessionInfo,
          config,
          prInfo
        );
        const baseWithSlack = { ...baseEventContext, ...slackCtx };
        const eventContext = checksMeta ? { ...baseWithSlack, __checksMeta: checksMeta } : baseWithSlack;
        const ctxWithStage = {
          ...eventContext || {},
          __stageHistoryBase: sessionInfo?.stageHistoryBase
        };
        const processedPrompt = await this.processPrompt(
          customPrompt,
          prInfo,
          ctxWithStage,
          _dependencyResults,
          config.__outputHistory,
          sessionInfo?.args,
          config.workflowInputs
        );
        const processedSchema = await this.renderSchema(
          config.schema,
          prInfo,
          ctxWithStage,
          _dependencyResults,
          config.__outputHistory,
          sessionInfo?.args,
          config.workflowInputs
        );
        const aiAny = config.ai || {};
        const persona = (aiAny?.ai_persona || config.ai_persona || "").toString().trim();
        const finalPrompt = persona ? `Persona: ${persona}

${processedPrompt}` : processedPrompt;
        const promptTypeOverride = (aiAny?.prompt_type || config.ai?.promptType || config.ai_prompt_type || "").toString().trim();
        try {
          const stepName = config.checkName || "unknown";
          const serviceForCapture = new AIReviewService(aiConfig);
          const finalPromptCapture = await serviceForCapture.buildCustomPrompt(
            prInfo,
            finalPrompt,
            processedSchema,
            {
              checkName: config.checkName,
              skipPRContext: config.ai?.skip_code_context === true
            }
          );
          sessionInfo?.hooks?.onPromptCaptured?.({
            step: String(stepName),
            provider: "ai",
            prompt: finalPromptCapture
          });
        } catch {
        }
        try {
          const stepName = config.checkName || "unknown";
          const mock = sessionInfo?.hooks?.mockForStep?.(String(stepName));
          if (mock !== void 0) {
            const ms = mock;
            const issuesArr = Array.isArray(ms?.issues) ? ms.issues : [];
            const out = ms && typeof ms === "object" && "output" in ms ? ms.output : ms;
            const summary = {
              issues: issuesArr,
              output: out,
              ...typeof ms?.content === "string" ? { content: String(ms.content) } : {}
            };
            return summary;
          }
        } catch {
        }
        try {
          if (promptTypeOverride) aiConfig.promptType = promptTypeOverride;
          const sys = (aiAny?.system_prompt || config.ai_system_prompt || "").toString().trim();
          const legacy = (aiAny?.custom_prompt || config.ai_custom_prompt || "").toString().trim();
          if (sys) aiConfig.systemPrompt = sys;
          else if (legacy) aiConfig.systemPrompt = legacy;
        } catch {
        }
        const service = new AIReviewService(aiConfig);
        const schema = processedSchema;
        try {
          let result;
          const prevPromptTypeEnv = process.env.VISOR_PROMPT_TYPE;
          const shouldIgnoreEnvPromptType = aiAny?.disableTools === true;
          let didAdjustPromptTypeEnv = false;
          if (promptTypeOverride) {
            process.env.VISOR_PROMPT_TYPE = promptTypeOverride;
            didAdjustPromptTypeEnv = true;
          } else if (shouldIgnoreEnvPromptType && prevPromptTypeEnv !== void 0) {
            delete process.env.VISOR_PROMPT_TYPE;
            didAdjustPromptTypeEnv = true;
          }
          try {
            const reuseEnabled = config.reuse_ai_session === true || typeof config.reuse_ai_session === "string";
            let promptUsed = finalPrompt;
            if (sessionInfo?.reuseSession && sessionInfo.parentSessionId && reuseEnabled) {
              try {
                const { SessionRegistry: SessionRegistry2 } = (init_session_registry(), __toCommonJS(session_registry_exports));
                const reg = SessionRegistry2.getInstance();
                if (!reg.hasSession(sessionInfo.parentSessionId)) {
                  if (aiConfig.debug || process.env.VISOR_DEBUG === "true") {
                    console.warn(
                      `\u26A0\uFE0F  Parent session ${sessionInfo.parentSessionId} not found; creating a new session for ${config.checkName}`
                    );
                  }
                  promptUsed = processedPrompt;
                  const fresh = await service.executeReview(
                    prInfo,
                    processedPrompt,
                    schema,
                    config.checkName,
                    config.sessionId
                  );
                  return {
                    ...fresh,
                    issues: new IssueFilter(config.suppressionEnabled !== false).filterIssues(
                      fresh.issues || [],
                      process.cwd()
                    )
                  };
                }
              } catch {
              }
              const sessionMode = config.session_mode || "clone";
              if (aiConfig.debug) {
                console.error(
                  `\u{1F504} Debug: Using session reuse with parent session: ${sessionInfo.parentSessionId} (mode: ${sessionMode})`
                );
              }
              promptUsed = processedPrompt;
              result = await service.executeReviewWithSessionReuse(
                prInfo,
                processedPrompt,
                sessionInfo.parentSessionId,
                schema,
                config.checkName,
                sessionMode
              );
            } else {
              if (aiConfig.debug) {
                console.error(`\u{1F195} Debug: Creating new AI session for check: ${config.checkName}`);
              }
              promptUsed = finalPrompt;
              result = await service.executeReview(
                prInfo,
                finalPrompt,
                schema,
                config.checkName,
                config.sessionId
              );
            }
            const suppressionEnabled = config.suppressionEnabled !== false;
            const issueFilter = new IssueFilter(suppressionEnabled);
            const filteredIssues = issueFilter.filterIssues(result.issues || [], process.cwd());
            const finalResult = {
              ...result,
              issues: filteredIssues
            };
            try {
              const span = trace.getSpan(context.active());
              if (span) {
                captureProviderCall(
                  span,
                  "ai",
                  {
                    prompt: promptUsed,
                    model: aiConfig.model
                  },
                  {
                    content: JSON.stringify(finalResult),
                    tokens: result.usage?.totalTokens
                  }
                );
                const outputForSpan = finalResult.output ?? finalResult;
                captureCheckOutput(span, outputForSpan);
              }
            } catch {
            }
            try {
              const checkId = config.checkName || config.id || "unknown";
              const outJson = JSON.stringify(finalResult.output ?? finalResult);
              const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
              emitNdjsonSpanWithEvents2(
                "visor.check",
                { "visor.check.id": checkId, "visor.check.output": outJson },
                []
              );
            } catch {
            }
            return finalResult;
          } finally {
            if (didAdjustPromptTypeEnv) {
              if (prevPromptTypeEnv === void 0) {
                delete process.env.VISOR_PROMPT_TYPE;
              } else {
                process.env.VISOR_PROMPT_TYPE = prevPromptTypeEnv;
              }
            }
          }
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          console.error(`\u274C AI Check Provider Error for check: ${errorMessage}`);
          const isCriticalError = errorMessage.includes("API rate limit") || errorMessage.includes("403") || errorMessage.includes("401") || errorMessage.includes("authentication") || errorMessage.includes("API key");
          if (isCriticalError) {
            console.error(`\u{1F6A8} CRITICAL ERROR: AI provider authentication or rate limit issue detected`);
            console.error(`\u{1F6A8} This check cannot proceed without valid API credentials`);
          }
          throw new Error(`AI analysis failed: ${errorMessage}`);
        } finally {
          if (customToolsServer) {
            try {
              await customToolsServer.stop();
              if (aiConfig.debug || process.env.VISOR_DEBUG === "true") {
                logger.debug("[AICheckProvider] Custom tools SSE server stopped");
              }
            } catch (error) {
              logger.error(
                `[AICheckProvider] Error stopping custom tools SSE server: ${error instanceof Error ? error.message : "Unknown error"}`
              );
            }
          }
        }
      }
      /**
       * Get custom tool items from check configuration
       * Returns an array of tool items (string names or workflow references)
       */
      getCustomToolsForAI(config) {
        const aiCustomTools = config.ai_custom_tools;
        if (!aiCustomTools) {
          return [];
        }
        if (Array.isArray(aiCustomTools)) {
          return aiCustomTools.filter(
            (item) => typeof item === "string" || isWorkflowToolReference(item)
          );
        }
        if (typeof aiCustomTools === "string") {
          return [aiCustomTools];
        }
        if (isWorkflowToolReference(aiCustomTools)) {
          return [aiCustomTools];
        }
        return [];
      }
      /**
       * Load custom tools from global configuration and workflow registry
       * Supports both traditional custom tools and workflow-as-tool references
       */
      loadCustomTools(toolItems, config) {
        const tools = /* @__PURE__ */ new Map();
        const globalTools = config.__globalTools;
        for (const item of toolItems) {
          const workflowTool = resolveWorkflowToolFromItem(item);
          if (workflowTool) {
            logger.debug(`[AICheckProvider] Loaded workflow '${workflowTool.name}' as custom tool`);
            tools.set(workflowTool.name, workflowTool);
            continue;
          }
          if (typeof item === "string") {
            if (globalTools && globalTools[item]) {
              const tool = globalTools[item];
              tool.name = tool.name || item;
              tools.set(item, tool);
              continue;
            }
            logger.warn(
              `[AICheckProvider] Custom tool '${item}' not found in global tools or workflow registry`
            );
          } else if (isWorkflowToolReference(item)) {
            logger.warn(
              `[AICheckProvider] Workflow '${item.workflow}' referenced but not found in registry`
            );
          }
        }
        if (tools.size === 0 && toolItems.length > 0 && !globalTools) {
          logger.warn(
            `[AICheckProvider] ai_custom_tools specified but no global tools found in configuration and no workflows matched`
          );
        }
        return tools;
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "prompt",
          "focus",
          "schema",
          "group",
          "ai.provider",
          "ai.model",
          "ai.apiKey",
          "ai.timeout",
          "ai.mcpServers",
          "ai.enableDelegate",
          // legacy persona/prompt keys supported in config
          "ai_persona",
          "ai_prompt_type",
          "ai_custom_prompt",
          "ai_system_prompt",
          // new provider resilience and tools toggles
          "ai.retry",
          "ai.fallback",
          "ai.allowEdit",
          "ai.allowedTools",
          "ai.disableTools",
          "ai.allowBash",
          "ai.bashConfig",
          "ai_model",
          "ai_provider",
          "ai_mcp_servers",
          "env"
        ];
      }
      async isAvailable() {
        return !!(process.env.GOOGLE_API_KEY || process.env.ANTHROPIC_API_KEY || process.env.OPENAI_API_KEY || // AWS Bedrock credentials check
        process.env.AWS_ACCESS_KEY_ID && process.env.AWS_SECRET_ACCESS_KEY || process.env.AWS_BEDROCK_API_KEY);
      }
      getRequirements() {
        return [
          "At least one of: GOOGLE_API_KEY, ANTHROPIC_API_KEY, OPENAI_API_KEY, or AWS credentials (AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY)",
          "Optional: MODEL_NAME environment variable",
          "Optional: AWS_REGION for Bedrock provider",
          "Network access to AI provider APIs"
        ];
      }
    };
  }
});

// src/providers/http-check-provider.ts
var HttpCheckProvider;
var init_http_check_provider = __esm({
  "src/providers/http-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_issue_filter();
    init_liquid_extensions();
    init_lazy_otel();
    init_state_capture();
    init_env_resolver();
    HttpCheckProvider = class extends CheckProvider {
      liquid;
      constructor() {
        super();
        this.liquid = createExtendedLiquid();
      }
      getName() {
        return "http";
      }
      getDescription() {
        return "Send data to external HTTP endpoint for notifications or integration";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "http") {
          return false;
        }
        if (typeof cfg.url !== "string" || !cfg.url) {
          return false;
        }
        if (typeof cfg.body !== "string" || !cfg.body) {
          return false;
        }
        try {
          new URL(cfg.url);
          return true;
        } catch {
          return false;
        }
      }
      async execute(prInfo, config, dependencyResults, _sessionInfo) {
        const url = config.url;
        const bodyTemplate = config.body;
        const method = config.method || "POST";
        const headers = config.headers || {};
        const timeout = config.timeout || 3e4;
        const templateContext = {
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            body: prInfo.body,
            author: prInfo.author,
            base: prInfo.base,
            head: prInfo.head,
            totalAdditions: prInfo.totalAdditions,
            totalDeletions: prInfo.totalDeletions
          },
          files: prInfo.files.map((f) => ({
            filename: f.filename,
            status: f.status,
            additions: f.additions,
            deletions: f.deletions,
            changes: f.changes,
            patch: f.patch
          })),
          outputs: dependencyResults ? Object.fromEntries(dependencyResults) : {},
          metadata: config.metadata || {}
        };
        try {
          const span = trace.getSpan(context.active());
          if (span) {
            captureCheckInputContext(span, templateContext);
          }
        } catch {
        }
        let payload;
        try {
          const renderedBody = await this.liquid.parseAndRender(bodyTemplate, templateContext);
          try {
            payload = JSON.parse(renderedBody);
          } catch {
            payload = { message: renderedBody };
          }
        } catch (error) {
          return this.createErrorResult(
            url,
            new Error(
              `Template rendering failed: ${error instanceof Error ? error.message : "Unknown error"}`
            )
          );
        }
        try {
          const resolvedHeaders = EnvironmentResolver.resolveHeaders(headers);
          const response = await this.sendWebhookRequest(
            url,
            method,
            resolvedHeaders,
            payload,
            timeout
          );
          const result = this.parseWebhookResponse(response, url);
          const suppressionEnabled = config.suppressionEnabled !== false;
          const issueFilter = new IssueFilter(suppressionEnabled);
          const filteredIssues = issueFilter.filterIssues(result.issues || [], process.cwd());
          const finalResult = {
            ...result,
            issues: filteredIssues
          };
          try {
            const span = trace.getSpan(context.active());
            if (span) {
              const sanitizedHeaders = EnvironmentResolver.sanitizeHeaders(resolvedHeaders);
              captureProviderCall(
                span,
                "http",
                {
                  url,
                  method,
                  headers: sanitizedHeaders,
                  body: JSON.stringify(payload).substring(0, 500)
                },
                {
                  content: JSON.stringify(response).substring(0, 500)
                }
              );
              const outputForSpan = finalResult.output ?? finalResult;
              captureCheckOutput(span, outputForSpan);
            }
          } catch {
          }
          return finalResult;
        } catch (error) {
          return this.createErrorResult(url, error);
        }
      }
      async sendWebhookRequest(url, method, headers, payload, timeout) {
        if (typeof fetch === "undefined") {
          throw new Error("Webhook provider requires Node.js 18+ or node-fetch package");
        }
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        try {
          const response = await fetch(url, {
            method,
            headers: {
              "Content-Type": "application/json",
              ...headers
            },
            body: JSON.stringify(payload),
            signal: controller.signal
          });
          clearTimeout(timeoutId);
          if (!response.ok) {
            throw new Error(`Webhook returned ${response.status}: ${response.statusText}`);
          }
          return await response.json();
        } catch (error) {
          clearTimeout(timeoutId);
          if (error instanceof Error && error.name === "AbortError") {
            throw new Error(`Webhook request timed out after ${timeout}ms`);
          }
          throw error;
        }
      }
      parseWebhookResponse(response, url) {
        if (!response || typeof response !== "object") {
          return this.createErrorResult(url, new Error("Invalid webhook response format"));
        }
        const issues = Array.isArray(response.comments) ? response.comments.map((c) => ({
          file: c.file || "unknown",
          line: c.line || 0,
          endLine: c.endLine,
          ruleId: c.ruleId || `webhook/${this.validateCategory(c.category)}`,
          message: c.message || "",
          severity: this.validateSeverity(c.severity),
          category: this.validateCategory(c.category),
          suggestion: c.suggestion,
          replacement: c.replacement
        })) : [];
        return {
          issues
        };
      }
      createErrorResult(url, error) {
        const errorMessage = error instanceof Error ? error.message : "Unknown error";
        return {
          issues: [
            {
              file: "webhook",
              line: 0,
              endLine: void 0,
              ruleId: "webhook/error",
              message: `Webhook execution error: ${errorMessage}`,
              severity: "error",
              category: "logic",
              suggestion: void 0,
              replacement: void 0
            }
          ]
        };
      }
      validateSeverity(severity) {
        const valid = ["info", "warning", "error", "critical"];
        return valid.includes(severity) ? severity : "info";
      }
      validateCategory(category) {
        const valid = ["security", "performance", "style", "logic", "documentation"];
        return valid.includes(category) ? category : "logic";
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "url",
          "body",
          "method",
          "headers",
          "timeout",
          "metadata",
          "depends_on",
          "on",
          "if",
          "group",
          "schedule"
        ];
      }
      async isAvailable() {
        return typeof fetch !== "undefined";
      }
      getRequirements() {
        return [
          "Valid HTTP URL",
          "Body template (Liquid) for payload construction",
          "Network access to HTTP endpoint",
          "Optional: Dependencies for accessing their outputs in templates"
        ];
      }
    };
  }
});

// src/providers/http-input-provider.ts
var HttpInputProvider;
var init_http_input_provider = __esm({
  "src/providers/http-input-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_liquid_extensions();
    init_logger();
    HttpInputProvider = class extends CheckProvider {
      liquid;
      webhookContext;
      constructor() {
        super();
        this.liquid = createExtendedLiquid();
      }
      /**
       * Set webhook context for accessing webhook data
       */
      setWebhookContext(webhookContext) {
        this.webhookContext = webhookContext;
      }
      getName() {
        return "http_input";
      }
      getDescription() {
        return "Receive and process HTTP webhook input data for use by dependent checks";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "http_input") {
          return false;
        }
        if (typeof cfg.endpoint !== "string" || !cfg.endpoint) {
          return false;
        }
        if (cfg.transform !== void 0 && typeof cfg.transform !== "string") {
          return false;
        }
        return true;
      }
      async execute(prInfo, config, _dependencyResults, _sessionInfo) {
        const endpoint = config.endpoint;
        const transform = config.transform;
        const webhookData = this.getWebhookData(endpoint);
        if (!webhookData) {
          return {
            issues: []
          };
        }
        let processedData = webhookData;
        if (transform) {
          try {
            const templateContext = {
              webhook: webhookData,
              pr: {
                number: prInfo.number,
                title: prInfo.title,
                author: prInfo.author,
                base: prInfo.base,
                head: prInfo.head
              }
            };
            const rendered = await this.liquid.parseAndRender(transform, templateContext);
            processedData = JSON.parse(rendered);
            logger.verbose(`\u2713 Applied webhook transform successfully`);
          } catch (error) {
            logger.error(
              `\u2717 Failed to transform webhook data: ${error instanceof Error ? error.message : "Unknown error"}`
            );
            return {
              issues: [
                {
                  file: "webhook_input",
                  line: 0,
                  ruleId: "webhook_input/transform_error",
                  message: `Failed to transform webhook data: ${error instanceof Error ? error.message : "Unknown error"}`,
                  severity: "error",
                  category: "logic"
                }
              ]
            };
          }
        }
        return {
          issues: [],
          // Add custom data field that will be passed through
          data: processedData
        };
      }
      getWebhookData(endpoint) {
        if (this.webhookContext) {
          return this.webhookContext.get(endpoint) || null;
        }
        const globalWebhookStore = global.__visor_webhook_data;
        if (globalWebhookStore && globalWebhookStore.get) {
          console.warn(
            "HttpInputProvider: Using deprecated global webhook store. Please use webhook context instead."
          );
          return globalWebhookStore.get(endpoint) || null;
        }
        return null;
      }
      getSupportedConfigKeys() {
        return ["type", "endpoint", "transform", "on", "depends_on", "if", "group"];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "HTTP server must be configured and running",
          "Valid endpoint path specified",
          "Optional: Transform template for data processing"
        ];
      }
    };
  }
});

// src/utils/template-context.ts
function prCacheKey(pr) {
  let sum = 0;
  for (const f of pr.files) sum += (f.additions || 0) + (f.deletions || 0) + (f.changes || 0);
  return [pr.number, pr.title, pr.author, pr.base, pr.head, pr.files.length, sum].join("|");
}
function buildProviderTemplateContext(prInfo, dependencyResults, memoryStore, outputHistory, stageHistoryBase, opts = {
  attachMemoryReadHelpers: true
}) {
  const context2 = {};
  const key = prCacheKey(prInfo);
  let prObj = prCache.get(key);
  if (!prObj) {
    prObj = {
      number: prInfo.number,
      title: prInfo.title,
      body: prInfo.body,
      author: prInfo.author,
      base: prInfo.base,
      head: prInfo.head,
      totalAdditions: prInfo.totalAdditions,
      totalDeletions: prInfo.totalDeletions,
      files: prInfo.files.map((f) => ({
        filename: f.filename,
        status: f.status,
        additions: f.additions,
        deletions: f.deletions,
        changes: f.changes
      }))
    };
    prCache.set(key, prObj);
    if (prCache.size > PR_CACHE_LIMIT) {
      const first = prCache.keys().next();
      if (!first.done) prCache.delete(first.value);
    }
  }
  context2.pr = prObj;
  const outputs = {};
  const outputsRaw = {};
  const history = {};
  if (dependencyResults) {
    for (const [checkName, result] of dependencyResults.entries()) {
      if (typeof checkName !== "string") continue;
      const summary = result;
      if (checkName.endsWith("-raw")) {
        const name = checkName.slice(0, -4);
        outputsRaw[name] = summary.output !== void 0 ? summary.output : summary;
      } else {
        const extracted = summary.output !== void 0 ? summary.output : summary;
        outputs[checkName] = extracted;
      }
    }
  }
  if (outputHistory) {
    for (const [checkName, historyArray] of outputHistory) {
      const arr = Array.isArray(historyArray) ? historyArray : [];
      const filtered = arr.filter((v) => {
        try {
          if (!v || typeof v !== "object") return true;
          const obj = v;
          if (Array.isArray(obj.forEachItems)) return false;
          if (obj.isForEach === true && obj.forEachItems !== void 0)
            return false;
        } catch {
        }
        return true;
      });
      history[checkName] = filtered;
    }
  }
  const historyStage = {};
  try {
    if (outputHistory && stageHistoryBase) {
      for (const [checkName, historyArray] of outputHistory) {
        const start = stageHistoryBase[checkName] || 0;
        const arr = Array.isArray(historyArray) ? historyArray : [];
        historyStage[checkName] = arr.slice(start);
      }
    }
  } catch {
  }
  outputs.history = history;
  context2.outputs = outputs;
  context2.outputs_history = history;
  context2.outputs_history_stage = historyStage;
  context2.outputs_raw = outputsRaw;
  if (opts.attachMemoryReadHelpers && memoryStore) {
    context2.memory = {
      get: (key2, ns) => memoryStore.get(key2, ns),
      has: (key2, ns) => memoryStore.has(key2, ns),
      list: (ns) => memoryStore.list(ns),
      getAll: (ns) => memoryStore.getAll(ns)
    };
  }
  if (opts.args) {
    context2.args = opts.args;
  }
  return context2;
}
var PR_CACHE_LIMIT, prCache;
var init_template_context = __esm({
  "src/utils/template-context.ts"() {
    "use strict";
    PR_CACHE_LIMIT = 16;
    prCache = /* @__PURE__ */ new Map();
  }
});

// src/providers/http-client-provider.ts
var fs11, path12, HttpClientProvider;
var init_http_client_provider = __esm({
  "src/providers/http-client-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_liquid_extensions();
    init_env_resolver();
    init_sandbox();
    init_template_context();
    init_logger();
    fs11 = __toESM(require("fs"));
    path12 = __toESM(require("path"));
    HttpClientProvider = class extends CheckProvider {
      liquid;
      sandbox;
      constructor() {
        super();
        this.liquid = createExtendedLiquid();
      }
      createSecureSandbox() {
        return createSecureSandbox();
      }
      getName() {
        return "http_client";
      }
      getDescription() {
        return "Fetch data from HTTP endpoints for use by dependent checks";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "http_client") {
          return false;
        }
        if (typeof cfg.url !== "string" || !cfg.url) {
          return false;
        }
        try {
          new URL(cfg.url);
          return true;
        } catch {
          return false;
        }
      }
      async execute(prInfo, config, dependencyResults, context2) {
        const url = config.url;
        const method = config.method || "GET";
        const headers = config.headers || {};
        const timeout = config.timeout || 3e4;
        const transform = config.transform;
        const transformJs = config.transform_js;
        const bodyTemplate = config.body;
        const outputFileTemplate = config.output_file;
        const skipIfExists = config.skip_if_exists !== false;
        let resolvedUrlForErrors = url;
        try {
          const templateContext = buildProviderTemplateContext(
            prInfo,
            dependencyResults,
            void 0,
            // memoryStore
            void 0,
            // outputHistory
            void 0,
            // stageHistoryBase
            { attachMemoryReadHelpers: false }
          );
          templateContext.env = process.env;
          let renderedUrl = String(EnvironmentResolver.resolveValue(url));
          resolvedUrlForErrors = renderedUrl;
          if (renderedUrl.includes("{{") || renderedUrl.includes("{%")) {
            renderedUrl = await this.liquid.parseAndRender(renderedUrl, templateContext);
            resolvedUrlForErrors = renderedUrl;
          }
          let requestBody;
          if (bodyTemplate) {
            let resolvedBody = String(EnvironmentResolver.resolveValue(bodyTemplate));
            if (resolvedBody.includes("{{") || resolvedBody.includes("{%")) {
              resolvedBody = await this.liquid.parseAndRender(resolvedBody, templateContext);
            }
            requestBody = resolvedBody;
          }
          const resolvedHeaders = {};
          for (const [key, value] of Object.entries(headers)) {
            let resolvedValue = String(EnvironmentResolver.resolveValue(value));
            if (resolvedValue.includes("{{") || resolvedValue.includes("{%")) {
              resolvedValue = await this.liquid.parseAndRender(resolvedValue, templateContext);
            }
            resolvedHeaders[key] = resolvedValue;
            if (key.toLowerCase() === "authorization") {
              const maskedValue = resolvedValue.length > 20 ? `${resolvedValue.substring(0, 15)}...${resolvedValue.substring(resolvedValue.length - 5)}` : resolvedValue;
              logger.verbose(`[http_client] ${key}: ${maskedValue}`);
            }
          }
          let resolvedOutputFile;
          if (outputFileTemplate) {
            let outputPath = String(EnvironmentResolver.resolveValue(outputFileTemplate));
            if (outputPath.includes("{{") || outputPath.includes("{%")) {
              outputPath = await this.liquid.parseAndRender(outputPath, templateContext);
            }
            resolvedOutputFile = outputPath.trim();
            const parentContext = context2?._parentContext;
            const workingDirectory = parentContext?.workingDirectory;
            const workspaceEnabled = parentContext?.workspace?.isEnabled?.();
            if (workspaceEnabled && workingDirectory && !path12.isAbsolute(resolvedOutputFile)) {
              resolvedOutputFile = path12.join(workingDirectory, resolvedOutputFile);
              logger.debug(
                `[http_client] Resolved relative output_file to workspace: ${resolvedOutputFile}`
              );
            }
            if (skipIfExists && fs11.existsSync(resolvedOutputFile)) {
              const stats = fs11.statSync(resolvedOutputFile);
              logger.verbose(`[http_client] File cached: ${resolvedOutputFile} (${stats.size} bytes)`);
              return {
                issues: [],
                file_path: resolvedOutputFile,
                size: stats.size,
                cached: true
              };
            }
          }
          const stepName = config.checkName || "unknown";
          const mock = context2?.hooks?.mockForStep?.(String(stepName));
          if (mock !== void 0) {
            const mockObj = typeof mock === "object" && mock !== null ? mock : { data: mock };
            return {
              issues: [],
              ...mockObj
            };
          }
          logger.verbose(`[http_client] ${method} ${renderedUrl}`);
          if (requestBody) {
            logger.verbose(
              `[http_client] Body: ${requestBody.substring(0, 500)}${requestBody.length > 500 ? "..." : ""}`
            );
          }
          if (resolvedOutputFile) {
            const fileResult = await this.downloadToFile(
              renderedUrl,
              method,
              resolvedHeaders,
              requestBody,
              timeout,
              resolvedOutputFile
            );
            return fileResult;
          }
          const data = await this.fetchData(renderedUrl, method, resolvedHeaders, requestBody, timeout);
          let processedData = data;
          if (transform) {
            try {
              const transformContext = {
                response: data,
                pr: templateContext.pr,
                outputs: templateContext.outputs
              };
              const rendered = await this.liquid.parseAndRender(transform, transformContext);
              if (rendered.trim().startsWith("{") || rendered.trim().startsWith("[")) {
                processedData = JSON.parse(rendered);
              } else {
                processedData = rendered;
              }
            } catch (error) {
              return {
                issues: [
                  {
                    file: "http_client",
                    line: 0,
                    ruleId: "http_client/transform_error",
                    message: `Failed to transform response data: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          if (transformJs) {
            try {
              if (!this.sandbox) {
                this.sandbox = this.createSecureSandbox();
              }
              const jsScope = {
                output: data,
                pr: templateContext.pr,
                outputs: templateContext.outputs,
                env: process.env
              };
              const result = compileAndRun(this.sandbox, transformJs, jsScope, {
                injectLog: true,
                logPrefix: "\u{1F50D} [transform_js]",
                wrapFunction: true
              });
              processedData = result;
              logger.verbose(`\u2713 Applied JavaScript transform successfully`);
            } catch (error) {
              logger.error(
                `\u2717 Failed to apply JavaScript transform: ${error instanceof Error ? error.message : "Unknown error"}`
              );
              return {
                issues: [
                  {
                    file: "http_client",
                    line: 0,
                    ruleId: "http_client/transform_js_error",
                    message: `Failed to apply JavaScript transform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          return {
            issues: [],
            output: processedData
          };
        } catch (error) {
          return {
            issues: [
              {
                file: "http_client",
                line: 0,
                ruleId: "http_client/fetch_error",
                message: `Failed to fetch from ${resolvedUrlForErrors}: ${error instanceof Error ? error.message : "Unknown error"}`,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      async fetchData(url, method, headers, body, timeout = 3e4) {
        if (typeof fetch === "undefined") {
          throw new Error("HTTP client provider requires Node.js 18+ or node-fetch package");
        }
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        try {
          const requestOptions = {
            method,
            headers: {
              ...headers
            },
            signal: controller.signal
          };
          if (method !== "GET" && body) {
            requestOptions.body = body;
            if (!headers["Content-Type"] && !headers["content-type"]) {
              requestOptions.headers = {
                ...requestOptions.headers,
                "Content-Type": "application/json"
              };
            }
          }
          const response = await fetch(url, requestOptions);
          clearTimeout(timeoutId);
          logger.verbose(`[http_client] Response: ${response.status} ${response.statusText}`);
          if (!response.ok) {
            try {
              const errorBody = await response.text();
              logger.warn(`[http_client] Error body: ${errorBody.substring(0, 500)}`);
            } catch {
            }
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
          }
          const contentType = response.headers.get("content-type");
          if (contentType && contentType.includes("application/json")) {
            return await response.json();
          }
          const text = await response.text();
          if (text.trim().startsWith("{") || text.trim().startsWith("[")) {
            try {
              return JSON.parse(text);
            } catch {
              return text;
            }
          }
          return text;
        } catch (error) {
          clearTimeout(timeoutId);
          if (error instanceof Error && error.name === "AbortError") {
            throw new Error(`Request timed out after ${timeout}ms`);
          }
          throw error;
        }
      }
      async downloadToFile(url, method, headers, body, timeout, outputFile) {
        if (typeof fetch === "undefined") {
          throw new Error("HTTP client provider requires Node.js 18+ or node-fetch package");
        }
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        try {
          const requestOptions = {
            method,
            headers: { ...headers },
            signal: controller.signal
          };
          if (method !== "GET" && body) {
            requestOptions.body = body;
            if (!headers["Content-Type"] && !headers["content-type"]) {
              requestOptions.headers = {
                ...requestOptions.headers,
                "Content-Type": "application/json"
              };
            }
          }
          const response = await fetch(url, requestOptions);
          clearTimeout(timeoutId);
          if (!response.ok) {
            return {
              issues: [
                {
                  file: "http_client",
                  line: 0,
                  ruleId: "http_client/download_error",
                  message: `Failed to download file: HTTP ${response.status}: ${response.statusText}`,
                  severity: "error",
                  category: "logic"
                }
              ]
            };
          }
          const parentDir = path12.dirname(outputFile);
          if (parentDir && !fs11.existsSync(parentDir)) {
            fs11.mkdirSync(parentDir, { recursive: true });
          }
          const arrayBuffer = await response.arrayBuffer();
          const buffer = Buffer.from(arrayBuffer);
          fs11.writeFileSync(outputFile, buffer);
          const contentType = response.headers.get("content-type") || "application/octet-stream";
          logger.verbose(`[http_client] Downloaded: ${outputFile} (${buffer.length} bytes)`);
          return {
            issues: [],
            file_path: outputFile,
            size: buffer.length,
            content_type: contentType,
            cached: false
          };
        } catch (error) {
          clearTimeout(timeoutId);
          if (error instanceof Error && error.name === "AbortError") {
            return {
              issues: [
                {
                  file: "http_client",
                  line: 0,
                  ruleId: "http_client/download_timeout",
                  message: `Download timed out after ${timeout}ms`,
                  severity: "error",
                  category: "logic"
                }
              ]
            };
          }
          return {
            issues: [
              {
                file: "http_client",
                line: 0,
                ruleId: "http_client/download_error",
                message: `Failed to download file: ${error instanceof Error ? error.message : "Unknown error"}`,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "url",
          "method",
          "headers",
          "body",
          "transform",
          "transform_js",
          "timeout",
          "output_file",
          "skip_if_exists",
          "depends_on",
          "on",
          "if",
          "group",
          "schedule"
        ];
      }
      async isAvailable() {
        return typeof fetch !== "undefined";
      }
      getRequirements() {
        return [
          "Valid HTTP/HTTPS URL to fetch from",
          "Network access to the endpoint",
          "Optional: Transform template for processing response data",
          "Optional: Body template for POST/PUT requests",
          "Optional: output_file path to download response to a file",
          "Optional: skip_if_exists (default: true) to enable caching for file downloads"
        ];
      }
    };
  }
});

// src/providers/noop-check-provider.ts
var NoopCheckProvider;
var init_noop_check_provider = __esm({
  "src/providers/noop-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    NoopCheckProvider = class extends CheckProvider {
      getName() {
        return "noop";
      }
      getDescription() {
        return "No-operation provider for command orchestration and dependency triggering";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "noop") {
          return false;
        }
        return true;
      }
      async execute(_prInfo, _config, _dependencyResults, _sessionInfo) {
        return {
          issues: []
        };
      }
      getSupportedConfigKeys() {
        return ["type", "command", "depends_on", "on", "if", "group"];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "No external dependencies required",
          "Used for command orchestration and dependency triggering"
        ];
      }
    };
  }
});

// src/providers/log-check-provider.ts
var LogCheckProvider;
var init_log_check_provider = __esm({
  "src/providers/log-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_liquid_extensions();
    init_logger();
    LogCheckProvider = class extends CheckProvider {
      liquid;
      constructor() {
        super();
        this.liquid = createExtendedLiquid({
          strictVariables: false,
          strictFilters: false
        });
      }
      getName() {
        return "log";
      }
      getDescription() {
        return "Output debugging and logging information for troubleshooting check workflows";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "log") {
          return false;
        }
        if (!cfg.message || typeof cfg.message !== "string") {
          return false;
        }
        if (cfg.level && !["debug", "info", "warn", "error"].includes(cfg.level)) {
          return false;
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, context2) {
        const message = config.message;
        const level = config.level || "info";
        const includePrContext = config.include_pr_context !== false;
        const includeDependencies = config.include_dependencies !== false;
        const includeMetadata = config.include_metadata !== false;
        const templateContext = this.buildTemplateContext(
          prInfo,
          dependencyResults,
          includePrContext,
          includeDependencies,
          includeMetadata,
          config.__outputHistory,
          context2,
          config
        );
        const renderedMessage = await this.liquid.parseAndRender(message, templateContext);
        const logOutput = this.formatLogOutput(
          level,
          renderedMessage,
          templateContext,
          includePrContext,
          includeDependencies,
          includeMetadata
        );
        if (level === "error") logger.error(logOutput);
        else if (level === "warn") logger.warn(logOutput);
        else if (level === "debug") logger.debug(logOutput);
        else logger.info(logOutput);
        const summary = {
          issues: [],
          logOutput
        };
        if (config.group === "chat") {
          summary.output = { text: renderedMessage };
        }
        return summary;
      }
      buildTemplateContext(prInfo, dependencyResults, _includePrContext = true, _includeDependencies = true, includeMetadata = true, outputHistory, executionContext, config) {
        const context2 = {};
        context2.pr = {
          number: prInfo.number,
          title: prInfo.title,
          body: prInfo.body,
          author: prInfo.author,
          base: prInfo.base,
          head: prInfo.head,
          totalAdditions: prInfo.totalAdditions,
          totalDeletions: prInfo.totalDeletions,
          files: prInfo.files.map((f) => ({
            filename: f.filename,
            status: f.status,
            additions: f.additions,
            deletions: f.deletions,
            changes: f.changes
          }))
        };
        context2.filenames = prInfo.files.map((f) => f.filename);
        context2.fileCount = prInfo.files.length;
        if (dependencyResults) {
          const dependencies = {};
          const outputs = {};
          const outputsRaw = {};
          const history = {};
          context2.dependencyCount = dependencyResults.size;
          for (const [checkName, result] of dependencyResults.entries()) {
            if (typeof checkName !== "string") continue;
            dependencies[checkName] = {
              issueCount: result.issues?.length || 0,
              suggestionCount: 0,
              issues: result.issues || []
            };
            const summary = result;
            if (typeof checkName === "string" && checkName.endsWith("-raw")) {
              const name = checkName.slice(0, -4);
              outputsRaw[name] = summary.output !== void 0 ? summary.output : summary;
            } else {
              outputs[checkName] = summary.output !== void 0 ? summary.output : summary;
            }
          }
          if (outputHistory) {
            for (const [checkName, historyArray] of outputHistory) {
              history[checkName] = historyArray;
            }
          }
          outputs.history = history;
          context2.dependencies = dependencies;
          context2.outputs = outputs;
          context2.outputs_history = history;
          context2.outputs_raw = outputsRaw;
        }
        if (includeMetadata) {
          context2.metadata = {
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            executionTime: Date.now(),
            nodeVersion: process.version,
            platform: process.platform,
            workingDirectory: process.cwd()
          };
        }
        const workflowInputs = config?.workflowInputs || executionContext?.workflowInputs || {};
        logger.debug(
          `[LogProvider] Adding ${Object.keys(workflowInputs).length} workflow inputs to context`
        );
        context2.inputs = workflowInputs;
        return context2;
      }
      formatLogOutput(level, message, templateContext, includePrContext, includeDependencies, includeMetadata) {
        const sections = [];
        const levelEmoji = this.getLevelEmoji(level);
        sections.push(`${levelEmoji} **${level.toUpperCase()}**: ${message}`);
        if (includePrContext && templateContext.pr) {
          const pr = templateContext.pr;
          sections.push("");
          sections.push("### PR Context");
          sections.push(`- **PR #${pr.number}**: ${pr.title}`);
          sections.push(`- **Author**: ${pr.author}`);
          sections.push(`- **Base**: ${pr.base} \u2192 **Head**: ${pr.head}`);
          sections.push(`- **Changes**: +${pr.totalAdditions} -${pr.totalDeletions}`);
          sections.push(`- **Files Modified**: ${templateContext.fileCount}`);
        }
        if (includeDependencies && templateContext.dependencies) {
          const deps = templateContext.dependencies;
          sections.push("");
          sections.push("### Dependency Results");
          if (Object.keys(deps).length === 0) {
            sections.push("- No dependency results available");
          } else {
            for (const [checkName, result] of Object.entries(deps)) {
              sections.push(
                `- **${checkName}**: ${result.issueCount} issues, ${result.suggestionCount} suggestions`
              );
            }
          }
        }
        if (includeMetadata && templateContext.metadata) {
          const meta = templateContext.metadata;
          sections.push("");
          sections.push("### Execution Metadata");
          sections.push(`- **Timestamp**: ${meta.timestamp}`);
          sections.push(`- **Node Version**: ${meta.nodeVersion}`);
          sections.push(`- **Platform**: ${meta.platform}`);
          sections.push(`- **Working Directory**: ${meta.workingDirectory}`);
        }
        return sections.join("\n");
      }
      getLevelEmoji(level) {
        switch (level) {
          case "debug":
            return "\u{1F41B}";
          case "info":
            return "\u2139\uFE0F";
          case "warn":
            return "\u26A0\uFE0F";
          case "error":
            return "\u274C";
          default:
            return "\u2139\uFE0F";
        }
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "message",
          "level",
          "include_pr_context",
          "include_dependencies",
          "include_metadata",
          "group",
          "command",
          "depends_on",
          "on",
          "if"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "No external dependencies required",
          "Used for debugging and logging check execution flow"
        ];
      }
    };
  }
});

// src/test-runner/recorders/global-recorder.ts
var global_recorder_exports = {};
__export(global_recorder_exports, {
  getGlobalRecorder: () => getGlobalRecorder,
  setGlobalRecorder: () => setGlobalRecorder
});
function setGlobalRecorder(r) {
  __rec = r;
}
function getGlobalRecorder() {
  return __rec;
}
var __rec;
var init_global_recorder = __esm({
  "src/test-runner/recorders/global-recorder.ts"() {
    "use strict";
    __rec = null;
  }
});

// src/providers/github-ops-provider.ts
var GitHubOpsProvider;
var init_github_ops_provider = __esm({
  "src/providers/github-ops-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_sandbox();
    init_liquid_extensions();
    init_logger();
    GitHubOpsProvider = class extends CheckProvider {
      sandbox;
      getName() {
        return "github";
      }
      getDescription() {
        return "Native GitHub operations (labels, comments, reviewers) executed via Octokit";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") return false;
        const cfg = config;
        return typeof cfg.op === "string" && cfg.op.length > 0;
      }
      getSupportedConfigKeys() {
        return ["op", "values", "value"];
      }
      async isAvailable() {
        return Boolean(
          process.env.GITHUB_TOKEN || process.env["INPUT_GITHUB-TOKEN"] || process.env.GITHUB_REPOSITORY
        );
      }
      getRequirements() {
        return ["GITHUB_TOKEN or INPUT_GITHUB-TOKEN", "GITHUB_REPOSITORY"];
      }
      async execute(prInfo, config, dependencyResults) {
        const cfg = config;
        let octokit = config.eventContext?.octokit;
        if (process.env.VISOR_DEBUG === "true") {
          try {
            logger.debug(`[github-ops] pre-fallback octokit? ${!!octokit}`);
          } catch {
          }
        }
        if (!octokit) {
          try {
            const { getGlobalRecorder: getGlobalRecorder2 } = (init_global_recorder(), __toCommonJS(global_recorder_exports));
            const rec = getGlobalRecorder2 && getGlobalRecorder2();
            if (rec) octokit = rec;
          } catch {
          }
        }
        if (!octokit) {
          if (process.env.VISOR_DEBUG === "true") {
            try {
              console.error("[github-ops] missing octokit after fallback \u2014 returning issue");
            } catch {
            }
          }
          return {
            issues: [
              {
                file: "system",
                line: 0,
                ruleId: "github/missing_octokit",
                message: "No authenticated Octokit instance available in event context. GitHub operations require proper authentication context.",
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
        const repoEnv = process.env.GITHUB_REPOSITORY || "";
        let owner = "";
        let repo = "";
        if (repoEnv.includes("/")) {
          [owner, repo] = repoEnv.split("/");
        } else {
          try {
            const ec = config.eventContext || {};
            owner = ec?.repository?.owner?.login || owner;
            repo = ec?.repository?.name || repo;
          } catch {
          }
        }
        try {
          if (process.env.VISOR_DEBUG === "true") {
            logger.info(
              `[github-ops] context octokit? ${!!octokit} repo=${owner}/${repo} pr#=${prInfo?.number}`
            );
          }
        } catch {
        }
        if (!owner || !repo || !prInfo?.number) {
          return {
            issues: [
              {
                file: "system",
                line: 0,
                ruleId: "github/missing_context",
                message: "Missing owner/repo or PR number; GitHub operations require Action context",
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
        let valuesRaw = [];
        if (Array.isArray(cfg.values)) valuesRaw = cfg.values.map((v) => String(v));
        else if (typeof cfg.values === "string") valuesRaw = [cfg.values];
        else if (typeof cfg.value === "string") valuesRaw = [cfg.value];
        try {
          if (process.env.VISOR_DEBUG === "true") {
            logger.info(`[github-ops] op=${cfg.op} valuesRaw(before)=${JSON.stringify(valuesRaw)}`);
          }
        } catch {
        }
        const renderValues = async (arr) => {
          if (!arr || arr.length === 0) return [];
          const liq = createExtendedLiquid({
            cache: false,
            strictFilters: false,
            strictVariables: false
          });
          const outputs = {};
          if (dependencyResults) {
            for (const [name, result] of dependencyResults.entries()) {
              const summary = result;
              outputs[name] = summary.output !== void 0 ? summary.output : summary;
            }
          }
          try {
            const hist = config.__outputHistory;
            if (hist) {
              for (const [name, arr2] of hist.entries()) {
                if (!outputs[name] && Array.isArray(arr2) && arr2.length > 0) {
                  outputs[name] = arr2[arr2.length - 1];
                }
              }
            }
          } catch {
          }
          const ctx = {
            pr: {
              number: prInfo.number,
              title: prInfo.title,
              author: prInfo.author,
              branch: prInfo.head,
              base: prInfo.base,
              authorAssociation: prInfo.authorAssociation
            },
            outputs
          };
          try {
            if (process.env.VISOR_DEBUG === "true") {
              logger.info(`[github-ops] deps keys=${Object.keys(outputs).join(", ")}`);
              const ov = outputs["overview"];
              if (ov) {
                logger.info(`[github-ops] outputs.overview.keys=${Object.keys(ov).join(",")}`);
                if (ov.tags) {
                  logger.info(
                    `[github-ops] outputs.overview.tags keys=${Object.keys(ov.tags).join(",")}`
                  );
                  try {
                    logger.info(
                      `[github-ops] outputs.overview.tags['review-effort']=${String(ov.tags["review-effort"])}`
                    );
                  } catch {
                  }
                }
              }
            }
          } catch {
          }
          const out = [];
          for (const item of arr) {
            if (typeof item === "string" && (item.includes("{{") || item.includes("{%"))) {
              try {
                const rendered = await liq.parseAndRender(item, ctx);
                out.push(rendered);
              } catch (e) {
                const msg = e instanceof Error ? e.message : String(e);
                if (process.env.VISOR_DEBUG === "true") {
                  logger.warn(`[github-ops] liquid_render_error: ${msg}`);
                }
                return Promise.reject({
                  issues: [
                    {
                      file: "system",
                      line: 0,
                      ruleId: "github/liquid_render_error",
                      message: `Failed to render template: ${msg}`,
                      severity: "error",
                      category: "logic"
                    }
                  ]
                });
              }
            } else {
              out.push(String(item));
            }
          }
          return out;
        };
        let values = await renderValues(valuesRaw);
        try {
          const flattened = [];
          for (const v of values) {
            const t = String(v ?? "").trim();
            if (!t) continue;
            let expanded = false;
            if (t.startsWith("[") && t.endsWith("]")) {
              try {
                const arr = JSON.parse(t);
                if (Array.isArray(arr)) {
                  for (const x of arr) flattened.push(String(x ?? ""));
                  expanded = true;
                }
              } catch {
              }
            }
            if (expanded) continue;
            if (t.includes("\n")) {
              for (const line of t.split("\n")) {
                const s = line.trim();
                if (s) flattened.push(s);
              }
              expanded = true;
            }
            if (!expanded) flattened.push(t);
          }
          values = flattened;
        } catch {
        }
        const depOutputs = {};
        if (dependencyResults) {
          for (const [name, result] of dependencyResults.entries()) {
            const summary = result;
            depOutputs[name] = summary.output !== void 0 ? summary.output : summary;
          }
        }
        const sanitizeLabel2 = (s) => s.replace(/[^A-Za-z0-9:\/\- ]/g, "").replace(/\/{2,}/g, "/").trim();
        values = (Array.isArray(values) ? values : []).map((v) => String(v ?? "")).map(sanitizeLabel2).filter(Boolean);
        if (values.length === 0 && Object.keys(depOutputs).length > 0) {
          try {
            const lbls = [];
            for (const obj of Object.values(depOutputs)) {
              const labelsAny = obj?.labels;
              if (Array.isArray(labelsAny)) {
                for (const v of labelsAny) lbls.push(String(v ?? ""));
              }
            }
            const norm = lbls.map((s) => s.trim()).filter(Boolean).map((s) => s.replace(/[^A-Za-z0-9:\/\- ]/g, "").replace(/\/{2,}/g, "/"));
            values = Array.from(new Set(norm));
            if (process.env.VISOR_DEBUG === "true") {
              logger.info(`[github-ops] derived values from deps.labels: ${JSON.stringify(values)}`);
            }
          } catch {
          }
        }
        if (values.length === 0 && dependencyResults && dependencyResults.size > 0) {
          try {
            const derived = [];
            for (const result of dependencyResults.values()) {
              const out = result?.output ?? result;
              const tags = out?.["tags"];
              if (tags && typeof tags === "object") {
                const label = tags["label"];
                const effort = tags["review-effort"];
                if (label != null) derived.push(String(label));
                if (effort !== void 0 && effort !== null)
                  derived.push(`review/effort:${String(effort)}`);
              }
            }
            values = derived;
            if (process.env.VISOR_DEBUG === "true") {
              logger.info(`[github-ops] derived values from deps: ${JSON.stringify(values)}`);
            }
          } catch {
          }
        }
        values = Array.from(new Set(values));
        try {
          if (process.env.NODE_ENV === "test" || process.env.VISOR_DEBUG === "true") {
            logger.info(`[github-ops] ${cfg.op} resolved values: ${JSON.stringify(values)}`);
          }
        } catch {
        }
        try {
          switch (cfg.op) {
            case "labels.add": {
              if (values.length === 0) break;
              try {
                if (process.env.VISOR_OUTPUT_FORMAT !== "json")
                  logger.step(`[github-ops] labels.add -> ${JSON.stringify(values)}`);
              } catch {
              }
              await octokit.rest.issues.addLabels({
                owner,
                repo,
                issue_number: prInfo.number,
                labels: values
              });
              break;
            }
            case "labels.remove": {
              for (const l of values) {
                await octokit.rest.issues.removeLabel({
                  owner,
                  repo,
                  issue_number: prInfo.number,
                  name: l
                });
              }
              break;
            }
            case "comment.create": {
              const body = values.join("\n").trim();
              if (body)
                await octokit.rest.issues.createComment({
                  owner,
                  repo,
                  issue_number: prInfo.number,
                  body
                });
              break;
            }
            default:
              return {
                issues: [
                  {
                    file: "system",
                    line: 0,
                    ruleId: "github/unsupported_op",
                    message: `Unsupported GitHub op: ${cfg.op}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
          }
          return { issues: [] };
        } catch (e) {
          const msg = e instanceof Error ? e.message : String(e);
          try {
            logger.error(`[github-ops] op_failed ${cfg.op}: ${msg}`);
          } catch {
          }
          return {
            issues: [
              {
                file: "system",
                line: 0,
                ruleId: "github/op_failed",
                message: `GitHub operation failed (${cfg.op}): ${msg}`,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      /**
       * Create a secure sandbox for evaluating small expressions without access to process/env
       */
      getSecureSandbox() {
        if (this.sandbox) return this.sandbox;
        this.sandbox = createSecureSandbox();
        return this.sandbox;
      }
    };
  }
});

// src/providers/claude-code-types.ts
async function safeImport(moduleName) {
  try {
    return await import(moduleName);
  } catch {
    return null;
  }
}
var init_claude_code_types = __esm({
  "src/providers/claude-code-types.ts"() {
    "use strict";
  }
});

// src/providers/claude-code-check-provider.ts
function isClaudeCodeConstructor(value) {
  return typeof value === "function";
}
var import_promises4, import_path4, ClaudeCodeSDKNotInstalledError, ClaudeCodeAPIKeyMissingError, ClaudeCodeCheckProvider;
var init_claude_code_check_provider = __esm({
  "src/providers/claude-code-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_env_resolver();
    init_issue_filter();
    init_liquid_extensions();
    import_promises4 = __toESM(require("fs/promises"));
    import_path4 = __toESM(require("path"));
    init_claude_code_types();
    ClaudeCodeSDKNotInstalledError = class extends Error {
      constructor() {
        super(
          "Claude Code SDK is not installed. Install with: npm install @anthropic/claude-code-sdk @modelcontextprotocol/sdk"
        );
        this.name = "ClaudeCodeSDKNotInstalledError";
      }
    };
    ClaudeCodeAPIKeyMissingError = class extends Error {
      constructor() {
        super(
          "No API key found for Claude Code provider. Set CLAUDE_CODE_API_KEY or ANTHROPIC_API_KEY environment variable."
        );
        this.name = "ClaudeCodeAPIKeyMissingError";
      }
    };
    ClaudeCodeCheckProvider = class extends CheckProvider {
      liquidEngine;
      claudeCodeClient = null;
      constructor() {
        super();
        this.liquidEngine = createExtendedLiquid();
      }
      getName() {
        return "claude-code";
      }
      getDescription() {
        return "AI-powered code review using Claude Code with MCP tools support";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "claude-code") {
          return false;
        }
        if (!cfg.prompt || typeof cfg.prompt !== "string") {
          return false;
        }
        if (cfg.claude_code) {
          const claudeCodeConfig = cfg.claude_code;
          if (claudeCodeConfig.allowedTools && !Array.isArray(claudeCodeConfig.allowedTools)) {
            return false;
          }
          if (claudeCodeConfig.maxTurns && typeof claudeCodeConfig.maxTurns !== "number") {
            return false;
          }
          if (claudeCodeConfig.systemPrompt && typeof claudeCodeConfig.systemPrompt !== "string") {
            return false;
          }
          if (claudeCodeConfig.mcpServers) {
            if (typeof claudeCodeConfig.mcpServers !== "object") {
              return false;
            }
            for (const serverConfig of Object.values(claudeCodeConfig.mcpServers)) {
              if (!serverConfig.command || typeof serverConfig.command !== "string") {
                return false;
              }
              if (serverConfig.args && !Array.isArray(serverConfig.args)) {
                return false;
              }
            }
          }
        }
        return true;
      }
      /**
       * Initialize Claude Code SDK client
       */
      async initializeClaudeCodeClient() {
        if (this.claudeCodeClient) {
          return this.claudeCodeClient;
        }
        const claudeCodeModule = await safeImport("@anthropic/claude-code-sdk");
        if (!claudeCodeModule) {
          throw new ClaudeCodeSDKNotInstalledError();
        }
        const ClaudeCodeCtor = claudeCodeModule.ClaudeCode || claudeCodeModule.default?.ClaudeCode;
        if (!isClaudeCodeConstructor(ClaudeCodeCtor)) {
          throw new Error("ClaudeCode class not found in @anthropic/claude-code-sdk");
        }
        const apiKey = process.env.CLAUDE_CODE_API_KEY || process.env.ANTHROPIC_API_KEY;
        if (!apiKey) {
          throw new ClaudeCodeAPIKeyMissingError();
        }
        try {
          const client = new ClaudeCodeCtor({
            apiKey
          });
          this.claudeCodeClient = client;
          return client;
        } catch (error) {
          throw new Error(
            `Failed to initialize Claude Code SDK: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Group files by their file extension for template context
       */
      groupFilesByExtension(files) {
        const grouped = {};
        files.forEach((file) => {
          const parts = file.filename.split(".");
          const ext = parts.length > 1 ? parts.pop()?.toLowerCase() || "noext" : "noext";
          if (!grouped[ext]) {
            grouped[ext] = [];
          }
          grouped[ext].push(file);
        });
        return grouped;
      }
      /**
       * Process prompt configuration to resolve final prompt string
       */
      async processPrompt(promptConfig, prInfo, eventContext, dependencyResults) {
        let promptContent;
        if (await this.isFilePath(promptConfig)) {
          promptContent = await this.loadPromptFromFile(promptConfig);
        } else {
          promptContent = promptConfig;
        }
        return await this.renderPromptTemplate(promptContent, prInfo, eventContext, dependencyResults);
      }
      /**
       * Detect if a string is likely a file path and if the file exists
       */
      async isFilePath(str) {
        if (!str || str.trim() !== str || str.length > 512) {
          return false;
        }
        if (/\s{2,}/.test(str) || // Multiple consecutive spaces
        /\n/.test(str) || // Contains newlines
        /^(please|analyze|review|check|find|identify|look|search)/i.test(str.trim()) || // Starts with command words
        str.split(" ").length > 8) {
          return false;
        }
        if (!/[\/\\]/.test(str)) {
          if (/\b(the|and|or|but|for|with|by|from|in|on|at|as)\b/i.test(str)) {
            return false;
          }
        }
        const hasFileExtension = /\.[a-zA-Z0-9]{1,10}$/i.test(str);
        const hasPathSeparators = /[\/\\]/.test(str);
        const isRelativePath = /^\.{1,2}\//.test(str);
        const isAbsolutePath = import_path4.default.isAbsolute(str);
        const hasTypicalFileChars = /^[a-zA-Z0-9._\-\/\\:~]+$/.test(str);
        if (!(hasFileExtension || isRelativePath || isAbsolutePath || hasPathSeparators)) {
          return false;
        }
        if (!hasTypicalFileChars) {
          return false;
        }
        try {
          let resolvedPath;
          if (import_path4.default.isAbsolute(str)) {
            resolvedPath = import_path4.default.normalize(str);
          } else {
            resolvedPath = import_path4.default.resolve(process.cwd(), str);
          }
          try {
            const stat = await import_promises4.default.stat(resolvedPath);
            return stat.isFile();
          } catch {
            return hasFileExtension && (isRelativePath || isAbsolutePath || hasPathSeparators);
          }
        } catch {
          return false;
        }
      }
      /**
       * Load prompt content from file with security validation
       */
      async loadPromptFromFile(promptPath) {
        if (!promptPath.endsWith(".liquid")) {
          throw new Error("Prompt file must have .liquid extension");
        }
        let resolvedPath;
        if (import_path4.default.isAbsolute(promptPath)) {
          resolvedPath = promptPath;
        } else {
          resolvedPath = import_path4.default.resolve(process.cwd(), promptPath);
        }
        if (!import_path4.default.isAbsolute(promptPath)) {
          const normalizedPath = import_path4.default.normalize(resolvedPath);
          const currentDir = import_path4.default.resolve(process.cwd());
          if (!normalizedPath.startsWith(currentDir)) {
            throw new Error("Invalid prompt file path: path traversal detected");
          }
        }
        if (promptPath.includes("../..")) {
          throw new Error("Invalid prompt file path: path traversal detected");
        }
        try {
          const promptContent = await import_promises4.default.readFile(resolvedPath, "utf-8");
          return promptContent;
        } catch (error) {
          throw new Error(
            `Failed to load prompt from ${resolvedPath}: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Render Liquid template in prompt with comprehensive context
       */
      async renderPromptTemplate(promptContent, prInfo, eventContext, dependencyResults) {
        const templateContext = {
          // PR Information
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            body: prInfo.body,
            author: prInfo.author,
            baseBranch: prInfo.base,
            headBranch: prInfo.head,
            isIncremental: prInfo.isIncremental,
            filesChanged: prInfo.files?.map((f) => f.filename) || [],
            totalAdditions: prInfo.files?.reduce((sum, f) => sum + f.additions, 0) || 0,
            totalDeletions: prInfo.files?.reduce((sum, f) => sum + f.deletions, 0) || 0,
            totalChanges: prInfo.files?.reduce((sum, f) => sum + f.changes, 0) || 0,
            base: prInfo.base,
            head: prInfo.head
          },
          // File Details
          files: prInfo.files || [],
          description: prInfo.body || "",
          // GitHub Event Context
          event: eventContext ? {
            name: eventContext.event_name || "unknown",
            action: eventContext.action,
            isPullRequest: !prInfo.isIssue,
            // Repository Info
            repository: eventContext.repository ? {
              owner: eventContext.repository?.owner?.login,
              name: eventContext.repository?.name,
              fullName: eventContext.repository ? `${eventContext.repository?.owner?.login}/${eventContext.repository?.name}` : void 0
            } : void 0,
            // Comment Data (for comment events)
            comment: eventContext.comment ? {
              body: eventContext.comment?.body,
              author: eventContext.comment?.user?.login
            } : void 0,
            // Raw event payload for advanced use cases
            payload: eventContext
          } : void 0,
          // Utility data for templates
          utils: {
            // Date/time helpers
            now: (/* @__PURE__ */ new Date()).toISOString(),
            today: (/* @__PURE__ */ new Date()).toISOString().split("T")[0],
            // Dynamic file grouping by extension
            filesByExtension: this.groupFilesByExtension(prInfo.files || []),
            // File status categorizations
            addedFiles: (prInfo.files || []).filter((f) => f.status === "added"),
            modifiedFiles: (prInfo.files || []).filter((f) => f.status === "modified"),
            removedFiles: (prInfo.files || []).filter((f) => f.status === "removed"),
            renamedFiles: (prInfo.files || []).filter((f) => f.status === "renamed"),
            // Change analysis
            hasLargeChanges: (prInfo.files || []).some((f) => f.changes > 50),
            totalFiles: (prInfo.files || []).length
          },
          // Previous check outputs (dependency results)
          // Expose raw output directly if available, otherwise expose the result as-is
          outputs: dependencyResults ? Object.fromEntries(
            Array.from(dependencyResults.entries()).map(([checkName, result]) => [
              checkName,
              // If the result has a direct output field, use it directly
              // Otherwise, expose the entire result
              (() => {
                const summary = result;
                return summary.output !== void 0 ? summary.output : summary;
              })()
            ])
          ) : {}
        };
        try {
          return await this.liquidEngine.parseAndRender(promptContent, templateContext);
        } catch (error) {
          throw new Error(
            `Failed to render prompt template: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Parse structured response from Claude Code
       */
      parseStructuredResponse(content) {
        try {
          const parsed = JSON.parse(content);
          return {
            issues: parsed.issues || []
          };
        } catch {
          return {
            issues: []
          };
        }
      }
      async execute(prInfo, config, dependencyResults, sessionInfo) {
        if (config.env) {
          const result = EnvironmentResolver.withTemporaryEnv(config.env, () => {
            return this.executeWithConfig(prInfo, config, dependencyResults, sessionInfo);
          });
          if (result instanceof Promise) {
            return result;
          }
          return result;
        }
        return this.executeWithConfig(prInfo, config, dependencyResults, sessionInfo);
      }
      async executeWithConfig(prInfo, config, dependencyResults, sessionInfo) {
        try {
          const stepName = config.checkName || "claude-code";
          const mock = sessionInfo?.hooks?.mockForStep?.(String(stepName));
          if (mock !== void 0) {
            if (mock && typeof mock === "object" && "issues" in mock) {
              return mock;
            }
            return { issues: [], output: mock };
          }
        } catch {
        }
        const claudeCodeConfig = config.claude_code || {};
        const customPrompt = config.prompt;
        if (!customPrompt) {
          throw new Error(
            `No prompt defined for check. All checks must have prompts defined in .visor.yaml configuration.`
          );
        }
        const processedPrompt = await this.processPrompt(
          customPrompt,
          prInfo,
          config.eventContext,
          dependencyResults
        );
        const startTime = Date.now();
        try {
          const client = await this.initializeClaudeCodeClient();
          const query = {
            query: processedPrompt,
            maxTurns: claudeCodeConfig.maxTurns || 5,
            systemPrompt: claudeCodeConfig.systemPrompt,
            subagent: claudeCodeConfig.subagent
          };
          if (claudeCodeConfig.allowedTools && claudeCodeConfig.allowedTools.length > 0) {
            query.tools = claudeCodeConfig.allowedTools.map((name) => ({ name }));
          }
          if (claudeCodeConfig.mcpServers && Object.keys(claudeCodeConfig.mcpServers).length > 0) {
            query.mcpServers = claudeCodeConfig.mcpServers;
          }
          let response;
          if (sessionInfo?.reuseSession && sessionInfo.parentSessionId) {
            response = await client.query({
              ...query,
              sessionId: sessionInfo.parentSessionId
            });
          } else {
            response = await client.query(query);
          }
          const result = this.parseStructuredResponse(response.content);
          result.debug = {
            prompt: processedPrompt,
            rawResponse: response.content,
            provider: "claude-code",
            model: "claude-code",
            apiKeySource: "CLAUDE_CODE_API_KEY",
            processingTime: Date.now() - startTime,
            promptLength: processedPrompt.length,
            responseLength: response.content.length,
            jsonParseSuccess: true,
            errors: [],
            checksExecuted: [config.checkName || "claude-code-check"],
            parallelExecution: false,
            timestamp: (/* @__PURE__ */ new Date()).toISOString(),
            // Claude Code specific debug info
            sessionId: response.session_id,
            turnCount: response.turn_count,
            usage: response.usage
          };
          const suppressionEnabled = config.suppressionEnabled !== false;
          const issueFilter = new IssueFilter(suppressionEnabled);
          const filteredIssues = issueFilter.filterIssues(result.issues || [], process.cwd());
          return {
            ...result,
            issues: filteredIssues
          };
        } catch (error) {
          if (error instanceof ClaudeCodeSDKNotInstalledError || error instanceof ClaudeCodeAPIKeyMissingError) {
            throw error;
          }
          const errorMessage = error instanceof Error ? error.message : String(error);
          console.error(`\u274C Claude Code Check Provider Error: ${errorMessage}`);
          const isCriticalError = errorMessage.includes("API rate limit") || errorMessage.includes("403") || errorMessage.includes("401") || errorMessage.includes("authentication");
          if (isCriticalError) {
            console.error(
              `\u{1F6A8} CRITICAL ERROR: Claude Code provider authentication or setup issue detected`
            );
            console.error(
              `\u{1F6A8} This check cannot proceed without valid API credentials and SDK installation`
            );
          }
          throw new Error(`Claude Code analysis failed: ${errorMessage}`);
        }
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "prompt",
          "claude_code.allowedTools",
          "claude_code.maxTurns",
          "claude_code.systemPrompt",
          "claude_code.mcpServers",
          "claude_code.subagent",
          "claude_code.hooks",
          "env",
          "checkName",
          "sessionId",
          "suppressionEnabled"
        ];
      }
      async isAvailable() {
        try {
          const hasApiKey = !!(process.env.CLAUDE_CODE_API_KEY || process.env.ANTHROPIC_API_KEY);
          if (!hasApiKey) {
            return false;
          }
          const claudeCodeModule = await safeImport("@anthropic/claude-code-sdk");
          if (!claudeCodeModule) {
            return false;
          }
          const ClaudeCode = claudeCodeModule.ClaudeCode || claudeCodeModule.default?.ClaudeCode;
          return !!ClaudeCode;
        } catch {
          return false;
        }
      }
      getRequirements() {
        return [
          "CLAUDE_CODE_API_KEY or ANTHROPIC_API_KEY environment variable",
          "@anthropic/claude-code-sdk npm package",
          "@modelcontextprotocol/sdk npm package (for MCP support)",
          "Network access to Claude Code API"
        ];
      }
    };
  }
});

// src/utils/env-exposure.ts
var env_exposure_exports = {};
__export(env_exposure_exports, {
  buildSandboxEnv: () => buildSandboxEnv
});
function buildSandboxEnv(input) {
  const denyDefaults = [
    "GITHUB_TOKEN",
    "INPUT_GITHUB-TOKEN",
    "ACTIONS_RUNTIME_TOKEN",
    "ACTIONS_ID_TOKEN_REQUEST_TOKEN",
    "AWS_ACCESS_KEY_ID",
    "AWS_SECRET_ACCESS_KEY",
    "AWS_SESSION_TOKEN",
    "AZURE_CLIENT_SECRET",
    "GOOGLE_APPLICATION_CREDENTIALS",
    "OPENAI_API_KEY",
    "ANTHROPIC_API_KEY",
    "HUGGINGFACE_API_KEY",
    "CLAUDE_CODE_API_KEY",
    "PROBE_API_KEY"
  ];
  const denyExtra = (input.VISOR_DENY_ENV || "").split(",").map((s) => s.trim()).filter(Boolean);
  const deny = Array.from(/* @__PURE__ */ new Set([...denyDefaults, ...denyExtra]));
  const allowSpec = (input.VISOR_ALLOW_ENV || "*").trim();
  const denyMatch = (key) => {
    for (const pat of deny) {
      if (!pat) continue;
      if (pat.endsWith("*")) {
        const prefix = pat.slice(0, -1);
        if (key.startsWith(prefix)) return true;
      } else if (key === pat) {
        return true;
      }
    }
    if (/(_TOKEN|_SECRET|_PASSWORD|_PRIVATE_KEY)$/i.test(key)) return true;
    return false;
  };
  const out = {};
  if (allowSpec !== "*") {
    const allow = allowSpec.split(",").map((s) => s.trim()).filter(Boolean);
    for (const key of allow) {
      const val = input[key];
      if (key && val !== void 0 && !denyMatch(key)) out[key] = String(val);
    }
    return out;
  }
  for (const [k, v] of Object.entries(input)) {
    if (v === void 0 || v === null) continue;
    if (denyMatch(k)) continue;
    out[k] = String(v);
  }
  return out;
}
var init_env_exposure = __esm({
  "src/utils/env-exposure.ts"() {
    "use strict";
  }
});

// src/providers/command-check-provider.ts
var CommandCheckProvider;
var init_command_check_provider = __esm({
  "src/providers/command-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_sandbox();
    init_liquid_extensions();
    init_logger();
    init_command_executor();
    init_author_permissions();
    init_lazy_otel();
    init_state_capture();
    CommandCheckProvider = class extends CheckProvider {
      liquid;
      sandbox;
      constructor() {
        super();
        this.liquid = createExtendedLiquid({
          cache: false,
          strictFilters: false,
          strictVariables: false
        });
      }
      createSecureSandbox() {
        return createSecureSandbox();
      }
      getName() {
        return "command";
      }
      getDescription() {
        return "Execute shell commands and capture output for processing";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (!cfg.exec || typeof cfg.exec !== "string") {
          return false;
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, context2) {
        try {
          logger.info(
            `  command provider: executing check=${String(config.checkName || config.type)} hasTransformJs=${Boolean(
              config.transform_js
            )}`
          );
        } catch {
        }
        const command = config.exec;
        const transform = config.transform;
        const transformJs = config.transform_js;
        const outputsObj = this.buildOutputContext(
          dependencyResults,
          config.__outputHistory
        );
        const outputsRaw = {};
        if (dependencyResults) {
          for (const [key, value] of dependencyResults.entries()) {
            if (typeof key !== "string") continue;
            if (key.endsWith("-raw")) {
              const name = key.slice(0, -4);
              const summary = value;
              outputsRaw[name] = summary.output !== void 0 ? summary.output : summary;
            }
          }
        }
        const templateContext = {
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            author: prInfo.author,
            branch: prInfo.head,
            base: prInfo.base
          },
          files: prInfo.files,
          fileCount: prInfo.files.length,
          outputs: outputsObj,
          // Alias: outputs_history mirrors outputs.history for consistency
          outputs_history: outputsObj.history || {},
          // Stage-scoped history slice based on baseline provided by runner
          outputs_history_stage: (() => {
            const stage = {};
            try {
              const base = context2?.stageHistoryBase;
              const histMap = config.__outputHistory;
              if (!base || !histMap) return stage;
              for (const [k, v] of histMap.entries()) {
                const start = base[k] || 0;
                const arr = Array.isArray(v) ? v : [];
                stage[k] = arr.slice(start);
              }
            } catch {
            }
            return stage;
          })(),
          // New: outputs_raw exposes aggregate values (e.g., full arrays for forEach parents)
          outputs_raw: outputsRaw,
          // Workflow inputs (when executing within a workflow)
          // Check config first (set by projectWorkflowToGraph), then fall back to context
          inputs: config.workflowInputs || context2?.workflowInputs || {},
          // Custom arguments from on_init 'with' directive
          args: context2?.args || {},
          env: this.getSafeEnvironmentVariables()
        };
        logger.debug(
          `\u{1F527} Debug: Template outputs keys: ${Object.keys(templateContext.outputs || {}).join(", ")}`
        );
        try {
          const span = trace.getSpan(context.active());
          if (span) {
            captureCheckInputContext(span, templateContext);
          }
        } catch {
        }
        try {
          const checkId = config.checkName || config.id || "unknown";
          const ctxJson = JSON.stringify(sanitizeContextForTelemetry(templateContext));
          const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
          emitNdjsonSpanWithEvents2(
            "visor.check",
            { "visor.check.id": checkId, "visor.check.input.context": ctxJson },
            [{ name: "check.started" }, { name: "check.completed" }]
          );
        } catch {
        }
        try {
          const stepName = config.checkName || "unknown";
          if (process.env.VISOR_DEBUG === "true") {
            logger.debug(
              `[Command] Mock check: stepName=${stepName}, context=${!!context2}, hooks=${!!context2?.hooks}, mockForStep=${!!context2?.hooks?.mockForStep}`
            );
          }
          const rawMock = context2?.hooks?.mockForStep?.(String(stepName));
          if (process.env.VISOR_DEBUG === "true") {
            logger.debug(
              `[Command] Mock result: ${rawMock !== void 0 ? "found" : "not found"}, value=${JSON.stringify(rawMock)?.slice(0, 200)}`
            );
          }
          if (rawMock !== void 0) {
            let mock;
            if (typeof rawMock === "number") {
              mock = { exit_code: Number(rawMock) };
            } else if (typeof rawMock === "string") {
              mock = { stdout: String(rawMock) };
            } else {
              mock = rawMock;
            }
            const m = mock;
            const isCommandMock = m.stdout !== void 0 || m.stderr !== void 0 || m.exit_code !== void 0 || m.exit !== void 0;
            let out;
            if (isCommandMock) {
              out = m.stdout ?? "";
              try {
                if (typeof out === "string" && (out.trim().startsWith("{") || out.trim().startsWith("["))) {
                  out = JSON.parse(out);
                }
              } catch {
              }
            } else {
              out = mock;
            }
            const code = isCommandMock ? typeof m.exit_code === "number" ? m.exit_code : typeof m.exit === "number" ? m.exit : 0 : 0;
            let outputWithMeta;
            if (isCommandMock) {
              if (out && typeof out === "object" && !Array.isArray(out)) {
                outputWithMeta = { ...out, exit_code: code };
              } else {
                outputWithMeta = { value: out, exit_code: code };
              }
            } else {
              outputWithMeta = out;
            }
            if (code !== 0) {
              return {
                issues: [
                  {
                    file: "command",
                    line: 0,
                    ruleId: "command/execution_error",
                    message: `Mocked command exited with code ${code}`,
                    severity: "error",
                    category: "logic"
                  }
                ],
                output: outputWithMeta
              };
            }
            return { issues: [], output: outputWithMeta };
          }
        } catch {
        }
        try {
          let renderedCommand = command;
          if (command.includes("{{") || command.includes("{%")) {
            renderedCommand = await this.renderCommandTemplate(command, templateContext);
          }
          logger.debug(`\u{1F527} Debug: Rendered command: ${renderedCommand}`);
          const scriptEnv = {};
          for (const [key, value] of Object.entries(process.env)) {
            if (value !== void 0) {
              scriptEnv[key] = value;
            }
          }
          if (config.env) {
            for (const [key, value] of Object.entries(config.env)) {
              if (value !== void 0 && value !== null) {
                scriptEnv[key] = String(value);
              }
            }
          }
          const timeoutMs = config.timeout || 6e4;
          const normalizeNodeEval = (cmd) => {
            const re = /^(?<prefix>\s*(?:\/usr\/bin\/env\s+)?node(?:\.exe)?\s+(?:-e|--eval)\s+)(['"])([\s\S]*?)\2(?<suffix>\s|$)/;
            const m = cmd.match(re);
            if (!m || !m.groups) return cmd;
            const prefix = m.groups.prefix;
            const quote = m[2];
            const code = m[3];
            const suffix = m.groups.suffix || "";
            if (!code.includes("\n")) return cmd;
            const escaped = code.replace(/\n/g, "\\n");
            return cmd.replace(re, `${prefix}${quote}${escaped}${quote}${suffix}`);
          };
          const safeCommand = normalizeNodeEval(renderedCommand);
          const parentContext = context2?._parentContext;
          const workingDirectory = parentContext?.workingDirectory;
          const workspaceEnabled = parentContext?.workspace?.isEnabled?.();
          const cwd = workspaceEnabled && workingDirectory ? workingDirectory : void 0;
          if (cwd) {
            logger.debug(`[command] Using workspace working directory: ${cwd}`);
          }
          const execResult = await commandExecutor.execute(safeCommand, {
            env: scriptEnv,
            timeout: timeoutMs,
            cwd
          });
          const { stdout, stderr, exitCode } = execResult;
          if (stderr) {
            logger.debug(`Command stderr: ${stderr}`);
          }
          if (exitCode !== 0) {
            const errorMessage = stderr || `Command exited with code ${exitCode}`;
            logger.error(`Command failed with exit code ${exitCode}: ${errorMessage}`);
            return {
              issues: [
                {
                  file: "command",
                  line: 0,
                  ruleId: "command/execution_error",
                  message: `Command execution failed: ${errorMessage}`,
                  severity: "error",
                  category: "logic"
                }
              ]
            };
          }
          const rawOutput = stdout.trim();
          let output = rawOutput;
          try {
            const parsed = JSON.parse(rawOutput);
            output = parsed;
            logger.debug(`\u{1F527} Debug: Parsed entire output as JSON successfully`);
          } catch {
            const extractedTail = this.extractJsonFromEnd(rawOutput);
            if (extractedTail) {
              try {
                output = JSON.parse(extractedTail);
              } catch {
                output = rawOutput;
              }
            } else {
              const extractedAny = this.extractJsonAnywhere(rawOutput);
              if (extractedAny) {
                try {
                  output = JSON.parse(extractedAny);
                } catch {
                  output = rawOutput;
                }
              } else {
                const m = /\berror\b\s*[:=]\s*(true|false)/i.exec(rawOutput);
                if (m) {
                  output = { error: m[1].toLowerCase() === "true" };
                } else {
                  output = rawOutput;
                }
              }
            }
          }
          let finalOutput = output;
          if (transform) {
            try {
              const transformContext = {
                ...templateContext,
                output
                // Use parsed output for Liquid (object if JSON, string otherwise)
              };
              const rendered = await this.liquid.parseAndRender(transform, transformContext);
              try {
                finalOutput = JSON.parse(rendered.trim());
                logger.verbose(`\u2713 Applied Liquid transform successfully (parsed as JSON)`);
              } catch {
                finalOutput = rendered.trim();
                logger.verbose(`\u2713 Applied Liquid transform successfully (string output)`);
              }
              try {
                const span = trace.getSpan(context.active());
                if (span) {
                  const { captureLiquidEvaluation: captureLiquidEvaluation2 } = (init_state_capture(), __toCommonJS(state_capture_exports));
                  captureLiquidEvaluation2(span, transform, transformContext, rendered);
                }
              } catch {
              }
            } catch (error) {
              logger.error(
                `\u2717 Failed to apply Liquid transform: ${error instanceof Error ? error.message : "Unknown error"}`
              );
              return {
                issues: [
                  {
                    file: "command",
                    line: 0,
                    ruleId: "command/transform_error",
                    message: `Failed to apply Liquid transform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          if (transformJs) {
            try {
              const jsContext = {
                output: this.makeJsonSmart(rawOutput),
                pr: templateContext.pr,
                files: templateContext.files,
                outputs: this.makeOutputsJsonSmart(templateContext.outputs),
                inputs: templateContext.inputs || {},
                env: templateContext.env,
                permissions: createPermissionHelpers(
                  resolveAssociationFromEvent(prInfo.eventContext, prInfo.authorAssociation),
                  detectLocalMode()
                )
              };
              const trimmedTransform = transformJs.trim();
              const buildBodyWithReturn = (raw) => {
                const t = raw.trim();
                const lines = t.split(/\n/);
                let i = lines.length - 1;
                while (i >= 0 && lines[i].trim().length === 0) i--;
                if (i < 0) return "return undefined;";
                const lastLine = lines[i].trim();
                if (/^return\b/i.test(lastLine)) {
                  return t;
                }
                const idx = t.lastIndexOf(lastLine);
                const head = idx >= 0 ? t.slice(0, idx) : "";
                const lastExpr = lastLine.replace(/;\s*$/, "");
                return `${head}
return (${lastExpr});`;
              };
              const bodyWithReturn = buildBodyWithReturn(trimmedTransform);
              const code = `
            const output = scope.output;
            const pr = scope.pr;
            const files = scope.files;
            const outputs = scope.outputs;
            const inputs = scope.inputs;
            const env = scope.env;
            const log = (...args) => { console.log('\u{1F50D} Debug:', ...args); };
            const hasMinPermission = scope.permissions.hasMinPermission;
            const isOwner = scope.permissions.isOwner;
            const isMember = scope.permissions.isMember;
            const isCollaborator = scope.permissions.isCollaborator;
            const isContributor = scope.permissions.isContributor;
            const isFirstTimer = scope.permissions.isFirstTimer;
            const __result = (function(){
${bodyWithReturn}
            })();
            return __result;
          `;
              if (!this.sandbox) {
                this.sandbox = this.createSecureSandbox();
              }
              let parsedFromSandboxJson = void 0;
              try {
                const stringifyCode = `
              const output = scope.output;
              const pr = scope.pr;
              const files = scope.files;
              const outputs = scope.outputs;
              const env = scope.env;
              const log = (...args) => { console.log('\u{1F50D} Debug:', ...args); };
              const hasMinPermission = scope.permissions.hasMinPermission;
              const isOwner = scope.permissions.isOwner;
              const isMember = scope.permissions.isMember;
              const isCollaborator = scope.permissions.isCollaborator;
              const isContributor = scope.permissions.isContributor;
              const isFirstTimer = scope.permissions.isFirstTimer;
              const __ret = (function(){
${bodyWithReturn}
              })();
              return typeof __ret === 'object' && __ret !== null ? JSON.stringify(__ret) : null;
            `;
                const stringifyExec = this.sandbox.compile(stringifyCode);
                const jsonStr = stringifyExec({ scope: jsContext }).run();
                if (typeof jsonStr === "string" && jsonStr.trim().startsWith("{")) {
                  parsedFromSandboxJson = JSON.parse(jsonStr);
                }
              } catch {
              }
              if (parsedFromSandboxJson !== void 0) {
                finalOutput = parsedFromSandboxJson;
              } else {
                finalOutput = compileAndRun(
                  this.sandbox,
                  code,
                  { scope: jsContext },
                  { injectLog: false, wrapFunction: false }
                );
              }
              try {
                if (finalOutput && typeof finalOutput === "object" && !Array.isArray(finalOutput) && (finalOutput.error === void 0 || finalOutput.issues === void 0)) {
                  const vm = await import("vm");
                  const vmContext = vm.createContext({ scope: jsContext });
                  const vmCode = `
                (function(){
                  const output = scope.output; const pr = scope.pr; const files = scope.files; const outputs = scope.outputs; const env = scope.env; const log = ()=>{};
${bodyWithReturn}
                })()
              `;
                  const vmResult = vm.runInContext(vmCode, vmContext, { timeout: 1e3 });
                  if (vmResult && typeof vmResult === "object") {
                    finalOutput = vmResult;
                  }
                }
              } catch {
              }
              let finalSnapshot = null;
              try {
                if (finalOutput && typeof finalOutput === "object" && !Array.isArray(finalOutput)) {
                  try {
                    const stringifyExec = this.sandbox.compile("return JSON.stringify(scope.obj);");
                    const jsonStr = stringifyExec({ obj: finalOutput }).run();
                    if (typeof jsonStr === "string" && jsonStr.trim().startsWith("{")) {
                      finalSnapshot = JSON.parse(jsonStr);
                    }
                  } catch {
                  }
                  if (!finalSnapshot) {
                    try {
                      finalSnapshot = JSON.parse(JSON.stringify(finalOutput));
                    } catch {
                    }
                  }
                  if (!finalSnapshot) {
                    const tmp = {};
                    for (const k of Object.keys(finalOutput)) {
                      tmp[k] = finalOutput[k];
                    }
                    finalSnapshot = tmp;
                  }
                }
              } catch {
              }
              this.__lastTransformSnapshot = finalSnapshot;
              try {
                const isObj = finalOutput && typeof finalOutput === "object" && !Array.isArray(finalOutput);
                const keys = isObj ? Object.keys(finalOutput).join(",") : typeof finalOutput;
                logger.debug(
                  `  transform_js: output typeof=${Array.isArray(finalOutput) ? "array" : typeof finalOutput} keys=${keys}`
                );
                if (isObj && finalOutput.issues) {
                  const mi = finalOutput.issues;
                  logger.debug(
                    `  transform_js: issues typeof=${Array.isArray(mi) ? "array" : typeof mi} len=${mi && mi.length || 0}`
                  );
                }
                try {
                  if (isObj)
                    logger.debug(`  transform_js: error value=${String(finalOutput.error)}`);
                } catch {
                }
              } catch {
              }
              logger.verbose(`\u2713 Applied JavaScript transform successfully`);
            } catch (error) {
              logger.error(
                `\u2717 Failed to apply JavaScript transform: ${error instanceof Error ? error.message : "Unknown error"}`
              );
              return {
                issues: [
                  {
                    file: "command",
                    line: 0,
                    ruleId: "command/transform_js_error",
                    message: `Failed to apply JavaScript transform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          let issues = [];
          let outputForDependents = finalOutput;
          const snapshotForExtraction = this.__lastTransformSnapshot || null;
          try {
            if (snapshotForExtraction) {
              logger.debug(`  provider: snapshot keys=${Object.keys(snapshotForExtraction).join(",")}`);
            } else {
              logger.debug(`  provider: snapshot is null`);
            }
          } catch {
          }
          try {
            if (Array.isArray(outputForDependents) && outputForDependents.length === 1) {
              const first = outputForDependents[0];
              if (typeof first === "string") {
                try {
                  outputForDependents = JSON.parse(first);
                } catch {
                }
              } else if (first && typeof first === "object") {
                outputForDependents = first;
              }
            }
          } catch {
          }
          let content;
          let extracted = null;
          const trimmedRawOutput = typeof rawOutput === "string" ? rawOutput.trim() : void 0;
          const commandConfig = config;
          const isForEachParent = commandConfig.forEach === true;
          if (!isForEachParent) {
            try {
              const baseObj = snapshotForExtraction || finalOutput;
              if (baseObj && typeof baseObj === "object" && Object.prototype.hasOwnProperty.call(baseObj, "issues")) {
                const remaining = { ...baseObj };
                delete remaining.issues;
                outputForDependents = Object.keys(remaining).length > 0 ? remaining : void 0;
                try {
                  const k = outputForDependents && typeof outputForDependents === "object" ? Object.keys(outputForDependents).join(",") : String(outputForDependents);
                  logger.debug(`  provider: generic-remaining keys=${k}`);
                } catch {
                }
              }
            } catch {
            }
            const objForExtraction = snapshotForExtraction || finalOutput;
            if (objForExtraction && typeof objForExtraction === "object") {
              try {
                const rec = objForExtraction;
                const maybeIssues = rec.issues;
                const toPlainArray = (v) => {
                  if (Array.isArray(v)) return v;
                  try {
                    if (v && typeof v === "object" && typeof v[Symbol.iterator] === "function") {
                      return Array.from(v);
                    }
                  } catch {
                  }
                  const len = Number((v || {}).length);
                  if (Number.isFinite(len) && len >= 0) {
                    const arr2 = [];
                    for (let i = 0; i < len; i++) arr2.push(v[i]);
                    return arr2;
                  }
                  try {
                    const cloned = JSON.parse(JSON.stringify(v));
                    return Array.isArray(cloned) ? cloned : null;
                  } catch {
                    return null;
                  }
                };
                try {
                  const ctor = maybeIssues && maybeIssues.constructor ? maybeIssues.constructor.name : "unknown";
                  logger.debug(
                    `  provider: issues inspect typeof=${typeof maybeIssues} Array.isArray=${Array.isArray(
                      maybeIssues
                    )} ctor=${ctor} keys=${Object.keys(maybeIssues || {}).join(",")}`
                  );
                } catch {
                }
                const arr = toPlainArray(maybeIssues);
                if (arr) {
                  const norm = this.normalizeIssueArray(arr);
                  if (norm) {
                    issues = norm;
                    const remaining = { ...rec };
                    delete remaining.issues;
                    outputForDependents = Object.keys(remaining).length > 0 ? remaining : void 0;
                    try {
                      const keys = outputForDependents && typeof outputForDependents === "object" ? Object.keys(outputForDependents).join(",") : String(outputForDependents);
                      logger.info(
                        `  provider: fast-path issues=${issues.length} remaining keys=${keys}`
                      );
                    } catch {
                    }
                  } else {
                    try {
                      logger.info("  provider: fast-path norm failed");
                    } catch {
                    }
                  }
                } else {
                  try {
                    logger.info("  provider: fast-path arr unavailable");
                  } catch {
                  }
                }
              } catch {
              }
            }
            let extractionTarget = snapshotForExtraction || finalOutput;
            try {
              if (Array.isArray(extractionTarget) && extractionTarget.length === 1) {
                const first = extractionTarget[0];
                if (typeof first === "string") {
                  try {
                    extractionTarget = JSON.parse(first);
                  } catch {
                    extractionTarget = first;
                  }
                } else if (first && typeof first === "object") {
                  extractionTarget = first;
                }
              }
            } catch {
            }
            extracted = this.extractIssuesFromOutput(extractionTarget);
            try {
              if (extractionTarget !== (snapshotForExtraction || finalOutput)) {
                finalOutput = extractionTarget;
              }
            } catch {
            }
            if (!extracted && finalOutput && typeof finalOutput === "object") {
              try {
                const rec = finalOutput;
                const maybeIssues = rec.issues;
                if (maybeIssues && typeof maybeIssues === "object") {
                  let arr = null;
                  try {
                    if (typeof maybeIssues[Symbol.iterator] === "function") {
                      arr = Array.from(maybeIssues);
                    }
                  } catch {
                  }
                  if (!arr) {
                    const len = Number(maybeIssues.length);
                    if (Number.isFinite(len) && len >= 0) {
                      arr = [];
                      for (let i = 0; i < len; i++) arr.push(maybeIssues[i]);
                    }
                  }
                  if (!arr) {
                    try {
                      arr = JSON.parse(JSON.stringify(maybeIssues));
                    } catch {
                    }
                  }
                  if (arr && Array.isArray(arr)) {
                    const norm = this.normalizeIssueArray(arr);
                    if (norm) {
                      issues = norm;
                      const remaining = { ...rec };
                      delete remaining.issues;
                      outputForDependents = Object.keys(remaining).length > 0 ? remaining : void 0;
                    }
                  }
                }
              } catch {
              }
            }
            if (!extracted && typeof finalOutput === "string") {
              try {
                const parsed = JSON.parse(finalOutput);
                extracted = this.extractIssuesFromOutput(parsed);
                if (extracted) {
                  issues = extracted.issues;
                  outputForDependents = extracted.remainingOutput;
                  if (typeof extracted.remainingOutput === "object" && extracted.remainingOutput !== null && typeof extracted.remainingOutput.content === "string") {
                    const c = String(extracted.remainingOutput.content).trim();
                    if (c) content = c;
                  }
                }
              } catch {
                try {
                  const any = this.extractJsonAnywhere(finalOutput);
                  if (any) {
                    const parsed = JSON.parse(any);
                    extracted = this.extractIssuesFromOutput(parsed);
                    if (extracted) {
                      issues = extracted.issues;
                      outputForDependents = extracted.remainingOutput;
                      if (typeof extracted.remainingOutput === "object" && extracted.remainingOutput !== null && typeof extracted.remainingOutput.content === "string") {
                        const c = String(extracted.remainingOutput.content).trim();
                        if (c) content = c;
                      }
                    }
                  }
                } catch {
                }
              }
            } else if (extracted) {
              issues = extracted.issues;
              outputForDependents = extracted.remainingOutput;
              if (typeof extracted.remainingOutput === "object" && extracted.remainingOutput !== null && typeof extracted.remainingOutput.content === "string") {
                const c = String(extracted.remainingOutput.content).trim();
                if (c) content = c;
              }
            }
            if (!issues.length && this.shouldTreatAsTextOutput(trimmedRawOutput)) {
              content = trimmedRawOutput;
            } else if (issues.length && typeof extracted?.remainingOutput === "string") {
              const trimmed = extracted.remainingOutput.trim();
              if (trimmed) {
                content = trimmed;
              }
            }
            if (!issues.length && typeof trimmedRawOutput === "string") {
              try {
                const tryParsed = JSON.parse(trimmedRawOutput);
                const reextract = this.extractIssuesFromOutput(tryParsed);
                if (reextract && reextract.issues && reextract.issues.length) {
                  issues = reextract.issues;
                  if (!outputForDependents && reextract.remainingOutput) {
                    outputForDependents = reextract.remainingOutput;
                  }
                } else if (Array.isArray(tryParsed)) {
                  const first = tryParsed[0];
                  if (first && typeof first === "object" && Array.isArray(first.issues)) {
                    const merged = [];
                    for (const el of tryParsed) {
                      if (el && typeof el === "object" && Array.isArray(el.issues)) {
                        merged.push(...el.issues);
                      }
                    }
                    const flat = this.normalizeIssueArray(merged);
                    if (flat) issues = flat;
                  } else {
                    const converted = [];
                    for (const el of tryParsed) {
                      if (typeof el === "string") {
                        try {
                          const obj = JSON.parse(el);
                          converted.push(obj);
                        } catch {
                        }
                      } else {
                        converted.push(el);
                      }
                    }
                    const flat = this.normalizeIssueArray(converted);
                    if (flat) issues = flat;
                  }
                }
              } catch {
              }
              if (!issues.length) {
                try {
                  const any = this.extractJsonAnywhere(trimmedRawOutput);
                  if (any) {
                    const tryParsed = JSON.parse(any);
                    const reextract = this.extractIssuesFromOutput(tryParsed);
                    if (reextract && reextract.issues && reextract.issues.length) {
                      issues = reextract.issues;
                      if (!outputForDependents && reextract.remainingOutput) {
                        outputForDependents = reextract.remainingOutput;
                      }
                    }
                  }
                } catch {
                }
              }
            }
            try {
              const srcObj = snapshotForExtraction || finalOutput;
              if (outputForDependents && typeof outputForDependents === "object" && srcObj && typeof srcObj === "object") {
                for (const k of Object.keys(srcObj)) {
                  const v = srcObj[k];
                  if (typeof v === "boolean" || typeof v === "number" || typeof v === "string") {
                    outputForDependents[k] = v;
                  }
                }
              }
            } catch {
            }
            try {
              if (outputForDependents && typeof outputForDependents === "object" && !Array.isArray(outputForDependents)) {
                const plain = {};
                for (const k of Object.keys(outputForDependents)) {
                  plain[k] = outputForDependents[k];
                }
                outputForDependents = plain;
              }
            } catch {
            }
          }
          if (!content && this.shouldTreatAsTextOutput(trimmedRawOutput) && !isForEachParent) {
            content = trimmedRawOutput;
          }
          try {
            if (outputForDependents && typeof outputForDependents === "object") {
              outputForDependents = JSON.parse(JSON.stringify(outputForDependents));
            }
          } catch {
          }
          const promoted = {};
          try {
            const srcObj = snapshotForExtraction || finalOutput;
            if (srcObj && typeof srcObj === "object") {
              for (const k of Object.keys(srcObj)) {
                const v = srcObj[k];
                if (typeof v === "boolean") {
                  if (v === true && promoted[k] === void 0) promoted[k] = true;
                } else if ((typeof v === "number" || typeof v === "string") && promoted[k] === void 0) {
                  promoted[k] = v;
                }
              }
            }
          } catch {
          }
          const result = {
            issues,
            output: outputForDependents,
            ...content ? { content } : {},
            ...promoted
          };
          try {
            const span = trace.getSpan(context.active());
            if (span) {
              captureCheckOutput(span, outputForDependents);
              if (transformJs && output !== finalOutput) {
                captureTransformJS(span, transformJs, output, finalOutput);
              }
            }
          } catch {
          }
          try {
            const checkId = config.checkName || config.id || "unknown";
            const outJson = JSON.stringify(result.output ?? result);
            const { emitNdjsonSpanWithEvents: emitNdjsonSpanWithEvents2 } = (init_fallback_ndjson(), __toCommonJS(fallback_ndjson_exports));
            emitNdjsonSpanWithEvents2(
              "visor.check",
              { "visor.check.id": checkId, "visor.check.output": outJson },
              [{ name: "check.started" }, { name: "check.completed" }]
            );
          } catch {
          }
          try {
            if (transformJs) {
              const rawObj = snapshotForExtraction || finalOutput;
              if (rawObj && typeof rawObj === "object") {
                result.__raw = rawObj;
              }
            }
          } catch {
          }
          try {
            const srcObj = snapshotForExtraction || finalOutput;
            const srcErr = (() => {
              try {
                if (snapshotForExtraction && typeof snapshotForExtraction === "object" && snapshotForExtraction.error !== void 0) {
                  return Boolean(snapshotForExtraction.error);
                }
                if (finalOutput && typeof finalOutput === "object" && finalOutput.error !== void 0) {
                  return Boolean(finalOutput.error);
                }
              } catch {
              }
              return void 0;
            })();
            const dst = result.output;
            if (srcObj && typeof srcObj === "object" && dst && typeof dst === "object") {
              try {
                logger.debug(
                  `  provider: safeguard src.error typeof=${typeof srcObj.error} val=${String(srcObj.error)} dst.hasErrorBefore=${String(dst.error !== void 0)}`
                );
              } catch {
              }
              for (const k of Object.keys(srcObj)) {
                const v = srcObj[k];
                if (typeof v === "boolean" || typeof v === "number" || typeof v === "string") {
                  dst[k] = v;
                }
              }
              if (srcErr !== void 0 && dst.error === void 0) {
                dst.error = srcErr;
                try {
                  const k = Object.keys(dst).join(",");
                  logger.debug(
                    `  provider: safeguard merged error -> output keys=${k} val=${String(dst.error)}`
                  );
                } catch {
                }
              }
            }
          } catch {
          }
          try {
            const out = result.output;
            if (out && typeof out === "object") {
              const k = Object.keys(out).join(",");
              logger.debug(`  provider: return output keys=${k}`);
            } else {
              logger.debug(`  provider: return output type=${typeof out}`);
            }
          } catch {
          }
          return result;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : "Unknown error";
          let isTimeout = false;
          if (error && typeof error === "object") {
            const execError = error;
            if (execError.killed && execError.signal === "SIGTERM") {
              isTimeout = true;
            }
            if (execError.code === "ETIMEDOUT") {
              isTimeout = true;
            }
          }
          let stderrOutput = "";
          if (error && typeof error === "object") {
            const execError = error;
            if (execError.stderr) {
              stderrOutput = execError.stderr.trim();
            }
          }
          let detailedMessage;
          let ruleId;
          if (isTimeout) {
            const timeoutMs = config.timeout || 6e4;
            detailedMessage = `Command execution timed out after ${timeoutMs} milliseconds`;
            if (stderrOutput) {
              detailedMessage += `

Stderr output:
${stderrOutput}`;
            }
            ruleId = "command/timeout";
          } else {
            detailedMessage = stderrOutput ? `Command execution failed: ${errorMessage}

Stderr output:
${stderrOutput}` : `Command execution failed: ${errorMessage}`;
            ruleId = "command/execution_error";
          }
          logger.error(`\u2717 ${detailedMessage}`);
          return {
            issues: [
              {
                file: "command",
                line: 0,
                ruleId,
                message: detailedMessage,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      buildOutputContext(dependencyResults, outputHistory) {
        if (!dependencyResults) {
          return {};
        }
        const outputs = {};
        const history = {};
        for (const [checkName, result] of dependencyResults) {
          const summary = result;
          const value = summary.output !== void 0 ? summary.output : summary;
          outputs[checkName] = this.makeJsonSmart(value);
        }
        if (outputHistory) {
          for (const [checkName, historyArray] of outputHistory) {
            history[checkName] = historyArray.map((val) => this.makeJsonSmart(val));
          }
        }
        outputs.history = history;
        return outputs;
      }
      /**
       * Wrap a value with JSON-smart behavior:
       *  - If it's a JSON string, expose parsed properties via Proxy (e.g., value.key)
       *  - When coerced to string (toString/valueOf/Symbol.toPrimitive), return the original raw string
       *  - If parsing fails or value is not a string, return the value unchanged
       *  - Attempts to extract JSON from the end of the output if full parse fails
       */
      makeJsonSmart(value) {
        if (typeof value !== "string") {
          return value;
        }
        const raw = value;
        let parsed;
        try {
          parsed = JSON.parse(raw);
        } catch {
          const jsonMatch = this.extractJsonFromEnd(raw);
          if (jsonMatch) {
            try {
              parsed = JSON.parse(jsonMatch);
              logger.debug(
                `\u{1F527} Debug: Extracted JSON from end of output (${jsonMatch.length} chars from ${raw.length} total)`
              );
            } catch {
              return raw;
            }
          } else {
            return raw;
          }
        }
        const boxed = new String(raw);
        const handler = {
          get(target, prop, receiver) {
            if (prop === "toString" || prop === "valueOf") {
              return () => raw;
            }
            if (prop === Symbol.toPrimitive) {
              return () => raw;
            }
            if (parsed != null && (typeof parsed === "object" || Array.isArray(parsed))) {
              if (prop in parsed) {
                return parsed[prop];
              }
            }
            return Reflect.get(target, prop, receiver);
          },
          has(_target, prop) {
            if (parsed != null && (typeof parsed === "object" || Array.isArray(parsed))) {
              if (prop in parsed) return true;
            }
            return false;
          },
          ownKeys(_target) {
            if (parsed != null && (typeof parsed === "object" || Array.isArray(parsed))) {
              try {
                return Reflect.ownKeys(parsed);
              } catch {
                return [];
              }
            }
            return [];
          },
          getOwnPropertyDescriptor(_target, prop) {
            if (parsed != null && (typeof parsed === "object" || Array.isArray(parsed))) {
              const descriptor = Object.getOwnPropertyDescriptor(parsed, prop);
              if (descriptor) return descriptor;
            }
            return {
              configurable: true,
              enumerable: true,
              writable: false,
              value: void 0
            };
          }
        };
        return new Proxy(boxed, handler);
      }
      /**
       * Extract JSON from the end of a string that may contain logs/debug output
       * Looks for the last occurrence of { or [ and tries to parse from there
       */
      extractJsonFromEnd(text) {
        const lastBrace = Math.max(text.lastIndexOf("}"), text.lastIndexOf("]"));
        if (lastBrace === -1) return null;
        let open = 0;
        for (let i = lastBrace; i >= 0; i--) {
          const ch = text[i];
          if (ch === "}" || ch === "]") open++;
          else if (ch === "{" || ch === "[") open--;
          if (open === 0 && (ch === "{" || ch === "[")) {
            const candidate = text.slice(i, lastBrace + 1).trim();
            try {
              JSON.parse(candidate);
              return candidate;
            } catch {
              return null;
            }
          }
        }
        return null;
      }
      // Extract any balanced JSON object/array substring from anywhere in the text
      extractJsonAnywhere(text) {
        const n = text.length;
        let best = null;
        for (let i = 0; i < n; i++) {
          const start = text[i];
          if (start !== "{" && start !== "[") continue;
          let open = 0;
          let inString = false;
          let escape = false;
          for (let j = i; j < n; j++) {
            const ch = text[j];
            if (escape) {
              escape = false;
              continue;
            }
            if (ch === "\\") {
              escape = true;
              continue;
            }
            if (ch === '"') {
              inString = !inString;
              continue;
            }
            if (inString) continue;
            if (ch === "{" || ch === "[") open++;
            else if (ch === "}" || ch === "]") open--;
            if (open === 0 && (ch === "}" || ch === "]")) {
              const candidate = text.slice(i, j + 1).trim();
              try {
                JSON.parse(candidate);
                best = candidate;
              } catch {
                const strict = this.looseJsonToStrict(candidate);
                if (strict) {
                  try {
                    JSON.parse(strict);
                    best = strict;
                  } catch {
                  }
                }
              }
              break;
            }
          }
        }
        return best;
      }
      // Best-effort conversion of object-literal-like strings to strict JSON
      looseJsonToStrict(candidate) {
        try {
          let s = candidate.trim();
          s = s.replace(/'/g, '"');
          s = s.replace(/([\{,]\s*)([A-Za-z_][A-Za-z0-9_-]*)\s*:/g, '$1"$2":');
          s = s.replace(/:\s*([A-Za-z_][A-Za-z0-9_-]*)\s*(?=[,}])/g, (_match, word) => {
            const lw = String(word).toLowerCase();
            if (lw === "true" || lw === "false" || lw === "null") return `:${lw}`;
            return `:"${word}"`;
          });
          return s;
        } catch {
          return null;
        }
      }
      /**
       * Recursively apply JSON-smart wrapper to outputs object values
       */
      makeOutputsJsonSmart(outputs) {
        const wrapped = {};
        for (const [k, v] of Object.entries(outputs || {})) {
          wrapped[k] = this.makeJsonSmart(v);
        }
        return wrapped;
      }
      getSafeEnvironmentVariables() {
        const safeVars = {};
        const { buildSandboxEnv: buildSandboxEnv2 } = (init_env_exposure(), __toCommonJS(env_exposure_exports));
        const merged = buildSandboxEnv2(process.env);
        for (const [key, value] of Object.entries(merged)) {
          safeVars[key] = String(value);
        }
        safeVars["PWD"] = process.cwd();
        return safeVars;
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "exec",
          "transform",
          "transform_js",
          "env",
          "timeout",
          "depends_on",
          "on",
          "if",
          "group",
          "forEach"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "Valid shell command to execute",
          "Shell environment available",
          "Optional: Transform template for processing output"
        ];
      }
      extractIssuesFromOutput(output) {
        try {
          logger.info(
            `  extractIssuesFromOutput: typeof=${Array.isArray(output) ? "array" : typeof output}`
          );
          if (typeof output === "object" && output) {
            const rec = output;
            logger.info(
              `  extractIssuesFromOutput: keys=${Object.keys(rec).join(",")} issuesIsArray=${Array.isArray(
                rec.issues
              )}`
            );
          }
        } catch {
        }
        if (output === null || output === void 0) {
          return null;
        }
        if (typeof output === "string") {
          return null;
        }
        if (Array.isArray(output)) {
          const first = output[0];
          if (first && typeof first === "object" && !Array.isArray(first.message) && Array.isArray(first.issues)) {
            const merged = [];
            for (const el of output) {
              if (el && typeof el === "object" && Array.isArray(el.issues)) {
                merged.push(...el.issues);
              }
            }
            const flat = this.normalizeIssueArray(merged);
            if (flat) return { issues: flat, remainingOutput: void 0 };
          } else {
            const issues = this.normalizeIssueArray(output);
            if (issues) {
              return { issues, remainingOutput: void 0 };
            }
          }
          return null;
        }
        if (typeof output === "object") {
          const record = output;
          if (Array.isArray(record.issues)) {
            const issues = this.normalizeIssueArray(record.issues);
            if (!issues) {
              return null;
            }
            const remaining = { ...record };
            delete remaining.issues;
            const remainingKeys = Object.keys(remaining);
            const remainingOutput = remainingKeys.length > 0 ? remaining : void 0;
            return {
              issues,
              remainingOutput
            };
          }
          const singleIssue = this.normalizeIssue(record);
          if (singleIssue) {
            return { issues: [singleIssue], remainingOutput: void 0 };
          }
        }
        return null;
      }
      shouldTreatAsTextOutput(value) {
        if (!value) {
          return false;
        }
        const trimmed = value.trim();
        if (!trimmed) {
          return false;
        }
        const startsJson = trimmed.startsWith("{") && trimmed.endsWith("}") || trimmed.startsWith("[") && trimmed.endsWith("]");
        return !startsJson;
      }
      normalizeIssueArray(values) {
        const normalized = [];
        for (const value of values) {
          const issue = this.normalizeIssue(value);
          if (!issue) {
            return null;
          }
          normalized.push(issue);
        }
        return normalized;
      }
      normalizeIssue(raw) {
        if (!raw || typeof raw !== "object") {
          return null;
        }
        const data = raw;
        const message = this.toTrimmedString(
          data.message || data.text || data.description || data.summary
        );
        if (!message) {
          return null;
        }
        const hasIssueField = data.file !== void 0 || data.path !== void 0 || data.filename !== void 0 || data.line !== void 0 || data.startLine !== void 0 || data.lineNumber !== void 0 || data.severity !== void 0 || data.level !== void 0 || data.priority !== void 0 || data.ruleId !== void 0 || data.rule !== void 0 || data.category !== void 0 || data.type !== void 0;
        if (!hasIssueField) {
          return null;
        }
        const allowedSeverities = /* @__PURE__ */ new Set(["info", "warning", "error", "critical"]);
        const severityRaw = this.toTrimmedString(data.severity || data.level || data.priority);
        let severity = "warning";
        if (severityRaw) {
          const lower = severityRaw.toLowerCase();
          if (allowedSeverities.has(lower)) {
            severity = lower;
          } else if (["fatal", "high"].includes(lower)) {
            severity = "error";
          } else if (["medium", "moderate"].includes(lower)) {
            severity = "warning";
          } else if (["low", "minor"].includes(lower)) {
            severity = "info";
          }
        }
        const allowedCategories = /* @__PURE__ */ new Set([
          "security",
          "performance",
          "style",
          "logic",
          "documentation"
        ]);
        const categoryRaw = this.toTrimmedString(data.category || data.type || data.group);
        let category = "logic";
        if (categoryRaw && allowedCategories.has(categoryRaw.toLowerCase())) {
          category = categoryRaw.toLowerCase();
        }
        const file = this.toTrimmedString(data.file || data.path || data.filename) || "system";
        const line = this.toNumber(data.line || data.startLine || data.lineNumber) ?? 0;
        const endLine = this.toNumber(data.endLine || data.end_line || data.stopLine);
        const suggestion = this.toTrimmedString(data.suggestion);
        const replacement = this.toTrimmedString(data.replacement);
        const ruleId = this.toTrimmedString(data.ruleId || data.rule || data.id || data.check) || "command";
        return {
          file,
          line,
          endLine: endLine ?? void 0,
          ruleId,
          message,
          severity,
          category,
          suggestion: suggestion || void 0,
          replacement: replacement || void 0
        };
      }
      toTrimmedString(value) {
        if (typeof value === "string") {
          const trimmed = value.trim();
          return trimmed.length > 0 ? trimmed : null;
        }
        if (value !== null && value !== void 0 && typeof value.toString === "function") {
          const converted = String(value).trim();
          return converted.length > 0 ? converted : null;
        }
        return null;
      }
      toNumber(value) {
        if (value === null || value === void 0) {
          return null;
        }
        const num = Number(value);
        if (Number.isFinite(num)) {
          return Math.trunc(num);
        }
        return null;
      }
      async renderCommandTemplate(template, context2) {
        try {
          let tpl = template;
          if (tpl.includes("{{")) {
            tpl = tpl.replace(/\{\{([\s\S]*?)\}\}/g, (_m, inner) => {
              const fixed = String(inner).replace(/\[\"/g, "['").replace(/\"\]/g, "']");
              return `{{ ${fixed} }}`;
            });
          }
          let rendered = await this.liquid.parseAndRender(tpl, context2);
          if (/\{\{[\s\S]*?\}\}/.test(rendered)) {
            try {
              rendered = this.renderWithJsExpressions(rendered, context2);
            } catch {
            }
          }
          return rendered;
        } catch (error) {
          logger.debug(`\u{1F527} Debug: Liquid templating failed, trying JS-expression fallback: ${error}`);
          try {
            return this.renderWithJsExpressions(template, context2);
          } catch {
            return template;
          }
        }
      }
      renderWithJsExpressions(template, context2) {
        const scope = {
          pr: context2.pr,
          files: context2.files,
          outputs: context2.outputs,
          env: context2.env
        };
        const expressionRegex = /\{\{\s*([^{}]+?)\s*\}\}/g;
        return template.replace(expressionRegex, (_match, expr) => {
          const expression = String(expr).trim();
          if (!expression) return "";
          try {
            const evalCode = `
          const pr = scope.pr;
          const files = scope.files;
          const outputs = scope.outputs;
          const env = scope.env;
          return (${expression});
        `;
            if (!this.sandbox) this.sandbox = this.createSecureSandbox();
            const evaluator = this.sandbox.compile(evalCode);
            const result = evaluator({ scope }).run();
            return result === void 0 || result === null ? "" : String(result);
          } catch {
            return "";
          }
        });
      }
    };
  }
});

// src/utils/script-memory-ops.ts
function createSyncMemoryOps(store) {
  let saveNeeded = false;
  const ensureNs = (ns) => {
    const nsName = ns || store.getDefaultNamespace();
    const anyStore = store;
    if (!anyStore["data"].has(nsName)) {
      anyStore["data"].set(nsName, /* @__PURE__ */ new Map());
    }
    return nsName;
  };
  const ops = {
    get: (key, ns) => store.get(key, ns),
    has: (key, ns) => store.has(key, ns),
    list: (ns) => store.list(ns),
    getAll: (ns) => store.getAll(ns),
    set: (key, value, ns) => {
      const nsName = ensureNs(ns);
      store["data"].get(nsName).set(key, value);
      saveNeeded = true;
      return value;
    },
    append: (key, value, ns) => {
      const existing = store.get(key, ns);
      let newValue;
      if (existing === void 0) newValue = [value];
      else if (Array.isArray(existing)) newValue = [...existing, value];
      else newValue = [existing, value];
      const nsName = ensureNs(ns);
      store["data"].get(nsName).set(key, newValue);
      saveNeeded = true;
      return newValue;
    },
    increment: (key, amount = 1, ns) => {
      const nsName = ensureNs(ns);
      const current = store.get(key, nsName);
      const numCurrent = typeof current === "number" ? current : 0;
      const newValue = numCurrent + amount;
      store["data"].get(nsName).set(key, newValue);
      saveNeeded = true;
      return newValue;
    },
    delete: (key, ns) => {
      const nsName = ensureNs(ns);
      const d = store["data"].get(nsName)?.delete(key) || false;
      if (d) saveNeeded = true;
      return d;
    },
    clear: (ns) => {
      if (ns) store["data"].delete(ns);
      else store["data"].clear();
      saveNeeded = true;
    }
  };
  return { ops, needsSave: () => saveNeeded };
}
var init_script_memory_ops = __esm({
  "src/utils/script-memory-ops.ts"() {
    "use strict";
  }
});

// src/providers/memory-check-provider.ts
var MemoryCheckProvider;
var init_memory_check_provider = __esm({
  "src/providers/memory-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_memory_store();
    init_liquid_extensions();
    init_logger();
    init_sandbox();
    init_template_context();
    init_script_memory_ops();
    MemoryCheckProvider = class extends CheckProvider {
      liquid;
      sandbox;
      constructor() {
        super();
        this.liquid = createExtendedLiquid({
          strictVariables: false,
          strictFilters: false
        });
      }
      /**
       * Create a secure sandbox for JavaScript execution
       */
      createSecureSandbox() {
        return createSecureSandbox();
      }
      getName() {
        return "memory";
      }
      getDescription() {
        return "Memory/state management provider for persistent key-value storage across checks";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "memory") {
          return false;
        }
        if (!cfg.operation || typeof cfg.operation !== "string") {
          return false;
        }
        const operation = cfg.operation;
        const validOps = ["get", "set", "append", "increment", "delete", "clear", "list"];
        if (!validOps.includes(operation)) {
          return false;
        }
        if (["get", "set", "append", "increment", "delete"].includes(operation)) {
          if (!cfg.key || typeof cfg.key !== "string") {
            return false;
          }
        }
        if (["set", "append"].includes(operation)) {
          if (cfg.value === void 0 && !cfg.value_js) {
            return false;
          }
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, _sessionInfo) {
        const operation = config.operation;
        const key = config.key;
        const namespace = config.namespace;
        const memoryStore = MemoryStore.getInstance();
        const templateContext = this.buildTemplateContext(
          prInfo,
          dependencyResults,
          memoryStore,
          config.__outputHistory,
          _sessionInfo?.stageHistoryBase,
          _sessionInfo?.args
        );
        let result;
        try {
          switch (operation) {
            case "get":
              result = await this.handleGet(memoryStore, key, namespace);
              break;
            case "set":
              result = await this.handleSet(memoryStore, key, config, namespace, templateContext);
              break;
            case "append":
              result = await this.handleAppend(memoryStore, key, config, namespace, templateContext);
              break;
            case "increment":
              result = await this.handleIncrement(
                memoryStore,
                key,
                config,
                namespace,
                templateContext
              );
              break;
            case "delete":
              result = await this.handleDelete(memoryStore, key, namespace);
              break;
            case "clear":
              result = await this.handleClear(memoryStore, namespace);
              break;
            case "list":
              result = await this.handleList(memoryStore, namespace);
              break;
            default:
              throw new Error(`Unknown memory operation: ${operation}`);
          }
          return {
            issues: [],
            output: result
          };
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : "Unknown error in memory operation";
          logger.error(`Memory operation failed: ${errorMsg}`);
          return {
            issues: [],
            output: null,
            error: errorMsg
          };
        }
      }
      async handleGet(store, key, namespace) {
        const value = store.get(key, namespace);
        logger.debug(
          `Memory GET: ${namespace || store.getDefaultNamespace()}.${key} = ${JSON.stringify(value)}`
        );
        return value;
      }
      async handleSet(store, key, config, namespace, context2) {
        const value = await this.computeValue(config, context2);
        await store.set(key, value, namespace);
        logger.debug(
          `Memory SET: ${namespace || store.getDefaultNamespace()}.${key} = ${JSON.stringify(value)}`
        );
        return value;
      }
      async handleAppend(store, key, config, namespace, context2) {
        const value = await this.computeValue(config, context2);
        await store.append(key, value, namespace);
        const result = store.get(key, namespace);
        logger.debug(
          `Memory APPEND: ${namespace || store.getDefaultNamespace()}.${key} += ${JSON.stringify(value)} (now: ${JSON.stringify(result)})`
        );
        return result;
      }
      async handleIncrement(store, key, config, namespace, context2) {
        let amount = 1;
        if (config.value !== void 0 || config.value_js) {
          const computedValue = await this.computeValue(config, context2);
          if (typeof computedValue === "number") {
            amount = computedValue;
          } else {
            throw new Error(`Increment amount must be a number, got ${typeof computedValue}`);
          }
        }
        const result = await store.increment(key, amount, namespace);
        logger.debug(
          `Memory INCREMENT: ${namespace || store.getDefaultNamespace()}.${key} += ${amount} (now: ${result})`
        );
        return result;
      }
      async handleDelete(store, key, namespace) {
        const deleted = await store.delete(key, namespace);
        logger.debug(
          `Memory DELETE: ${namespace || store.getDefaultNamespace()}.${key} (deleted: ${deleted})`
        );
        return deleted;
      }
      async handleClear(store, namespace) {
        await store.clear(namespace);
        logger.debug(`Memory CLEAR: ${namespace ? `namespace ${namespace}` : "all namespaces"}`);
      }
      async handleList(store, namespace) {
        const keys = store.list(namespace);
        logger.debug(`Memory LIST: ${namespace || store.getDefaultNamespace()} (${keys.length} keys)`);
        return keys;
      }
      // For custom JavaScript execution use ScriptCheckProvider.
      /**
       * Compute value from config using value, value_js, transform, or transform_js
       */
      async computeValue(config, context2) {
        let value;
        if (config.value_js && typeof config.value_js === "string") {
          value = this.evaluateJavaScript(config.value_js, context2);
        } else {
          value = config.value;
        }
        if (config.transform && typeof config.transform === "string") {
          const rendered = await this.liquid.parseAndRender(config.transform, {
            ...context2,
            value
          });
          value = rendered;
        }
        if (config.transform_js && typeof config.transform_js === "string") {
          value = this.evaluateJavaScript(config.transform_js, { ...context2, value });
        }
        return value;
      }
      /**
       * Evaluate JavaScript expression in context using SandboxJS for secure execution
       */
      evaluateJavaScript(expression, context2) {
        if (!this.sandbox) {
          this.sandbox = this.createSecureSandbox();
        }
        try {
          const scope = { ...context2 };
          return compileAndRun(this.sandbox, `return (${expression});`, scope, {
            injectLog: true,
            wrapFunction: false,
            logPrefix: "[memory:value_js]"
          });
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : "Unknown error";
          throw new Error(`Failed to evaluate value_js: ${errorMsg}`);
        }
      }
      // No full-script execution in memory provider. Use ScriptCheckProvider.
      /**
       * Build template context for Liquid and JS evaluation
       */
      buildTemplateContext(prInfo, dependencyResults, memoryStore, outputHistory, stageHistoryBase, args) {
        const base = buildProviderTemplateContext(
          prInfo,
          dependencyResults,
          memoryStore,
          outputHistory,
          stageHistoryBase,
          { attachMemoryReadHelpers: true, args }
        );
        if (memoryStore) {
          const { ops } = createSyncMemoryOps(memoryStore);
          base.memory = ops;
        }
        return base;
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "operation",
          "key",
          "value",
          "value_js",
          "transform",
          "transform_js",
          "namespace",
          "depends_on",
          "group",
          "command",
          "on",
          "if",
          "fail_if",
          "on_fail",
          "on_success"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "No external dependencies required",
          "Used for state management and persistent storage across checks"
        ];
      }
    };
  }
});

// src/providers/mcp-check-provider.ts
var import_client, import_stdio, import_sse, import_streamableHttp, McpCheckProvider;
var init_mcp_check_provider = __esm({
  "src/providers/mcp-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_logger();
    init_liquid_extensions();
    import_client = require("@modelcontextprotocol/sdk/client/index.js");
    import_stdio = require("@modelcontextprotocol/sdk/client/stdio.js");
    import_sse = require("@modelcontextprotocol/sdk/client/sse.js");
    import_streamableHttp = require("@modelcontextprotocol/sdk/client/streamableHttp.js");
    init_sandbox();
    init_env_resolver();
    init_custom_tool_executor();
    McpCheckProvider = class extends CheckProvider {
      liquid;
      sandbox;
      customToolExecutor;
      constructor() {
        super();
        this.liquid = createExtendedLiquid({
          cache: false,
          strictFilters: false,
          strictVariables: false
        });
      }
      /**
       * Set custom tools for this provider
       */
      setCustomTools(tools) {
        if (!this.customToolExecutor) {
          this.customToolExecutor = new CustomToolExecutor(tools);
        } else {
          this.customToolExecutor.registerTools(tools);
        }
      }
      /**
       * Create a secure sandbox for JavaScript execution
       * - Uses Sandbox.SAFE_GLOBALS which excludes: Function, eval, require, process, etc.
       * - Only allows explicitly whitelisted prototype methods
       * - No access to filesystem, network, or system resources
       */
      createSecureSandbox() {
        return createSecureSandbox();
      }
      getName() {
        return "mcp";
      }
      getDescription() {
        return "Call MCP tools directly using stdio, SSE, HTTP, or custom YAML-defined tools";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (!cfg.method || typeof cfg.method !== "string") {
          logger.error("MCP check requires a method name");
          return false;
        }
        const transport = cfg.transport || "stdio";
        if (transport === "stdio") {
          if (!cfg.command || typeof cfg.command !== "string") {
            logger.error("MCP stdio transport requires a command");
            return false;
          }
          if (/[;&|`$(){}[\]]/.test(cfg.command)) {
            logger.error("MCP stdio command contains potentially unsafe characters");
            return false;
          }
        } else if (transport === "sse" || transport === "http") {
          if (!cfg.url || typeof cfg.url !== "string") {
            logger.error(`MCP ${transport} transport requires a URL`);
            return false;
          }
          try {
            const parsedUrl = new URL(cfg.url);
            if (parsedUrl.protocol !== "http:" && parsedUrl.protocol !== "https:") {
              logger.error(
                `Invalid URL protocol for MCP ${transport} transport: ${parsedUrl.protocol}. Only http: and https: are allowed.`
              );
              return false;
            }
          } catch {
            logger.error(`Invalid URL format for MCP ${transport} transport: ${cfg.url}`);
            return false;
          }
        } else if (transport === "custom") {
          logger.debug(`MCP custom transport will validate tool '${cfg.method}' at execution time`);
        } else {
          logger.error(
            `Invalid MCP transport: ${transport}. Must be 'stdio', 'sse', 'http', or 'custom'`
          );
          return false;
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, sessionInfo) {
        const cfg = config;
        try {
          const templateContext = {
            pr: {
              number: prInfo.number,
              title: prInfo.title,
              author: prInfo.author,
              branch: prInfo.head,
              base: prInfo.base
            },
            files: prInfo.files,
            fileCount: prInfo.files.length,
            outputs: this.buildOutputContext(dependencyResults),
            args: sessionInfo?.args || {},
            env: this.getSafeEnvironmentVariables()
          };
          let methodArgs = cfg.methodArgs || {};
          if (cfg.argsTransform) {
            const rendered = await this.liquid.parseAndRender(cfg.argsTransform, templateContext);
            try {
              methodArgs = JSON.parse(rendered);
            } catch (error) {
              logger.error(`Failed to parse argsTransform as JSON: ${error}`);
              return {
                issues: [
                  {
                    file: "mcp",
                    line: 0,
                    ruleId: "mcp/args_transform_error",
                    message: `Failed to parse argsTransform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          const result = await this.executeMcpMethod(cfg, methodArgs, prInfo, dependencyResults);
          let finalOutput = result;
          if (cfg.transform) {
            try {
              const transformContext = {
                ...templateContext,
                output: result
              };
              const rendered = await this.liquid.parseAndRender(cfg.transform, transformContext);
              try {
                finalOutput = JSON.parse(rendered.trim());
              } catch {
                finalOutput = rendered.trim();
              }
            } catch (error) {
              logger.error(`Failed to apply Liquid transform: ${error}`);
              return {
                issues: [
                  {
                    file: "mcp",
                    line: 0,
                    ruleId: "mcp/transform_error",
                    message: `Failed to apply transform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          if (cfg.transform_js) {
            try {
              if (!this.sandbox) {
                this.sandbox = this.createSecureSandbox();
              }
              const scope = {
                output: finalOutput,
                pr: templateContext.pr,
                files: templateContext.files,
                outputs: templateContext.outputs,
                env: templateContext.env
              };
              finalOutput = compileAndRun(
                this.sandbox,
                `return (${cfg.transform_js});`,
                scope,
                { injectLog: true, wrapFunction: false, logPrefix: "[mcp:transform_js]" }
              );
            } catch (error) {
              logger.error(`Failed to apply JavaScript transform: ${error}`);
              return {
                issues: [
                  {
                    file: "mcp",
                    line: 0,
                    ruleId: "mcp/transform_js_error",
                    message: `Failed to apply JavaScript transform: ${error instanceof Error ? error.message : "Unknown error"}`,
                    severity: "error",
                    category: "logic"
                  }
                ]
              };
            }
          }
          const extracted = this.extractIssuesFromOutput(finalOutput);
          if (extracted) {
            return {
              issues: extracted.issues,
              ...extracted.remainingOutput ? { output: extracted.remainingOutput } : {}
            };
          }
          return {
            issues: [],
            ...finalOutput ? { output: finalOutput } : {}
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : "Unknown error";
          logger.error(`MCP check failed: ${errorMessage}`);
          return {
            issues: [
              {
                file: "mcp",
                line: 0,
                ruleId: "mcp/execution_error",
                message: `MCP check failed: ${errorMessage}`,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      /**
       * Execute an MCP method using the configured transport
       */
      async executeMcpMethod(config, methodArgs, prInfo, dependencyResults) {
        const transport = config.transport || "stdio";
        const timeout = (config.timeout || 60) * 1e3;
        if (transport === "custom") {
          if (!this.customToolExecutor) {
            throw new Error(
              'No custom tools available. Define tools in the "tools" section of your configuration.'
            );
          }
          const tool = this.customToolExecutor.getTool(config.method);
          if (!tool) {
            throw new Error(
              `Custom tool not found: ${config.method}. Available tools: ${this.customToolExecutor.getTools().map((t) => t.name).join(", ")}`
            );
          }
          const context2 = {
            pr: prInfo ? {
              number: prInfo.number,
              title: prInfo.title,
              author: prInfo.author,
              branch: prInfo.head,
              base: prInfo.base
            } : void 0,
            files: prInfo?.files,
            outputs: this.buildOutputContext(dependencyResults),
            env: this.getSafeEnvironmentVariables()
          };
          return await this.customToolExecutor.execute(config.method, methodArgs, context2);
        } else if (transport === "stdio") {
          return await this.executeStdioMethod(config, methodArgs, timeout);
        } else if (transport === "sse") {
          return await this.executeSseMethod(config, methodArgs, timeout);
        } else if (transport === "http") {
          return await this.executeHttpMethod(config, methodArgs, timeout);
        } else {
          throw new Error(`Unsupported transport: ${transport}`);
        }
      }
      /**
       * Generic method to execute MCP method with any transport
       */
      async executeWithTransport(transport, config, methodArgs, timeout, transportName) {
        const client = new import_client.Client(
          {
            name: "visor-mcp-client",
            version: "1.0.0"
          },
          {
            capabilities: {}
          }
        );
        try {
          let timeoutId;
          try {
            await Promise.race([
              client.connect(transport),
              new Promise((_, reject) => {
                timeoutId = setTimeout(() => reject(new Error("Connection timeout")), timeout);
              })
            ]);
          } finally {
            if (timeoutId) {
              clearTimeout(timeoutId);
            }
          }
          logger.debug(`Connected to MCP server via ${transportName}`);
          if (transport instanceof import_streamableHttp.StreamableHTTPClientTransport && transport.sessionId) {
            logger.debug(`MCP Session ID: ${transport.sessionId}`);
          }
          try {
            const toolsResult = await client.listTools();
            logger.debug(`Available MCP tools: ${JSON.stringify(toolsResult?.tools || [])}`);
          } catch (error) {
            logger.debug(`Could not list MCP tools: ${error}`);
          }
          let callTimeoutId;
          try {
            const result = await Promise.race([
              client.callTool({
                name: config.method,
                arguments: methodArgs
              }),
              new Promise((_, reject) => {
                callTimeoutId = setTimeout(() => reject(new Error("Request timeout")), timeout);
              })
            ]);
            logger.debug(`MCP method result: ${JSON.stringify(result)}`);
            return result;
          } finally {
            if (callTimeoutId) {
              clearTimeout(callTimeoutId);
            }
          }
        } finally {
          try {
            await client.close();
          } catch (error) {
            logger.debug(`Error closing MCP client: ${error}`);
          }
        }
      }
      /**
       * Execute MCP method using stdio transport
       */
      async executeStdioMethod(config, methodArgs, timeout) {
        const transport = new import_stdio.StdioClientTransport({
          command: config.command,
          args: config.command_args,
          env: config.env,
          cwd: config.workingDirectory
        });
        return this.executeWithTransport(
          transport,
          config,
          methodArgs,
          timeout,
          `stdio: ${config.command}`
        );
      }
      /**
       * Execute MCP method using SSE transport
       */
      async executeSseMethod(config, methodArgs, timeout) {
        const requestInit = {};
        if (config.headers) {
          requestInit.headers = EnvironmentResolver.resolveHeaders(config.headers);
        }
        const transport = new import_sse.SSEClientTransport(new URL(config.url), {
          requestInit
        });
        return this.executeWithTransport(transport, config, methodArgs, timeout, `SSE: ${config.url}`);
      }
      /**
       * Execute MCP method using Streamable HTTP transport
       */
      async executeHttpMethod(config, methodArgs, timeout) {
        const requestInit = {};
        if (config.headers) {
          requestInit.headers = EnvironmentResolver.resolveHeaders(config.headers);
        }
        const transport = new import_streamableHttp.StreamableHTTPClientTransport(new URL(config.url), {
          requestInit,
          sessionId: config.sessionId
        });
        return this.executeWithTransport(
          transport,
          config,
          methodArgs,
          timeout,
          `Streamable HTTP: ${config.url}`
        );
      }
      /**
       * Build output context from dependency results
       */
      buildOutputContext(dependencyResults) {
        if (!dependencyResults) {
          return {};
        }
        const outputs = {};
        for (const [checkName, result] of dependencyResults) {
          const summary = result;
          outputs[checkName] = summary.output !== void 0 ? summary.output : summary;
        }
        return outputs;
      }
      /**
       * Get safe environment variables
       */
      getSafeEnvironmentVariables() {
        const safeVars = {};
        const allowedPrefixes = [];
        const { buildSandboxEnv: buildSandboxEnv2 } = (init_env_exposure(), __toCommonJS(env_exposure_exports));
        const merged = buildSandboxEnv2(process.env);
        for (const [key, value] of Object.entries(merged)) {
          safeVars[key] = String(value);
        }
        safeVars["PWD"] = process.cwd();
        return safeVars;
      }
      /**
       * Extract issues from MCP output
       */
      extractIssuesFromOutput(output) {
        if (output === null || output === void 0) {
          return null;
        }
        if (typeof output === "string") {
          try {
            const parsed = JSON.parse(output);
            return this.extractIssuesFromOutput(parsed);
          } catch {
            return null;
          }
        }
        if (Array.isArray(output)) {
          const issues = this.normalizeIssueArray(output);
          if (issues) {
            return { issues, remainingOutput: void 0 };
          }
          return null;
        }
        if (typeof output === "object") {
          const record = output;
          if (Array.isArray(record.issues)) {
            const issues = this.normalizeIssueArray(record.issues);
            if (!issues) {
              return null;
            }
            const remaining = { ...record };
            delete remaining.issues;
            return {
              issues,
              remainingOutput: Object.keys(remaining).length > 0 ? remaining : void 0
            };
          }
          const singleIssue = this.normalizeIssue(record);
          if (singleIssue) {
            return { issues: [singleIssue], remainingOutput: void 0 };
          }
        }
        return null;
      }
      /**
       * Normalize an array of issues
       */
      normalizeIssueArray(values) {
        const normalized = [];
        for (const value of values) {
          const issue = this.normalizeIssue(value);
          if (!issue) {
            return null;
          }
          normalized.push(issue);
        }
        return normalized;
      }
      /**
       * Normalize a single issue
       */
      normalizeIssue(raw) {
        if (!raw || typeof raw !== "object") {
          return null;
        }
        const data = raw;
        const message = this.toTrimmedString(
          data.message || data.text || data.description || data.summary
        );
        if (!message) {
          return null;
        }
        const allowedSeverities = /* @__PURE__ */ new Set(["info", "warning", "error", "critical"]);
        const severityRaw = this.toTrimmedString(data.severity || data.level || data.priority);
        let severity = "warning";
        if (severityRaw) {
          const lower = severityRaw.toLowerCase();
          if (allowedSeverities.has(lower)) {
            severity = lower;
          }
        }
        const allowedCategories = /* @__PURE__ */ new Set([
          "security",
          "performance",
          "style",
          "logic",
          "documentation"
        ]);
        const categoryRaw = this.toTrimmedString(data.category || data.type || data.group);
        let category = "logic";
        if (categoryRaw && allowedCategories.has(categoryRaw.toLowerCase())) {
          category = categoryRaw.toLowerCase();
        }
        const file = this.toTrimmedString(data.file || data.path || data.filename) || "system";
        const line = this.toNumber(data.line || data.startLine || data.lineNumber) ?? 0;
        const endLine = this.toNumber(data.endLine || data.end_line || data.stopLine);
        const suggestion = this.toTrimmedString(data.suggestion);
        const replacement = this.toTrimmedString(data.replacement);
        const ruleId = this.toTrimmedString(data.ruleId || data.rule || data.id || data.check) || "mcp";
        return {
          file,
          line,
          endLine: endLine ?? void 0,
          ruleId,
          message,
          severity,
          category,
          suggestion: suggestion || void 0,
          replacement: replacement || void 0
        };
      }
      toTrimmedString(value) {
        if (typeof value === "string") {
          const trimmed = value.trim();
          return trimmed.length > 0 ? trimmed : null;
        }
        if (value !== null && value !== void 0 && typeof value.toString === "function") {
          const converted = String(value).trim();
          return converted.length > 0 ? converted : null;
        }
        return null;
      }
      toNumber(value) {
        if (value === null || value === void 0) {
          return null;
        }
        const num = Number(value);
        if (Number.isFinite(num)) {
          return Math.trunc(num);
        }
        return null;
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "transport",
          "command",
          "command_args",
          "env",
          "workingDirectory",
          "url",
          "headers",
          "sessionId",
          "method",
          "methodArgs",
          "argsTransform",
          "transform",
          "transform_js",
          "timeout",
          "depends_on",
          "on",
          "if",
          "group"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return ["MCP method name specified", "Transport configuration (stdio: command, sse/http: url)"];
      }
    };
  }
});

// src/utils/interactive-prompt.ts
async function acquirePromptLock() {
  if (!activePrompt) {
    activePrompt = true;
    return;
  }
  await new Promise((resolve9) => waiters.push(resolve9));
  activePrompt = true;
}
function releasePromptLock() {
  activePrompt = false;
  const next = waiters.shift();
  if (next) next();
}
async function interactivePrompt(options) {
  await acquirePromptLock();
  return new Promise((resolve9, reject) => {
    const dbg = process.env.VISOR_DEBUG === "true";
    try {
      if (dbg) {
        const counts = {
          data: process.stdin.listenerCount("data"),
          end: process.stdin.listenerCount("end"),
          error: process.stdin.listenerCount("error"),
          readable: process.stdin.listenerCount("readable"),
          close: process.stdin.listenerCount("close")
        };
        console.error(
          `[human-input] starting prompt: isTTY=${!!process.stdin.isTTY} active=${activePrompt} waiters=${waiters.length} listeners=${JSON.stringify(counts)}`
        );
      }
    } catch {
    }
    try {
      if (process.stdin.isTTY && typeof process.stdin.setRawMode === "function") {
        process.stdin.setRawMode(false);
      }
      process.stdin.resume();
    } catch {
    }
    try {
      process.stdin.setEncoding("utf8");
    } catch {
    }
    let rl;
    const allowEmpty = options.allowEmpty ?? false;
    const multiline = options.multiline ?? false;
    const defaultValue = options.defaultValue;
    let timeoutId;
    const cleanup = () => {
      if (timeoutId) clearTimeout(timeoutId);
      try {
        rl?.removeAllListeners();
      } catch {
      }
      try {
        rl?.close();
      } catch {
      }
      try {
        if (process.stdin.isTTY && typeof process.stdin.setRawMode === "function") {
          process.stdin.setRawMode(false);
        }
      } catch {
      }
      try {
        process.stdin.pause();
      } catch {
      }
      try {
        releasePromptLock();
      } catch {
      }
      try {
        if (process.stdout.__restoreWrites) {
          process.stdout.__restoreWrites();
        }
      } catch {
      }
      try {
        if (process.stderr.__restoreWrites) {
          process.stderr.__restoreWrites();
        }
      } catch {
      }
      try {
        if (dbg) {
          const counts = {
            data: process.stdin.listenerCount("data"),
            end: process.stdin.listenerCount("end"),
            error: process.stdin.listenerCount("error"),
            readable: process.stdin.listenerCount("readable"),
            close: process.stdin.listenerCount("close")
          };
          console.error(
            `[human-input] cleanup: isTTY=${!!process.stdin.isTTY} active=false waiters=${waiters.length} listeners=${JSON.stringify(counts)}`
          );
        }
      } catch {
      }
    };
    const finish = (value) => {
      cleanup();
      resolve9(value);
    };
    if (options.timeout && options.timeout > 0) {
      timeoutId = setTimeout(() => {
        cleanup();
        if (defaultValue !== void 0) return resolve9(defaultValue);
        return reject(new Error("Input timeout"));
      }, options.timeout);
    }
    const header = [];
    if (options.prompt && options.prompt.trim()) header.push(options.prompt.trim());
    if (multiline) header.push("(Ctrl+D to submit)");
    if (options.placeholder && !multiline) header.push(options.placeholder);
    const width = Math.max(
      20,
      Math.min(process.stdout && process.stdout.columns || 80, 100)
    );
    const dash = "-".repeat(width);
    try {
      console.log("\n" + dash);
      if (header.length) console.log(header.join("\n"));
      console.log(dash);
    } catch {
    }
    if (multiline) {
      rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout,
        terminal: true
      });
      let buf = "";
      process.stdout.write("> ");
      rl.on("line", (line) => {
        buf += (buf ? "\n" : "") + line;
        process.stdout.write("> ");
      });
      rl.on("close", () => {
        const trimmed = buf.trim();
        if (!trimmed && !allowEmpty && defaultValue === void 0) {
          return reject(new Error("Empty input not allowed"));
        }
        return finish(trimmed || defaultValue || "");
      });
      rl.on("SIGINT", () => {
        try {
          process.stdout.write("\n");
        } catch {
        }
        cleanup();
        process.exit(130);
      });
    } else {
      const readLineRaw = async () => {
        return new Promise((resolveRaw) => {
          let buf = "";
          const onData = (chunk) => {
            const s = chunk.toString("utf8");
            for (let i = 0; i < s.length; i++) {
              const ch = s[i];
              const code = s.charCodeAt(i);
              if (ch === "\n" || ch === "\r") {
                try {
                  process.stdout.write("\n");
                } catch {
                }
                teardown();
                resolveRaw(buf);
                return;
              }
              if (ch === "\b" || code === 127) {
                if (buf.length > 0) {
                  buf = buf.slice(0, -1);
                  try {
                    process.stdout.write("\b \b");
                  } catch {
                  }
                }
                continue;
              }
              if (code === 3) {
                try {
                  process.stdout.write("\n");
                } catch {
                }
                teardown();
                process.exit(130);
              }
              if (code >= 32) {
                buf += ch;
                try {
                  process.stdout.write(ch);
                } catch {
                }
              }
            }
          };
          const teardown = () => {
            try {
              process.stdin.off("data", onData);
            } catch {
            }
            try {
              if (process.stdin.isTTY && typeof process.stdin.setRawMode === "function") {
                process.stdin.setRawMode(false);
              }
            } catch {
            }
          };
          try {
            if (process.stdin.isTTY && typeof process.stdin.setRawMode === "function") {
              process.stdin.setRawMode(true);
            }
          } catch {
          }
          process.stdin.on("data", onData);
          try {
            process.stdout.write("> ");
          } catch {
          }
        });
      };
      (async () => {
        const answer = await readLineRaw();
        const trimmed = (answer || "").trim();
        if (!trimmed && !allowEmpty && defaultValue === void 0) {
          cleanup();
          return reject(new Error("Empty input not allowed"));
        }
        return finish(trimmed || defaultValue || "");
      })().catch((err) => {
        cleanup();
        reject(err);
      });
    }
  });
}
async function simplePrompt(prompt) {
  return new Promise((resolve9) => {
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout
    });
    rl.on("SIGINT", () => {
      try {
        process.stdout.write("\n");
      } catch {
      }
      rl.close();
      process.exit(130);
    });
    rl.question(`${prompt}
> `, (answer) => {
      rl.close();
      resolve9(answer.trim());
    });
  });
}
var readline, activePrompt, waiters;
var init_interactive_prompt = __esm({
  "src/utils/interactive-prompt.ts"() {
    "use strict";
    readline = __toESM(require("readline"));
    activePrompt = false;
    waiters = [];
  }
});

// src/slack/prompt-state.ts
var prompt_state_exports = {};
__export(prompt_state_exports, {
  PromptStateManager: () => PromptStateManager,
  getPromptStateManager: () => getPromptStateManager,
  resetPromptStateManager: () => resetPromptStateManager
});
function getPromptStateManager(ttlMs) {
  if (!__promptState) __promptState = new PromptStateManager(ttlMs);
  return __promptState;
}
function resetPromptStateManager() {
  __promptState = void 0;
}
var PromptStateManager, __promptState;
var init_prompt_state = __esm({
  "src/slack/prompt-state.ts"() {
    "use strict";
    init_logger();
    PromptStateManager = class {
      waiting = /* @__PURE__ */ new Map();
      // key: `${channel}:${threadTs}`
      ttlMs;
      timer;
      firstMessage = /* @__PURE__ */ new Map();
      summaryTs = /* @__PURE__ */ new Map();
      // key: threadKey -> group -> ts
      constructor(ttlMs = 60 * 60 * 1e3) {
        this.ttlMs = ttlMs;
        this.startCleanup();
      }
      key(channel, threadTs) {
        return `${channel}:${threadTs}`;
      }
      setWaiting(channel, threadTs, info) {
        const key = this.key(channel, threadTs);
        const value = { ...info, timestamp: Date.now(), channel, threadTs };
        this.waiting.set(key, value);
        try {
          logger.info(
            `[prompt-state] waiting set for ${key} (check=${info.checkName}, prompt="${info.prompt.substring(
              0,
              60
            )}\u2026")`
          );
        } catch {
        }
      }
      getWaiting(channel, threadTs) {
        const key = this.key(channel, threadTs);
        const info = this.waiting.get(key);
        if (!info) return void 0;
        const age = Date.now() - info.timestamp;
        if (age > this.ttlMs) {
          this.waiting.delete(key);
          try {
            logger.warn(`[prompt-state] expired ${key} (age=${Math.round(age / 1e3)}s)`);
          } catch {
          }
          return void 0;
        }
        return info;
      }
      clear(channel, threadTs) {
        const key = this.key(channel, threadTs);
        const had = this.waiting.delete(key);
        if (had) {
          try {
            logger.info(`[prompt-state] cleared ${key}`);
          } catch {
          }
        }
        return had;
      }
      /** Merge updates into an existing waiting entry */
      update(channel, threadTs, patch) {
        const key = this.key(channel, threadTs);
        const prev = this.waiting.get(key);
        if (!prev) return void 0;
        const next = { ...prev, ...patch };
        this.waiting.set(key, next);
        try {
          if (patch.snapshotPath) {
            logger.info(`[prompt-state] snapshotPath set for ${key}`);
          }
        } catch {
        }
        return next;
      }
      // First message capture helpers
      setFirstMessage(channel, threadTs, text) {
        const key = this.key(channel, threadTs);
        if (!text || !text.trim()) return;
        const existing = this.firstMessage.get(key);
        if (!existing || existing.consumed) {
          this.firstMessage.set(key, { text, consumed: false });
        }
      }
      consumeFirstMessage(channel, threadTs) {
        const key = this.key(channel, threadTs);
        const entry = this.firstMessage.get(key);
        if (entry && !entry.consumed) {
          entry.consumed = true;
          this.firstMessage.set(key, entry);
          return entry.text;
        }
        return void 0;
      }
      hasUnconsumedFirstMessage(channel, threadTs) {
        const key = this.key(channel, threadTs);
        const e = this.firstMessage.get(key);
        return !!(e && !e.consumed && e.text && e.text.trim());
      }
      startCleanup(intervalMs = 5 * 60 * 1e3) {
        if (this.timer) clearInterval(this.timer);
        this.timer = setInterval(() => this.cleanup(), intervalMs);
        if (this.timer.unref) this.timer.unref();
      }
      cleanup() {
        const now = Date.now();
        let removed = 0;
        for (const [key, info] of this.waiting.entries()) {
          if (now - info.timestamp > this.ttlMs) {
            this.waiting.delete(key);
            removed++;
          }
        }
        for (const [key] of this.firstMessage.entries()) {
          const waitingInfo = this.waiting.get(key);
          if (!waitingInfo) {
            const entry = this.firstMessage.get(key);
            if (entry?.consumed) {
              this.firstMessage.delete(key);
              removed++;
            }
          }
        }
        if (removed) {
          try {
            logger.info(`[prompt-state] cleanup removed ${removed} entries`);
          } catch {
          }
        }
        return removed;
      }
    };
  }
});

// src/utils/stdin-reader.ts
function isStdinAvailable() {
  return !process.stdin.isTTY;
}
async function readStdin(timeout, maxSize = 1024 * 1024) {
  return new Promise((resolve9, reject) => {
    let data = "";
    let timeoutId;
    if (timeout) {
      timeoutId = setTimeout(() => {
        cleanup();
        reject(new Error(`Stdin read timeout after ${timeout}ms`));
      }, timeout);
    }
    const cleanup = () => {
      if (timeoutId) {
        clearTimeout(timeoutId);
      }
      process.stdin.removeListener("data", onData);
      process.stdin.removeListener("end", onEnd);
      process.stdin.removeListener("error", onError);
      process.stdin.pause();
    };
    const onData = (chunk) => {
      data += chunk.toString();
      if (data.length > maxSize) {
        cleanup();
        reject(new Error(`Input exceeds maximum size of ${maxSize} bytes`));
      }
    };
    const onEnd = () => {
      cleanup();
      resolve9(data.trim());
    };
    const onError = (err) => {
      cleanup();
      reject(err);
    };
    process.stdin.setEncoding("utf8");
    process.stdin.on("data", onData);
    process.stdin.on("end", onEnd);
    process.stdin.on("error", onError);
    process.stdin.resume();
  });
}
async function tryReadStdin(timeout, maxSize = 1024 * 1024) {
  if (!isStdinAvailable()) {
    return null;
  }
  try {
    return await readStdin(timeout, maxSize);
  } catch {
    return null;
  }
}
var init_stdin_reader = __esm({
  "src/utils/stdin-reader.ts"() {
    "use strict";
  }
});

// src/providers/human-input-check-provider.ts
var fs13, path14, HumanInputCheckProvider;
var init_human_input_check_provider = __esm({
  "src/providers/human-input-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_interactive_prompt();
    init_prompt_state();
    init_liquid_extensions();
    init_stdin_reader();
    fs13 = __toESM(require("fs"));
    path14 = __toESM(require("path"));
    HumanInputCheckProvider = class _HumanInputCheckProvider extends CheckProvider {
      liquid;
      /**
       * @deprecated Use ExecutionContext.cliMessage instead
       * Kept for backward compatibility
       */
      static cliMessage;
      /**
       * @deprecated Use ExecutionContext.hooks instead
       * Kept for backward compatibility
       */
      static hooks = {};
      /**
       * Set the CLI message value (from --message argument)
       * @deprecated Use ExecutionContext.cliMessage instead
       */
      static setCLIMessage(message) {
        _HumanInputCheckProvider.cliMessage = message;
      }
      /**
       * Get the current CLI message value
       * @deprecated Use ExecutionContext.cliMessage instead
       */
      static getCLIMessage() {
        return _HumanInputCheckProvider.cliMessage;
      }
      /**
       * Set hooks for SDK mode
       * @deprecated Use ExecutionContext.hooks instead
       */
      static setHooks(hooks) {
        _HumanInputCheckProvider.hooks = hooks;
      }
      getName() {
        return "human-input";
      }
      getDescription() {
        return "Prompts for human input during workflow execution (CLI interactive or SDK hook)";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          return false;
        }
        const cfg = config;
        if (cfg.type !== "human-input") {
          return false;
        }
        if (!cfg.prompt || typeof cfg.prompt !== "string") {
          console.error('human-input check requires a "prompt" field');
          return false;
        }
        return true;
      }
      /** Build a template context for Liquid rendering */
      buildTemplateContext(prInfo, dependencyResults, outputHistory, _context) {
        const ctx = {};
        try {
          ctx.pr = {
            number: prInfo.number,
            title: prInfo.title,
            body: prInfo.body,
            author: prInfo.author,
            base: prInfo.base,
            head: prInfo.head,
            files: (prInfo.files || []).map((f) => ({
              filename: f.filename,
              status: f.status,
              additions: f.additions,
              deletions: f.deletions,
              changes: f.changes
            }))
          };
        } catch {
        }
        try {
          const safeEnv = (() => {
            try {
              const { buildSandboxEnv: buildSandboxEnv2 } = (init_env_exposure(), __toCommonJS(env_exposure_exports));
              return buildSandboxEnv2(process.env);
            } catch {
              return {};
            }
          })();
          ctx.event = { event_name: prInfo?.eventType || "manual" };
          ctx.env = safeEnv;
        } catch {
        }
        ctx.utils = {
          now: (/* @__PURE__ */ new Date()).toISOString(),
          today: (/* @__PURE__ */ new Date()).toISOString().split("T")[0]
        };
        const outputs = {};
        const outputsRaw = {};
        if (dependencyResults) {
          for (const [name, res] of dependencyResults.entries()) {
            const summary = res;
            if (typeof name === "string" && name.endsWith("-raw")) {
              outputsRaw[name.slice(0, -4)] = summary.output !== void 0 ? summary.output : summary;
            } else {
              outputs[name] = summary.output !== void 0 ? summary.output : summary;
            }
          }
        }
        ctx.outputs = outputs;
        ctx.outputs_raw = outputsRaw;
        const hist = {};
        if (outputHistory) {
          for (const [k, v] of outputHistory.entries()) hist[k] = Array.isArray(v) ? v : [];
        }
        ctx.outputs_history = hist;
        try {
          const anyCtx = _context;
          const checksMeta = anyCtx?.checksMeta;
          if (checksMeta && typeof checksMeta === "object") {
            ctx.checks_meta = checksMeta;
          }
        } catch {
        }
        return ctx;
      }
      /**
       * Check if a string looks like a file path
       */
      looksLikePath(str) {
        return str.includes("/") || str.includes("\\");
      }
      /**
       * Sanitize user input to prevent injection attacks in dependent checks
       * Removes potentially dangerous characters while preserving useful input
       */
      sanitizeInput(input) {
        const collapseStutter = (s) => {
          if (!s || s.length < 4) return s;
          let dupPairs = 0;
          let pairs = 0;
          for (let i = 0; i + 1 < s.length; i++) {
            const a = s[i];
            const b = s[i + 1];
            if (/^[\x20-\x7E]$/.test(a) && /^[\x20-\x7E]$/.test(b)) {
              pairs++;
              if (a === b) dupPairs++;
            }
          }
          const ratio = pairs > 0 ? dupPairs / pairs : 0;
          if (ratio < 0.5) return s;
          let out = "";
          for (let i = 0; i < s.length; i++) {
            const a = s[i];
            const b = i + 1 < s.length ? s[i + 1] : "";
            if (b && a === b) {
              out += a;
              i++;
            } else {
              out += a;
            }
          }
          return out;
        };
        input = collapseStutter(input);
        let sanitized = input.replace(/\0/g, "");
        sanitized = sanitized.replace(/[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]/g, "");
        const maxLength = 100 * 1024;
        if (sanitized.length > maxLength) {
          sanitized = sanitized.substring(0, maxLength);
        }
        return sanitized;
      }
      /**
       * Try to read message from file if it exists
       * Validates path to prevent directory traversal attacks
       */
      async tryReadFile(filePath) {
        try {
          const absolutePath = path14.isAbsolute(filePath) ? filePath : path14.resolve(process.cwd(), filePath);
          const normalizedPath = path14.normalize(absolutePath);
          const cwd = process.cwd();
          if (!normalizedPath.startsWith(cwd + path14.sep) && normalizedPath !== cwd) {
            return null;
          }
          try {
            await fs13.promises.access(normalizedPath, fs13.constants.R_OK);
            const stats = await fs13.promises.stat(normalizedPath);
            if (!stats.isFile()) {
              return null;
            }
            const content = await fs13.promises.readFile(normalizedPath, "utf-8");
            return content.trim();
          } catch {
            return null;
          }
        } catch {
        }
        return null;
      }
      /**
       * Get user input through various methods
       */
      async getUserInput(checkName, config, context2) {
        try {
          const payload = context2?.webhookContext?.webhookData?.get(
            config?.endpoint || "/bots/slack/support"
          );
          const ev = payload && payload.event;
          const channel = ev && String(ev.channel || "");
          const threadTs = ev && String(ev.thread_ts || ev.ts || ev.event_ts || "");
          const text = ev && String(ev.text || "");
          if (channel && threadTs) {
            const mgr = getPromptStateManager();
            try {
              const waiting2 = mgr.getWaiting(channel, threadTs);
              const promptsPosted = waiting2?.promptsPosted || 0;
              if (promptsPosted === 0 && mgr.hasUnconsumedFirstMessage(channel, threadTs)) {
                const first = mgr.consumeFirstMessage(channel, threadTs);
                if (first && first.trim().length > 0) {
                  return first;
                }
              }
            } catch {
            }
            const waiting = mgr.getWaiting(channel, threadTs);
            if (waiting && waiting.checkName === checkName) {
              const answer = text.replace(/<@[A-Z0-9]+>/gi, "").trim();
              mgr.clear(channel, threadTs);
              if (!answer && config.allow_empty !== true) {
              } else {
                return answer || config.default || "";
              }
            } else {
              const prompt2 = String(config.prompt || "Please provide input:");
              try {
                await context2?.eventBus?.emit({
                  type: "HumanInputRequested",
                  checkId: checkName,
                  prompt: prompt2,
                  channel,
                  threadTs,
                  threadKey: `${channel}:${threadTs}`
                });
              } catch {
              }
              throw this.buildAwaitingError(checkName, prompt2);
            }
          }
        } catch (e) {
          if (e && e.issues) throw e;
        }
        try {
          const mockVal = context2?.hooks?.mockForStep?.(checkName);
          if (mockVal !== void 0 && mockVal !== null) {
            const s = String(mockVal);
            return s;
          }
        } catch {
        }
        const prompt = config.prompt || "Please provide input:";
        const placeholder = config.placeholder || "Enter your response...";
        const allowEmpty = config.allow_empty ?? false;
        const multiline = config.multiline ?? false;
        const timeout = config.timeout ? config.timeout * 1e3 : void 0;
        const defaultValue = config.default;
        const testMode = String(process.env.VISOR_TEST_MODE || "").toLowerCase() === "true";
        const ciMode = String(process.env.CI || "").toLowerCase() === "true" || String(process.env.GITHUB_ACTIONS || "").toLowerCase() === "true";
        if (testMode || ciMode) {
          const val = config.default || "";
          return val;
        }
        const cliMessage = context2?.cliMessage ?? _HumanInputCheckProvider.cliMessage;
        if (cliMessage !== void 0) {
          const message = cliMessage;
          if (this.looksLikePath(message)) {
            const fileContent = await this.tryReadFile(message);
            if (fileContent !== null) {
              return fileContent;
            }
          }
          return message;
        }
        const stdinInput = await tryReadStdin(timeout);
        if (stdinInput !== null && stdinInput.length > 0) {
          return stdinInput;
        }
        const hooks = context2?.hooks ?? _HumanInputCheckProvider.hooks;
        if (hooks?.onHumanInput) {
          const request = {
            checkId: checkName,
            prompt,
            placeholder,
            allowEmpty,
            multiline,
            timeout,
            default: defaultValue
          };
          try {
            const result = await hooks.onHumanInput(request);
            return result;
          } catch (error) {
            throw new Error(
              `Hook onHumanInput failed: ${error instanceof Error ? error.message : String(error)}`
            );
          }
        }
        if (process.stdin.isTTY) {
          try {
            const result = await interactivePrompt({
              prompt,
              placeholder,
              multiline,
              timeout,
              defaultValue,
              allowEmpty
            });
            return result;
          } catch (error) {
            throw new Error(
              `Interactive prompt failed: ${error instanceof Error ? error.message : String(error)}`
            );
          }
        }
        try {
          const result = await simplePrompt(prompt);
          if (!result && !allowEmpty && !defaultValue) {
            throw new Error("Empty input not allowed");
          }
          return result || defaultValue || "";
        } catch (error) {
          throw new Error(
            `Simple prompt failed: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /** Build a deterministic, fatal error used to pause Slack-driven runs. */
      buildAwaitingError(checkName, prompt) {
        const err = new Error(`awaiting human input for ${checkName}`);
        err.issues = [
          {
            file: "system",
            line: 0,
            ruleId: `${checkName}/execution_error`,
            message: `Awaiting human input (Slack thread): ${prompt.slice(0, 80)}`,
            severity: "error",
            category: "logic"
          }
        ];
        return err;
      }
      async execute(_prInfo, config, _dependencyResults, context2) {
        const checkName = config.checkName || "human-input";
        try {
          try {
            this.liquid = this.liquid || createExtendedLiquid({ strictVariables: false, strictFilters: false });
            const tctx = this.buildTemplateContext(
              _prInfo,
              _dependencyResults,
              config.__outputHistory,
              context2
            );
            if (typeof config.prompt === "string") {
              let rendered = await this.liquid.parseAndRender(config.prompt, tctx);
              if (/\{\{|\{%/.test(rendered)) {
                try {
                  rendered = await this.liquid.parseAndRender(rendered, tctx);
                } catch {
                }
              }
              try {
                const stepName = config.checkName || "unknown";
                context2?.hooks?.onPromptCaptured?.({
                  step: String(stepName),
                  provider: "human-input",
                  prompt: rendered
                });
              } catch {
              }
              config = { ...config, prompt: rendered };
            }
            if (typeof config.placeholder === "string") {
              let ph = await this.liquid.parseAndRender(config.placeholder, tctx);
              if (/\{\{|\{%/.test(ph)) {
                try {
                  ph = await this.liquid.parseAndRender(ph, tctx);
                } catch {
                }
              }
              config.placeholder = ph;
            }
          } catch (e) {
            const err = e || {};
            const raw = String(config?.prompt || "");
            const lines = raw.split(/\r?\n/);
            const lineNum = Number(err.line || err?.token?.line || err?.location?.line || 0);
            const colNum = Number(err.col || err?.token?.col || err?.location?.col || 0);
            let snippet = "";
            if (lineNum > 0) {
              const start = Math.max(1, lineNum - 3);
              const end = Math.max(lineNum + 2, lineNum);
              const width = String(end).length;
              for (let i = start; i <= Math.min(end, lines.length); i++) {
                const ln = `${String(i).padStart(width, " ")} | ${lines[i - 1] ?? ""}`;
                snippet += ln + "\n";
                if (i === lineNum) {
                  const caretPad = " ".repeat(Math.max(0, colNum > 1 ? colNum - 1 : 0) + width + 3);
                  snippet += caretPad + "^\n";
                }
              }
            }
            try {
              console.error(
                `\u26A0\uFE0F  human-input: Liquid render failed: ${e instanceof Error ? e.message : String(e)}
${snippet}`
              );
            } catch {
            }
          }
          const userInput = await this.getUserInput(checkName, config, context2);
          const sanitizedInput = this.sanitizeInput(userInput);
          return {
            issues: [],
            output: { text: sanitizedInput, ts: Date.now() }
          };
        } catch (error) {
          if (error && error.issues) {
            const summary = {
              issues: error.issues
            };
            summary.awaitingHumanInput = true;
            return summary;
          }
          return {
            issues: [
              {
                file: "",
                line: 0,
                ruleId: "human-input-error",
                message: `Failed to get user input: ${error instanceof Error ? error.message : String(error)}`,
                severity: "error",
                category: "logic"
              }
            ]
          };
        }
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "prompt",
          "placeholder",
          "allow_empty",
          "multiline",
          "timeout",
          "default",
          "depends_on",
          "on",
          "if",
          "group"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return [
          "No external dependencies required",
          "Works in CLI mode with --message argument, piped stdin, or interactive prompts",
          "SDK mode requires onHumanInput hook to be configured"
        ];
      }
    };
  }
});

// src/providers/script-check-provider.ts
var ScriptCheckProvider;
var init_script_check_provider = __esm({
  "src/providers/script-check-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_liquid_extensions();
    init_logger();
    init_memory_store();
    init_sandbox();
    init_template_context();
    init_script_memory_ops();
    ScriptCheckProvider = class extends CheckProvider {
      liquid;
      constructor() {
        super();
        this.liquid = createExtendedLiquid({
          strictVariables: false,
          strictFilters: false
        });
      }
      createSecureSandbox() {
        return createSecureSandbox();
      }
      getName() {
        return "script";
      }
      getDescription() {
        return "Execute JavaScript with access to PR context, dependency outputs, and memory.";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") return false;
        const cfg = config;
        if (typeof cfg.content !== "string") return false;
        const trimmed = cfg.content.trim();
        if (trimmed.length === 0) return false;
        try {
          const bytes = Buffer.byteLength(cfg.content, "utf8");
          if (bytes > 1024 * 1024) return false;
        } catch {
        }
        if (cfg.content.indexOf("\0") >= 0) return false;
        return true;
      }
      async execute(prInfo, config, dependencyResults, _sessionInfo) {
        try {
          const stepName = config.checkName || "unknown";
          const mock = _sessionInfo?.hooks?.mockForStep?.(String(stepName));
          if (mock !== void 0) {
            return { issues: [], output: mock };
          }
        } catch {
        }
        const script = String(config.content || "");
        const memoryStore = MemoryStore.getInstance();
        const ctx = buildProviderTemplateContext(
          prInfo,
          dependencyResults,
          memoryStore,
          config.__outputHistory,
          _sessionInfo?.stageHistoryBase,
          { attachMemoryReadHelpers: false, args: _sessionInfo?.args }
        );
        const inputs = config.workflowInputs || _sessionInfo?.workflowInputs || {};
        ctx.inputs = inputs;
        ctx.env = process.env;
        const { ops, needsSave } = createSyncMemoryOps(memoryStore);
        ctx.memory = ops;
        ctx.escapeXml = (str) => {
          if (str == null) return "";
          return String(str).replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;").replace(/"/g, "&quot;").replace(/'/g, "&apos;");
        };
        ctx.btoa = (str) => {
          return Buffer.from(String(str), "binary").toString("base64");
        };
        ctx.atob = (str) => {
          return Buffer.from(String(str), "base64").toString("binary");
        };
        const sandbox = this.createSecureSandbox();
        let result;
        try {
          result = compileAndRun(
            sandbox,
            script,
            { ...ctx },
            {
              injectLog: true,
              wrapFunction: true,
              logPrefix: "[script]"
            }
          );
        } catch (error) {
          const msg = error instanceof Error ? error.message : "Unknown error";
          logger.error(`[script] execution error: ${msg}`);
          return {
            issues: [
              {
                file: "script",
                line: 0,
                ruleId: "script/execution_error",
                message: msg,
                severity: "error",
                category: "logic"
              }
            ],
            output: null
          };
        }
        try {
          if (needsSave() && memoryStore.getConfig().storage === "file" && memoryStore.getConfig().auto_save) {
            await memoryStore.save();
          }
        } catch (e) {
          logger.warn(`[script] memory save failed: ${e instanceof Error ? e.message : String(e)}`);
        }
        try {
          if (process.env.VISOR_DEBUG === "true") {
            const name = String(config.checkName || "");
            const t = typeof result;
            console.error(
              `[script-return] ${name} outputType=${t} hasArray=${Array.isArray(result)} hasObj=${result && typeof result === "object"}`
            );
          }
        } catch {
        }
        const out = { issues: [], output: result };
        try {
          out.__histTracked = true;
        } catch {
        }
        return out;
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "content",
          "depends_on",
          "group",
          "on",
          "if",
          "fail_if",
          "on_fail",
          "on_success"
        ];
      }
      async isAvailable() {
        return true;
      }
      getRequirements() {
        return ["No external dependencies required"];
      }
      // No local buildTemplateContext; uses shared builder above
    };
  }
});

// src/utils/worktree-manager.ts
var fs14, fsp, path15, crypto, WorktreeManager, worktreeManager;
var init_worktree_manager = __esm({
  "src/utils/worktree-manager.ts"() {
    "use strict";
    fs14 = __toESM(require("fs"));
    fsp = __toESM(require("fs/promises"));
    path15 = __toESM(require("path"));
    crypto = __toESM(require("crypto"));
    init_command_executor();
    init_logger();
    WorktreeManager = class _WorktreeManager {
      static instance;
      config;
      activeWorktrees;
      cleanupHandlersRegistered = false;
      constructor() {
        let cwd;
        try {
          cwd = process.cwd() || "/tmp";
        } catch {
          cwd = "/tmp";
        }
        const defaultBasePath = process.env.VISOR_WORKTREE_PATH || path15.join(cwd, ".visor", "worktrees");
        this.config = {
          enabled: true,
          base_path: defaultBasePath,
          cleanup_on_exit: true,
          max_age_hours: 24
        };
        this.activeWorktrees = /* @__PURE__ */ new Map();
        this.ensureDirectories();
        this.registerCleanupHandlers();
      }
      static getInstance() {
        if (!_WorktreeManager.instance) {
          _WorktreeManager.instance = new _WorktreeManager();
        }
        return _WorktreeManager.instance;
      }
      /**
       * Update configuration
       */
      configure(config) {
        this.config = { ...this.config, ...config };
        this.ensureDirectories();
      }
      getConfig() {
        return { ...this.config };
      }
      /**
       * Ensure base directories exist
       */
      ensureDirectories() {
        if (!this.config.base_path) {
          logger.debug("Skipping directory creation: base_path not initialized");
          return;
        }
        const reposDir = this.getReposDir();
        const worktreesDir = this.getWorktreesDir();
        if (!fs14.existsSync(reposDir)) {
          fs14.mkdirSync(reposDir, { recursive: true });
          logger.debug(`Created repos directory: ${reposDir}`);
        }
        if (!fs14.existsSync(worktreesDir)) {
          fs14.mkdirSync(worktreesDir, { recursive: true });
          logger.debug(`Created worktrees directory: ${worktreesDir}`);
        }
      }
      getReposDir() {
        return path15.join(this.config.base_path, "repos");
      }
      getWorktreesDir() {
        return path15.join(this.config.base_path, "worktrees");
      }
      /**
       * Generate a unique worktree ID
       */
      generateWorktreeId(repository, ref) {
        const sanitizedRepo = repository.replace(/[^a-zA-Z0-9-]/g, "-");
        const sanitizedRef = ref.replace(/[^a-zA-Z0-9-]/g, "-");
        const hash = crypto.createHash("md5").update(`${repository}:${ref}:${Date.now()}`).digest("hex").substring(0, 8);
        return `${sanitizedRepo}-${sanitizedRef}-${hash}`;
      }
      /**
       * Get or create bare repository
       */
      async getOrCreateBareRepo(repository, repoUrl, token, fetchDepth, cloneTimeoutMs) {
        const reposDir = this.getReposDir();
        const repoName = repository.replace(/\//g, "-");
        const bareRepoPath = path15.join(reposDir, `${repoName}.git`);
        if (fs14.existsSync(bareRepoPath)) {
          logger.debug(`Bare repository already exists: ${bareRepoPath}`);
          const verifyResult = await this.verifyBareRepoRemote(bareRepoPath, repoUrl);
          if (verifyResult === "timeout") {
            logger.info(`Using stale bare repository (verification timed out): ${bareRepoPath}`);
            return bareRepoPath;
          } else if (verifyResult === false) {
            logger.warn(
              `Bare repository at ${bareRepoPath} has incorrect remote, removing and re-cloning`
            );
            await fsp.rm(bareRepoPath, { recursive: true, force: true });
          } else {
            await this.updateBareRepo(bareRepoPath);
            return bareRepoPath;
          }
        }
        const cloneUrl = this.buildAuthenticatedUrl(repoUrl, token);
        const redactedUrl = this.redactUrl(cloneUrl);
        logger.info(
          `Cloning bare repository: ${redactedUrl}${fetchDepth ? ` (depth: ${fetchDepth})` : ""}`
        );
        let cloneCmd = `git clone --bare`;
        if (fetchDepth && fetchDepth > 0) {
          const depth = parseInt(String(fetchDepth), 10);
          if (isNaN(depth) || depth < 1) {
            throw new Error("fetch_depth must be a positive integer");
          }
          cloneCmd += ` --depth ${depth}`;
        }
        cloneCmd += ` ${this.escapeShellArg(cloneUrl)} ${this.escapeShellArg(bareRepoPath)}`;
        const result = await this.executeGitCommand(cloneCmd, {
          timeout: cloneTimeoutMs || 3e5
          // default 5 minutes
        });
        if (result.exitCode !== 0) {
          const redactedStderr = this.redactUrl(result.stderr);
          throw new Error(`Failed to clone bare repository: ${redactedStderr}`);
        }
        logger.info(`Successfully cloned bare repository to ${bareRepoPath}`);
        return bareRepoPath;
      }
      /**
       * Update bare repository refs
       */
      async updateBareRepo(bareRepoPath) {
        logger.debug(`Updating bare repository: ${bareRepoPath}`);
        try {
          const updateCmd = `git -C ${this.escapeShellArg(bareRepoPath)} remote update --prune`;
          const result = await this.executeGitCommand(updateCmd, { timeout: 6e4 });
          if (result.exitCode !== 0) {
            logger.warn(`Failed to update bare repository: ${result.stderr}`);
          } else {
            logger.debug(`Successfully updated bare repository`);
          }
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.warn(`Failed to update bare repository (will use stale refs): ${errorMessage}`);
        }
      }
      /**
       * Verify that a bare repository has the correct remote URL.
       * This prevents reusing corrupted repos that were cloned from a different repository.
       * Returns: true (valid), false (invalid - should re-clone), or 'timeout' (use stale cache)
       */
      async verifyBareRepoRemote(bareRepoPath, expectedUrl) {
        try {
          const cmd = `git -C ${this.escapeShellArg(bareRepoPath)} remote get-url origin`;
          const result = await this.executeGitCommand(cmd, { timeout: 1e4 });
          if (result.exitCode !== 0) {
            logger.warn(`Failed to get remote URL for ${bareRepoPath}: ${result.stderr}`);
            return false;
          }
          const actualUrl = result.stdout.trim();
          const normalizeUrl = (url) => {
            if (url.startsWith("git@github.com:")) {
              url = url.replace("git@github.com:", "https://github.com/");
            }
            return url.replace(/:\/\/[^@]+@/, "://").replace(/\.git$/, "").replace(/\/$/, "").toLowerCase();
          };
          const normalizedExpected = normalizeUrl(expectedUrl);
          const normalizedActual = normalizeUrl(actualUrl);
          if (normalizedExpected !== normalizedActual) {
            logger.warn(`Bare repo remote mismatch: expected ${expectedUrl}, got ${actualUrl}`);
            return false;
          }
          logger.debug(`Bare repo remote verified: ${actualUrl}`);
          return true;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          if (errorMessage.includes("timed out")) {
            logger.warn(`Timeout verifying bare repo remote (will use stale cache): ${errorMessage}`);
            return "timeout";
          }
          logger.warn(`Error verifying bare repo remote: ${error}`);
          return false;
        }
      }
      /**
       * Create a new worktree for the given repository/ref.
       *
       * Important: we always create worktrees in a detached HEAD state pinned
       * to a specific commit SHA rather than a named branch like "main". Git
       * only allows a branch to be checked out in a single worktree at a time;
       * using the raw commit (plus --detach) lets multiple workflows safely
       * create independent worktrees for the same branch without hitting
       * errors like:
       *
       *   fatal: 'main' is already used by worktree at '.../TykTechnologies-tyk-docs-main-XXXX'
       */
      async createWorktree(repository, repoUrl, ref, options = {}) {
        this.validateRef(ref);
        const bareRepoPath = await this.getOrCreateBareRepo(
          repository,
          repoUrl,
          options.token,
          options.fetchDepth,
          options.cloneTimeoutMs
        );
        const worktreeId = this.generateWorktreeId(repository, ref);
        let worktreePath = options.workingDirectory || path15.join(this.getWorktreesDir(), worktreeId);
        if (options.workingDirectory) {
          worktreePath = this.validatePath(options.workingDirectory);
        }
        if (fs14.existsSync(worktreePath)) {
          logger.debug(`Worktree already exists: ${worktreePath}`);
          const metadata2 = await this.loadMetadata(worktreePath);
          if (metadata2) {
            if (metadata2.ref === ref) {
              if (options.clean) {
                logger.debug(`Cleaning existing worktree`);
                await this.cleanWorktree(worktreePath);
              }
              this.activeWorktrees.set(worktreeId, metadata2);
              return {
                id: worktreeId,
                path: worktreePath,
                ref: metadata2.ref,
                commit: metadata2.commit,
                metadata: metadata2,
                locked: false
              };
            } else {
              logger.info(
                `Worktree exists with different ref (${metadata2.ref} -> ${ref}), updating...`
              );
              try {
                const bareRepoPath2 = metadata2.bare_repo_path || await this.getOrCreateBareRepo(
                  repository,
                  repoUrl,
                  options.token,
                  options.fetchDepth,
                  options.cloneTimeoutMs
                );
                await this.fetchRef(bareRepoPath2, ref);
                const newCommit = await this.getCommitShaForRef(bareRepoPath2, ref);
                const checkoutCmd = `git -C ${this.escapeShellArg(worktreePath)} checkout --detach ${this.escapeShellArg(newCommit)}`;
                const checkoutResult = await this.executeGitCommand(checkoutCmd, { timeout: 6e4 });
                if (checkoutResult.exitCode !== 0) {
                  throw new Error(`Failed to checkout new ref: ${checkoutResult.stderr}`);
                }
                const updatedMetadata = {
                  ...metadata2,
                  ref,
                  commit: newCommit,
                  created_at: (/* @__PURE__ */ new Date()).toISOString()
                };
                await this.saveMetadata(worktreePath, updatedMetadata);
                if (options.clean) {
                  logger.debug(`Cleaning updated worktree`);
                  await this.cleanWorktree(worktreePath);
                }
                this.activeWorktrees.set(worktreeId, updatedMetadata);
                logger.info(`Successfully updated worktree to ${ref} (${newCommit})`);
                return {
                  id: worktreeId,
                  path: worktreePath,
                  ref,
                  commit: newCommit,
                  metadata: updatedMetadata,
                  locked: false
                };
              } catch (error) {
                const errorMessage = error instanceof Error ? error.message : String(error);
                logger.warn(`Failed to update worktree, will recreate: ${errorMessage}`);
                await fsp.rm(worktreePath, { recursive: true, force: true });
              }
            }
          } else {
            logger.info(`Removing stale directory (no metadata): ${worktreePath}`);
            await fsp.rm(worktreePath, { recursive: true, force: true });
          }
        }
        await this.fetchRef(bareRepoPath, ref);
        const commit = await this.getCommitShaForRef(bareRepoPath, ref);
        await this.pruneWorktrees(bareRepoPath);
        logger.info(`Creating worktree for ${repository}@${ref} (${commit})`);
        const createCmd = `git -C ${this.escapeShellArg(
          bareRepoPath
        )} worktree add --detach ${this.escapeShellArg(worktreePath)} ${this.escapeShellArg(commit)}`;
        const result = await this.executeGitCommand(createCmd, { timeout: 6e4 });
        if (result.exitCode !== 0) {
          throw new Error(`Failed to create worktree: ${result.stderr}`);
        }
        const metadata = {
          worktree_id: worktreeId,
          created_at: (/* @__PURE__ */ new Date()).toISOString(),
          workflow_id: options.workflowId,
          ref,
          commit,
          repository,
          pid: process.pid,
          cleanup_on_exit: true,
          bare_repo_path: bareRepoPath,
          worktree_path: worktreePath
        };
        await this.saveMetadata(worktreePath, metadata);
        this.activeWorktrees.set(worktreeId, metadata);
        logger.info(`Successfully created worktree: ${worktreePath}`);
        return {
          id: worktreeId,
          path: worktreePath,
          ref,
          commit,
          metadata,
          locked: false
        };
      }
      /**
       * Prune stale worktree entries from a bare repository.
       * This removes entries for worktrees whose directories no longer exist.
       */
      async pruneWorktrees(bareRepoPath) {
        logger.debug(`Pruning stale worktrees for ${bareRepoPath}`);
        const pruneCmd = `git -C ${this.escapeShellArg(bareRepoPath)} worktree prune`;
        const result = await this.executeGitCommand(pruneCmd, { timeout: 1e4 });
        if (result.exitCode !== 0) {
          logger.warn(`Failed to prune worktrees: ${result.stderr}`);
        } else {
          logger.debug(`Successfully pruned stale worktrees`);
        }
      }
      /**
       * Fetch a specific ref in bare repository
       */
      async fetchRef(bareRepoPath, ref) {
        this.validateRef(ref);
        logger.debug(`Fetching ref: ${ref}`);
        const fetchCmd = `git -C ${this.escapeShellArg(bareRepoPath)} fetch origin ${this.escapeShellArg(ref + ":" + ref)} 2>&1 || true`;
        await this.executeGitCommand(fetchCmd, { timeout: 6e4 });
      }
      /**
       * Clean worktree (reset and remove untracked files)
       */
      async cleanWorktree(worktreePath) {
        const resetCmd = `git -C ${this.escapeShellArg(worktreePath)} reset --hard HEAD`;
        await this.executeGitCommand(resetCmd);
        const cleanCmd = `git -C ${this.escapeShellArg(worktreePath)} clean -fdx`;
        await this.executeGitCommand(cleanCmd);
      }
      /**
       * Get commit SHA for a given ref inside a bare repository.
       *
       * This runs after fetchRef so that <ref> should resolve to either a
       * local branch, tag, or remote-tracking ref.
       *
       * If the ref is "main" or "master" and doesn't exist, automatically
       * falls back to the other common default branch name.
       */
      async getCommitShaForRef(bareRepoPath, ref) {
        const cmd = `git -C ${this.escapeShellArg(bareRepoPath)} rev-parse ${this.escapeShellArg(ref)}`;
        const result = await this.executeGitCommand(cmd);
        if (result.exitCode !== 0) {
          const fallbackRefs = {
            main: "master",
            master: "main"
          };
          const fallbackRef = fallbackRefs[ref];
          if (fallbackRef) {
            logger.debug(`Ref '${ref}' not found, trying fallback '${fallbackRef}'`);
            await this.fetchRef(bareRepoPath, fallbackRef);
            const fallbackCmd = `git -C ${this.escapeShellArg(bareRepoPath)} rev-parse ${this.escapeShellArg(fallbackRef)}`;
            const fallbackResult = await this.executeGitCommand(fallbackCmd);
            if (fallbackResult.exitCode === 0) {
              logger.info(`Using fallback branch '${fallbackRef}' instead of '${ref}'`);
              return fallbackResult.stdout.trim();
            }
          }
          throw new Error(`Failed to get commit SHA for ref ${ref}: ${result.stderr}`);
        }
        return result.stdout.trim();
      }
      /**
       * Remove a worktree
       */
      async removeWorktree(worktreeId) {
        const metadata = this.activeWorktrees.get(worktreeId);
        if (!metadata) {
          logger.warn(`Worktree not found in active list: ${worktreeId}`);
          return;
        }
        const { bare_repo_path, worktree_path } = metadata;
        logger.info(`Removing worktree: ${worktree_path}`);
        const removeCmd = `git -C ${this.escapeShellArg(bare_repo_path)} worktree remove ${this.escapeShellArg(worktree_path)} --force`;
        const result = await this.executeGitCommand(removeCmd, { timeout: 3e4 });
        if (result.exitCode !== 0) {
          logger.warn(`Failed to remove worktree via git: ${result.stderr}`);
          if (fs14.existsSync(worktree_path)) {
            logger.debug(`Manually removing worktree directory`);
            fs14.rmSync(worktree_path, { recursive: true, force: true });
          }
        }
        this.activeWorktrees.delete(worktreeId);
        logger.info(`Successfully removed worktree: ${worktreeId}`);
      }
      /**
       * Save worktree metadata
       */
      async saveMetadata(worktreePath, metadata) {
        const metadataPath = path15.join(worktreePath, ".visor-metadata.json");
        fs14.writeFileSync(metadataPath, JSON.stringify(metadata, null, 2), "utf8");
      }
      /**
       * Load worktree metadata
       */
      async loadMetadata(worktreePath) {
        const metadataPath = path15.join(worktreePath, ".visor-metadata.json");
        if (!fs14.existsSync(metadataPath)) {
          return null;
        }
        try {
          const content = fs14.readFileSync(metadataPath, "utf8");
          return JSON.parse(content);
        } catch (error) {
          logger.warn(`Failed to load metadata: ${error}`);
          return null;
        }
      }
      /**
       * List all worktrees
       */
      async listWorktrees() {
        const worktreesDir = this.getWorktreesDir();
        if (!fs14.existsSync(worktreesDir)) {
          return [];
        }
        const entries = fs14.readdirSync(worktreesDir, { withFileTypes: true });
        const worktrees = [];
        for (const entry of entries) {
          if (!entry.isDirectory()) continue;
          const worktreePath = path15.join(worktreesDir, entry.name);
          const metadata = await this.loadMetadata(worktreePath);
          if (metadata) {
            worktrees.push({
              id: metadata.worktree_id,
              path: worktreePath,
              ref: metadata.ref,
              commit: metadata.commit,
              metadata,
              locked: this.isProcessAlive(metadata.pid)
            });
          }
        }
        return worktrees;
      }
      /**
       * Cleanup stale worktrees
       */
      async cleanupStaleWorktrees() {
        logger.debug("Cleaning up stale worktrees");
        const worktrees = await this.listWorktrees();
        const now = /* @__PURE__ */ new Date();
        const maxAgeMs = this.config.max_age_hours * 60 * 60 * 1e3;
        for (const worktree of worktrees) {
          const createdAt = new Date(worktree.metadata.created_at);
          const ageMs = now.getTime() - createdAt.getTime();
          if (worktree.locked) {
            continue;
          }
          if (ageMs > maxAgeMs) {
            logger.info(
              `Removing stale worktree: ${worktree.id} (age: ${Math.round(ageMs / 1e3 / 60)} minutes)`
            );
            await this.removeWorktree(worktree.id);
          }
        }
      }
      /**
       * Cleanup all worktrees for current process
       */
      async cleanupProcessWorktrees() {
        logger.debug("Cleaning up worktrees for current process");
        const currentPid = process.pid;
        const worktrees = await this.listWorktrees();
        for (const worktree of worktrees) {
          if (worktree.metadata.pid === currentPid && worktree.metadata.cleanup_on_exit) {
            logger.info(`Cleaning up worktree: ${worktree.id}`);
            await this.removeWorktree(worktree.id);
          }
        }
      }
      /**
       * Check if a process is alive
       */
      isProcessAlive(pid) {
        try {
          process.kill(pid, 0);
          return true;
        } catch (_error) {
          return false;
        }
      }
      /**
       * Register cleanup handlers
       */
      registerCleanupHandlers() {
        if (this.cleanupHandlersRegistered) {
          return;
        }
        if (this.config.cleanup_on_exit) {
          process.on("exit", () => {
            logger.debug("Process exiting, cleanup handler triggered");
          });
          process.on("SIGINT", async () => {
            logger.info("SIGINT received, cleaning up worktrees");
            await this.cleanupProcessWorktrees();
            process.exit(130);
          });
          process.on("SIGTERM", async () => {
            logger.info("SIGTERM received, cleaning up worktrees");
            await this.cleanupProcessWorktrees();
            process.exit(143);
          });
          process.on("uncaughtException", async (error) => {
            logger.error(`Uncaught exception, cleaning up worktrees: ${error}`);
            await this.cleanupProcessWorktrees();
            process.exit(1);
          });
        }
        this.cleanupHandlersRegistered = true;
      }
      /**
       * Escape shell argument to prevent command injection
       *
       * Uses POSIX-standard single-quote escaping which prevents ALL shell metacharacter
       * interpretation (including $, `, \, ", ;, &, |, etc.)
       *
       * How it works:
       * - Everything is wrapped in single quotes: 'arg'
       * - Single quotes within are escaped as: '  '\''
       *   (close quote, literal escaped quote, open quote)
       *
       * This is safer than double quotes which still allow $expansion and `backticks`
       *
       * Example: "foo'bar"  'foo'\''bar'
       */
      escapeShellArg(arg) {
        return `'${arg.replace(/'/g, "'\\''")}'`;
      }
      /**
       * Validate git ref to prevent command injection
       */
      validateRef(ref) {
        const safeRefPattern = /^[a-zA-Z0-9._/:-]+$/;
        if (!safeRefPattern.test(ref)) {
          throw new Error(
            `Invalid git ref: ${ref}. Refs must only contain alphanumeric characters, dots, underscores, slashes, colons, and hyphens.`
          );
        }
        if (ref.includes("..") || ref.startsWith("-") || ref.endsWith(".lock")) {
          throw new Error(
            `Invalid git ref: ${ref}. Refs cannot contain '..', start with '-', or end with '.lock'.`
          );
        }
        if (ref.length > 256) {
          throw new Error(`Invalid git ref: ${ref}. Refs cannot exceed 256 characters.`);
        }
      }
      /**
       * Validate path to prevent directory traversal
       */
      validatePath(userPath) {
        const resolvedPath = path15.resolve(userPath);
        if (!path15.isAbsolute(resolvedPath)) {
          throw new Error("Path must be absolute");
        }
        const sensitivePatterns = [
          "/etc",
          "/root",
          "/boot",
          "/sys",
          "/proc",
          "/dev",
          "C:\\Windows\\System32",
          "C:\\Program Files"
        ];
        for (const pattern of sensitivePatterns) {
          if (resolvedPath.startsWith(pattern)) {
            throw new Error(`Access to system directory ${pattern} is not allowed`);
          }
        }
        return resolvedPath;
      }
      /**
       * Redact sensitive tokens from URLs for logging
       */
      redactUrl(url) {
        return url.replace(/x-access-token:[^@]+@/g, "x-access-token:[REDACTED]@").replace(/:\/\/[^:]+:[^@]+@/g, "://[REDACTED]:[REDACTED]@");
      }
      /**
       * Execute a git command
       */
      async executeGitCommand(command, options = {}) {
        const gitEnv = {
          ...process.env,
          ...options.env,
          GIT_TERMINAL_PROMPT: "0",
          GIT_SSH_COMMAND: "ssh -o BatchMode=yes -o StrictHostKeyChecking=no"
        };
        const result = await commandExecutor.execute(command, {
          timeout: options.timeout || 3e4,
          env: gitEnv
        });
        return {
          stdout: result.stdout,
          stderr: result.stderr,
          exitCode: result.exitCode
        };
      }
      /**
       * Build authenticated URL with token
       */
      buildAuthenticatedUrl(repoUrl, token) {
        if (!token) {
          return repoUrl;
        }
        if (repoUrl.includes("github.com")) {
          if (repoUrl.startsWith("git@github.com:")) {
            repoUrl = repoUrl.replace("git@github.com:", "https://github.com/");
          }
          if (repoUrl.startsWith("https://")) {
            return repoUrl.replace("https://", `https://x-access-token:${token}@`);
          }
        }
        return repoUrl;
      }
      /**
       * Get repository URL from repository identifier
       */
      getRepositoryUrl(repository, _token) {
        if (repository.startsWith("http://") || repository.startsWith("https://") || repository.startsWith("git@")) {
          return repository;
        }
        return `https://github.com/${repository}.git`;
      }
    };
    worktreeManager = WorktreeManager.getInstance();
  }
});

// src/providers/git-checkout-provider.ts
var GitCheckoutProvider;
var init_git_checkout_provider = __esm({
  "src/providers/git-checkout-provider.ts"() {
    "use strict";
    init_check_provider_interface();
    init_worktree_manager();
    init_logger();
    init_liquid_extensions();
    init_env_exposure();
    GitCheckoutProvider = class extends CheckProvider {
      liquid = createExtendedLiquid();
      getName() {
        return "git-checkout";
      }
      getDescription() {
        return "Checkout code from git repositories using worktrees for efficient multi-workflow execution";
      }
      async validateConfig(config) {
        if (!config || typeof config !== "object") {
          logger.error("Invalid config: must be an object");
          return false;
        }
        const checkoutConfig = config;
        if (!checkoutConfig.ref || typeof checkoutConfig.ref !== "string") {
          logger.error("Invalid config: ref is required and must be a string");
          return false;
        }
        if (checkoutConfig.fetch_depth !== void 0) {
          if (typeof checkoutConfig.fetch_depth !== "number" || checkoutConfig.fetch_depth < 0) {
            logger.error("Invalid config: fetch_depth must be a non-negative number");
            return false;
          }
        }
        if (checkoutConfig.fetch_tags !== void 0 && typeof checkoutConfig.fetch_tags !== "boolean") {
          logger.error("Invalid config: fetch_tags must be a boolean");
          return false;
        }
        if (checkoutConfig.submodules !== void 0) {
          const validSubmoduleValues = [true, false, "recursive"];
          if (!validSubmoduleValues.includes(checkoutConfig.submodules)) {
            logger.error('Invalid config: submodules must be true, false, or "recursive"');
            return false;
          }
        }
        if (checkoutConfig.sparse_checkout !== void 0 && !Array.isArray(checkoutConfig.sparse_checkout)) {
          logger.error("Invalid config: sparse_checkout must be an array");
          return false;
        }
        if (checkoutConfig.clone_timeout_ms !== void 0) {
          if (typeof checkoutConfig.clone_timeout_ms !== "number" || checkoutConfig.clone_timeout_ms <= 0) {
            logger.error("Invalid config: clone_timeout_ms must be a positive number (milliseconds)");
            return false;
          }
        }
        return true;
      }
      async execute(prInfo, config, dependencyResults, context2) {
        const checkoutConfig = config;
        const issues = [];
        try {
          const stepName = config.checkName || "git-checkout";
          if (process.env.VISOR_DEBUG === "true") {
            logger.debug(
              `[GitCheckout] Mock check: stepName=${stepName}, context=${!!context2}, hooks=${!!context2?.hooks}, mockForStep=${!!context2?.hooks?.mockForStep}`
            );
          }
          const mock = context2?.hooks?.mockForStep?.(String(stepName));
          if (process.env.VISOR_DEBUG === "true") {
            logger.debug(
              `[GitCheckout] Mock result: ${mock !== void 0 ? "found" : "not found"}, value=${JSON.stringify(mock)}`
            );
          }
          if (mock !== void 0) {
            if (mock && typeof mock === "object") {
              const mockOutput = mock;
              if (mockOutput.success === false) {
                const errorMsg = String(mockOutput.error || "Mocked checkout failure");
                if (process.env.VISOR_DEBUG === "true") {
                  logger.debug(`[GitCheckout] Returning mock failure: ${errorMsg}`);
                }
                return {
                  issues: [
                    {
                      file: "git-checkout",
                      line: 0,
                      ruleId: "git-checkout/error",
                      message: `Failed to checkout code: ${errorMsg}`,
                      severity: "error",
                      category: "logic"
                    }
                  ],
                  output: mockOutput
                };
              }
              if (process.env.VISOR_DEBUG === "true") {
                logger.debug(`[GitCheckout] Returning mock success: ${JSON.stringify(mockOutput)}`);
              }
              return { issues: [], output: mockOutput };
            }
            if (process.env.VISOR_DEBUG === "true") {
              logger.debug(`[GitCheckout] Returning primitive mock: ${String(mock)}`);
            }
            return { issues: [], output: { success: true, path: String(mock) } };
          }
        } catch {
        }
        try {
          const templateContext = this.buildTemplateContext(
            prInfo,
            dependencyResults,
            context2,
            checkoutConfig
          );
          let resolvedRef = await this.liquid.parseAndRender(checkoutConfig.ref, templateContext);
          if (!resolvedRef || resolvedRef.trim().length === 0) {
            resolvedRef = "HEAD";
          }
          const resolvedRepository = checkoutConfig.repository ? await this.liquid.parseAndRender(checkoutConfig.repository, templateContext) : process.env.GITHUB_REPOSITORY || "unknown/unknown";
          const resolvedToken = checkoutConfig.token ? await this.liquid.parseAndRender(checkoutConfig.token, templateContext) : void 0;
          const resolvedWorkingDirectory = checkoutConfig.working_directory ? await this.liquid.parseAndRender(checkoutConfig.working_directory, templateContext) : void 0;
          logger.info(`Checking out repository: ${resolvedRepository}@${resolvedRef}`);
          const repoUrl = worktreeManager.getRepositoryUrl(resolvedRepository, resolvedToken);
          const worktree = await worktreeManager.createWorktree(
            resolvedRepository,
            repoUrl,
            resolvedRef,
            {
              token: resolvedToken,
              workingDirectory: resolvedWorkingDirectory,
              clean: checkoutConfig.clean !== false,
              // Default: true
              workflowId: context2?.workflowId,
              fetchDepth: checkoutConfig.fetch_depth,
              cloneTimeoutMs: checkoutConfig.clone_timeout_ms
            }
          );
          const output = {
            success: true,
            path: worktree.path,
            ref: resolvedRef,
            commit: worktree.commit,
            worktree_id: worktree.id,
            repository: resolvedRepository,
            is_worktree: true
          };
          const workspace = context2?._parentContext?.workspace;
          const checkName = config?.checkName || "unknown";
          logger.info(`[GitCheckout] Workspace check for '${checkName}':`);
          logger.info(`[GitCheckout]   _parentContext exists: ${!!context2?._parentContext}`);
          logger.info(`[GitCheckout]   workspace exists: ${!!workspace}`);
          logger.info(`[GitCheckout]   workspace.isEnabled(): ${workspace?.isEnabled?.() ?? "N/A"}`);
          if (workspace) {
            const projectCountBefore = workspace.listProjects?.()?.length ?? "N/A";
            logger.debug(`[GitCheckout]   projects before addProject: ${projectCountBefore}`);
          }
          if (workspace?.isEnabled()) {
            try {
              const workspacePath = await workspace.addProject(resolvedRepository, worktree.path);
              output.workspace_path = workspacePath;
              const projectCountAfter = workspace.listProjects?.()?.length ?? "N/A";
              logger.debug(`[GitCheckout] Added project to workspace: ${workspacePath}`);
              logger.debug(`[GitCheckout]   projects after addProject: ${projectCountAfter}`);
            } catch (error) {
              logger.warn(`Failed to add project to workspace: ${error}`);
            }
          } else {
            logger.debug(`[GitCheckout] Workspace not enabled, skipping addProject`);
          }
          logger.info(
            `Successfully checked out ${resolvedRepository}@${resolvedRef} to ${worktree.path}`
          );
          return {
            issues,
            output
          };
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          logger.error(`Git checkout failed: ${errorMessage}`);
          issues.push({
            file: "git-checkout",
            line: 0,
            ruleId: "git-checkout/error",
            message: `Failed to checkout code: ${errorMessage}`,
            severity: "error",
            category: "logic"
          });
          const output = {
            success: false,
            error: errorMessage
          };
          return {
            issues,
            output
          };
        }
      }
      /**
       * Build template context for variable resolution
       */
      buildTemplateContext(prInfo, dependencyResults, context2, config) {
        const outputsObj = {};
        if (dependencyResults) {
          for (const [checkName, result] of dependencyResults.entries()) {
            outputsObj[checkName] = result.output !== void 0 ? result.output : result;
          }
        }
        const outputHistory = config?.__outputHistory;
        const historyObj = {};
        if (outputHistory) {
          for (const [checkName, history] of outputHistory.entries()) {
            historyObj[checkName] = history;
          }
        }
        const safeEnv = buildSandboxEnv(process.env);
        return {
          pr: {
            number: prInfo.number,
            title: prInfo.title,
            author: prInfo.author,
            head: prInfo.head,
            base: prInfo.base,
            repo: process.env.GITHUB_REPOSITORY || "",
            files: prInfo.files
          },
          files: prInfo.files,
          outputs: outputsObj,
          outputs_history: historyObj,
          env: safeEnv,
          // Check config first (set by projectWorkflowToGraph), then fall back to context
          inputs: config?.workflowInputs || context2?.workflowInputs
        };
      }
      getSupportedConfigKeys() {
        return [
          "type",
          "ref",
          "repository",
          "token",
          "fetch_depth",
          "fetch_tags",
          "submodules",
          "working_directory",
          "use_worktree",
          "clean",
          "sparse_checkout",
          "lfs",
          "timeout",
          "criticality",
          "assume",
          "guarantee",
          "cleanup_on_failure",
          "persist_worktree",
          "depends_on",
          "if",
          "fail_if",
          "on"
        ];
      }
      async isAvailable() {
        try {
          const { commandExecutor: commandExecutor2 } = await Promise.resolve().then(() => (init_command_executor(), command_executor_exports));
          const result = await commandExecutor2.execute("git --version", { timeout: 5e3 });
          return result.exitCode === 0;
        } catch (_error) {
          return false;
        }
      }
      getRequirements() {
        return ["git"];
      }
    };
  }
});

// src/providers/check-provider-registry.ts
var check_provider_registry_exports = {};
__export(check_provider_registry_exports, {
  CheckProviderRegistry: () => CheckProviderRegistry
});
var CheckProviderRegistry;
var init_check_provider_registry = __esm({
  "src/providers/check-provider-registry.ts"() {
    "use strict";
    init_ai_check_provider();
    init_http_check_provider();
    init_http_input_provider();
    init_http_client_provider();
    init_noop_check_provider();
    init_log_check_provider();
    init_github_ops_provider();
    init_claude_code_check_provider();
    init_command_check_provider();
    init_memory_check_provider();
    init_mcp_check_provider();
    init_human_input_check_provider();
    init_script_check_provider();
    init_workflow_check_provider();
    init_git_checkout_provider();
    CheckProviderRegistry = class _CheckProviderRegistry {
      providers = /* @__PURE__ */ new Map();
      static instance;
      customTools;
      constructor() {
        this.registerDefaultProviders();
      }
      /**
       * Get singleton instance
       */
      static getInstance() {
        if (!_CheckProviderRegistry.instance) {
          _CheckProviderRegistry.instance = new _CheckProviderRegistry();
        }
        return _CheckProviderRegistry.instance;
      }
      /**
       * Register default built-in providers
       */
      registerDefaultProviders() {
        this.register(new AICheckProvider());
        this.register(new CommandCheckProvider());
        this.register(new ScriptCheckProvider());
        this.register(new HttpCheckProvider());
        this.register(new HttpInputProvider());
        this.register(new HttpClientProvider());
        this.register(new NoopCheckProvider());
        this.register(new LogCheckProvider());
        this.register(new MemoryCheckProvider());
        this.register(new GitHubOpsProvider());
        this.register(new HumanInputCheckProvider());
        this.register(new WorkflowCheckProvider());
        this.register(new GitCheckoutProvider());
        try {
          this.register(new ClaudeCodeCheckProvider());
        } catch (error) {
          console.error(
            `Warning: Failed to register ClaudeCodeCheckProvider: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
        try {
          const mcpProvider = new McpCheckProvider();
          if (this.customTools) {
            mcpProvider.setCustomTools(this.customTools);
          }
          this.register(mcpProvider);
        } catch (error) {
          console.error(
            `Warning: Failed to register McpCheckProvider: ${error instanceof Error ? error.message : "Unknown error"}`
          );
        }
      }
      /**
       * Register a check provider
       */
      register(provider) {
        const name = provider.getName();
        if (this.providers.has(name)) {
          throw new Error(`Provider '${name}' is already registered`);
        }
        this.providers.set(name, provider);
        if (process.env.VISOR_DEBUG === "true") {
          console.error(`Registered check provider: ${name}`);
        }
      }
      /**
       * Unregister a check provider
       */
      unregister(name) {
        if (!this.providers.has(name)) {
          throw new Error(`Provider '${name}' not found`);
        }
        this.providers.delete(name);
        console.error(`Unregistered check provider: ${name}`);
      }
      /**
       * Get a provider by name
       */
      getProvider(name) {
        return this.providers.get(name);
      }
      /**
       * Get provider or throw if not found
       */
      getProviderOrThrow(name) {
        const provider = this.providers.get(name);
        if (!provider) {
          throw new Error(
            `Check provider '${name}' not found. Available providers: ${this.getAvailableProviders().join(", ")}`
          );
        }
        return provider;
      }
      /**
       * Check if a provider exists
       */
      hasProvider(name) {
        return this.providers.has(name);
      }
      /**
       * Get all registered provider names
       */
      getAvailableProviders() {
        return Array.from(this.providers.keys());
      }
      /**
       * Get all providers
       */
      getAllProviders() {
        return Array.from(this.providers.values());
      }
      /**
       * Set custom tools that can be used by the MCP provider
       */
      setCustomTools(tools) {
        this.customTools = tools;
        const mcpProvider = this.providers.get("mcp");
        if (mcpProvider) {
          mcpProvider.setCustomTools(tools);
        }
      }
      /**
       * Get providers that are currently available (have required dependencies)
       */
      async getActiveProviders() {
        const providers = this.getAllProviders();
        const activeProviders = [];
        for (const provider of providers) {
          if (await provider.isAvailable()) {
            activeProviders.push(provider);
          }
        }
        return activeProviders;
      }
      /**
       * List provider information
       */
      async listProviders() {
        const providers = this.getAllProviders();
        const info = [];
        for (const provider of providers) {
          info.push({
            name: provider.getName(),
            description: provider.getDescription(),
            available: await provider.isAvailable(),
            requirements: provider.getRequirements()
          });
        }
        return info;
      }
      /**
       * Reset registry (mainly for testing)
       */
      reset() {
        this.providers.clear();
        this.registerDefaultProviders();
      }
      /**
       * Clear singleton instance (for testing)
       */
      static clearInstance() {
        _CheckProviderRegistry.instance = void 0;
      }
    };
  }
});

// src/state-machine/dispatch/foreach-processor.ts
async function executeCheckWithForEachItems(checkId, forEachParent, forEachItems, context2, state, emitEvent, transition) {
  try {
    const snapId = context2.journal.beginSnapshot();
    const visible = context2.journal.readVisible(context2.sessionId, snapId, context2.event);
    let latestItems;
    for (let i = visible.length - 1; i >= 0; i--) {
      const e = visible[i];
      if (e.checkId === forEachParent && Array.isArray(e.scope) && e.scope.length === 0) {
        const r = e.result;
        if (r && Array.isArray(r.forEachItems)) {
          latestItems = r.forEachItems;
          break;
        }
      }
    }
    if (Array.isArray(latestItems)) {
      if (context2.debug) {
        try {
          const prevLen = Array.isArray(forEachItems) ? forEachItems.length : 0;
          const newLen = latestItems.length;
          if (prevLen !== newLen) {
            logger.info(
              `[LevelDispatch] Refreshing forEachItems for ${checkId}: from parent '${forEachParent}' latestItems=${newLen} (was ${prevLen})`
            );
          }
        } catch {
        }
      }
      forEachItems = latestItems;
    }
  } catch (e) {
    if (context2.debug) {
      logger.warn(
        `[LevelDispatch] Failed to refresh forEachItems from journal for ${forEachParent}: ${e}`
      );
    }
  }
  const checkConfig = context2.config.checks?.[checkId];
  if (!checkConfig) {
    throw new Error(`Check configuration not found: ${checkId}`);
  }
  logger.info(
    `[LevelDispatch][DEBUG] executeCheckWithForEachItems: checkId=${checkId}, forEachParent=${forEachParent}, items=${forEachItems.length}`
  );
  logger.info(
    `[LevelDispatch][DEBUG] forEachItems: ${JSON.stringify(forEachItems).substring(0, 200)}`
  );
  const allIssues = [];
  const perItemResults = [];
  const allOutputs = [];
  const allContents = [];
  const perIterationDurations = [];
  try {
    const wave = state.wave;
    const lvl = state.currentLevel ?? "?";
    const banner = `\u2501\u2501\u2501 CHECK ${checkId} (wave ${wave}, level ${lvl}, forEach parent) \u2501\u2501\u2501`;
    const isTTY = typeof process !== "undefined" ? !!process.stderr.isTTY : false;
    const outputFormat = process.env.VISOR_OUTPUT_FORMAT || "";
    const isJsonLike = outputFormat === "json" || outputFormat === "sarif";
    if (isTTY && !isJsonLike) {
      const cyan = "\x1B[36m";
      const reset = "\x1B[0m";
      logger.info(`${cyan}${banner}${reset}`);
    } else {
      logger.info(banner);
    }
  } catch {
  }
  for (let itemIndex = 0; itemIndex < forEachItems.length; itemIndex++) {
    const iterationStartMs = Date.now();
    const scope = [
      { check: forEachParent, index: itemIndex }
    ];
    const forEachItem = forEachItems[itemIndex];
    logger.info(
      `[LevelDispatch][DEBUG] Starting iteration ${itemIndex} of ${checkId}, parent=${forEachParent}, item=${JSON.stringify(forEachItem)?.substring(0, 100)}`
    );
    const shouldSkipDueToParentFailure = forEachItem?.__failed === true || forEachItem?.__skip === true;
    if (shouldSkipDueToParentFailure) {
      logger.info(
        `\u23ED  Skipped ${checkId} iteration ${itemIndex} (forEach parent "${forEachParent}" iteration ${itemIndex} marked as failed)`
      );
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      perItemResults.push({ issues: [] });
      allOutputs.push({ __skip: true });
      continue;
    }
    try {
      emitNdjsonSpanWithEvents(
        "visor.foreach.item",
        {
          "visor.check.id": checkId,
          "visor.foreach.index": itemIndex,
          "visor.foreach.total": forEachItems.length
        },
        []
      );
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to emit foreach.item span: ${error}`);
    }
    emitEvent({ type: "CheckScheduled", checkId, scope });
    const dispatch = {
      id: `${checkId}-${itemIndex}-${Date.now()}`,
      checkId,
      scope,
      provider: context2.checks[checkId]?.providerType || "unknown",
      startMs: Date.now(),
      attempts: 1,
      foreachIndex: itemIndex
    };
    state.activeDispatches.set(`${checkId}-${itemIndex}`, dispatch);
    try {
      const providerType = checkConfig.type || "ai";
      const providerRegistry = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports)).CheckProviderRegistry.getInstance();
      const provider = providerRegistry.getProviderOrThrow(providerType);
      const outputHistory = buildOutputHistoryFromJournal(context2);
      const workflowInputs = resolveWorkflowInputs(checkConfig, context2);
      const providerConfig = {
        type: providerType,
        checkName: checkId,
        prompt: checkConfig.prompt,
        exec: checkConfig.exec,
        schema: checkConfig.schema,
        group: checkConfig.group,
        focus: checkConfig.focus || (() => {
          const focusMap = {
            security: "security",
            performance: "performance",
            style: "style",
            architecture: "architecture"
          };
          return focusMap[checkId] || "all";
        })(),
        transform: checkConfig.transform,
        transform_js: checkConfig.transform_js,
        env: checkConfig.env,
        forEach: checkConfig.forEach,
        ...checkConfig,
        eventContext: context2.prInfo?.eventContext || {},
        __outputHistory: outputHistory,
        // Propagate workflow inputs for template access via {{ inputs.* }}
        workflowInputs,
        ai: {
          ...checkConfig.ai || {},
          timeout: checkConfig.ai?.timeout || 12e5,
          debug: !!context2.debug
        }
      };
      const dependencyResults = buildDependencyResultsWithScope(
        checkId,
        checkConfig,
        context2,
        scope
      );
      try {
        const rawDeps = checkConfig?.depends_on || [];
        const depList = Array.isArray(rawDeps) ? rawDeps : [rawDeps];
        if (depList.length > 0) {
          const groupSatisfied = (token) => {
            if (typeof token !== "string") return true;
            const orOptions = token.includes("|") ? token.split("|").map((s) => s.trim()).filter(Boolean) : [token];
            for (const opt of orOptions) {
              const dr = dependencyResults.get(opt);
              const depCfg = context2.config.checks?.[opt];
              const cont = !!(depCfg && depCfg.continue_on_failure === true);
              let failed = false;
              let skipped = false;
              if (!dr) failed = true;
              else {
                const out = dr.output;
                const fatal = hasFatalIssues(dr);
                failed = fatal || !!out && typeof out === "object" && out.__failed === true;
                skipped = !!(out && typeof out === "object" && out.__skip === true);
              }
              const satisfied = !skipped && (!failed || cont);
              if (satisfied) return true;
            }
            return false;
          };
          let allSatisfied = true;
          for (const token of depList) {
            if (!groupSatisfied(token)) {
              allSatisfied = false;
              break;
            }
          }
          if (!allSatisfied) {
            if (context2.debug) {
              logger.info(
                `[LevelDispatch] Skipping ${checkId} iteration ${itemIndex} due to unsatisfied dependency group(s)`
              );
            }
            const iterationDurationMs2 = Date.now() - iterationStartMs;
            perIterationDurations.push(iterationDurationMs2);
            perItemResults.push({ issues: [] });
            allOutputs.push({ __skip: true });
            continue;
          }
        }
      } catch {
      }
      const prInfo = context2.prInfo || {
        number: 1,
        title: "State Machine Execution",
        author: "system",
        eventType: context2.event || "manual",
        eventContext: {},
        files: [],
        commits: []
      };
      const executionContext = {
        ...context2.executionContext,
        _engineMode: context2.mode,
        _parentContext: context2,
        _parentState: state
      };
      const result = await withActiveSpan(
        `visor.check.${checkId}`,
        {
          "visor.check.id": checkId,
          "visor.check.type": providerType,
          session_id: context2.sessionId,
          wave: state.wave
        },
        async () => provider.execute(prInfo, providerConfig, dependencyResults, executionContext)
      );
      const enrichedIssues = (result.issues || []).map((issue) => ({
        ...issue,
        checkName: checkId,
        ruleId: `${checkId}/${issue.ruleId || "unknown"}`,
        group: checkConfig.group,
        schema: typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema,
        template: checkConfig.template,
        timestamp: Date.now()
      }));
      const enrichedResult = { ...result, issues: enrichedIssues };
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      updateStats(
        [{ checkId, result: enrichedResult, duration: iterationDurationMs }],
        state,
        true
      );
      try {
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: enrichedResult,
          event: context2.event || "manual",
          scope
        });
        logger.info(
          `[LevelDispatch][DEBUG] Committing to journal: checkId=${checkId}, scope=${JSON.stringify(scope)}, hasOutput=${enrichedResult.output !== void 0}`
        );
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit per-iteration result to journal: ${error}`);
      }
      perItemResults.push(enrichedResult);
      if (enrichedResult.content)
        allContents.push(String(enrichedResult.content));
      if (enrichedResult.output !== void 0)
        allOutputs.push(enrichedResult.output);
      allIssues.push(...enrichedResult.issues || []);
      emitEvent({ type: "CheckCompleted", checkId, scope, result: enrichedResult });
    } catch (error) {
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      const err = error instanceof Error ? error : new Error(String(error));
      logger.error(
        `[LevelDispatch] Error executing ${checkId} iteration ${itemIndex}: ${err.message}`
      );
      updateStats(
        [
          {
            checkId,
            result: {
              issues: [
                {
                  severity: "error",
                  category: "logic",
                  ruleId: `${checkId}/error`,
                  file: "system",
                  line: 0,
                  message: err.message,
                  timestamp: Date.now()
                }
              ]
            },
            error: err,
            duration: iterationDurationMs
          }
        ],
        state,
        true
      );
      allOutputs.push({ __failed: true });
      perItemResults.push({
        issues: [
          {
            severity: "error",
            category: "logic",
            ruleId: `${checkId}/error`,
            file: "system",
            line: 0,
            message: err.message,
            timestamp: Date.now()
          }
        ]
      });
      emitEvent({
        type: "CheckErrored",
        checkId,
        scope,
        error: { message: err.message, stack: err.stack, name: err.name }
      });
    } finally {
      state.activeDispatches.delete(`${checkId}-${itemIndex}`);
    }
  }
  const checkStats = state.stats.get(checkId);
  if (checkStats) {
    checkStats.outputsProduced = allOutputs.length;
    checkStats.perIterationDuration = perIterationDurations;
    const previewItems = allOutputs.slice(0, 3).map((item) => {
      const str = typeof item === "string" ? item : JSON.stringify(item) ?? "undefined";
      return str.length > 50 ? str.substring(0, 50) + "..." : str;
    });
    checkStats.forEachPreview = allOutputs.length > 3 ? [...previewItems, `...${allOutputs.length - 3} more`] : previewItems;
    state.stats.set(checkId, checkStats);
    if (checkStats.totalRuns > 0 && checkStats.failedRuns === checkStats.totalRuns) {
      logger.info(
        `[LevelDispatch] forEach check ${checkId} failed completely (${checkStats.failedRuns}/${checkStats.totalRuns} iterations failed)`
      );
      state.failedChecks = state.failedChecks || /* @__PURE__ */ new Set();
      state.failedChecks.add(checkId);
    }
  }
  const aggregatedResult = {
    issues: allIssues,
    isForEach: true,
    forEachItems: allOutputs,
    forEachItemResults: perItemResults,
    ...allContents.length > 0 ? { content: allContents.join("\n") } : {}
  };
  logger.info(
    `[LevelDispatch][DEBUG] Aggregated result for ${checkId}: forEachItems.length=${allOutputs.length}, results=${perItemResults.length}`
  );
  logger.info(`[LevelDispatch][DEBUG] allOutputs: ${JSON.stringify(allOutputs).substring(0, 200)}`);
  try {
    logger.info(`[LevelDispatch] Calling handleRouting for ${checkId}`);
  } catch {
  }
  let wasHalted = false;
  try {
    state.completedChecks.add(checkId);
    const currentWaveCompletions = state.currentWaveCompletions;
    if (currentWaveCompletions) currentWaveCompletions.add(checkId);
    wasHalted = await handleRouting(context2, state, transition, emitEvent, {
      checkId,
      scope: [],
      result: aggregatedResult,
      checkConfig,
      success: !hasFatalIssues(aggregatedResult)
    });
  } catch (error) {
    logger.warn(`[LevelDispatch] Routing error for aggregated forEach ${checkId}: ${error}`);
  }
  if (wasHalted) {
    logger.info(`[LevelDispatch] Execution halted after routing for aggregated forEach ${checkId}`);
    return aggregatedResult;
  }
  try {
    context2.journal.commitEntry({
      sessionId: context2.sessionId,
      checkId,
      result: aggregatedResult,
      event: context2.event || "manual",
      scope: []
    });
    logger.info(`[LevelDispatch][DEBUG] Committed aggregated result to journal with scope=[]`);
  } catch (error) {
    logger.warn(`[LevelDispatch] Failed to commit aggregated forEach result to journal: ${error}`);
  }
  emitEvent({ type: "CheckCompleted", checkId, scope: [], result: aggregatedResult });
  const parentCheckConfig = context2.config.checks?.[forEachParent];
  logger.info(
    `[LevelDispatch][DEBUG] Checking on_finish for forEach parent ${forEachParent}: has_on_finish=${!!parentCheckConfig?.on_finish}, is_forEach=${!!parentCheckConfig?.forEach}`
  );
  if (parentCheckConfig?.on_finish && parentCheckConfig.forEach) {
    logger.info(
      `[LevelDispatch] Processing on_finish for forEach parent ${forEachParent} after children complete`
    );
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const { ContextView: ContextView2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
      const contextView = new ContextView2(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        context2.event
      );
      const parentResult = contextView.get(forEachParent);
      if (parentResult) {
        logger.info(
          `[LevelDispatch] Found parent result for ${forEachParent}, evaluating on_finish`
        );
        const onFinish = parentCheckConfig.on_finish;
        let queuedForward = false;
        logger.info(
          `[LevelDispatch] on_finish.run: ${onFinish.run?.length || 0} targets, targets=${JSON.stringify(onFinish.run || [])}`
        );
        if (onFinish.run && onFinish.run.length > 0) {
          for (const targetCheck of onFinish.run) {
            logger.info(`[LevelDispatch] Processing on_finish.run target: ${targetCheck}`);
            logger.info(
              `[LevelDispatch] Loop budget check: routingLoopCount=${state.routingLoopCount}, max_loops=${context2.config.routing?.max_loops ?? 10}`
            );
            if (checkLoopBudget(context2, state, "on_finish", "run")) {
              const errorIssue = {
                file: "system",
                line: 0,
                ruleId: `${forEachParent}/routing/loop_budget_exceeded`,
                message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_finish run`,
                severity: "error",
                category: "logic"
              };
              parentResult.issues = [...parentResult.issues || [], errorIssue];
              try {
                context2.journal.commitEntry({
                  sessionId: context2.sessionId,
                  checkId: forEachParent,
                  result: parentResult,
                  event: context2.event || "manual",
                  scope: []
                });
              } catch (err) {
                logger.warn(
                  `[LevelDispatch] Failed to commit parent result with loop budget error: ${err}`
                );
              }
              return aggregatedResult;
            }
            state.routingLoopCount++;
            emitEvent({
              type: "ForwardRunRequested",
              target: targetCheck,
              scope: [],
              origin: "run"
            });
            queuedForward = true;
          }
        }
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] Evaluating on_finish.goto_js for forEach parent: ${forEachParent}`
          );
          if (onFinish.goto_js)
            logger.info(`[LevelDispatch] goto_js code: ${onFinish.goto_js.substring(0, 200)}`);
          try {
            const snapshotId2 = context2.journal.beginSnapshot();
            const all = context2.journal.readVisible(context2.sessionId, snapshotId2, void 0);
            const keys = Array.from(new Set(all.map((e) => e.checkId)));
            logger.info(`[LevelDispatch] history keys: ${keys.join(", ")}`);
          } catch {
          }
        }
        const gotoTarget = await evaluateGoto(
          onFinish.goto_js,
          onFinish.goto,
          forEachParent,
          parentCheckConfig,
          parentResult,
          context2,
          state
        );
        if (context2.debug)
          logger.info(`[LevelDispatch] goto_js evaluation result: ${gotoTarget || "null"}`);
        if (gotoTarget) {
          if (queuedForward && gotoTarget === forEachParent) {
            logger.info(
              `[LevelDispatch] on_finish.goto to self (${gotoTarget}) deferred, will process after WaveRetry`
            );
            emitEvent({ type: "WaveRetry", reason: "on_finish" });
          } else {
            if (checkLoopBudget(context2, state, "on_finish", "goto")) {
              const errorIssue = {
                file: "system",
                line: 0,
                ruleId: `${forEachParent}/routing/loop_budget_exceeded`,
                message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_finish goto`,
                severity: "error",
                category: "logic"
              };
              parentResult.issues = [...parentResult.issues || [], errorIssue];
              try {
                context2.journal.commitEntry({
                  sessionId: context2.sessionId,
                  checkId: forEachParent,
                  result: parentResult,
                  event: context2.event || "manual",
                  scope: []
                });
              } catch {
              }
              return aggregatedResult;
            }
            state.routingLoopCount++;
            emitEvent({ type: "ForwardRunRequested", target: gotoTarget, origin: "goto" });
          }
        }
        if (queuedForward) {
          const guardKey = `waveRetry:on_finish:${forEachParent}:wave:${state.wave}`;
          logger.info(
            `[LevelDispatch] Checking WaveRetry guard: ${guardKey}, has=${!!state.forwardRunGuards?.has(guardKey)}`
          );
          if (!state.forwardRunGuards?.has(guardKey)) {
            state.forwardRunGuards?.add(guardKey);
            logger.info(`[LevelDispatch] Emitting WaveRetry event for on_finish.run targets`);
            emitEvent({ type: "WaveRetry", reason: "on_finish" });
          }
        }
      }
    } catch {
    }
  }
  return aggregatedResult;
}
var init_foreach_processor = __esm({
  "src/state-machine/dispatch/foreach-processor.ts"() {
    "use strict";
    init_logger();
    init_fallback_ndjson();
    init_trace_helpers();
    init_history_snapshot();
    init_dependency_gating();
    init_stats_manager();
    init_routing();
    init_workflow_inputs();
  }
});

// src/state-machine/dispatch/on-init-handlers.ts
async function renderTemplateArguments(args, prInfo, dependencyResults, executionContext) {
  const renderedArgs = {};
  if (!args) {
    return renderedArgs;
  }
  const liquid = createExtendedLiquid();
  for (const [key, value] of Object.entries(args)) {
    if (typeof value === "string") {
      try {
        renderedArgs[key] = await liquid.parseAndRender(value, {
          pr: prInfo,
          outputs: dependencyResults,
          env: process.env,
          args: executionContext.args || {}
        });
      } catch (error) {
        logger.warn(`[OnInit] Failed to render template for ${key}: ${error}`);
        renderedArgs[key] = value;
      }
    } else {
      renderedArgs[key] = value;
    }
  }
  return renderedArgs;
}
async function executeInvocation(item, context2, scope, prInfo, dependencyResults, executionContext) {
  const CheckProviderRegistry2 = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports)).CheckProviderRegistry;
  const providerRegistry = CheckProviderRegistry2.getInstance();
  const renderedArgs = await renderTemplateArguments(
    item.with,
    prInfo,
    dependencyResults,
    executionContext
  );
  if ("tool" in item) {
    const toolName = item.tool;
    const toolDef = context2.config.tools?.[toolName];
    if (!toolDef) {
      throw new Error(`Tool '${toolName}' not found in tools: section`);
    }
    logger.info(`[OnInit] Executing tool: ${toolName}`);
    const tempCheckConfig = {
      type: "mcp",
      method: toolName,
      transport: "custom",
      args: renderedArgs
    };
    const provider = providerRegistry.getProviderOrThrow("mcp");
    const result = await provider.execute(
      prInfo,
      tempCheckConfig,
      dependencyResults,
      executionContext
    );
    const output = result.output;
    logger.info(`[OnInit] Tool ${toolName} completed`);
    return output;
  } else if ("step" in item) {
    const stepName = item.step;
    const stepConfig = context2.config.checks?.[stepName];
    if (!stepConfig) {
      throw new Error(`Step '${stepName}' not found in checks: section`);
    }
    logger.info(`[OnInit] Executing step: ${stepName}`);
    const enrichedExecutionContext = {
      ...executionContext,
      args: renderedArgs
    };
    const providerType = stepConfig.type || "ai";
    const provider = providerRegistry.getProviderOrThrow(providerType);
    const { buildOutputHistoryFromJournal: buildOutputHistoryFromJournal3 } = (init_history_snapshot(), __toCommonJS(history_snapshot_exports));
    const outputHistory = buildOutputHistoryFromJournal3(context2);
    const providerConfig = {
      type: providerType,
      checkName: stepName,
      prompt: stepConfig.prompt,
      exec: stepConfig.exec,
      schema: stepConfig.schema,
      group: stepConfig.group,
      transform: stepConfig.transform,
      transform_js: stepConfig.transform_js,
      env: stepConfig.env,
      ...stepConfig,
      eventContext: prInfo?.eventContext || {},
      __outputHistory: outputHistory,
      ai: {
        ...stepConfig.ai || {},
        timeout: stepConfig.ai?.timeout || 12e5,
        debug: !!context2.debug
      }
    };
    const result = await provider.execute(
      prInfo,
      providerConfig,
      dependencyResults,
      enrichedExecutionContext
    );
    const output = result.output;
    logger.info(`[OnInit] Step ${stepName} completed`);
    return output;
  } else if ("workflow" in item) {
    const workflowName = item.workflow;
    if (!workflowName) {
      throw new Error("Workflow name is required in on_init workflow invocation");
    }
    logger.info(`[OnInit] Executing workflow: ${workflowName}`);
    const tempCheckConfig = {
      type: "workflow",
      workflow: workflowName,
      args: renderedArgs,
      overrides: item.overrides,
      output_mapping: item.output_mapping
    };
    const provider = providerRegistry.getProviderOrThrow("workflow");
    const result = await provider.execute(
      prInfo,
      tempCheckConfig,
      dependencyResults,
      executionContext
    );
    const output = result.output;
    logger.info(`[OnInit] Workflow ${workflowName} completed`);
    return output;
  }
  throw new Error("Invalid on_init invocation: must specify tool, step, or workflow");
}
async function executeToolInvocation(item, context2, scope, prInfo, dependencyResults, executionContext) {
  return executeInvocation(item, context2, scope, prInfo, dependencyResults, executionContext);
}
async function executeStepInvocation(item, context2, scope, prInfo, dependencyResults, executionContext) {
  return executeInvocation(item, context2, scope, prInfo, dependencyResults, executionContext);
}
async function executeWorkflowInvocation(item, context2, scope, prInfo, dependencyResults, executionContext) {
  return executeInvocation(item, context2, scope, prInfo, dependencyResults, executionContext);
}
var init_on_init_handlers = __esm({
  "src/state-machine/dispatch/on-init-handlers.ts"() {
    "use strict";
    init_logger();
    init_liquid_extensions();
  }
});

// src/state-machine/dispatch/execution-invoker.ts
var execution_invoker_exports = {};
__export(execution_invoker_exports, {
  executeSingleCheck: () => executeSingleCheck
});
function normalizeRunItems(run) {
  if (!Array.isArray(run)) return [];
  return run.filter(Boolean);
}
function detectInvocationType(item) {
  if (typeof item === "string") return "step";
  if ("tool" in item) return "tool";
  if ("workflow" in item) return "workflow";
  if ("step" in item) return "step";
  throw new Error(
    `Invalid on_init item type: ${JSON.stringify(item)}. Must specify tool, step, or workflow.`
  );
}
async function executeOnInitItem(item, context2, scope, prInfo, dependencyResults, executionContext) {
  const itemType = detectInvocationType(item);
  let output;
  let outputName;
  switch (itemType) {
    case "tool": {
      const toolItem = item;
      output = await executeToolInvocation(
        toolItem,
        context2,
        scope,
        prInfo,
        dependencyResults,
        executionContext
      );
      outputName = toolItem.as || toolItem.tool;
      break;
    }
    case "step": {
      if (typeof item === "string") {
        const stepItem = { step: item, with: void 0, as: item };
        output = await executeStepInvocation(
          stepItem,
          context2,
          scope,
          prInfo,
          dependencyResults,
          executionContext
        );
        outputName = item;
      } else {
        const stepItem = item;
        output = await executeStepInvocation(
          stepItem,
          context2,
          scope,
          prInfo,
          dependencyResults,
          executionContext
        );
        outputName = stepItem.as || stepItem.step;
      }
      break;
    }
    case "workflow": {
      const workflowItem = item;
      output = await executeWorkflowInvocation(
        workflowItem,
        context2,
        scope,
        prInfo,
        dependencyResults,
        executionContext
      );
      outputName = workflowItem.as || workflowItem.workflow;
      break;
    }
    default:
      throw new Error(`Unknown on_init item type: ${itemType}`);
  }
  return { output, outputName };
}
async function handleOnInit(checkId, onInit, context2, scope, prInfo, dependencyResults, executionContext) {
  logger.info(`[OnInit] Processing on_init for check: ${checkId}`);
  if (executionContext.__onInitDepth && executionContext.__onInitDepth > 0) {
    logger.warn(
      `[OnInit] Skipping nested on_init for ${checkId} (depth: ${executionContext.__onInitDepth})`
    );
    return;
  }
  let runItems = [];
  if (onInit.run_js) {
    logger.info(`[OnInit] Evaluating run_js for ${checkId}`);
    try {
      const sandbox = createSecureSandbox();
      const result = await compileAndRun(
        sandbox,
        onInit.run_js,
        {
          pr: prInfo,
          outputs: dependencyResults,
          env: process.env,
          args: executionContext.args || {}
        },
        { injectLog: true, wrapFunction: false }
      );
      if (Array.isArray(result)) {
        runItems = result;
      } else {
        logger.warn(`[OnInit] run_js for ${checkId} did not return an array, got ${typeof result}`);
      }
    } catch (error) {
      const err = error instanceof Error ? error : new Error(String(error));
      logger.error(`[OnInit] Error evaluating run_js for ${checkId}: ${err.message}`);
      const wrappedError = new Error(`on_init.run_js evaluation failed: ${err.message}`);
      wrappedError.stack = err.stack;
      throw wrappedError;
    }
  } else if (onInit.run) {
    runItems = normalizeRunItems(onInit.run);
  }
  if (runItems.length === 0) {
    logger.info(`[OnInit] No items to run for ${checkId}`);
    return;
  }
  if (runItems.length > MAX_ON_INIT_ITEMS) {
    const msg = `on_init for ${checkId} has ${runItems.length} items, exceeding maximum of ${MAX_ON_INIT_ITEMS}`;
    logger.error(`[OnInit] ${msg}`);
    throw new Error(msg);
  }
  logger.info(`[OnInit] Running ${runItems.length} items for ${checkId}`);
  const originalDepth = executionContext.__onInitDepth || 0;
  executionContext.__onInitDepth = originalDepth + 1;
  try {
    for (let i = 0; i < runItems.length; i++) {
      const item = runItems[i];
      const itemType = detectInvocationType(item);
      const itemName = typeof item === "string" ? item : "tool" in item ? item.tool : "step" in item ? item.step : "workflow" in item ? item.workflow : "unknown";
      logger.info(`[OnInit] [${i + 1}/${runItems.length}] Executing ${itemType}: ${itemName}`);
      try {
        const { output, outputName } = await executeOnInitItem(
          item,
          context2,
          scope,
          prInfo,
          dependencyResults,
          executionContext
        );
        dependencyResults[outputName] = output;
        logger.info(`[OnInit] Stored output as: ${outputName}`);
      } catch (error) {
        const err = error instanceof Error ? error : new Error(String(error));
        logger.error(
          `[OnInit] Error executing ${itemType} ${itemName} for ${checkId}: ${err.message}`
        );
        const wrappedError = new Error(`on_init ${itemType} '${itemName}' failed: ${err.message}`);
        wrappedError.stack = err.stack;
        throw wrappedError;
      }
    }
    logger.info(`[OnInit] Completed all on_init items for ${checkId}`);
  } finally {
    executionContext.__onInitDepth = originalDepth;
  }
}
async function executeSingleCheck(checkId, context2, state, emitEvent, transition, evaluateIf, scopeOverride) {
  const checkConfig = context2.config.checks?.[checkId];
  if (checkConfig?.if) {
    const shouldRun = await evaluateIf(checkId, checkConfig, context2, state);
    if (!shouldRun) {
      logger.info(
        `\u23ED  Skipped (if: ${checkConfig.if.substring(0, 40)}${checkConfig.if.length > 40 ? "..." : ""})`
      );
      const emptyResult = { issues: [] };
      try {
        Object.defineProperty(emptyResult, "__skipped", {
          value: "if_condition",
          enumerable: false
        });
      } catch {
      }
      state.completedChecks.add(checkId);
      const stats = {
        checkName: checkId,
        totalRuns: 0,
        successfulRuns: 0,
        failedRuns: 0,
        skippedRuns: 0,
        skipped: true,
        skipReason: "if_condition",
        skipCondition: checkConfig.if,
        totalDuration: 0,
        issuesFound: 0,
        issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
      };
      state.stats.set(checkId, stats);
      logger.info(`[LevelDispatch] Recorded skip stats for ${checkId}: skipReason=if_condition`);
      try {
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: emptyResult,
          event: context2.event || "manual",
          scope: []
        });
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit skipped result to journal: ${error}`);
      }
      emitEvent({ type: "CheckCompleted", checkId, scope: [], result: emptyResult });
      return emptyResult;
    }
  }
  const dependencies = checkConfig?.depends_on || [];
  const depList = Array.isArray(dependencies) ? dependencies : [dependencies];
  const failedChecks = state.failedChecks;
  const tokens = depList.filter(Boolean);
  const groupSatisfied = (token) => {
    const options = token.includes("|") ? token.split("|").map((s) => s.trim()).filter(Boolean) : [token];
    for (const opt of options) {
      const depCfg = context2.config.checks?.[opt];
      const cont = !!(depCfg && depCfg.continue_on_failure === true);
      const st = state.stats.get(opt);
      const skipped = !!(st && st.skipped === true);
      const skipReason = st?.skipReason;
      const skippedDueToEmptyForEach = skipped && skipReason === "forEach_empty";
      const wasMarkedFailed = !!(failedChecks && failedChecks.has(opt)) && !skippedDueToEmptyForEach;
      const failedOnly = !!(st && (st.failedRuns || 0) > 0 && (st.successfulRuns || 0) === 0);
      const satisfied = (!skipped || skippedDueToEmptyForEach) && (!failedOnly && !wasMarkedFailed || cont);
      if (satisfied) return true;
    }
    return false;
  };
  if (tokens.length > 0) {
    let allOk = true;
    for (const t of tokens) {
      if (!groupSatisfied(t)) {
        allOk = false;
        break;
      }
    }
    if (!allOk) {
      const emptyResult = { issues: [] };
      try {
        Object.defineProperty(emptyResult, "__skipped", {
          value: "dependency_failed",
          enumerable: false
        });
      } catch {
      }
      state.completedChecks.add(checkId);
      state.failedChecks = state.failedChecks || /* @__PURE__ */ new Set();
      state.failedChecks.add(checkId);
      const stats = {
        checkName: checkId,
        totalRuns: 0,
        successfulRuns: 0,
        failedRuns: 0,
        skippedRuns: 0,
        skipped: true,
        skipReason: "dependency_failed",
        totalDuration: 0,
        issuesFound: 0,
        issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
      };
      state.stats.set(checkId, stats);
      try {
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: emptyResult,
          event: context2.event || "manual",
          scope: []
        });
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit empty result to journal: ${error}`);
      }
      emitEvent({ type: "CheckCompleted", checkId, scope: [], result: emptyResult });
      return emptyResult;
    }
  }
  try {
    const wave = state.wave;
    const level = state.currentLevel ?? "?";
    const banner = `\u2501\u2501\u2501 CHECK ${checkId} (wave ${wave}, level ${level}) \u2501\u2501\u2501`;
    const isTTY = typeof process !== "undefined" ? !!process.stderr.isTTY : false;
    const outputFormat = process.env.VISOR_OUTPUT_FORMAT || "";
    const isJsonLike = outputFormat === "json" || outputFormat === "sarif";
    if (isTTY && !isJsonLike) {
      const cyan = "\x1B[36m";
      const reset = "\x1B[0m";
      logger.info(`${cyan}${banner}${reset}`);
    } else {
      logger.info(banner);
    }
  } catch {
  }
  let forEachParent;
  let forEachItems;
  for (const depId of depList) {
    if (!depId) continue;
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const { ContextView: ContextView2 } = (init_snapshot_store(), __toCommonJS(snapshot_store_exports));
      const contextView = new ContextView2(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        context2.event
      );
      const depResult = contextView.get(depId);
      if (depResult?.forEachItems && Array.isArray(depResult.forEachItems)) {
        forEachParent = depId;
        forEachItems = depResult.forEachItems;
        break;
      }
    } catch {
    }
  }
  if (forEachParent && forEachItems !== void 0) {
    let fanoutMode = "reduce";
    const explicit = checkConfig?.fanout;
    if (explicit === "map" || explicit === "reduce") fanoutMode = explicit;
    else {
      const providerType = context2.checks[checkId]?.providerType || "";
      const reduceProviders = /* @__PURE__ */ new Set(["log", "memory", "script", "workflow", "noop"]);
      fanoutMode = reduceProviders.has(providerType) ? "reduce" : "map";
    }
    if (fanoutMode === "map") {
      if (forEachItems.length === 0) {
        logger.info(`\u23ED  Skipped (forEach parent "${forEachParent}" has 0 items)`);
        const emptyResult = { issues: [] };
        try {
          Object.defineProperty(emptyResult, "__skipped", {
            value: "forEach_empty",
            enumerable: false
          });
        } catch {
        }
        state.completedChecks.add(checkId);
        let derivedSkipReason = "forEach_empty";
        try {
          const parentFailed = !!(state.failedChecks && state.failedChecks.has(forEachParent)) || (() => {
            const s = state.stats.get(forEachParent);
            return !!(s && (s.failedRuns || 0) > 0);
          })();
          if (parentFailed) derivedSkipReason = "dependency_failed";
        } catch {
        }
        const stats = {
          checkName: checkId,
          totalRuns: 0,
          successfulRuns: 0,
          failedRuns: 0,
          skippedRuns: 0,
          skipped: true,
          skipReason: derivedSkipReason,
          totalDuration: 0,
          issuesFound: 0,
          issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
        };
        state.stats.set(checkId, stats);
        try {
          context2.journal.commitEntry({
            sessionId: context2.sessionId,
            checkId,
            result: emptyResult,
            event: context2.event || "manual",
            scope: []
          });
        } catch (error) {
          logger.warn(`[LevelDispatch] Failed to commit empty result to journal: ${error}`);
        }
        emitEvent({ type: "CheckCompleted", checkId, scope: [], result: emptyResult });
        return emptyResult;
      }
      return await executeCheckWithForEachItems(
        checkId,
        forEachParent,
        forEachItems,
        context2,
        state,
        emitEvent,
        transition
      );
    }
  }
  const scope = scopeOverride || [];
  emitEvent({ type: "CheckScheduled", checkId, scope });
  const startTime = Date.now();
  const dispatch = {
    id: `${checkId}-${Date.now()}`,
    checkId,
    scope,
    provider: context2.checks[checkId]?.providerType || "unknown",
    startMs: startTime,
    attempts: 1
  };
  state.activeDispatches.set(checkId, dispatch);
  try {
    if (!checkConfig) throw new Error(`Check configuration not found: ${checkId}`);
    const providerType = checkConfig.type || "ai";
    const providerRegistry = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports)).CheckProviderRegistry.getInstance();
    const provider = providerRegistry.getProviderOrThrow(providerType);
    const outputHistory = buildOutputHistoryFromJournal(context2);
    const workflowInputs = resolveWorkflowInputs(checkConfig, context2);
    const providerConfig = {
      type: providerType,
      checkName: checkId,
      prompt: checkConfig.prompt,
      exec: checkConfig.exec,
      schema: checkConfig.schema,
      group: checkConfig.group,
      focus: checkConfig.focus || mapCheckNameToFocus(checkId),
      transform: checkConfig.transform,
      transform_js: checkConfig.transform_js,
      env: checkConfig.env,
      forEach: checkConfig.forEach,
      ...checkConfig,
      eventContext: context2.prInfo?.eventContext || {},
      __outputHistory: outputHistory,
      // Propagate workflow inputs for template access via {{ inputs.* }}
      workflowInputs,
      ai: {
        ...checkConfig.ai || {},
        timeout: checkConfig.ai?.timeout || 12e5,
        debug: !!context2.debug
      }
    };
    const dependencyResults = buildDependencyResultsWithScope(checkId, checkConfig, context2, scope);
    const prInfo = context2.prInfo || {
      number: 1,
      title: "State Machine Execution",
      author: "system",
      eventType: context2.event || "manual",
      eventContext: {},
      files: [],
      commits: []
    };
    let parentSessionId;
    let reuseSession = false;
    try {
      const reuseCfg = checkConfig.reuse_ai_session;
      if (reuseCfg === "self") {
        const snapshotId = context2.journal.beginSnapshot();
        const visible = context2.journal.readVisible(
          context2.sessionId,
          snapshotId,
          context2.event
        );
        const prior = visible.filter(
          (e) => e.checkId === checkId && (!e.scope || e.scope.length === 0)
        );
        if (prior.length > 0) {
          const last = prior[prior.length - 1];
          const sess = last.result?.sessionId;
          if (typeof sess === "string" && sess.length > 0) {
            parentSessionId = sess;
            reuseSession = true;
          }
        }
      }
    } catch {
      parentSessionId = void 0;
      reuseSession = false;
    }
    const executionContext = {
      ...context2.executionContext,
      _engineMode: context2.mode,
      _parentContext: context2,
      _parentState: state,
      // Explicitly propagate workspace reference for nested workflows
      workspace: context2.workspace
    };
    if (reuseSession && parentSessionId) {
      executionContext.parentSessionId = parentSessionId;
      executionContext.reuseSession = true;
    }
    if (checkConfig.on_init) {
      try {
        const dependencyResultsMap = {};
        for (const [key, value] of dependencyResults.entries()) {
          dependencyResultsMap[key] = value;
        }
        await handleOnInit(
          checkId,
          checkConfig.on_init,
          context2,
          scope,
          prInfo,
          dependencyResultsMap,
          executionContext
        );
        for (const [key, value] of Object.entries(dependencyResultsMap)) {
          if (!dependencyResults.has(key)) {
            dependencyResults.set(key, value);
          }
        }
      } catch (error) {
        const err = error instanceof Error ? error : new Error(String(error));
        logger.error(`[LevelDispatch] on_init failed for ${checkId}: ${err.message}`);
        throw err;
      }
    }
    try {
      emitNdjsonFallback("visor.provider", {
        "visor.check.id": checkId,
        "visor.provider.type": providerType
      });
    } catch {
    }
    const result = await withActiveSpan(
      `visor.check.${checkId}`,
      {
        "visor.check.id": checkId,
        "visor.check.type": providerType,
        session_id: context2.sessionId,
        wave: state.wave
      },
      async () => provider.execute(prInfo, providerConfig, dependencyResults, executionContext)
    );
    const enrichedIssues = (result.issues || []).map((issue) => ({
      ...issue,
      checkName: checkId,
      ruleId: `${checkId}/${issue.ruleId || "unknown"}`,
      group: checkConfig.group,
      schema: typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema,
      template: checkConfig.template,
      timestamp: Date.now()
    }));
    const enrichedResult = { ...result, issues: enrichedIssues };
    let isForEach = false;
    let forEachItemsLocal;
    if (checkConfig.forEach) {
      const output = result.output;
      if (Array.isArray(output)) {
        isForEach = true;
        forEachItemsLocal = output;
        enrichedResult.isForEach = true;
        enrichedResult.forEachItems = output;
      } else {
        if (context2.debug)
          logger.warn(
            `[LevelDispatch] Check ${checkId} has forEach:true but output is not an array: ${typeof output}, converting to single-item array`
          );
        isForEach = true;
        forEachItemsLocal = [output];
        enrichedResult.isForEach = true;
        enrichedResult.forEachItems = [output];
      }
    }
    if (result.isForEach) enrichedResult.isForEach = true;
    if (result.forEachItems) enrichedResult.forEachItems = result.forEachItems;
    if (result.forEachItemResults)
      enrichedResult.forEachItemResults = result.forEachItemResults;
    if (result.forEachFatalMask)
      enrichedResult.forEachFatalMask = result.forEachFatalMask;
    let renderedContent;
    try {
      renderedContent = await renderTemplateContent(checkId, checkConfig, enrichedResult);
      if (renderedContent) emitMermaidFromMarkdown(checkId, renderedContent, "content");
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to render template for ${checkId}: ${error}`);
    }
    let outputWithTimestamp = void 0;
    if (result.output !== void 0) {
      const output = result.output;
      if (output !== null && typeof output === "object" && !Array.isArray(output))
        outputWithTimestamp = { ...output, ts: Date.now() };
      else outputWithTimestamp = output;
    }
    const enrichedResultWithContent = renderedContent ? { ...enrichedResult, content: renderedContent } : enrichedResult;
    const enrichedResultWithTimestamp = outputWithTimestamp !== void 0 ? { ...enrichedResultWithContent, output: outputWithTimestamp } : enrichedResultWithContent;
    state.completedChecks.add(checkId);
    const currentWaveCompletions = state.currentWaveCompletions;
    if (currentWaveCompletions) currentWaveCompletions.add(checkId);
    try {
      logger.info(`[LevelDispatch] Calling handleRouting for ${checkId}`);
    } catch {
    }
    const wasHalted = await handleRouting(context2, state, transition, emitEvent, {
      checkId,
      scope,
      result: enrichedResult,
      checkConfig,
      success: !hasFatalIssues(enrichedResult)
    });
    if (wasHalted) {
      logger.info(`[LevelDispatch] Execution halted after routing for ${checkId}`);
      return enrichedResult;
    }
    try {
      const commitResult = {
        ...enrichedResult,
        ...renderedContent ? { content: renderedContent } : {},
        ...result.output !== void 0 ? outputWithTimestamp !== void 0 ? { output: outputWithTimestamp } : { output: result.output } : {}
      };
      context2.journal.commitEntry({
        sessionId: context2.sessionId,
        checkId,
        result: commitResult,
        event: context2.event || "manual",
        scope
      });
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to commit to journal: ${error}`);
    }
    try {
      const duration = Date.now() - startTime;
      updateStats([{ checkId, result: enrichedResult, duration }], state, false);
    } catch {
    }
    if (isForEach) {
      try {
        const existing = state.stats.get(checkId);
        const aggStats = existing || {
          checkName: checkId,
          totalRuns: 0,
          successfulRuns: 0,
          failedRuns: 0,
          skippedRuns: 0,
          skipped: false,
          totalDuration: 0,
          issuesFound: 0,
          issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
        };
        aggStats.totalRuns++;
        const hasFatal = hasFatalIssues(enrichedResultWithTimestamp);
        if (hasFatal) aggStats.failedRuns++;
        else aggStats.successfulRuns++;
        const items = enrichedResultWithTimestamp.forEachItems;
        if (Array.isArray(items)) aggStats.outputsProduced = items.length;
        state.stats.set(checkId, aggStats);
      } catch {
      }
    }
    if (isForEach && forEachItemsLocal && Array.isArray(forEachItemsLocal)) {
      for (let itemIndex = 0; itemIndex < forEachItemsLocal.length; itemIndex++) {
        const itemScope = [
          { check: checkId, index: itemIndex }
        ];
        const item = forEachItemsLocal[itemIndex];
        try {
          context2.journal.commitEntry({
            sessionId: context2.sessionId,
            checkId,
            result: { issues: [], output: item },
            event: context2.event || "manual",
            scope: itemScope
          });
        } catch (error) {
          logger.warn(
            `[LevelDispatch] Failed to commit per-item journal for ${checkId} item ${itemIndex}: ${error}`
          );
        }
      }
    }
    state.activeDispatches.delete(checkId);
    emitEvent({
      type: "CheckCompleted",
      checkId,
      scope,
      result: {
        ...enrichedResult,
        output: result.output,
        content: renderedContent || result.content
      }
    });
    return enrichedResult;
  } catch (error) {
    const err = error instanceof Error ? error : new Error(String(error));
    logger.error(`[LevelDispatch] Error executing check ${checkId}: ${err.message}`);
    state.activeDispatches.delete(checkId);
    emitEvent({
      type: "CheckErrored",
      checkId,
      scope,
      error: { message: err.message, stack: err.stack, name: err.name }
    });
    throw err;
  }
}
function mapCheckNameToFocus(checkName) {
  const focusMap = {
    security: "security",
    performance: "performance",
    style: "style",
    architecture: "architecture"
  };
  return focusMap[checkName] || "all";
}
var MAX_ON_INIT_ITEMS;
var init_execution_invoker = __esm({
  "src/state-machine/dispatch/execution-invoker.ts"() {
    "use strict";
    init_logger();
    init_trace_helpers();
    init_mermaid_telemetry();
    init_fallback_ndjson();
    init_history_snapshot();
    init_dependency_gating();
    init_template_renderer();
    init_stats_manager();
    init_routing();
    init_foreach_processor();
    init_stats_manager();
    init_on_init_handlers();
    init_sandbox();
    init_workflow_inputs();
    MAX_ON_INIT_ITEMS = 50;
  }
});

// src/state-machine/dispatch/renderer-schema.ts
var renderer_schema_exports = {};
__export(renderer_schema_exports, {
  loadRendererSchema: () => loadRendererSchema
});
async function loadRendererSchema(name) {
  try {
    const fs20 = await import("fs/promises");
    const path22 = await import("path");
    const sanitized = String(name).replace(/[^a-zA-Z0-9-]/g, "");
    if (!sanitized) return void 0;
    const candidates = [
      // When bundled with ncc, __dirname is dist/ and output/ is at dist/output/
      path22.join(__dirname, "output", sanitized, "schema.json"),
      // When running from source, __dirname is src/state-machine/dispatch/ and output/ is at output/
      path22.join(__dirname, "..", "..", "output", sanitized, "schema.json"),
      // When running from a checkout with output/ folder copied to CWD
      path22.join(process.cwd(), "output", sanitized, "schema.json"),
      // Fallback: cwd/dist/output/
      path22.join(process.cwd(), "dist", "output", sanitized, "schema.json")
    ];
    for (const p of candidates) {
      try {
        const raw = await fs20.readFile(p, "utf-8");
        return JSON.parse(raw);
      } catch {
      }
    }
  } catch (e) {
    try {
      logger.warn(`[schema-loader] Failed to load renderer schema '${name}': ${String(e)}`);
    } catch {
    }
  }
  return void 0;
}
var init_renderer_schema = __esm({
  "src/state-machine/dispatch/renderer-schema.ts"() {
    "use strict";
    init_logger();
  }
});

// src/state-machine/states/level-dispatch.ts
function mapCheckNameToFocus2(checkName) {
  const focusMap = {
    security: "security",
    performance: "performance",
    style: "style",
    architecture: "architecture"
  };
  return focusMap[checkName] || "all";
}
function formatScopeLabel2(scope) {
  if (!scope || scope.length === 0) return "";
  return scope.map((item) => `${item.check}:${item.index}`).join("|");
}
function recordOnFinishRoutingEvent(args) {
  const attrs = {
    check_id: args.checkId,
    trigger: "on_finish",
    action: args.action,
    target: args.target,
    source: args.source
  };
  const scopeLabel = formatScopeLabel2(args.scope);
  if (scopeLabel) attrs.scope = scopeLabel;
  if (args.gotoEvent) attrs.goto_event = args.gotoEvent;
  addEvent("visor.routing", attrs);
}
function getHistoryLimit3() {
  const raw = process.env.VISOR_TEST_HISTORY_LIMIT || process.env.VISOR_OUTPUT_HISTORY_LIMIT;
  if (!raw) return void 0;
  const n = parseInt(raw, 10);
  return Number.isFinite(n) && n > 0 ? n : void 0;
}
function buildOutputHistoryFromJournal2(context2) {
  const outputHistory = /* @__PURE__ */ new Map();
  const limit = getHistoryLimit3();
  try {
    const snapshot = context2.journal.beginSnapshot();
    const allEntries = context2.journal.readVisible(context2.sessionId, snapshot, void 0);
    for (const entry of allEntries) {
      const checkId = entry.checkId;
      if (!outputHistory.has(checkId)) {
        outputHistory.set(checkId, []);
      }
      const payload = entry.result.output !== void 0 ? entry.result.output : entry.result;
      if (payload !== void 0) {
        const arr = outputHistory.get(checkId);
        arr.push(payload);
        if (limit && arr.length > limit) {
          arr.splice(0, arr.length - limit);
        }
      }
    }
  } catch (error) {
    logger.debug(`[LevelDispatch] Error building output history: ${error}`);
  }
  return outputHistory;
}
async function evaluateIfCondition(checkId, checkConfig, context2, state) {
  const ifExpression = checkConfig.if;
  if (!ifExpression) {
    return true;
  }
  try {
    const evaluator = new FailureConditionEvaluator();
    const previousResults = /* @__PURE__ */ new Map();
    const currentWaveCompletions = state.currentWaveCompletions;
    const useGlobalOutputsFlag = !!(state.flags && state.flags.forwardRunActive);
    const waveKind = state.flags && state.flags.waveKind || void 0;
    const hasDeps = (() => {
      try {
        const deps = checkConfig?.depends_on;
        if (!deps) return false;
        if (Array.isArray(deps)) return deps.length > 0;
        return typeof deps === "string" ? deps.trim().length > 0 : false;
      } catch {
        return false;
      }
    })();
    const useGlobalOutputs = hasDeps || useGlobalOutputsFlag && waveKind === "forward";
    if (useGlobalOutputs) {
      try {
        const snapshotId = context2.journal.beginSnapshot();
        const ContextView2 = (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView;
        const contextView = new ContextView2(
          context2.journal,
          context2.sessionId,
          snapshotId,
          [],
          context2.event
        );
        for (const key of Object.keys(context2.checks || {})) {
          const jr = contextView.get(key);
          if (jr) previousResults.set(key, jr);
        }
      } catch {
      }
    } else if (currentWaveCompletions) {
      for (const key of currentWaveCompletions) {
        try {
          const snapshotId = context2.journal.beginSnapshot();
          const ContextView2 = (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView;
          const contextView = new ContextView2(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            context2.event
          );
          const journalResult = contextView.get(key);
          if (journalResult) {
            previousResults.set(key, journalResult);
          }
        } catch {
        }
      }
    }
    const envSnapshot = {};
    for (const [key, value] of Object.entries(process.env)) {
      if (value !== void 0) {
        envSnapshot[key] = value;
      }
    }
    if (context2.config.env) {
      for (const [key, value] of Object.entries(context2.config.env)) {
        if (value !== void 0 && value !== null) {
          envSnapshot[key] = String(value);
        }
      }
    }
    const contextData = {
      previousResults,
      event: context2.event || "manual",
      branch: context2.prInfo?.branch,
      baseBranch: context2.prInfo?.baseBranch,
      filesChanged: context2.prInfo?.files?.map((f) => f.filename),
      environment: envSnapshot,
      workflowInputs: context2.config.workflow_inputs || {}
    };
    const shouldRun = await evaluator.evaluateIfCondition(checkId, ifExpression, contextData);
    return shouldRun;
  } catch (error) {
    const msg = error instanceof Error ? error.message : String(error);
    logger.error(`Failed to evaluate if expression for check '${checkId}': ${msg}`);
    return false;
  }
}
async function handleLevelDispatch(context2, state, transition, emitEvent) {
  const level = state.levelQueue.shift();
  if (!level) {
    if (context2.debug) {
      logger.info("[LevelDispatch] No more levels in queue");
    }
    transition("WavePlanning");
    return;
  }
  if (context2.debug) {
    logger.info(
      `[LevelDispatch] Executing level ${level.level} with ${level.parallel.length} checks`
    );
  }
  state.currentLevel = level.level;
  state.currentLevelChecks = new Set(level.parallel);
  const levelChecksPreview = level.parallel.slice(0, 5).join(",");
  setSpanAttributes({
    level_size: level.parallel.length,
    level_checks_preview: levelChecksPreview
  });
  emitEvent({ type: "LevelReady", level, wave: state.wave });
  const maxParallelism = context2.maxParallelism || 10;
  const results = [];
  const sessionGroups = groupBySession(level.parallel, context2);
  for (const group of sessionGroups) {
    const groupResults = await executeCheckGroup(
      group,
      context2,
      state,
      maxParallelism,
      emitEvent,
      transition
    );
    results.push(...groupResults);
    if (context2.failFast && shouldFailFast(results)) {
      logger.warn("[LevelDispatch] Fail-fast triggered");
      state.flags.failFastTriggered = true;
      break;
    }
  }
  emitEvent({ type: "LevelDepleted", level: level.level, wave: state.wave });
  const nonForEachResults = results.filter((r) => {
    if (r.result.isForEach) return false;
    if (r.result.__skipped) return false;
    return true;
  });
  updateStats2(nonForEachResults, state);
  if (state.flags.failFastTriggered) {
    state.levelQueue = [];
    if (context2.debug) {
      logger.info("[LevelDispatch] Fail-fast triggered, clearing level queue");
    }
  }
  state.currentLevelChecks.clear();
  if (state.currentState !== "Error") {
    transition("WavePlanning");
  } else {
    logger.info("[LevelDispatch] Skipping transition to WavePlanning - already in Error state");
  }
}
function groupBySession(checks, context2) {
  const sessionProviderMap = /* @__PURE__ */ new Map();
  const noSessionChecks = [];
  for (const checkId of checks) {
    const metadata = context2.checks[checkId];
    const sessionProvider = metadata?.sessionProvider;
    if (sessionProvider) {
      const group = sessionProviderMap.get(sessionProvider) || [];
      group.push(checkId);
      sessionProviderMap.set(sessionProvider, group);
    } else {
      noSessionChecks.push(checkId);
    }
  }
  const groups = [];
  for (const group of sessionProviderMap.values()) {
    groups.push(group);
  }
  if (noSessionChecks.length > 0) {
    groups.push(noSessionChecks);
  }
  return groups;
}
async function executeCheckGroup(checks, context2, state, maxParallelism, emitEvent, transition) {
  const results = [];
  const seen = /* @__PURE__ */ new Set();
  const uniqueChecks = [];
  for (const id of checks) {
    if (!seen.has(id)) {
      seen.add(id);
      uniqueChecks.push(id);
    }
  }
  const pool = [];
  for (const checkId of uniqueChecks) {
    const scopedRuns = state.pendingRunScopes && state.pendingRunScopes.get(checkId) || [];
    try {
      const currentWaveCompletions = state.currentWaveCompletions;
      if (currentWaveCompletions && currentWaveCompletions.has(checkId)) {
        if (context2.debug) {
          logger.info(`[LevelDispatch] Skipping ${checkId}: already completed in current wave`);
        }
        continue;
      }
    } catch {
    }
    if (pool.length >= maxParallelism) {
      await Promise.race(pool);
      pool.splice(
        0,
        pool.length,
        ...pool.filter((p) => {
          const settled = p._settled;
          return !settled;
        })
      );
    }
    const runOnce = async (scopeOverride) => {
      const startTime = Date.now();
      try {
        const result = await executeSingleCheck2(
          checkId,
          context2,
          state,
          emitEvent,
          transition,
          scopeOverride
        );
        const duration = Date.now() - startTime;
        results.push({ checkId, result, duration });
      } catch (error) {
        const duration = Date.now() - startTime;
        const err = error instanceof Error ? error : new Error(String(error));
        logger.error(`[LevelDispatch] Error executing check ${checkId}: ${err.message}`);
        results.push({ checkId, result: { issues: [] }, error: err, duration });
      }
    };
    const promise = (async () => {
      if (scopedRuns.length > 0) {
        for (const sc of scopedRuns) {
          await runOnce(sc);
        }
        try {
          state.pendingRunScopes?.delete(checkId);
        } catch {
        }
      } else {
        await runOnce();
      }
    })();
    promise.then(() => {
      promise._settled = true;
    }).catch(() => {
      promise._settled = true;
    });
    pool.push(promise);
  }
  await Promise.all(pool);
  return results;
}
async function executeCheckWithForEachItems2(checkId, forEachParent, forEachItems, context2, state, emitEvent, transition) {
  try {
    const snapId = context2.journal.beginSnapshot();
    const visible = context2.journal.readVisible(context2.sessionId, snapId, context2.event);
    let latestItems;
    for (let i = visible.length - 1; i >= 0; i--) {
      const e = visible[i];
      if (e.checkId === forEachParent && Array.isArray(e.scope) && e.scope.length === 0) {
        const r = e.result;
        if (r && Array.isArray(r.forEachItems)) {
          latestItems = r.forEachItems;
          break;
        }
      }
    }
    if (Array.isArray(latestItems)) {
      if (context2.debug) {
        try {
          const prevLen = Array.isArray(forEachItems) ? forEachItems.length : 0;
          const newLen = latestItems.length;
          if (prevLen !== newLen) {
            logger.info(
              `[LevelDispatch] Refreshing forEachItems for ${checkId}: from parent '${forEachParent}' latestItems=${newLen} (was ${prevLen})`
            );
          }
        } catch {
        }
      }
      forEachItems = latestItems;
    }
  } catch (e) {
    if (context2.debug) {
      logger.warn(
        `[LevelDispatch] Failed to refresh forEachItems from journal for ${forEachParent}: ${e}`
      );
    }
  }
  const checkConfig = context2.config.checks?.[checkId];
  if (!checkConfig) {
    throw new Error(`Check configuration not found: ${checkId}`);
  }
  logger.info(
    `[LevelDispatch][DEBUG] executeCheckWithForEachItems: checkId=${checkId}, forEachParent=${forEachParent}, items=${forEachItems.length}`
  );
  logger.info(
    `[LevelDispatch][DEBUG] forEachItems: ${JSON.stringify(forEachItems).substring(0, 200)}`
  );
  const allIssues = [];
  const perItemResults = [];
  const allOutputs = [];
  const allContents = [];
  const perIterationDurations = [];
  const scope = [];
  const sharedDependencyResults = buildDependencyResultsWithScope2(
    checkId,
    checkConfig,
    context2,
    scope
  );
  if (checkConfig.on_init) {
    try {
      const { handleOnInit: handleOnInit2 } = (init_execution_invoker(), __toCommonJS(execution_invoker_exports));
      const dependencyResultsMap = {};
      for (const [key, value] of sharedDependencyResults.entries()) {
        dependencyResultsMap[key] = value;
      }
      const prInfo = context2.prInfo;
      const executionContext = {
        sessionId: context2.sessionId,
        checkId,
        event: context2.event,
        _parentContext: context2
      };
      await handleOnInit2(
        checkId,
        checkConfig.on_init,
        context2,
        scope,
        prInfo,
        dependencyResultsMap,
        executionContext
      );
      for (const [key, value] of Object.entries(dependencyResultsMap)) {
        if (!sharedDependencyResults.has(key)) {
          sharedDependencyResults.set(key, value);
        }
      }
      logger.info(`[LevelDispatch] on_init completed for ${checkId} before forEach loop`);
    } catch (error) {
      const err = error instanceof Error ? error : new Error(String(error));
      logger.error(`[LevelDispatch] on_init failed for ${checkId}: ${err.message}`);
      throw err;
    }
  }
  for (let itemIndex = 0; itemIndex < forEachItems.length; itemIndex++) {
    const iterationStartMs = Date.now();
    const scope2 = [
      { check: forEachParent, index: itemIndex }
    ];
    const forEachItem = forEachItems[itemIndex];
    logger.info(
      `[LevelDispatch][DEBUG] Starting iteration ${itemIndex} of ${checkId}, parent=${forEachParent}, item=${JSON.stringify(forEachItem)?.substring(0, 100)}`
    );
    const shouldSkipDueToParentFailure = forEachItem?.__failed === true || forEachItem?.__skip === true;
    if (shouldSkipDueToParentFailure) {
      logger.info(
        `\u23ED  Skipped ${checkId} iteration ${itemIndex} (forEach parent "${forEachParent}" iteration ${itemIndex} marked as failed)`
      );
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      perItemResults.push({ issues: [] });
      allOutputs.push({ __skip: true });
      continue;
    }
    try {
      emitNdjsonSpanWithEvents(
        "visor.foreach.item",
        {
          "visor.check.id": checkId,
          "visor.foreach.index": itemIndex,
          "visor.foreach.total": forEachItems.length
        },
        []
      );
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to emit foreach.item span: ${error}`);
    }
    emitEvent({ type: "CheckScheduled", checkId, scope: scope2 });
    const dispatch = {
      id: `${checkId}-${itemIndex}-${Date.now()}`,
      checkId,
      scope: scope2,
      provider: context2.checks[checkId]?.providerType || "unknown",
      startMs: Date.now(),
      attempts: 1,
      foreachIndex: itemIndex
    };
    state.activeDispatches.set(`${checkId}-${itemIndex}`, dispatch);
    try {
      const providerType = checkConfig.type || "ai";
      const providerRegistry = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports)).CheckProviderRegistry.getInstance();
      const provider = providerRegistry.getProviderOrThrow(providerType);
      const outputHistory = buildOutputHistoryFromJournal2(context2);
      const workflowInputs = resolveWorkflowInputs(checkConfig, context2);
      const providerConfig = {
        type: providerType,
        checkName: checkId,
        prompt: checkConfig.prompt,
        exec: checkConfig.exec,
        schema: checkConfig.schema,
        group: checkConfig.group,
        focus: checkConfig.focus || mapCheckNameToFocus2(checkId),
        transform: checkConfig.transform,
        transform_js: checkConfig.transform_js,
        env: checkConfig.env,
        forEach: checkConfig.forEach,
        ...checkConfig,
        eventContext: context2.prInfo?.eventContext || {},
        __outputHistory: outputHistory,
        // Propagate workflow inputs for template access via {{ inputs.* }}
        workflowInputs,
        ai: {
          ...checkConfig.ai || {},
          timeout: checkConfig.ai?.timeout || 12e5,
          debug: !!context2.debug
        }
      };
      try {
        const maybeOctokit = context2.executionContext?.octokit;
        if (maybeOctokit) {
          providerConfig.eventContext = {
            ...providerConfig.eventContext,
            octokit: maybeOctokit
          };
        }
      } catch {
      }
      try {
        const webhookCtx = context2.executionContext?.webhookContext;
        const webhookData = webhookCtx?.webhookData;
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] webhookContext: ${webhookCtx ? "present" : "absent"}, webhookData size: ${webhookData?.size || 0}`
          );
        }
        if (webhookData && webhookData.size > 0) {
          for (const payload of webhookData.values()) {
            const slackConv = payload?.slack_conversation;
            if (slackConv) {
              const event = payload?.event;
              const messageCount = Array.isArray(slackConv?.messages) ? slackConv.messages.length : 0;
              if (context2.debug) {
                logger.info(
                  `[LevelDispatch] Slack conversation extracted: ${messageCount} messages`
                );
              }
              providerConfig.eventContext = {
                ...providerConfig.eventContext,
                slack: {
                  event: event || {},
                  conversation: slackConv
                },
                conversation: slackConv
                // Also expose at top level for convenience
              };
              break;
            }
          }
        }
      } catch {
      }
      const dependencyResults = buildDependencyResultsWithScope2(
        checkId,
        checkConfig,
        context2,
        scope2
      );
      for (const [key, value] of sharedDependencyResults.entries()) {
        if (!dependencyResults.has(key)) {
          dependencyResults.set(key, value);
        }
      }
      try {
        const rawDeps = checkConfig?.depends_on || [];
        const depList = Array.isArray(rawDeps) ? rawDeps : [rawDeps];
        if (depList.length > 0) {
          const groupSatisfied = (token) => {
            if (typeof token !== "string") return true;
            const orOptions = token.includes("|") ? token.split("|").map((s) => s.trim()).filter(Boolean) : [token];
            for (const opt of orOptions) {
              const dr = dependencyResults.get(opt);
              const depCfg = context2.config.checks?.[opt];
              const cont = !!(depCfg && depCfg.continue_on_failure === true);
              let failed = false;
              let skipped = false;
              if (!dr) {
                failed = true;
              } else {
                const out = dr.output;
                const fatal = hasFatalIssues2(dr);
                failed = fatal || !!out && typeof out === "object" && out.__failed === true;
                skipped = !!(out && typeof out === "object" && out.__skip === true);
              }
              const satisfied = !skipped && (!failed || cont);
              if (satisfied) return true;
            }
            return false;
          };
          let allSatisfied = true;
          for (const token of depList) {
            if (!groupSatisfied(token)) {
              allSatisfied = false;
              break;
            }
          }
          if (!allSatisfied) {
            if (context2.debug) {
              logger.info(
                `[LevelDispatch] Skipping ${checkId} iteration ${itemIndex} due to unsatisfied dependency group(s)`
              );
            }
            const iterationDurationMs2 = Date.now() - iterationStartMs;
            perIterationDurations.push(iterationDurationMs2);
            perItemResults.push({ issues: [] });
            allOutputs.push({ __skip: true });
            continue;
          }
        }
      } catch {
      }
      const prInfo = context2.prInfo || {
        number: 1,
        title: "State Machine Execution",
        author: "system",
        eventType: context2.event || "manual",
        eventContext: {},
        files: [],
        commits: []
      };
      const executionContext = {
        ...context2.executionContext,
        _engineMode: context2.mode,
        _parentContext: context2,
        _parentState: state
      };
      {
        const assumeExpr = checkConfig?.assume;
        if (assumeExpr) {
          let ok = true;
          try {
            const evaluator = new FailureConditionEvaluator();
            const exprs = Array.isArray(assumeExpr) ? assumeExpr : [assumeExpr];
            for (const ex of exprs) {
              const res = await evaluator.evaluateIfCondition(checkId, ex, {
                event: context2.event || "manual",
                previousResults: dependencyResults
              });
              if (!res) {
                ok = false;
                break;
              }
            }
          } catch (error) {
            const msg = error instanceof Error ? error.message : String(error);
            logger.error(`Failed to evaluate assume expression for check '${checkId}': ${msg}`);
            ok = false;
          }
          if (!ok) {
            logger.info(
              `\u23ED  Skipped (assume: ${String(Array.isArray(assumeExpr) ? assumeExpr[0] : assumeExpr).substring(0, 40)}${String(Array.isArray(assumeExpr) ? assumeExpr[0] : assumeExpr).length > 40 ? "..." : ""})`
            );
            const iterationDurationMs2 = Date.now() - iterationStartMs;
            perIterationDurations.push(iterationDurationMs2);
            perItemResults.push({ issues: [] });
            allOutputs.push({ __skip: true });
            continue;
          }
        }
      }
      try {
        emitNdjsonFallback("visor.provider", {
          "visor.check.id": checkId,
          "visor.provider.type": providerType
        });
      } catch {
      }
      const itemResult = await withActiveSpan(
        `visor.check.${checkId}`,
        {
          "visor.check.id": checkId,
          "visor.check.type": providerType,
          "visor.foreach.index": itemIndex,
          session_id: context2.sessionId,
          wave: state.wave
        },
        async () => provider.execute(prInfo, providerConfig, dependencyResults, executionContext)
      );
      const enrichedIssues = (itemResult.issues || []).map((issue) => ({
        ...issue,
        checkName: checkId,
        ruleId: `${checkId}/${issue.ruleId || "unknown"}`,
        group: checkConfig.group,
        schema: typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema,
        template: checkConfig.template,
        timestamp: Date.now()
      }));
      let output = itemResult.output;
      let content = itemResult.content;
      if (!content && enrichedIssues.length > 0) {
        content = enrichedIssues.map(
          (i) => `- **${i.severity.toUpperCase()}**: ${i.message} (${i.file}:${i.line})`
        ).join("\n");
      }
      const iterationHasFatalIssues = enrichedIssues.some((issue) => {
        const ruleId = issue.ruleId || "";
        return ruleId.endsWith("/error") || // System errors
        ruleId.includes("/execution_error") || // Command failures
        ruleId.endsWith("_fail_if");
      });
      if (iterationHasFatalIssues && output !== void 0 && output !== null && typeof output === "object") {
        output = { ...output, __failed: true };
      } else if (iterationHasFatalIssues) {
        output = { __value: output, __failed: true };
      }
      logger.info(
        `[LevelDispatch][DEBUG] Iteration ${itemIndex}: output=${JSON.stringify(output)?.substring(0, 100)}, hasFatalIssues=${iterationHasFatalIssues}`
      );
      const enrichedResult = {
        ...itemResult,
        issues: enrichedIssues,
        ...content ? { content } : {}
      };
      try {
        let schemaObj = (typeof checkConfig.schema === "object" ? checkConfig.schema : void 0) || checkConfig.output_schema;
        if (!schemaObj && typeof checkConfig.schema === "string") {
          try {
            const { loadRendererSchema: loadRendererSchema2 } = await Promise.resolve().then(() => (init_renderer_schema(), renderer_schema_exports));
            schemaObj = await loadRendererSchema2(checkConfig.schema);
          } catch {
          }
        }
        const itemOutput = output;
        if (schemaObj && itemOutput !== void 0) {
          const Ajv4 = require("ajv");
          const ajv = new Ajv4({ allErrors: true, allowUnionTypes: true, strict: false });
          const validate = ajv.compile(schemaObj);
          const valid = validate(itemOutput);
          if (!valid) {
            const errs = (validate.errors || []).slice(0, 3).map((e) => e.message).join("; ");
            const issue = {
              file: "contract",
              line: 0,
              ruleId: `contract/schema_validation_failed`,
              message: `Output schema validation failed${errs ? `: ${errs}` : ""}`,
              severity: "error",
              category: "logic",
              checkName: checkId,
              group: checkConfig.group,
              schema: "json-schema",
              timestamp: Date.now()
            };
            enrichedResult.issues = [...enrichedResult.issues || [], issue];
            if (Array.isArray(enrichedIssues)) {
              enrichedIssues.push(issue);
            }
          }
        }
      } catch {
      }
      try {
        const guaranteeExpr = checkConfig?.guarantee;
        if (guaranteeExpr) {
          const evaluator = new FailureConditionEvaluator();
          const exprs = Array.isArray(guaranteeExpr) ? guaranteeExpr : [guaranteeExpr];
          for (const ex of exprs) {
            const holds = await evaluator.evaluateIfCondition(checkId, ex, {
              previousResults: dependencyResults,
              event: context2.event || "manual",
              output
              // Pass the iteration output for guarantee evaluation
            });
            if (!holds) {
              const issue = {
                file: "contract",
                line: 0,
                ruleId: `contract/guarantee_failed`,
                message: `Guarantee failed: ${ex}`,
                severity: "error",
                category: "logic",
                checkName: checkId,
                group: checkConfig.group,
                schema: typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema,
                timestamp: Date.now()
              };
              enrichedResult.issues = [...enrichedResult.issues || [], issue];
            }
          }
        }
      } catch {
      }
      if (checkConfig.fail_if) {
        try {
          const evaluator = new FailureConditionEvaluator();
          const failed = await evaluator.evaluateSimpleCondition(
            checkId,
            typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema || "",
            checkConfig.group || "",
            enrichedResult,
            checkConfig.fail_if,
            Object.fromEntries(dependencyResults.entries())
          );
          if (failed) {
            logger.warn(
              `[LevelDispatch] fail_if triggered for ${checkId} iteration ${itemIndex}: ${checkConfig.fail_if}`
            );
            const failIssue = {
              file: "system",
              line: 0,
              ruleId: `${checkId}/${checkId}_fail_if`,
              message: `Check failure condition met: ${checkConfig.fail_if}`,
              severity: "error",
              category: "logic",
              checkName: checkId,
              group: checkConfig.group,
              schema: typeof checkConfig.schema === "object" ? "custom" : checkConfig.schema,
              timestamp: Date.now()
            };
            enrichedResult.issues = [...enrichedResult.issues || [], failIssue];
            enrichedIssues.push(failIssue);
            allIssues.push(failIssue);
            const nowHasFatalIssues = enrichedResult.issues.some((issue) => {
              const ruleId = issue.ruleId || "";
              return ruleId.endsWith("/error") || ruleId.includes("/execution_error") || ruleId.endsWith("_fail_if");
            });
            if (nowHasFatalIssues && output !== void 0 && output !== null && typeof output === "object" && !output.__failed) {
              output = { ...output, __failed: true };
            } else if (nowHasFatalIssues && !output?.__failed) {
              output = { __value: output, __failed: true };
            }
          }
        } catch (error) {
          const msg = error instanceof Error ? error.message : String(error);
          logger.error(
            `[LevelDispatch] Error evaluating fail_if for ${checkId} iteration ${itemIndex}: ${msg}`
          );
        }
      }
      perItemResults.push(enrichedResult);
      allIssues.push(...enrichedIssues);
      allOutputs.push(output);
      if (typeof content === "string" && content.trim()) {
        allContents.push(content.trim());
      }
      try {
        const journalEntry = {
          sessionId: context2.sessionId,
          checkId,
          result: { ...enrichedResult, output },
          event: context2.event || "manual",
          scope: scope2
        };
        logger.info(
          `[LevelDispatch][DEBUG] Committing to journal: checkId=${checkId}, scope=${JSON.stringify(scope2)}, hasOutput=${output !== void 0}`
        );
        context2.journal.commitEntry(journalEntry);
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit to journal: ${error}`);
      }
      state.activeDispatches.delete(`${checkId}-${itemIndex}`);
      emitEvent({
        type: "CheckCompleted",
        checkId,
        scope: scope2,
        result: {
          ...enrichedResult,
          output
        }
      });
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      updateStats2(
        [{ checkId, result: enrichedResult, duration: iterationDurationMs }],
        state,
        true
      );
    } catch (error) {
      const iterationDurationMs = Date.now() - iterationStartMs;
      perIterationDurations.push(iterationDurationMs);
      const err = error instanceof Error ? error : new Error(String(error));
      logger.error(
        `[LevelDispatch] Error executing check ${checkId} item ${itemIndex}: ${err.message}`
      );
      state.activeDispatches.delete(`${checkId}-${itemIndex}`);
      emitEvent({
        type: "CheckErrored",
        checkId,
        scope: scope2,
        error: {
          message: err.message,
          stack: err.stack,
          name: err.name
        }
      });
      const errorIssue = {
        file: "",
        line: 0,
        ruleId: `${checkId}/error`,
        message: err.message,
        severity: "error",
        category: "logic"
      };
      allIssues.push(errorIssue);
      perItemResults.push({ issues: [errorIssue] });
      updateStats2(
        [{ checkId, result: { issues: [errorIssue] }, error: err, duration: iterationDurationMs }],
        state,
        true
      );
    }
  }
  state.completedChecks.add(checkId);
  const checkStats = state.stats.get(checkId);
  if (checkStats) {
    checkStats.outputsProduced = allOutputs.length;
    checkStats.perIterationDuration = perIterationDurations;
    const previewItems = allOutputs.slice(0, 3).map((item) => {
      const str = typeof item === "string" ? item : JSON.stringify(item) ?? "undefined";
      return str.length > 50 ? str.substring(0, 50) + "..." : str;
    });
    if (allOutputs.length > 3) {
      checkStats.forEachPreview = [...previewItems, `...${allOutputs.length - 3} more`];
    } else {
      checkStats.forEachPreview = previewItems;
    }
    state.stats.set(checkId, checkStats);
    if (checkStats.totalRuns > 0 && checkStats.failedRuns === checkStats.totalRuns) {
      logger.info(
        `[LevelDispatch] forEach check ${checkId} failed completely (${checkStats.failedRuns}/${checkStats.totalRuns} iterations failed)`
      );
      if (!state.failedChecks) {
        state.failedChecks = /* @__PURE__ */ new Set();
      }
      state.failedChecks.add(checkId);
    }
  }
  const aggregatedResult = {
    issues: allIssues,
    isForEach: true,
    forEachItems: allOutputs,
    forEachItemResults: perItemResults,
    // Include aggregated content from all iterations
    ...allContents.length > 0 ? { content: allContents.join("\n") } : {}
  };
  logger.info(
    `[LevelDispatch][DEBUG] Aggregated result for ${checkId}: forEachItems.length=${allOutputs.length}, results=${perItemResults.length}`
  );
  logger.info(`[LevelDispatch][DEBUG] allOutputs: ${JSON.stringify(allOutputs).substring(0, 200)}`);
  try {
    logger.info(`[LevelDispatch] Calling handleRouting for ${checkId}`);
  } catch {
  }
  let wasHalted = false;
  try {
    state.completedChecks.add(checkId);
    const currentWaveCompletions = state.currentWaveCompletions;
    if (currentWaveCompletions) currentWaveCompletions.add(checkId);
    wasHalted = await handleRouting(context2, state, transition, emitEvent, {
      checkId,
      scope: [],
      result: aggregatedResult,
      checkConfig,
      success: !hasFatalIssues2(aggregatedResult)
    });
  } catch (error) {
    logger.warn(`[LevelDispatch] Routing error for aggregated forEach ${checkId}: ${error}`);
  }
  if (wasHalted) {
    logger.info(`[LevelDispatch] Execution halted after routing for aggregated ${checkId}`);
    return aggregatedResult;
  }
  try {
    context2.journal.commitEntry({
      sessionId: context2.sessionId,
      checkId,
      result: aggregatedResult,
      event: context2.event || "manual",
      scope: []
    });
    logger.info(`[LevelDispatch][DEBUG] Committed aggregated result to journal with scope=[]`);
  } catch (error) {
    logger.warn(`[LevelDispatch] Failed to commit aggregated forEach result to journal: ${error}`);
  }
  emitEvent({
    type: "CheckCompleted",
    checkId,
    scope: [],
    result: aggregatedResult
  });
  const parentCheckConfig = context2.config.checks?.[forEachParent];
  logger.info(
    `[LevelDispatch][DEBUG] Checking on_finish for forEach parent ${forEachParent}: has_on_finish=${!!parentCheckConfig?.on_finish}, is_forEach=${!!parentCheckConfig?.forEach}`
  );
  if (parentCheckConfig?.on_finish && parentCheckConfig.forEach) {
    logger.info(
      `[LevelDispatch] Processing on_finish for forEach parent ${forEachParent} after children complete`
    );
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        context2.event
      );
      const parentResult = contextView.get(forEachParent);
      if (parentResult) {
        logger.info(
          `[LevelDispatch] Found parent result for ${forEachParent}, evaluating on_finish`
        );
        const onFinish = parentCheckConfig.on_finish;
        let queuedForward = false;
        logger.info(
          `[LevelDispatch] on_finish.run: ${onFinish.run?.length || 0} targets, targets=${JSON.stringify(onFinish.run || [])}`
        );
        if (onFinish.run && onFinish.run.length > 0) {
          for (const targetCheck of onFinish.run) {
            logger.info(`[LevelDispatch] Processing on_finish.run target: ${targetCheck}`);
            logger.info(
              `[LevelDispatch] Loop budget check: routingLoopCount=${state.routingLoopCount}, max_loops=${context2.config.routing?.max_loops ?? 10}`
            );
            if (checkLoopBudget(context2, state, "on_finish", "run")) {
              const errorIssue = {
                file: "system",
                line: 0,
                ruleId: `${forEachParent}/routing/loop_budget_exceeded`,
                message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_finish run`,
                severity: "error",
                category: "logic"
              };
              parentResult.issues = [...parentResult.issues || [], errorIssue];
              try {
                context2.journal.commitEntry({
                  sessionId: context2.sessionId,
                  checkId: forEachParent,
                  result: parentResult,
                  event: context2.event || "manual",
                  scope: []
                });
              } catch (err) {
                logger.warn(
                  `[LevelDispatch] Failed to commit parent result with loop budget error: ${err}`
                );
              }
              return aggregatedResult;
            }
            state.routingLoopCount++;
            recordOnFinishRoutingEvent({
              checkId: forEachParent,
              action: "run",
              target: targetCheck,
              source: "run",
              scope: []
            });
            emitEvent({
              type: "ForwardRunRequested",
              target: targetCheck,
              scope: [],
              origin: "run"
            });
            queuedForward = true;
          }
        }
        try {
          const { evaluateTransitions: evaluateTransitions2 } = await Promise.resolve().then(() => (init_routing(), routing_exports));
          const transTarget = await evaluateTransitions2(
            onFinish.transitions,
            forEachParent,
            parentCheckConfig,
            parentResult,
            context2,
            state
          );
          if (transTarget !== void 0) {
            if (transTarget) {
              if (checkLoopBudget(context2, state, "on_finish", "goto")) {
                const errorIssue = {
                  file: "system",
                  line: 0,
                  ruleId: `${forEachParent}/routing/loop_budget_exceeded`,
                  message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_finish transitions`,
                  severity: "error",
                  category: "logic"
                };
                parentResult.issues = [...parentResult.issues || [], errorIssue];
                try {
                  context2.journal.commitEntry({
                    sessionId: context2.sessionId,
                    checkId: forEachParent,
                    result: parentResult,
                    event: context2.event || "manual",
                    scope: []
                  });
                } catch {
                }
                return aggregatedResult;
              }
              state.routingLoopCount++;
              recordOnFinishRoutingEvent({
                checkId: forEachParent,
                action: "goto",
                target: transTarget.to,
                source: "transitions",
                scope: [],
                gotoEvent: transTarget.goto_event
              });
              emitEvent({
                type: "ForwardRunRequested",
                target: transTarget.to,
                scope: [],
                origin: "goto_js",
                gotoEvent: transTarget.goto_event
              });
              queuedForward = true;
            }
            if (queuedForward) {
            }
            return aggregatedResult;
          }
        } catch (e) {
          logger.error(
            `[LevelDispatch] Error evaluating on_finish transitions for ${forEachParent}: ${e instanceof Error ? e.message : String(e)}`
          );
        }
        const { evaluateGoto: evaluateGoto2 } = await Promise.resolve().then(() => (init_routing(), routing_exports));
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] Evaluating on_finish.goto_js for forEach parent: ${forEachParent}`
          );
          if (onFinish.goto_js) {
            logger.info(`[LevelDispatch] goto_js code: ${onFinish.goto_js.substring(0, 200)}`);
          }
          try {
            const snapshotId2 = context2.journal.beginSnapshot();
            const all = context2.journal.readVisible(context2.sessionId, snapshotId2, void 0);
            const keys = Array.from(new Set(all.map((e) => e.checkId)));
            logger.info(`[LevelDispatch] history keys: ${keys.join(", ")}`);
          } catch {
          }
        }
        const gotoTarget = await evaluateGoto2(
          onFinish.goto_js,
          onFinish.goto,
          forEachParent,
          parentCheckConfig,
          parentResult,
          context2,
          state
        );
        if (context2.debug) {
          logger.info(`[LevelDispatch] goto_js evaluation result: ${gotoTarget || "null"}`);
        }
        if (gotoTarget) {
          if (queuedForward && gotoTarget === forEachParent) {
            logger.info(
              `[LevelDispatch] on_finish.goto to self (${gotoTarget}) deferred, will process after WaveRetry`
            );
          }
          if (checkLoopBudget(context2, state, "on_finish", "goto")) {
            const errorIssue = {
              file: "system",
              line: 0,
              ruleId: `${forEachParent}/routing/loop_budget_exceeded`,
              message: `Routing loop budget exceeded (max_loops=${context2.config.routing?.max_loops ?? 10}) during on_finish goto`,
              severity: "error",
              category: "logic"
            };
            parentResult.issues = [...parentResult.issues || [], errorIssue];
            try {
              context2.journal.commitEntry({
                sessionId: context2.sessionId,
                checkId: forEachParent,
                result: parentResult,
                event: context2.event || "manual",
                scope: []
              });
            } catch (err) {
              logger.warn(
                `[LevelDispatch] Failed to commit parent result with loop budget error: ${err}`
              );
            }
            return aggregatedResult;
          }
          logger.info(`[LevelDispatch] on_finish for ${forEachParent} routing to: ${gotoTarget}`);
          state.routingLoopCount++;
          recordOnFinishRoutingEvent({
            checkId: forEachParent,
            action: "goto",
            target: gotoTarget,
            source: onFinish.goto_js ? "goto_js" : "goto",
            scope: []
          });
          emitEvent({
            type: "ForwardRunRequested",
            target: gotoTarget,
            scope: [],
            origin: "goto_js",
            gotoEvent: context2.event
          });
          state.flags.forwardRunRequested = true;
          try {
            const guardKeyGoto = `waveRetry:on_finish:${forEachParent}:wave:${state.wave}`;
            if (!state.forwardRunGuards?.has(guardKeyGoto)) {
              state.forwardRunGuards?.add(guardKeyGoto);
              emitEvent({ type: "WaveRetry", reason: "on_finish" });
            }
          } catch {
          }
        } else {
          logger.info(`[LevelDispatch] on_finish for ${forEachParent} returned null, no routing`);
        }
        if (queuedForward) {
          const guardKey = `waveRetry:on_finish:${forEachParent}:wave:${state.wave}`;
          logger.info(
            `[LevelDispatch] Checking WaveRetry guard: ${guardKey}, has=${!!state.forwardRunGuards?.has(guardKey)}`
          );
          if (!state.forwardRunGuards?.has(guardKey)) {
            state.forwardRunGuards?.add(guardKey);
            logger.info(`[LevelDispatch] Emitting WaveRetry event for on_finish.run targets`);
            emitEvent({ type: "WaveRetry", reason: "on_finish" });
          }
        } else {
        }
      } else {
        logger.warn(`[LevelDispatch] Could not find parent result for ${forEachParent} in journal`);
      }
    } catch (error) {
      logger.error(
        `[LevelDispatch] Error processing on_finish for forEach parent ${forEachParent}: ${error}`
      );
    }
  }
  return aggregatedResult;
}
async function executeSingleCheck2(checkId, context2, state, emitEvent, transition, scopeOverride) {
  const checkConfig = context2.config.checks?.[checkId];
  if (checkConfig?.if) {
    const shouldRun = await evaluateIfCondition(checkId, checkConfig, context2, state);
    if (!shouldRun) {
      logger.info(
        `\u23ED  Skipped (if: ${checkConfig.if.substring(0, 40)}${checkConfig.if.length > 40 ? "..." : ""})`
      );
      const emptyResult = { issues: [] };
      try {
        Object.defineProperty(emptyResult, "__skipped", {
          value: "if_condition",
          enumerable: false
        });
      } catch {
      }
      state.completedChecks.add(checkId);
      const stats = {
        checkName: checkId,
        totalRuns: 0,
        successfulRuns: 0,
        failedRuns: 0,
        skippedRuns: 0,
        skipped: true,
        skipReason: "if_condition",
        skipCondition: checkConfig.if,
        totalDuration: 0,
        issuesFound: 0,
        issuesBySeverity: {
          critical: 0,
          error: 0,
          warning: 0,
          info: 0
        }
      };
      state.stats.set(checkId, stats);
      logger.info(`[LevelDispatch] Recorded skip stats for ${checkId}: skipReason=if_condition`);
      try {
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: emptyResult,
          event: context2.event || "manual",
          scope: []
        });
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit skipped result to journal: ${error}`);
      }
      emitEvent({
        type: "CheckCompleted",
        checkId,
        scope: [],
        result: emptyResult
      });
      return emptyResult;
    }
  }
  const dependencies = checkConfig?.depends_on || [];
  const depList = Array.isArray(dependencies) ? dependencies : [dependencies];
  const failedChecks = state.failedChecks;
  const allowedFailedDeps = state.allowedFailedDeps?.get(checkId);
  const tokens = depList.filter(Boolean);
  const groupSatisfied = (token) => {
    const options = token.includes("|") ? token.split("|").map((s) => s.trim()).filter(Boolean) : [token];
    for (const opt of options) {
      const isAllowedFailedDep = !!(allowedFailedDeps && allowedFailedDeps.has(opt));
      if (isAllowedFailedDep) {
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] Allowing ${checkId} to run despite failed dependency ${opt} (on_fail.run)`
          );
        }
        return true;
      }
      const depCfg = context2.config.checks?.[opt];
      const cont = !!(depCfg && depCfg.continue_on_failure === true);
      const st = state.stats.get(opt);
      const skipped = !!(st && st.skipped === true);
      const skipReason = st?.skipReason;
      const skippedDueToEmptyForEach = skipped && skipReason === "forEach_empty";
      const wasMarkedFailed = !!(failedChecks && failedChecks.has(opt)) && !skippedDueToEmptyForEach;
      const failedOnly = !!(st && (st.failedRuns || 0) > 0 && (st.successfulRuns || 0) === 0);
      const satisfied = (!skipped || skippedDueToEmptyForEach) && (!failedOnly && !wasMarkedFailed || cont);
      if (satisfied) return true;
    }
    return false;
  };
  if (tokens.length > 0) {
    let allOk = true;
    for (const t of tokens) {
      if (!groupSatisfied(t)) {
        allOk = false;
        break;
      }
    }
    if (!allOk) {
      const emptyResult = { issues: [] };
      try {
        Object.defineProperty(emptyResult, "__skipped", {
          value: "dependency_failed",
          enumerable: false
        });
      } catch {
      }
      state.completedChecks.add(checkId);
      if (!state.failedChecks) state.failedChecks = /* @__PURE__ */ new Set();
      state.failedChecks.add(checkId);
      const stats = {
        checkName: checkId,
        totalRuns: 0,
        successfulRuns: 0,
        failedRuns: 0,
        skippedRuns: 0,
        skipped: true,
        skipReason: "dependency_failed",
        totalDuration: 0,
        issuesFound: 0,
        issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
      };
      state.stats.set(checkId, stats);
      try {
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: emptyResult,
          event: context2.event || "manual",
          scope: []
        });
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit empty result to journal: ${error}`);
      }
      emitEvent({ type: "CheckCompleted", checkId, scope: [], result: emptyResult });
      return emptyResult;
    }
  }
  let forEachParent;
  let forEachItems;
  for (const depId of depList) {
    if (!depId) continue;
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
        context2.journal,
        context2.sessionId,
        snapshotId,
        [],
        context2.event
      );
      const depResult = contextView.get(depId);
      if (context2.debug) {
        logger.info(
          `[LevelDispatch] Checking dependency ${depId} for ${checkId}: has forEachItems=${!!depResult?.forEachItems}, isArray=${Array.isArray(depResult?.forEachItems)}`
        );
        if (depResult?.forEachItems) {
          logger.info(
            `[LevelDispatch] forEachItems length: ${depResult.forEachItems.length}, items: ${JSON.stringify(depResult.forEachItems).substring(0, 200)}`
          );
        }
      }
      if (depResult?.forEachItems && Array.isArray(depResult.forEachItems)) {
        forEachParent = depId;
        forEachItems = depResult.forEachItems;
        if (context2.debug && forEachItems) {
          logger.info(
            `[LevelDispatch] Detected forEach parent ${depId} with ${forEachItems.length} items for check ${checkId}`
          );
        }
        break;
      }
    } catch (error) {
      if (context2.debug) {
        logger.warn(`[LevelDispatch] Error checking forEach parent ${depId}: ${error}`);
      }
    }
  }
  if (forEachParent && forEachItems !== void 0) {
    let fanoutMode = "reduce";
    const explicit = checkConfig?.fanout;
    if (explicit === "map" || explicit === "reduce") {
      fanoutMode = explicit;
    } else {
      const providerType = context2.checks[checkId]?.providerType || "";
      const reduceProviders = /* @__PURE__ */ new Set(["log", "memory", "script", "workflow", "noop"]);
      fanoutMode = reduceProviders.has(providerType) ? "reduce" : "map";
    }
    if (fanoutMode === "map") {
      if (forEachItems.length === 0) {
        logger.info(`\u23ED  Skipped (forEach parent "${forEachParent}" has 0 items)`);
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] Skipping check ${checkId}: forEach parent ${forEachParent} has zero items`
          );
        }
        const emptyResult = { issues: [] };
        try {
          Object.defineProperty(emptyResult, "__skipped", {
            value: "forEach_empty",
            enumerable: false
          });
        } catch {
        }
        state.completedChecks.add(checkId);
        if (!state.failedChecks) {
          state.failedChecks = /* @__PURE__ */ new Set();
        }
        state.failedChecks.add(checkId);
        let derivedSkipReason = "forEach_empty";
        try {
          const parentFailed = !!(state.failedChecks && state.failedChecks.has(forEachParent)) || (() => {
            const s = state.stats.get(forEachParent);
            return !!(s && (s.failedRuns || 0) > 0);
          })();
          if (parentFailed) derivedSkipReason = "dependency_failed";
        } catch {
        }
        const stats = {
          checkName: checkId,
          totalRuns: 0,
          successfulRuns: 0,
          failedRuns: 0,
          skippedRuns: 0,
          skipped: true,
          skipReason: derivedSkipReason,
          totalDuration: 0,
          issuesFound: 0,
          issuesBySeverity: {
            critical: 0,
            error: 0,
            warning: 0,
            info: 0
          }
        };
        state.stats.set(checkId, stats);
        try {
          context2.journal.commitEntry({
            sessionId: context2.sessionId,
            checkId,
            result: emptyResult,
            event: context2.event || "manual",
            scope: []
          });
        } catch (error) {
          logger.warn(`[LevelDispatch] Failed to commit empty result to journal: ${error}`);
        }
        emitEvent({
          type: "CheckCompleted",
          checkId,
          scope: [],
          result: emptyResult
        });
        return emptyResult;
      }
      return await executeCheckWithForEachItems2(
        checkId,
        forEachParent,
        forEachItems,
        context2,
        state,
        emitEvent,
        transition
      );
    }
  }
  const scope = scopeOverride || [];
  emitEvent({ type: "CheckScheduled", checkId, scope });
  const startTime = Date.now();
  const dispatch = {
    id: `${checkId}-${Date.now()}`,
    checkId,
    scope,
    provider: context2.checks[checkId]?.providerType || "unknown",
    startMs: startTime,
    attempts: 1
  };
  state.activeDispatches.set(checkId, dispatch);
  try {
    const checkConfig2 = context2.config.checks?.[checkId];
    if (!checkConfig2) {
      throw new Error(`Check configuration not found: ${checkId}`);
    }
    const checksMeta = {};
    try {
      const allChecks = context2.config.checks || {};
      for (const [id, cfg] of Object.entries(allChecks)) {
        const anyCfg = cfg;
        checksMeta[id] = { type: anyCfg.type, group: anyCfg.group };
      }
    } catch {
    }
    const providerType = checkConfig2.type || "ai";
    const providerRegistry = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports)).CheckProviderRegistry.getInstance();
    const provider = providerRegistry.getProviderOrThrow(providerType);
    const outputHistory = buildOutputHistoryFromJournal2(context2);
    const workflowInputs = resolveWorkflowInputs(checkConfig2, context2);
    const providerConfig = {
      type: providerType,
      checkName: checkId,
      prompt: checkConfig2.prompt,
      exec: checkConfig2.exec,
      schema: checkConfig2.schema,
      group: checkConfig2.group,
      focus: checkConfig2.focus || mapCheckNameToFocus2(checkId),
      transform: checkConfig2.transform,
      transform_js: checkConfig2.transform_js,
      env: checkConfig2.env,
      forEach: checkConfig2.forEach,
      ...checkConfig2,
      eventContext: context2.prInfo?.eventContext || {},
      // Expose history and checks metadata for template helpers
      __outputHistory: outputHistory,
      checksMeta,
      // Propagate workflow inputs for template access via {{ inputs.* }}
      workflowInputs,
      ai: {
        ...checkConfig2.ai || {},
        timeout: checkConfig2.ai?.timeout || 12e5,
        debug: !!context2.debug
      }
    };
    try {
      const maybeOctokit = context2.executionContext?.octokit;
      if (maybeOctokit) {
        providerConfig.eventContext = {
          ...providerConfig.eventContext,
          octokit: maybeOctokit
        };
      }
    } catch {
    }
    try {
      const webhookCtx = context2.executionContext?.webhookContext;
      const webhookData = webhookCtx?.webhookData;
      if (context2.debug) {
        logger.info(
          `[LevelDispatch] webhookContext: ${webhookCtx ? "present" : "absent"}, webhookData size: ${webhookData?.size || 0}`
        );
      }
      if (webhookData && webhookData.size > 0) {
        for (const payload of webhookData.values()) {
          const slackConv = payload?.slack_conversation;
          if (slackConv) {
            const event = payload?.event;
            const messageCount = Array.isArray(slackConv?.messages) ? slackConv.messages.length : 0;
            if (context2.debug) {
              logger.info(`[LevelDispatch] Slack conversation extracted: ${messageCount} messages`);
            }
            providerConfig.eventContext = {
              ...providerConfig.eventContext,
              slack: {
                event: event || {},
                conversation: slackConv
              },
              conversation: slackConv
              // Also expose at top level for convenience
            };
            break;
          }
        }
      }
    } catch {
    }
    const dependencyResults = buildDependencyResults(checkId, checkConfig2, context2, state);
    const prInfo = context2.prInfo || {
      number: 1,
      title: "State Machine Execution",
      author: "system",
      eventType: context2.event || "manual",
      eventContext: {},
      files: [],
      commits: []
    };
    const executionContext = {
      ...context2.executionContext,
      _engineMode: context2.mode,
      _parentContext: context2,
      _parentState: state,
      // Make checks metadata available to providers that want it
      checksMeta
    };
    {
      const assumeExpr = checkConfig2?.assume;
      if (assumeExpr) {
        let ok = true;
        try {
          const evaluator = new FailureConditionEvaluator();
          const exprs = Array.isArray(assumeExpr) ? assumeExpr : [assumeExpr];
          for (const ex of exprs) {
            const res = await evaluator.evaluateIfCondition(checkId, ex, {
              event: context2.event || "manual",
              previousResults: dependencyResults
            });
            if (!res) {
              ok = false;
              break;
            }
          }
        } catch (error) {
          const msg = error instanceof Error ? error.message : String(error);
          logger.error(`Failed to evaluate assume expression for check '${checkId}': ${msg}`);
          ok = false;
        }
        if (!ok) {
          logger.info(
            `\u23ED  Skipped (assume: ${String(Array.isArray(assumeExpr) ? assumeExpr[0] : assumeExpr).substring(0, 40)}${String(Array.isArray(assumeExpr) ? assumeExpr[0] : assumeExpr).length > 40 ? "..." : ""})`
          );
          state.completedChecks.add(checkId);
          const stats = {
            checkName: checkId,
            totalRuns: 0,
            successfulRuns: 0,
            failedRuns: 0,
            skippedRuns: 0,
            skipped: true,
            skipReason: "assume",
            totalDuration: 0,
            issuesFound: 0,
            issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
          };
          state.stats.set(checkId, stats);
          const emptyResult = { issues: [] };
          try {
            Object.defineProperty(emptyResult, "__skipped", {
              value: "assume",
              enumerable: false
            });
          } catch {
          }
          try {
            context2.journal.commitEntry({
              sessionId: context2.sessionId,
              checkId,
              result: emptyResult,
              event: context2.event || "manual",
              scope
            });
          } catch {
          }
          emitEvent({ type: "CheckCompleted", checkId, scope, result: emptyResult });
          return emptyResult;
        }
      }
    }
    try {
      emitNdjsonFallback("visor.provider", {
        "visor.check.id": checkId,
        "visor.provider.type": providerType
      });
    } catch {
    }
    const result = await withActiveSpan(
      `visor.check.${checkId}`,
      {
        "visor.check.id": checkId,
        "visor.check.type": providerType,
        session_id: context2.sessionId,
        wave: state.wave
      },
      async () => provider.execute(prInfo, providerConfig, dependencyResults, executionContext)
    );
    try {
      const awaitingHumanInput = result?.awaitingHumanInput === true || result?.output && result.output.awaitingHumanInput === true;
      if (awaitingHumanInput) {
        state.flags = state.flags || {};
        state.flags.awaitingHumanInput = true;
        logger.info(
          `[LevelDispatch] Set awaitingHumanInput=true for check ${checkId} (wave=${state.wave})`
        );
      }
    } catch (e) {
      logger.warn(`[LevelDispatch] Failed to check awaitingHumanInput flag: ${e}`);
    }
    const enrichedIssues = (result.issues || []).map((issue) => ({
      ...issue,
      checkName: checkId,
      ruleId: `${checkId}/${issue.ruleId || "unknown"}`,
      group: checkConfig2.group,
      schema: typeof checkConfig2.schema === "object" ? "custom" : checkConfig2.schema,
      template: checkConfig2.template,
      timestamp: Date.now()
    }));
    const enrichedResult = {
      ...result,
      issues: enrichedIssues
    };
    try {
      let schemaObj = (typeof checkConfig2.schema === "object" ? checkConfig2.schema : void 0) || checkConfig2.output_schema;
      if (!schemaObj && typeof checkConfig2.schema === "string") {
        try {
          const { loadRendererSchema: loadRendererSchema2 } = await Promise.resolve().then(() => (init_renderer_schema(), renderer_schema_exports));
          schemaObj = await loadRendererSchema2(checkConfig2.schema);
        } catch {
        }
      }
      if (schemaObj && enrichedResult?.output !== void 0) {
        const Ajv4 = require("ajv");
        const ajv = new Ajv4({ allErrors: true, allowUnionTypes: true, strict: false });
        const validate = ajv.compile(schemaObj);
        const valid = validate(enrichedResult.output);
        if (!valid) {
          const errs = (validate.errors || []).slice(0, 3).map((e) => e.message).join("; ");
          const issue = {
            file: "contract",
            line: 0,
            ruleId: `contract/schema_validation_failed`,
            message: `Output schema validation failed${errs ? `: ${errs}` : ""}`,
            severity: "error",
            category: "logic",
            checkName: checkId,
            group: checkConfig2.group,
            schema: "json-schema",
            timestamp: Date.now()
          };
          enrichedResult.issues = [...enrichedResult.issues || [], issue];
        }
      }
    } catch {
    }
    try {
      const guaranteeExpr = checkConfig2?.guarantee;
      if (guaranteeExpr) {
        const evaluator = new FailureConditionEvaluator();
        const exprs = Array.isArray(guaranteeExpr) ? guaranteeExpr : [guaranteeExpr];
        for (const ex of exprs) {
          const holds = await evaluator.evaluateIfCondition(checkId, ex, {
            previousResults: dependencyResults,
            event: context2.event || "manual",
            output: enrichedResult.output
          });
          if (!holds) {
            const issue = {
              file: "contract",
              line: 0,
              ruleId: `contract/guarantee_failed`,
              message: `Guarantee failed: ${ex}`,
              severity: "error",
              category: "logic",
              checkName: checkId,
              group: checkConfig2.group,
              schema: typeof checkConfig2.schema === "object" ? "custom" : checkConfig2.schema,
              timestamp: Date.now()
            };
            enrichedResult.issues = [...enrichedResult.issues || [], issue];
          }
        }
      }
    } catch {
    }
    let isForEach = result.isForEach;
    let forEachItems2 = result.forEachItems;
    logger.info(
      `[LevelDispatch][DEBUG] After execution ${checkId}: checkConfig.forEach=${checkConfig2.forEach}, output type=${typeof result.output}, isArray=${Array.isArray(result.output)}`
    );
    if (checkConfig2.forEach === true) {
      const output = result.output;
      logger.info(
        `[LevelDispatch][DEBUG] Processing forEach=true for ${checkId}, output=${JSON.stringify(output)?.substring(0, 200)}`
      );
      if (output === void 0) {
        logger.error(`[LevelDispatch] forEach check "${checkId}" produced undefined output`);
        const undefinedError = {
          file: "system",
          line: 0,
          // Mark as execution failure so dependents treat this as failed dependency
          ruleId: "forEach/execution_error",
          message: `forEach check "${checkId}" produced undefined output. Verify your command outputs valid data and your transform_js returns a value.`,
          severity: "error",
          category: "logic"
        };
        enrichedResult.issues = [...enrichedResult.issues || [], undefinedError];
        isForEach = true;
        forEachItems2 = [];
        enrichedResult.isForEach = true;
        enrichedResult.forEachItems = [];
        try {
          if (!state.failedChecks) {
            state.failedChecks = /* @__PURE__ */ new Set();
          }
          state.failedChecks.add(checkId);
        } catch {
        }
        try {
          state.completedChecks.add(checkId);
          const currentWaveCompletions2 = state.currentWaveCompletions;
          if (currentWaveCompletions2) currentWaveCompletions2.add(checkId);
          const existing = state.stats.get(checkId);
          const aggStats = existing || {
            checkName: checkId,
            totalRuns: 0,
            successfulRuns: 0,
            failedRuns: 0,
            skippedRuns: 0,
            skipped: false,
            totalDuration: 0,
            issuesFound: 0,
            issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
          };
          aggStats.totalRuns++;
          aggStats.failedRuns++;
          aggStats.outputsProduced = 0;
          state.stats.set(checkId, aggStats);
          context2.journal.commitEntry({
            sessionId: context2.sessionId,
            checkId,
            result: enrichedResult,
            event: context2.event || "manual",
            scope: []
          });
        } catch (err) {
          logger.warn(`[LevelDispatch] Failed to persist undefined forEach result: ${err}`);
        }
        try {
          state.activeDispatches.delete(checkId);
        } catch {
        }
        emitEvent({
          type: "CheckCompleted",
          checkId,
          scope: [],
          result: enrichedResult
        });
        return enrichedResult;
      } else if (Array.isArray(output)) {
        isForEach = true;
        forEachItems2 = output;
        enrichedResult.isForEach = true;
        enrichedResult.forEachItems = output;
        logger.info(`  Found ${output.length} items for forEach iteration`);
        if (context2.debug) {
          logger.info(
            `[LevelDispatch] Check ${checkId} is forEach parent with ${output.length} items`
          );
        }
      } else {
        if (context2.debug) {
          logger.warn(
            `[LevelDispatch] Check ${checkId} has forEach:true but output is not an array: ${typeof output}, converting to single-item array`
          );
        }
        isForEach = true;
        forEachItems2 = [output];
        enrichedResult.isForEach = true;
        enrichedResult.forEachItems = [output];
      }
    }
    if (result.isForEach) {
      enrichedResult.isForEach = true;
    }
    if (result.forEachItems) {
      enrichedResult.forEachItems = result.forEachItems;
    }
    if (result.forEachItemResults) {
      enrichedResult.forEachItemResults = result.forEachItemResults;
    }
    if (result.forEachFatalMask) {
      enrichedResult.forEachFatalMask = result.forEachFatalMask;
    }
    let renderedContent;
    try {
      renderedContent = await renderTemplateContent2(checkId, checkConfig2, enrichedResult);
      if (renderedContent) {
        logger.debug(
          `[LevelDispatch] Template rendered for ${checkId}: ${renderedContent.length} chars`
        );
        emitMermaidFromMarkdown(checkId, renderedContent, "content");
      } else {
        logger.debug(`[LevelDispatch] No template content rendered for ${checkId}`);
      }
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to render template for ${checkId}: ${error}`);
    }
    if (!renderedContent && enrichedIssues.length > 0) {
      renderedContent = enrichedIssues.map(
        (i) => `- **${i.severity.toUpperCase()}**: ${i.message} (${i.file}:${i.line})`
      ).join("\n");
    }
    let outputWithTimestamp = void 0;
    if (result.output !== void 0) {
      const output = result.output;
      if (output !== null && typeof output === "object" && !Array.isArray(output)) {
        outputWithTimestamp = { ...output, ts: Date.now() };
      } else {
        outputWithTimestamp = output;
      }
    }
    const enrichedResultWithContent = renderedContent ? { ...enrichedResult, content: renderedContent } : enrichedResult;
    const enrichedResultWithTimestamp = outputWithTimestamp !== void 0 ? { ...enrichedResultWithContent, output: outputWithTimestamp } : enrichedResultWithContent;
    state.completedChecks.add(checkId);
    const currentWaveCompletions = state.currentWaveCompletions;
    if (currentWaveCompletions) {
      currentWaveCompletions.add(checkId);
    }
    try {
      logger.info(`[LevelDispatch] Calling handleRouting for ${checkId}`);
    } catch {
    }
    const wasHalted = await handleRouting(context2, state, transition, emitEvent, {
      checkId,
      scope,
      result: enrichedResult,
      checkConfig: checkConfig2,
      success: !hasFatalIssues2(enrichedResult)
    });
    if (wasHalted) {
      logger.info(
        `[LevelDispatch] Execution halted after routing for ${checkId}, stopping level dispatch`
      );
      try {
        const commitResult = {
          ...enrichedResult,
          ...renderedContent ? { content: renderedContent } : {},
          ...result.output !== void 0 ? outputWithTimestamp !== void 0 ? { output: outputWithTimestamp } : { output: result.output } : {}
        };
        context2.journal.commitEntry({
          sessionId: context2.sessionId,
          checkId,
          result: commitResult,
          event: context2.event || "manual",
          scope
        });
      } catch (error) {
        logger.warn(`[LevelDispatch] Failed to commit halt result to journal: ${error}`);
      }
      return enrichedResult;
    }
    try {
      const commitResult = {
        ...enrichedResult,
        ...renderedContent ? { content: renderedContent } : {},
        ...result.output !== void 0 ? outputWithTimestamp !== void 0 ? { output: outputWithTimestamp } : { output: result.output } : {}
      };
      context2.journal.commitEntry({
        sessionId: context2.sessionId,
        checkId,
        result: commitResult,
        event: context2.event || "manual",
        scope
      });
    } catch (error) {
      logger.warn(`[LevelDispatch] Failed to commit to journal: ${error}`);
    }
    if (isForEach) {
      try {
        const existing = state.stats.get(checkId);
        const aggStats = existing || {
          checkName: checkId,
          totalRuns: 0,
          successfulRuns: 0,
          failedRuns: 0,
          skippedRuns: 0,
          skipped: false,
          totalDuration: 0,
          issuesFound: 0,
          issuesBySeverity: { critical: 0, error: 0, warning: 0, info: 0 }
        };
        aggStats.totalRuns++;
        const hasFatal = hasFatalIssues2(enrichedResultWithTimestamp);
        if (hasFatal) aggStats.failedRuns++;
        else aggStats.successfulRuns++;
        const items = enrichedResultWithTimestamp.forEachItems;
        if (Array.isArray(items)) aggStats.outputsProduced = items.length;
        state.stats.set(checkId, aggStats);
      } catch {
      }
    }
    if (isForEach && forEachItems2 && Array.isArray(forEachItems2)) {
      for (let itemIndex = 0; itemIndex < forEachItems2.length; itemIndex++) {
        const itemScope = [
          { check: checkId, index: itemIndex }
        ];
        const item = forEachItems2[itemIndex];
        try {
          context2.journal.commitEntry({
            sessionId: context2.sessionId,
            checkId,
            result: { issues: [], output: item },
            event: context2.event || "manual",
            scope: itemScope
          });
        } catch (error) {
          logger.warn(
            `[LevelDispatch] Failed to commit per-item journal for ${checkId} item ${itemIndex}: ${error}`
          );
        }
      }
    }
    state.activeDispatches.delete(checkId);
    emitEvent({
      type: "CheckCompleted",
      checkId,
      scope,
      result: {
        ...enrichedResult,
        output: result.output,
        content: renderedContent || result.content
      }
    });
    return enrichedResult;
  } catch (error) {
    const err = error instanceof Error ? error : new Error(String(error));
    logger.error(`[LevelDispatch] Error executing check ${checkId}: ${err.message}`);
    state.activeDispatches.delete(checkId);
    emitEvent({
      type: "CheckErrored",
      checkId,
      scope,
      error: {
        message: err.message,
        stack: err.stack,
        name: err.name
      }
    });
    throw err;
  }
}
function buildDependencyResultsWithScope2(checkId, checkConfig, context2, scope) {
  const dependencyResults = /* @__PURE__ */ new Map();
  const dependencies = checkConfig.depends_on || [];
  const depList = Array.isArray(dependencies) ? dependencies : [dependencies];
  const currentIndex = scope.length > 0 ? scope[scope.length - 1].index : void 0;
  for (const depId of depList) {
    if (!depId) continue;
    try {
      const snapshotId = context2.journal.beginSnapshot();
      const visible = context2.journal.readVisible(
        context2.sessionId,
        snapshotId,
        context2.event
      );
      const sameScope = (a, b) => {
        if (a.length !== b.length) return false;
        for (let i = 0; i < a.length; i++)
          if (a[i].check !== b[i].check || a[i].index !== b[i].index) return false;
        return true;
      };
      const matches = visible.filter((e) => e.checkId === depId && sameScope(e.scope, scope));
      let journalResult = matches.length > 0 ? matches[matches.length - 1].result : void 0;
      if (journalResult && Array.isArray(journalResult.forEachItems) && currentIndex !== void 0) {
        const perItemSummary = journalResult.forEachItemResults && journalResult.forEachItemResults[currentIndex] || { issues: [] };
        const perItemOutput = journalResult.forEachItems[currentIndex];
        const combined = { ...perItemSummary, output: perItemOutput };
        dependencyResults.set(depId, combined);
        continue;
      }
      if (!journalResult) {
        try {
          const rawView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            context2.event
          );
          const rawResult = rawView.get(depId);
          if (rawResult && Array.isArray(rawResult.forEachItems) && currentIndex !== void 0) {
            const perItemSummary = rawResult.forEachItemResults && rawResult.forEachItemResults[currentIndex] || { issues: [] };
            const perItemOutput = rawResult.forEachItems[currentIndex];
            const combined = { ...perItemSummary, output: perItemOutput };
            dependencyResults.set(depId, combined);
            continue;
          }
          journalResult = rawResult;
        } catch {
        }
      }
      if (journalResult) {
        dependencyResults.set(depId, journalResult);
        continue;
      }
    } catch {
    }
    dependencyResults.set(depId, { issues: [] });
  }
  try {
    const snapshotId = context2.journal.beginSnapshot();
    const contextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
      context2.journal,
      context2.sessionId,
      snapshotId,
      scope,
      context2.event
    );
    const allCheckNames = Object.keys(context2.config.checks || {});
    for (const checkName of allCheckNames) {
      if (dependencyResults.has(checkName)) continue;
      let jr = contextView.get(checkName);
      if (jr && Array.isArray(jr.forEachItems) && currentIndex !== void 0) {
        const perItemSummary = jr.forEachItemResults && jr.forEachItemResults[currentIndex] || { issues: [] };
        const perItemOutput = jr.forEachItems[currentIndex];
        const combined = { ...perItemSummary, output: perItemOutput };
        dependencyResults.set(checkName, combined);
        continue;
      }
      if (!jr) {
        try {
          const rawView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            context2.event
          );
          const raw = rawView.get(checkName);
          if (raw && Array.isArray(raw.forEachItems) && currentIndex !== void 0) {
            const perItemSummary = raw.forEachItemResults && raw.forEachItemResults[currentIndex] || { issues: [] };
            const perItemOutput = raw.forEachItems[currentIndex];
            const combined = { ...perItemSummary, output: perItemOutput };
            dependencyResults.set(checkName, combined);
            continue;
          }
          jr = raw;
        } catch {
        }
      }
      if (jr) {
        dependencyResults.set(checkName, jr);
      }
    }
    for (const checkName of allCheckNames) {
      const checkCfg = context2.config.checks?.[checkName];
      if (checkCfg?.forEach) {
        try {
          const rawContextView = new (init_snapshot_store(), __toCommonJS(snapshot_store_exports)).ContextView(
            context2.journal,
            context2.sessionId,
            snapshotId,
            [],
            // No scope - get parent-level result with forEachItems
            context2.event
          );
          const rawResult = rawContextView.get(checkName);
          if (rawResult && rawResult.forEachItems) {
            const rawKey = `${checkName}-raw`;
            dependencyResults.set(rawKey, {
              issues: [],
              output: rawResult.forEachItems
            });
          }
        } catch {
        }
      }
    }
  } catch {
  }
  return dependencyResults;
}
function buildDependencyResults(checkId, checkConfig, context2, _state) {
  return buildDependencyResultsWithScope2(checkId, checkConfig, context2, []);
}
function shouldFailFast(results) {
  for (const { result } of results) {
    if (!result || !result.issues) continue;
    if (hasFatalIssues2(result)) {
      return true;
    }
  }
  return false;
}
function hasFatalIssues2(result) {
  if (!result.issues) {
    return false;
  }
  return result.issues.some((issue) => {
    const ruleId = issue.ruleId || "";
    return ruleId.endsWith("/error") || // System errors
    ruleId.includes("/execution_error") || // Command failures
    ruleId.endsWith("_fail_if") && ruleId !== "global_fail_if";
  });
}
function updateStats2(results, state, isForEachIteration = false) {
  for (const { checkId, result, error, duration } of results) {
    const existing = state.stats.get(checkId);
    const stats = existing || {
      checkName: checkId,
      totalRuns: 0,
      successfulRuns: 0,
      failedRuns: 0,
      skippedRuns: 0,
      skipped: false,
      totalDuration: 0,
      issuesFound: 0,
      issuesBySeverity: {
        critical: 0,
        error: 0,
        warning: 0,
        info: 0
      }
    };
    if (checkId === "post-response") {
      logger.info(
        `[updateStats] Called for post-response: existing.skipped=${existing?.skipped}, stats.skipped=${stats.skipped}, skipReason=${stats.skipReason}`
      );
    }
    if (stats.skipped) {
      stats.skipped = false;
      if (checkId === "post-response") {
        logger.info(
          `[updateStats] Clearing skipped flag for post-response (was skipped, now executing)`
        );
      }
    }
    stats.totalRuns++;
    if (duration !== void 0) {
      stats.totalDuration += duration;
    }
    const hasExecutionFailure = result.issues?.some((issue) => {
      const ruleId = issue.ruleId || "";
      return ruleId.endsWith("/error") || // System errors, exceptions
      ruleId.includes("/execution_error") || // Command failures
      ruleId.endsWith("_fail_if") && ruleId !== "global_fail_if";
    });
    if (error) {
      stats.failedRuns++;
      stats.errorMessage = error.message;
      if (!isForEachIteration) {
        if (!state.failedChecks) {
          state.failedChecks = /* @__PURE__ */ new Set();
        }
        state.failedChecks.add(checkId);
      }
    } else if (hasExecutionFailure) {
      stats.failedRuns++;
      if (!isForEachIteration) {
        if (!state.failedChecks) {
          state.failedChecks = /* @__PURE__ */ new Set();
        }
        state.failedChecks.add(checkId);
      }
    } else {
      stats.successfulRuns++;
    }
    if (result.issues) {
      stats.issuesFound += result.issues.length;
      for (const issue of result.issues) {
        if (issue.severity === "critical") stats.issuesBySeverity.critical++;
        else if (issue.severity === "error") stats.issuesBySeverity.error++;
        else if (issue.severity === "warning") stats.issuesBySeverity.warning++;
        else if (issue.severity === "info") stats.issuesBySeverity.info++;
      }
    }
    if (stats.outputsProduced === void 0) {
      const forEachItems = result.forEachItems;
      if (Array.isArray(forEachItems)) {
        stats.outputsProduced = forEachItems.length;
      } else if (result.output !== void 0) {
        stats.outputsProduced = 1;
      }
    }
    state.stats.set(checkId, stats);
  }
}
async function renderTemplateContent2(checkId, checkConfig, reviewSummary) {
  try {
    const { createExtendedLiquid: createExtendedLiquid2 } = await Promise.resolve().then(() => (init_liquid_extensions(), liquid_extensions_exports));
    const fs20 = await import("fs/promises");
    const path22 = await import("path");
    const schemaRaw = checkConfig.schema || "plain";
    const schema = typeof schemaRaw === "string" ? schemaRaw : "code-review";
    let templateContent;
    if (checkConfig.template && checkConfig.template.content) {
      templateContent = String(checkConfig.template.content);
      logger.debug(`[LevelDispatch] Using inline template for ${checkId}`);
    } else if (checkConfig.template && checkConfig.template.file) {
      const file = String(checkConfig.template.file);
      const resolved = path22.resolve(process.cwd(), file);
      templateContent = await fs20.readFile(resolved, "utf-8");
      logger.debug(`[LevelDispatch] Using template file for ${checkId}: ${resolved}`);
    } else if (schema && schema !== "plain") {
      const sanitized = String(schema).replace(/[^a-zA-Z0-9-]/g, "");
      if (sanitized) {
        const candidatePaths = [
          path22.join(__dirname, "output", sanitized, "template.liquid"),
          // bundled: dist/output/
          path22.join(__dirname, "..", "..", "output", sanitized, "template.liquid"),
          // source (from state-machine/states)
          path22.join(__dirname, "..", "..", "..", "output", sanitized, "template.liquid"),
          // source (alternate)
          path22.join(process.cwd(), "output", sanitized, "template.liquid"),
          // fallback: cwd/output/
          path22.join(process.cwd(), "dist", "output", sanitized, "template.liquid")
          // fallback: cwd/dist/output/
        ];
        for (const p of candidatePaths) {
          try {
            templateContent = await fs20.readFile(p, "utf-8");
            if (templateContent) {
              logger.debug(`[LevelDispatch] Using schema template for ${checkId}: ${p}`);
              break;
            }
          } catch {
          }
        }
        if (!templateContent) {
          logger.debug(
            `[LevelDispatch] No template found for schema '${sanitized}' (tried ${candidatePaths.length} paths)`
          );
        }
      }
    }
    if (!templateContent) {
      logger.debug(`[LevelDispatch] No template content found for ${checkId}`);
      return void 0;
    }
    const liquid = createExtendedLiquid2({
      trimTagLeft: false,
      trimTagRight: false,
      trimOutputLeft: false,
      trimOutputRight: false,
      greedy: false
    });
    let output = reviewSummary.output;
    if (typeof output === "string") {
      const trimmed = output.trim();
      if (trimmed.startsWith("{") || trimmed.startsWith("[")) {
        try {
          output = JSON.parse(trimmed);
        } catch {
        }
      }
    }
    const templateData = {
      issues: reviewSummary.issues || [],
      checkName: checkId,
      output
    };
    logger.debug(
      `[LevelDispatch] Rendering template for ${checkId} with output keys: ${output && typeof output === "object" ? Object.keys(output).join(", ") : "none"}`
    );
    const rendered = await liquid.parseAndRender(templateContent, templateData);
    logger.debug(
      `[LevelDispatch] Template rendered successfully for ${checkId}: ${rendered.length} chars, trimmed: ${rendered.trim().length} chars`
    );
    return rendered.trim();
  } catch (error) {
    const msg = error instanceof Error ? error.message : String(error);
    logger.error(`[LevelDispatch] Failed to render template for ${checkId}: ${msg}`);
    return void 0;
  }
}
var init_level_dispatch = __esm({
  "src/state-machine/states/level-dispatch.ts"() {
    "use strict";
    init_logger();
    init_routing();
    init_trace_helpers();
    init_mermaid_telemetry();
    init_fallback_ndjson();
    init_failure_condition_evaluator();
    init_workflow_inputs();
  }
});

// src/state-machine/states/check-running.ts
async function handleCheckRunning(_context, _state, transition, _emitEvent) {
  transition("WavePlanning");
}
var init_check_running = __esm({
  "src/state-machine/states/check-running.ts"() {
    "use strict";
  }
});

// src/state-machine/states/completed.ts
async function handleCompleted(context2, state) {
  if (context2.debug) {
    logger.info("[Completed] Execution complete");
    logger.info(`[Completed] Total waves: ${state.wave + 1}`);
    logger.info(`[Completed] Checks completed: ${state.completedChecks.size}`);
    logger.info(`[Completed] Stats collected: ${state.stats.size}`);
  }
  if (context2.gitHubChecks) {
    if (context2.debug) {
      logger.info("[Completed] GitHub checks will be finalized by main engine");
    }
  }
}
var init_completed = __esm({
  "src/state-machine/states/completed.ts"() {
    "use strict";
    init_logger();
  }
});

// src/state-machine/states/error.ts
async function handleError(context2, state) {
  logger.error("[Error] State machine entered error state");
  const errorEvent = state.eventQueue.find((e) => e.type === "Shutdown" && e.error);
  if (errorEvent && errorEvent.type === "Shutdown" && errorEvent.error) {
    logger.error(`[Error] Fatal error: ${errorEvent.error.message}`);
    if (errorEvent.error.stack) {
      logger.error(`[Error] Stack: ${errorEvent.error.stack}`);
    }
  }
  if (context2.debug) {
    logger.info(`[Error] Completed ${state.completedChecks.size} checks before error`);
    logger.info(`[Error] Active dispatches: ${state.activeDispatches.size}`);
  }
}
var init_error = __esm({
  "src/state-machine/states/error.ts"() {
    "use strict";
    init_logger();
  }
});

// src/state-machine/runner.ts
var runner_exports = {};
__export(runner_exports, {
  StateMachineRunner: () => StateMachineRunner
});
var StateMachineRunner;
var init_runner = __esm({
  "src/state-machine/runner.ts"() {
    "use strict";
    init_human_id();
    init_logger();
    init_trace_helpers();
    init_init();
    init_plan_ready();
    init_wave_planning();
    init_level_dispatch();
    init_check_running();
    init_completed();
    init_error();
    StateMachineRunner = class {
      context;
      state;
      debugServer;
      hasRun = false;
      constructor(context2, debugServer) {
        this.context = context2;
        this.state = this.initializeState();
        this.debugServer = debugServer;
      }
      /**
       * Initialize the run state
       */
      initializeState() {
        const DEFAULT_MAX_WORKFLOW_DEPTH = 3;
        const configuredMaxDepth = (this.context && this.context.config && this.context.config.limits ? this.context.config.limits.max_workflow_depth : void 0) ?? DEFAULT_MAX_WORKFLOW_DEPTH;
        return {
          currentState: "Init",
          wave: 0,
          levelQueue: [],
          eventQueue: [],
          activeDispatches: /* @__PURE__ */ new Map(),
          completedChecks: /* @__PURE__ */ new Set(),
          flags: {
            failFastTriggered: false,
            forwardRunRequested: false,
            // Maximum nesting depth for nested workflows (configurable)
            maxWorkflowDepth: configuredMaxDepth,
            currentWorkflowDepth: 0
            // Start at root level
          },
          stats: /* @__PURE__ */ new Map(),
          historyLog: [],
          forwardRunGuards: /* @__PURE__ */ new Set(),
          currentLevelChecks: /* @__PURE__ */ new Set(),
          routingLoopCount: 0,
          pendingRunScopes: /* @__PURE__ */ new Map()
        };
      }
      /**
       * Execute the state machine
       */
      async run() {
        this.hasRun = true;
        try {
          this.emitEvent({ type: "StateTransition", from: "Init", to: "Init" });
          while (!this.isTerminalState(this.state.currentState)) {
            const currentState = this.state.currentState;
            if (this.context.debug) {
              logger.info(`[StateMachine] State: ${currentState}, Wave: ${this.state.wave}`);
            }
            await this.executeState(currentState);
            if (this.state.currentState === "Error") {
              break;
            }
          }
          return this.buildExecutionResult();
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : String(error);
          logger.error(`[StateMachine] Fatal error: ${errorMsg}`);
          const serializedError = {
            message: error instanceof Error ? error.message : String(error),
            stack: error instanceof Error ? error.stack : void 0,
            name: error instanceof Error ? error.name : void 0
          };
          this.emitEvent({ type: "Shutdown", error: serializedError });
          throw error;
        }
      }
      /**
       * Execute a specific state handler
       * M4: Wraps each state execution in an OTEL span for observability
       */
      async executeState(state) {
        const attrs = {
          state,
          engine_mode: this.context.mode,
          wave: this.state.wave,
          session_id: this.context.sessionId
        };
        const waveKind = this.state?.flags?.waveKind;
        if (waveKind) attrs.wave_kind = waveKind;
        return withActiveSpan(`engine.state.${state.toLowerCase()}`, attrs, async () => {
          try {
            switch (state) {
              case "Init":
                await handleInit(this.context, this.state, this.transition.bind(this));
                break;
              case "PlanReady":
                await handlePlanReady(this.context, this.state, this.transition.bind(this));
                break;
              case "WavePlanning":
                await handleWavePlanning(this.context, this.state, this.transition.bind(this));
                break;
              case "LevelDispatch":
                await handleLevelDispatch(
                  this.context,
                  this.state,
                  this.transition.bind(this),
                  this.emitEvent.bind(this)
                );
                break;
              case "CheckRunning":
                await handleCheckRunning(
                  this.context,
                  this.state,
                  this.transition.bind(this),
                  this.emitEvent.bind(this)
                );
                break;
              case "Routing":
                throw new Error("Routing state should be handled by CheckRunning");
              case "Completed":
                await handleCompleted(this.context, this.state);
                break;
              case "Error":
                await handleError(this.context, this.state);
                break;
              default:
                throw new Error(`Unknown state: ${state}`);
            }
          } catch (error) {
            const errorMsg = error instanceof Error ? error.message : String(error);
            logger.error(`[StateMachine] Error in state ${state}: ${errorMsg}`);
            const serializedError = {
              message: error instanceof Error ? error.message : String(error),
              stack: error instanceof Error ? error.stack : void 0,
              name: error instanceof Error ? error.name : void 0
            };
            this.emitEvent({ type: "Shutdown", error: serializedError });
            this.state.currentState = "Error";
            throw error;
          }
        });
      }
      /**
       * Transition to a new state
       * M4: Emits OTEL span for the transition with state metadata
       */
      transition(newState) {
        const oldState = this.state.currentState;
        this.state.currentState = newState;
        const transitionEvent = { type: "StateTransition", from: oldState, to: newState };
        this.emitEvent(transitionEvent);
        try {
          addEvent("engine.state_transition", {
            state_from: oldState,
            state_to: newState,
            engine_mode: this.context.mode,
            wave: this.state.wave,
            session_id: this.context.sessionId
          });
        } catch (_err) {
        }
        if (this.context.debug) {
          logger.info(`[StateMachine] Transition: ${oldState} -> ${newState}`);
        }
      }
      /**
       * Emit an engine event
       * M4: Streams events to debug visualizer for time-travel debugging
       */
      emitEvent(event) {
        this.state.historyLog.push(event);
        if (event.type === "ForwardRunRequested" || event.type === "WaveRetry") {
          this.state.eventQueue.push(event);
        }
        if (this.debugServer) {
          try {
            this.streamEventToDebugServer(event);
          } catch (_err) {
          }
        }
        try {
          const bus = this.context.eventBus;
          if (bus && typeof bus.emit === "function") {
            const envelope = {
              id: generateHumanId(),
              version: 1,
              timestamp: (/* @__PURE__ */ new Date()).toISOString(),
              runId: this.context.sessionId,
              workflowId: this.context.workflowId,
              wave: this.state.wave,
              payload: event
            };
            void bus.emit(envelope);
          }
        } catch {
        }
        if (event.type === "CheckCompleted") {
          try {
            const hook = this.context.executionContext?.hooks?.onCheckComplete;
            if (typeof hook === "function") {
              const checkConfig = this.context.config?.checks?.[event.checkId];
              hook({
                checkId: event.checkId,
                result: event.result,
                checkConfig: checkConfig ? {
                  type: checkConfig.type,
                  group: checkConfig.group,
                  criticality: checkConfig.criticality,
                  schema: checkConfig.schema
                } : void 0
              });
            }
          } catch {
          }
        }
        if (this.context.debug && event.type !== "StateTransition") {
          logger.debug(`[StateMachine] Event: ${event.type}`);
        }
      }
      /**
       * Stream an engine event to debug visualizer (M4)
       * Converts EngineEvent to ProcessedSpan format for visualization
       */
      streamEventToDebugServer(event) {
        if (!this.debugServer) return;
        const timestamp = process.hrtime();
        const span = {
          traceId: this.context.sessionId,
          spanId: `${event.type}-${Date.now()}`,
          name: `engine.event.${event.type.toLowerCase()}`,
          startTime: timestamp,
          endTime: timestamp,
          duration: 0,
          attributes: {
            event_type: event.type,
            engine_mode: this.context.mode,
            wave: this.state.wave,
            session_id: this.context.sessionId,
            ...this.extractEventAttributes(event)
          },
          events: [],
          status: "ok"
        };
        this.debugServer.emitSpan(span);
      }
      /**
       * Extract type-specific attributes from engine events
       */
      extractEventAttributes(event) {
        switch (event.type) {
          case "StateTransition":
            return { state_from: event.from, state_to: event.to };
          case "CheckScheduled":
          case "CheckCompleted":
          case "CheckErrored":
            return {
              check_id: event.checkId,
              scope: event.scope?.join(".") || ""
            };
          case "ForwardRunRequested":
            return {
              target: event.target,
              goto_event: event.gotoEvent,
              scope: event.scope?.join(".") || ""
            };
          case "WaveRetry":
            return { reason: event.reason };
          case "Shutdown":
            return {
              error: event.error?.message
            };
          default:
            return {};
        }
      }
      /**
       * Check if a state is terminal
       */
      isTerminalState(state) {
        return state === "Completed" || state === "Error";
      }
      /**
       * Build the final execution result
       */
      buildExecutionResult() {
        const stats = Array.from(this.state.stats.values());
        stats.sort((a, b) => (b.errorMessage ? 1 : 0) - (a.errorMessage ? 1 : 0));
        const results = this.aggregateResultsFromJournal();
        let totalDuration = 0;
        for (const stat of stats) {
          totalDuration = Math.max(totalDuration, stat.totalDuration);
        }
        try {
          for (const s of stats) {
            const sumSF = (s.successfulRuns || 0) + (s.failedRuns || 0);
            if (s.totalRuns !== void 0 && sumSF !== s.totalRuns) {
              if (sumSF > s.totalRuns) {
                const failures = Math.min(s.failedRuns || 0, s.totalRuns);
                s.failedRuns = failures;
                s.successfulRuns = Math.max(0, s.totalRuns - failures);
              } else {
                s.successfulRuns = (s.successfulRuns || 0) + (s.totalRuns - sumSF);
              }
            }
          }
        } catch {
        }
        if (this.context.debug) {
          logger.info("[StateMachine][Stats] Final statistics breakdown:");
          for (const s of stats) {
            logger.info(
              `  ${s.checkName}: totalRuns=${s.totalRuns}, successful=${s.successfulRuns}, failed=${s.failedRuns}`
            );
          }
          logger.info(
            `[StateMachine][Stats] Total: ${this.state.stats.size} configured, ${stats.reduce((sum, s) => sum + s.totalRuns, 0)} executions`
          );
        }
        return {
          results,
          statistics: {
            totalChecksConfigured: this.state.stats.size,
            totalExecutions: stats.reduce((sum, s) => sum + s.totalRuns, 0),
            successfulExecutions: stats.reduce((sum, s) => sum + s.successfulRuns, 0),
            failedExecutions: stats.reduce((sum, s) => sum + s.failedRuns, 0),
            skippedChecks: stats.filter((s) => s.skipped).length,
            totalDuration,
            checks: stats
          }
        };
      }
      /**
       * Aggregate results from journal into GroupedCheckResults format
       * This matches the format returned by the legacy engine
       */
      aggregateResultsFromJournal() {
        const groupedResults = {};
        const allEntries = this.context.journal.readVisible(
          this.context.sessionId,
          this.context.journal.beginSnapshot(),
          void 0
        );
        const checkEntries = /* @__PURE__ */ new Map();
        for (const entry of allEntries) {
          const existing = checkEntries.get(entry.checkId) || [];
          existing.push(entry);
          checkEntries.set(entry.checkId, existing);
        }
        for (const [checkId, entries] of checkEntries) {
          const checkConfig = this.context.config.checks?.[checkId];
          if (!checkConfig && checkId === "system") {
            const latestEntry = entries[entries.length - 1];
            if (latestEntry && latestEntry.result.issues) {
              if (!groupedResults["system"]) {
                groupedResults["system"] = [];
              }
              groupedResults["system"].push({
                checkName: "system",
                content: "",
                group: "system",
                output: void 0,
                debug: void 0,
                issues: latestEntry.result.issues
              });
            }
            continue;
          }
          if (!checkConfig) continue;
          const group = checkConfig.group || checkId;
          let content = "";
          let output = void 0;
          const allIssues = [];
          let debug = void 0;
          if (checkConfig.forEach && entries.length > 1) {
            const contents = [];
            for (const entry of entries) {
              if (entry.result.content) {
                contents.push(entry.result.content);
              }
              if (entry.result.issues) {
                allIssues.push(...entry.result.issues);
              }
              if (entry.result.debug) {
                debug = entry.result.debug;
              }
              if (entry.result.output !== void 0) {
                output = entry.result.output;
              }
            }
            content = contents.join("\n");
          } else {
            const latestEntry = entries[entries.length - 1];
            if (latestEntry) {
              content = latestEntry.result.content || "";
              output = latestEntry.result.output;
              if (latestEntry.result.issues) {
                allIssues.push(...latestEntry.result.issues);
              }
              debug = latestEntry.result.debug;
            }
          }
          const checkResult = {
            checkName: checkId,
            content,
            group,
            output,
            debug,
            issues: allIssues
          };
          if (!groupedResults[group]) {
            groupedResults[group] = [];
          }
          groupedResults[group].push(checkResult);
        }
        const suppressionEnabled = this.context.config.output?.suppressionEnabled ?? true;
        if (suppressionEnabled) {
          const { IssueFilter: IssueFilter2 } = (init_issue_filter(), __toCommonJS(issue_filter_exports));
          const filter = new IssueFilter2(true);
          for (const group of Object.keys(groupedResults)) {
            for (const checkResult of groupedResults[group]) {
              if (checkResult.issues && checkResult.issues.length > 0) {
                checkResult.issues = filter.filterIssues(
                  checkResult.issues,
                  this.context.workingDirectory
                );
              }
            }
          }
        }
        return groupedResults;
      }
      /**
       * Get current run state (for debugging/testing)
       */
      getState() {
        return this.state;
      }
      /**
       * Hydrate the runner with a previously serialized state. Must be called
       * before `run()` (i.e., when the runner has not started yet).
       */
      setState(state) {
        if (this.hasRun) {
          throw new Error("StateMachineRunner.setState: cannot set state after run() has started");
        }
        this.state = state;
      }
      /**
       * Bubble an event to parent context (nested workflows support)
       * This allows nested workflows to trigger re-runs in parent workflows
       */
      bubbleEventToParent(event) {
        if (this.state.parentContext && this.state.parentContext.mode === "state-machine") {
          if (this.context.debug) {
            logger.info(`[StateMachine] Bubbling event to parent: ${event.type}`);
          }
          if (!this.state.parentContext._bubbledEvents) {
            this.state.parentContext._bubbledEvents = [];
          }
          this.state.parentContext._bubbledEvents.push(event);
        }
      }
    };
  }
});

// src/utils/file-exclusion.ts
var import_ignore, fs15, path16, DEFAULT_EXCLUSION_PATTERNS, FileExclusionHelper;
var init_file_exclusion = __esm({
  "src/utils/file-exclusion.ts"() {
    "use strict";
    import_ignore = __toESM(require("ignore"));
    fs15 = __toESM(require("fs"));
    path16 = __toESM(require("path"));
    DEFAULT_EXCLUSION_PATTERNS = [
      "dist/",
      "build/",
      ".next/",
      "out/",
      "node_modules/",
      "coverage/",
      ".turbo/",
      "bundled/"
    ];
    FileExclusionHelper = class {
      gitignore = null;
      workingDirectory;
      /**
       * @param workingDirectory - Directory to search for .gitignore
       * @param additionalPatterns - Additional patterns to include (optional, defaults to common build artifacts)
       */
      constructor(workingDirectory = process.cwd(), additionalPatterns = DEFAULT_EXCLUSION_PATTERNS) {
        const normalizedPath = path16.resolve(workingDirectory);
        if (normalizedPath.includes("\0")) {
          throw new Error("Invalid workingDirectory: contains null bytes");
        }
        this.workingDirectory = normalizedPath;
        this.loadGitignore(additionalPatterns);
      }
      /**
       * Load .gitignore patterns from the working directory (called once in constructor)
       * @param additionalPatterns - Additional patterns to add to gitignore rules
       */
      loadGitignore(additionalPatterns) {
        const gitignorePath = path16.resolve(this.workingDirectory, ".gitignore");
        const resolvedWorkingDir = path16.resolve(this.workingDirectory);
        try {
          const relativePath = path16.relative(resolvedWorkingDir, gitignorePath);
          if (relativePath.startsWith("..") || path16.isAbsolute(relativePath)) {
            throw new Error("Invalid gitignore path: path traversal detected");
          }
          if (relativePath !== ".gitignore") {
            throw new Error("Invalid gitignore path: must be .gitignore in working directory");
          }
          this.gitignore = (0, import_ignore.default)();
          if (additionalPatterns && additionalPatterns.length > 0) {
            this.gitignore.add(additionalPatterns);
          }
          if (fs15.existsSync(gitignorePath)) {
            const rawContent = fs15.readFileSync(gitignorePath, "utf8");
            const gitignoreContent = rawContent.replace(/[\r\n]+/g, "\n").replace(/[\x00-\x09\x0B-\x1F\x7F]/g, "").split("\n").filter((line) => line.length < 1e3).join("\n").trim();
            this.gitignore.add(gitignoreContent);
            if (process.env.VISOR_DEBUG === "true") {
              console.error("\u2705 Loaded .gitignore patterns for file filtering");
            }
          } else if (additionalPatterns && additionalPatterns.length > 0) {
            console.error("No .gitignore found, using default exclusion patterns");
            console.warn("No .gitignore found, using default exclusion patterns");
          }
        } catch (error) {
          console.warn("Failed to load .gitignore:", error instanceof Error ? error.message : error);
        }
      }
      /**
       * Check if a file should be excluded based on .gitignore patterns
       */
      shouldExcludeFile(filename) {
        if (this.gitignore) {
          return this.gitignore.ignores(filename);
        }
        return false;
      }
    };
  }
});

// src/git-repository-analyzer.ts
var git_repository_analyzer_exports = {};
__export(git_repository_analyzer_exports, {
  GitRepositoryAnalyzer: () => GitRepositoryAnalyzer
});
var import_simple_git2, path17, fs16, MAX_PATCH_SIZE, GitRepositoryAnalyzer;
var init_git_repository_analyzer = __esm({
  "src/git-repository-analyzer.ts"() {
    "use strict";
    import_simple_git2 = require("simple-git");
    path17 = __toESM(require("path"));
    fs16 = __toESM(require("fs"));
    init_file_exclusion();
    MAX_PATCH_SIZE = 50 * 1024;
    GitRepositoryAnalyzer = class {
      git;
      cwd;
      fileExclusionHelper;
      constructor(workingDirectory = process.cwd()) {
        this.cwd = workingDirectory;
        this.git = (0, import_simple_git2.simpleGit)(workingDirectory);
        this.fileExclusionHelper = new FileExclusionHelper(workingDirectory);
      }
      /**
       * Analyze the current git repository state and return data compatible with PRInfo interface
       */
      async analyzeRepository(includeContext = true, enableBranchDiff = false) {
        const isRepo = await this.isGitRepository();
        if (!isRepo) {
          return this.createEmptyRepositoryInfo("Not a git repository");
        }
        try {
          const [status, currentBranch, baseBranch] = await Promise.all([
            this.git.status(),
            this.getCurrentBranch(),
            this.getBaseBranch()
          ]);
          const isFeatureBranch = currentBranch !== baseBranch && currentBranch !== "main" && currentBranch !== "master";
          let uncommittedFiles = await this.getUncommittedChanges(includeContext);
          if (isFeatureBranch && includeContext && enableBranchDiff) {
            if (uncommittedFiles.length > 0) {
              console.error(`\u{1F4CA} Feature branch detected: ${currentBranch}`);
              console.error(
                `\u26A0\uFE0F  Ignoring ${uncommittedFiles.length} uncommitted file(s) due to --analyze-branch-diff flag`
              );
            } else {
              console.error(`\u{1F4CA} Feature branch detected: ${currentBranch}`);
            }
            console.error(
              `\u{1F4C2} Analyzing diff vs ${baseBranch} (${uncommittedFiles.length > 0 ? "forced by --analyze-branch-diff" : "auto-enabled for code-review schemas"})`
            );
            uncommittedFiles = await this.getBranchDiff(baseBranch, includeContext);
          } else if (uncommittedFiles.length > 0) {
            console.error(`\u{1F4DD} Analyzing uncommitted changes (${uncommittedFiles.length} files)`);
          }
          let lastCommit = null;
          try {
            const recentCommits = await this.git.log({ maxCount: 1 });
            lastCommit = recentCommits.latest;
          } catch {
            console.error("\u{1F4DD} Repository has no commits yet, analyzing uncommitted changes");
          }
          let author = lastCommit?.author_name;
          if (!author) {
            try {
              const [userName, userEmail] = await Promise.all([
                this.git.raw(["config", "--local", "user.name"]).catch(() => null),
                this.git.raw(["config", "--local", "user.email"]).catch(() => null)
              ]);
              author = userName?.trim() || userEmail?.trim() || "unknown";
            } catch {
              author = "unknown";
            }
          }
          const repositoryInfo = {
            title: this.generateTitle(status, currentBranch),
            body: this.generateDescription(status, lastCommit),
            author,
            base: baseBranch,
            head: currentBranch,
            files: uncommittedFiles,
            totalAdditions: uncommittedFiles.reduce((sum, file) => sum + file.additions, 0),
            totalDeletions: uncommittedFiles.reduce((sum, file) => sum + file.deletions, 0),
            isGitRepository: true,
            workingDirectory: this.cwd
          };
          return repositoryInfo;
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : "Unknown error";
          console.error("Error analyzing git repository:", errorMessage);
          return this.createEmptyRepositoryInfo("Error analyzing git repository");
        }
      }
      /**
       * Convert GitRepositoryInfo to PRInfo format for compatibility with existing PRReviewer
       */
      toPRInfo(repositoryInfo, includeContext = true) {
        const files = repositoryInfo.files.map(
          (file) => ({
            filename: file.filename,
            additions: file.additions,
            deletions: file.deletions,
            changes: file.changes,
            patch: includeContext ? file.patch : void 0,
            status: file.status
          })
        );
        let fullDiff;
        if (includeContext) {
          fullDiff = files.filter((file) => file.patch).map((file) => `--- ${file.filename}
${file.patch}`).join("\n\n");
        }
        return {
          number: 0,
          // Local analysis doesn't have PR number
          title: repositoryInfo.title,
          body: repositoryInfo.body,
          author: repositoryInfo.author,
          base: repositoryInfo.base,
          head: repositoryInfo.head,
          files,
          totalAdditions: repositoryInfo.totalAdditions,
          totalDeletions: repositoryInfo.totalDeletions,
          fullDiff
        };
      }
      async isGitRepository() {
        try {
          await this.git.checkIsRepo();
          return true;
        } catch {
          return false;
        }
      }
      async getCurrentBranch() {
        try {
          const branchSummary = await this.git.branch();
          return branchSummary.current || "unknown";
        } catch {
          return "unknown";
        }
      }
      async getBaseBranch() {
        try {
          const branches = await this.git.branch(["-r"]);
          const mainBranches = ["origin/main", "origin/master", "origin/develop"];
          for (const mainBranch of mainBranches) {
            if (branches.all.includes(mainBranch)) {
              return mainBranch.replace("origin/", "");
            }
          }
          return "main";
        } catch {
          return "main";
        }
      }
      /**
       * Truncate a patch if it exceeds MAX_PATCH_SIZE
       */
      truncatePatch(patch, filename) {
        const patchSize = Buffer.byteLength(patch, "utf8");
        if (patchSize <= MAX_PATCH_SIZE) {
          return { patch, truncated: false };
        }
        const truncated = patch.substring(0, MAX_PATCH_SIZE);
        const truncatedPatch = `${truncated}

... [TRUNCATED: Diff too large (${(patchSize / 1024).toFixed(1)}KB), showing first ${(MAX_PATCH_SIZE / 1024).toFixed(0)}KB] ...`;
        console.error(
          `\u26A0\uFE0F  Truncated diff for ${filename} (${(patchSize / 1024).toFixed(1)}KB \u2192 ${(MAX_PATCH_SIZE / 1024).toFixed(0)}KB)`
        );
        return { patch: truncatedPatch, truncated: true };
      }
      async getRemoteInfo() {
        try {
          const remotes = await this.git.getRemotes(true);
          const origin = remotes.find((r) => r.name === "origin");
          return origin ? { name: origin.name, url: origin.refs.fetch || origin.refs.push || "" } : null;
        } catch {
          return null;
        }
      }
      async getUncommittedChanges(includeContext = true) {
        try {
          const status = await this.git.status();
          const changes = [];
          const fileChanges = [
            ...status.created.map((f) => ({ file: f, status: "added" })),
            ...status.deleted.map((f) => ({ file: f, status: "removed" })),
            ...status.modified.map((f) => ({ file: f, status: "modified" })),
            ...status.renamed.map((f) => ({
              file: typeof f === "string" ? f : f.to || f.from,
              status: "renamed"
            }))
          ];
          for (const { file, status: status2 } of fileChanges) {
            if (this.fileExclusionHelper.shouldExcludeFile(file)) {
              console.error(`\u23ED\uFE0F  Skipping excluded file: ${file}`);
              continue;
            }
            const filePath = path17.join(this.cwd, file);
            const fileChange = await this.analyzeFileChange(file, status2, filePath, includeContext);
            changes.push(fileChange);
          }
          return changes;
        } catch (error) {
          console.error("Error getting uncommitted changes:", error);
          return [];
        }
      }
      /**
       * Get diff between current branch and base branch (for feature branch analysis)
       */
      async getBranchDiff(baseBranch, includeContext = true) {
        try {
          const diffSummary = await this.git.diffSummary([baseBranch]);
          const changes = [];
          if (!diffSummary || !diffSummary.files) {
            return [];
          }
          for (const file of diffSummary.files) {
            if (this.fileExclusionHelper.shouldExcludeFile(file.file)) {
              console.error(`\u23ED\uFE0F  Skipping excluded file: ${file.file}`);
              continue;
            }
            const isBinary = "binary" in file && file.binary;
            const insertions = "insertions" in file ? file.insertions : 0;
            const deletions = "deletions" in file ? file.deletions : 0;
            const fileChanges = "changes" in file ? file.changes : 0;
            let status;
            if (isBinary) {
              status = "modified";
            } else if (insertions > 0 && deletions === 0) {
              status = "added";
            } else if (insertions === 0 && deletions > 0) {
              status = "removed";
            } else {
              status = "modified";
            }
            let patch;
            let truncated = false;
            if (includeContext && !isBinary) {
              try {
                const rawPatch = await this.git.diff([baseBranch, "--", file.file]);
                if (rawPatch) {
                  const result = this.truncatePatch(rawPatch, file.file);
                  patch = result.patch;
                  truncated = result.truncated;
                }
              } catch {
              }
            }
            const fileChange = {
              filename: file.file,
              additions: insertions,
              deletions,
              changes: fileChanges,
              status,
              patch,
              truncated
            };
            changes.push(fileChange);
          }
          return changes;
        } catch (error) {
          console.error("Error getting branch diff:", error);
          return [];
        }
      }
      async analyzeFileChange(filename, status, filePath, includeContext = true) {
        let additions = 0;
        let deletions = 0;
        let patch;
        let content;
        let truncated = false;
        try {
          if (includeContext && status !== "added" && fs16.existsSync(filePath)) {
            const diff = await this.git.diff(["--", filename]).catch(() => "");
            if (diff) {
              const result = this.truncatePatch(diff, filename);
              patch = result.patch;
              truncated = result.truncated;
              const lines = diff.split("\n");
              additions = lines.filter((line) => line.startsWith("+")).length;
              deletions = lines.filter((line) => line.startsWith("-")).length;
            }
          } else if (status !== "added" && fs16.existsSync(filePath)) {
            const diff = await this.git.diff(["--", filename]).catch(() => "");
            if (diff) {
              const lines = diff.split("\n");
              additions = lines.filter((line) => line.startsWith("+")).length;
              deletions = lines.filter((line) => line.startsWith("-")).length;
            }
          }
          if (status === "added" && fs16.existsSync(filePath)) {
            try {
              const stats = fs16.statSync(filePath);
              if (stats.isFile() && stats.size < 1024 * 1024) {
                if (includeContext) {
                  content = fs16.readFileSync(filePath, "utf8");
                  const result = this.truncatePatch(content, filename);
                  patch = result.patch;
                  truncated = result.truncated;
                }
                const fileContent = includeContext ? content : fs16.readFileSync(filePath, "utf8");
                additions = fileContent.split("\n").length;
              }
            } catch {
            }
          }
          if (status === "removed") {
            deletions = 1;
          }
        } catch (error) {
          console.error(`Error analyzing file change for ${filename}:`, error);
        }
        return {
          filename,
          status,
          additions,
          deletions,
          changes: additions + deletions,
          content,
          patch,
          truncated
        };
      }
      generateTitle(status, branch) {
        if (status.files.length === 0) {
          return `Local Analysis: ${branch} (No changes)`;
        }
        const changeTypes = [];
        if (status.created.length > 0) changeTypes.push(`${status.created.length} added`);
        if (status.modified.length > 0) changeTypes.push(`${status.modified.length} modified`);
        if (status.deleted.length > 0) changeTypes.push(`${status.deleted.length} deleted`);
        if (status.renamed.length > 0) changeTypes.push(`${status.renamed.length} renamed`);
        return `Local Analysis: ${branch} (${changeTypes.join(", ")})`;
      }
      generateDescription(status, lastCommit) {
        let description = `Analysis of local git repository working directory.

`;
        if (lastCommit) {
          description += `**Last Commit:** ${lastCommit.message}
`;
          description += `**Author:** ${lastCommit.author_name} <${lastCommit.author_email}>
`;
          description += `**Date:** ${lastCommit.date}

`;
        }
        if (status.files.length === 0) {
          description += `**Status:** Working directory is clean - no uncommitted changes found.
`;
        } else {
          description += `**Changes Summary:**
`;
          description += `- Files to be committed: ${status.staged.length}
`;
          description += `- Modified files: ${status.modified.length}
`;
          description += `- Untracked files: ${status.not_added.length}
`;
          if (status.conflicted.length > 0) {
            description += `- Conflicted files: ${status.conflicted.length}
`;
          }
        }
        return description;
      }
      createEmptyRepositoryInfo(reason) {
        return {
          title: `Local Analysis: ${reason}`,
          body: `Unable to analyze repository: ${reason}`,
          author: "system",
          base: "main",
          head: "HEAD",
          files: [],
          totalAdditions: 0,
          totalDeletions: 0,
          isGitRepository: false,
          workingDirectory: this.cwd
        };
      }
    };
  }
});

// src/utils/workspace-manager.ts
function shellEscape(str) {
  return "'" + str.replace(/'/g, "'\\''") + "'";
}
function sanitizePathComponent(name) {
  return name.replace(/\.\./g, "").replace(/[\/\\]/g, "-").replace(/^\.+/, "").trim() || "unnamed";
}
var fsp2, path18, WorkspaceManager;
var init_workspace_manager = __esm({
  "src/utils/workspace-manager.ts"() {
    "use strict";
    fsp2 = __toESM(require("fs/promises"));
    path18 = __toESM(require("path"));
    init_command_executor();
    init_logger();
    WorkspaceManager = class _WorkspaceManager {
      static instances = /* @__PURE__ */ new Map();
      sessionId;
      basePath;
      workspacePath;
      originalPath;
      config;
      initialized = false;
      mainProjectInfo = null;
      projects = /* @__PURE__ */ new Map();
      cleanupHandlersRegistered = false;
      usedNames = /* @__PURE__ */ new Set();
      constructor(sessionId, originalPath, config) {
        this.sessionId = sessionId;
        this.originalPath = originalPath;
        const configuredName = config?.name || process.env.VISOR_WORKSPACE_NAME;
        const configuredMainProjectName = config?.mainProjectName || process.env.VISOR_WORKSPACE_PROJECT;
        this.config = {
          enabled: true,
          basePath: process.env.VISOR_WORKSPACE_PATH || "/tmp/visor-workspaces",
          cleanupOnExit: true,
          name: configuredName,
          mainProjectName: configuredMainProjectName,
          ...config
        };
        this.basePath = this.config.basePath;
        const workspaceDirName = sanitizePathComponent(this.config.name || this.sessionId);
        this.workspacePath = path18.join(this.basePath, workspaceDirName);
      }
      /**
       * Get or create a WorkspaceManager instance for a session
       */
      static getInstance(sessionId, originalPath, config) {
        if (!_WorkspaceManager.instances.has(sessionId)) {
          _WorkspaceManager.instances.set(
            sessionId,
            new _WorkspaceManager(sessionId, originalPath, config)
          );
        }
        return _WorkspaceManager.instances.get(sessionId);
      }
      /**
       * Clear all instances (for testing)
       */
      static clearInstances() {
        _WorkspaceManager.instances.clear();
      }
      /**
       * Check if workspace isolation is enabled
       */
      isEnabled() {
        return this.config.enabled;
      }
      /**
       * Get the workspace path
       */
      getWorkspacePath() {
        return this.workspacePath;
      }
      /**
       * Get the original working directory
       */
      getOriginalPath() {
        return this.originalPath;
      }
      /**
       * Get workspace info (only available after initialize)
       */
      getWorkspaceInfo() {
        return this.mainProjectInfo;
      }
      /**
       * Initialize the workspace - creates workspace directory and main project worktree
       */
      async initialize() {
        if (!this.config.enabled) {
          throw new Error("Workspace isolation is not enabled");
        }
        if (this.initialized && this.mainProjectInfo) {
          return this.mainProjectInfo;
        }
        logger.info(`Initializing workspace: ${this.workspacePath}`);
        await fsp2.mkdir(this.workspacePath, { recursive: true });
        logger.debug(`Created workspace directory: ${this.workspacePath}`);
        const configuredMainProjectName = this.config.mainProjectName;
        const mainProjectName = sanitizePathComponent(
          configuredMainProjectName || this.extractProjectName(this.originalPath)
        );
        this.usedNames.add(mainProjectName);
        const mainProjectPath = path18.join(this.workspacePath, mainProjectName);
        const isGitRepo = await this.isGitRepository(this.originalPath);
        if (isGitRepo) {
          await this.createMainProjectWorktree(mainProjectPath);
        } else {
          logger.debug(`Original path is not a git repo, creating symlink`);
          try {
            await fsp2.symlink(this.originalPath, mainProjectPath);
          } catch (error) {
            throw new Error(`Failed to create symlink for main project: ${error}`);
          }
        }
        this.registerCleanupHandlers();
        this.mainProjectInfo = {
          sessionId: this.sessionId,
          workspacePath: this.workspacePath,
          mainProjectPath,
          mainProjectName,
          originalPath: this.originalPath
        };
        this.initialized = true;
        logger.info(`Workspace initialized: ${this.workspacePath}`);
        return this.mainProjectInfo;
      }
      /**
       * Add a project to the workspace (creates symlink to worktree)
       */
      async addProject(repository, worktreePath, description) {
        if (!this.initialized) {
          throw new Error("Workspace not initialized. Call initialize() first.");
        }
        let projectName = sanitizePathComponent(description || this.extractRepoName(repository));
        projectName = this.getUniqueName(projectName);
        this.usedNames.add(projectName);
        const workspacePath = path18.join(this.workspacePath, projectName);
        await fsp2.rm(workspacePath, { recursive: true, force: true });
        try {
          await fsp2.symlink(worktreePath, workspacePath);
        } catch (error) {
          throw new Error(`Failed to create symlink for project ${projectName}: ${error}`);
        }
        this.projects.set(projectName, {
          name: projectName,
          path: workspacePath,
          worktreePath,
          repository
        });
        logger.info(`Added project to workspace: ${projectName} -> ${worktreePath}`);
        return workspacePath;
      }
      /**
       * List all projects in the workspace
       */
      listProjects() {
        return Array.from(this.projects.values());
      }
      /**
       * Cleanup the workspace
       */
      async cleanup() {
        logger.info(`Cleaning up workspace: ${this.workspacePath}`);
        try {
          if (this.mainProjectInfo) {
            const mainProjectPath = this.mainProjectInfo.mainProjectPath;
            try {
              const stats = await fsp2.lstat(mainProjectPath);
              if (!stats.isSymbolicLink()) {
                await this.removeMainProjectWorktree(mainProjectPath);
              }
            } catch {
            }
          }
          await fsp2.rm(this.workspacePath, { recursive: true, force: true });
          logger.debug(`Removed workspace directory: ${this.workspacePath}`);
          _WorkspaceManager.instances.delete(this.sessionId);
          this.initialized = false;
          this.mainProjectInfo = null;
          this.projects.clear();
          this.usedNames.clear();
          logger.info(`Workspace cleanup completed: ${this.sessionId}`);
        } catch (error) {
          logger.warn(`Failed to cleanup workspace: ${error}`);
        }
      }
      /**
       * Create worktree for the main project
       *
       * visor-disable: architecture - Not using WorktreeManager here because:
       * 1. WorktreeManager expects remote URLs and clones to bare repos first
       * 2. This operates on the LOCAL repo we're already in (no cloning needed)
       * 3. Adding a "local mode" to WorktreeManager would add complexity for minimal benefit
       * The git commands here are simpler (just rev-parse + worktree add) vs WorktreeManager's
       * full clone/bare-repo/fetch/worktree pipeline.
       */
      async createMainProjectWorktree(targetPath) {
        logger.debug(`Creating main project worktree: ${targetPath}`);
        const headResult = await commandExecutor.execute(
          `git -C ${shellEscape(this.originalPath)} rev-parse HEAD`,
          {
            timeout: 1e4
          }
        );
        if (headResult.exitCode !== 0) {
          throw new Error(`Failed to get HEAD: ${headResult.stderr}`);
        }
        const headRef = headResult.stdout.trim();
        const createCmd = `git -C ${shellEscape(this.originalPath)} worktree add --detach ${shellEscape(targetPath)} ${shellEscape(headRef)}`;
        const result = await commandExecutor.execute(createCmd, { timeout: 6e4 });
        if (result.exitCode !== 0) {
          throw new Error(`Failed to create main project worktree: ${result.stderr}`);
        }
        logger.debug(`Created main project worktree at ${targetPath}`);
      }
      /**
       * Remove main project worktree
       */
      async removeMainProjectWorktree(worktreePath) {
        logger.debug(`Removing main project worktree: ${worktreePath}`);
        const removeCmd = `git -C ${shellEscape(this.originalPath)} worktree remove ${shellEscape(worktreePath)} --force`;
        const result = await commandExecutor.execute(removeCmd, { timeout: 3e4 });
        if (result.exitCode !== 0) {
          logger.warn(`Failed to remove worktree via git: ${result.stderr}`);
        }
      }
      /**
       * Check if a path is a git repository
       */
      async isGitRepository(dirPath) {
        try {
          const result = await commandExecutor.execute(
            `git -C ${shellEscape(dirPath)} rev-parse --git-dir`,
            {
              timeout: 5e3
            }
          );
          return result.exitCode === 0;
        } catch {
          return false;
        }
      }
      /**
       * Extract project name from path
       */
      extractProjectName(dirPath) {
        return path18.basename(dirPath);
      }
      /**
       * Extract repository name from owner/repo format
       */
      extractRepoName(repository) {
        if (repository.includes("://") || repository.startsWith("git@")) {
          const match = repository.match(/[/:]([^/:]+\/[^/:]+?)(?:\.git)?$/);
          if (match) {
            return match[1].split("/").pop() || repository;
          }
        }
        if (repository.includes("/")) {
          return repository.split("/").pop() || repository;
        }
        return repository;
      }
      /**
       * Get a unique name by appending a number if needed
       */
      getUniqueName(baseName) {
        if (!this.usedNames.has(baseName)) {
          return baseName;
        }
        let counter = 2;
        let uniqueName = `${baseName}-${counter}`;
        while (this.usedNames.has(uniqueName)) {
          counter++;
          uniqueName = `${baseName}-${counter}`;
        }
        return uniqueName;
      }
      /**
       * Register cleanup handlers for process exit
       */
      registerCleanupHandlers() {
        if (this.cleanupHandlersRegistered || !this.config.cleanupOnExit) {
          return;
        }
        this.cleanupHandlersRegistered = true;
      }
    };
  }
});

// src/state-machine/context/build-engine-context.ts
var build_engine_context_exports = {};
__export(build_engine_context_exports, {
  buildEngineContextForRun: () => buildEngineContextForRun,
  initializeWorkspace: () => initializeWorkspace
});
function applyCriticalityDefaults(cfg) {
  const checks = cfg.checks || {};
  for (const id of Object.keys(checks)) {
    const c = checks[id];
    if (!c.criticality) c.criticality = "policy";
    if (c.criticality === "info" && typeof c.continue_on_failure === "undefined")
      c.continue_on_failure = true;
  }
}
function buildEngineContextForRun(workingDirectory, config, prInfo, debug, maxParallelism, failFast, requestedChecks) {
  const clonedConfig = JSON.parse(JSON.stringify(config));
  const checks = {};
  applyCriticalityDefaults(clonedConfig);
  for (const [checkId, checkConfig] of Object.entries(clonedConfig.checks || {})) {
    checks[checkId] = {
      tags: checkConfig.tags || [],
      triggers: (Array.isArray(checkConfig.on) ? checkConfig.on : [checkConfig.on]).filter(
        Boolean
      ),
      group: checkConfig.group,
      providerType: checkConfig.type || "ai",
      // Normalize depends_on to array (supports string | string[])
      dependencies: Array.isArray(checkConfig.depends_on) ? checkConfig.depends_on : checkConfig.depends_on ? [checkConfig.depends_on] : []
    };
  }
  if (requestedChecks && requestedChecks.length > 0) {
    for (const checkName of requestedChecks) {
      if (!checks[checkName] && !clonedConfig.checks?.[checkName]) {
        logger.debug(`[StateMachine] Synthesizing minimal config for legacy check: ${checkName}`);
        if (!clonedConfig.checks) {
          clonedConfig.checks = {};
        }
        clonedConfig.checks[checkName] = {
          type: "ai",
          prompt: `Perform ${checkName} analysis`
        };
        checks[checkName] = {
          tags: [],
          triggers: [],
          group: "default",
          providerType: "ai",
          dependencies: []
        };
      }
    }
  }
  const journal = new ExecutionJournal();
  const memory = MemoryStore.getInstance(clonedConfig.memory);
  return {
    mode: "state-machine",
    config: clonedConfig,
    checks,
    journal,
    memory,
    workingDirectory,
    originalWorkingDirectory: workingDirectory,
    sessionId: generateHumanId(),
    event: prInfo.eventType,
    debug,
    maxParallelism,
    failFast,
    requestedChecks: requestedChecks && requestedChecks.length > 0 ? requestedChecks : void 0,
    // Store prInfo for later access (e.g., in getOutputHistorySnapshot)
    prInfo
  };
}
async function initializeWorkspace(context2) {
  const workspaceConfig = context2.config.workspace;
  const isEnabled2 = workspaceConfig?.enabled !== false && process.env.VISOR_WORKSPACE_ENABLED !== "false";
  if (!isEnabled2) {
    logger.debug("[Workspace] Workspace isolation is disabled");
    return context2;
  }
  const originalPath = context2.workingDirectory || process.cwd();
  try {
    const keepWorkspace = process.env.VISOR_KEEP_WORKSPACE === "true";
    const workspace = WorkspaceManager.getInstance(context2.sessionId, originalPath, {
      enabled: true,
      basePath: workspaceConfig?.base_path || process.env.VISOR_WORKSPACE_PATH || "/tmp/visor-workspaces",
      cleanupOnExit: keepWorkspace ? false : workspaceConfig?.cleanup_on_exit !== false,
      name: workspaceConfig?.name || process.env.VISOR_WORKSPACE_NAME,
      mainProjectName: workspaceConfig?.main_project_name || process.env.VISOR_WORKSPACE_PROJECT
    });
    const info = await workspace.initialize();
    context2.workspace = workspace;
    context2.workingDirectory = info.mainProjectPath;
    context2.originalWorkingDirectory = originalPath;
    try {
      process.env.VISOR_WORKSPACE_ROOT = info.workspacePath;
      process.env.VISOR_WORKSPACE_MAIN_PROJECT = info.mainProjectPath;
      process.env.VISOR_WORKSPACE_MAIN_PROJECT_NAME = info.mainProjectName;
      process.env.VISOR_ORIGINAL_WORKDIR = originalPath;
    } catch {
    }
    logger.info(`[Workspace] Initialized workspace: ${info.workspacePath}`);
    logger.debug(`[Workspace] Main project at: ${info.mainProjectPath}`);
    if (keepWorkspace) {
      logger.info(`[Workspace] Keeping workspace after execution (--keep-workspace)`);
    }
    return context2;
  } catch (error) {
    logger.warn(`[Workspace] Failed to initialize workspace: ${error}`);
    logger.debug("[Workspace] Continuing without workspace isolation");
    return context2;
  }
}
var init_build_engine_context = __esm({
  "src/state-machine/context/build-engine-context.ts"() {
    "use strict";
    init_snapshot_store();
    init_memory_store();
    init_human_id();
    init_logger();
    init_workspace_manager();
  }
});

// src/event-bus/event-bus.ts
var event_bus_exports = {};
__export(event_bus_exports, {
  EventBus: () => EventBus
});
var EventBus;
var init_event_bus = __esm({
  "src/event-bus/event-bus.ts"() {
    "use strict";
    EventBus = class {
      handlers = /* @__PURE__ */ new Map();
      anyHandlers = /* @__PURE__ */ new Set();
      on(eventType, handler) {
        const set = this.handlers.get(eventType) || /* @__PURE__ */ new Set();
        set.add(handler);
        this.handlers.set(eventType, set);
        return {
          unsubscribe: () => {
            set.delete(handler);
          }
        };
      }
      onAny(handler) {
        this.anyHandlers.add(handler);
        return { unsubscribe: () => this.anyHandlers.delete(handler) };
      }
      async emit(event) {
        const type = event?.payload?.type ?? event?.type ?? "unknown";
        const list = [
          ...Array.from(this.anyHandlers),
          ...Array.from(this.handlers.get(type) || [])
        ];
        for (const h of list) {
          await h(event);
        }
      }
    };
  }
});

// src/frontends/ndjson-sink.ts
var ndjson_sink_exports = {};
__export(ndjson_sink_exports, {
  NdjsonSink: () => NdjsonSink
});
var import_fs2, import_path5, NdjsonSink;
var init_ndjson_sink = __esm({
  "src/frontends/ndjson-sink.ts"() {
    "use strict";
    import_fs2 = __toESM(require("fs"));
    import_path5 = __toESM(require("path"));
    NdjsonSink = class {
      name = "ndjson-sink";
      cfg;
      unsub;
      filePath;
      constructor(config) {
        this.cfg = config || {};
      }
      start(ctx) {
        this.filePath = this.resolveFile(this.cfg.file || ".visor-events.ndjson");
        ctx.logger.info(`[ndjson-sink] Writing events to ${this.filePath}`);
        this.unsub = ctx.eventBus.onAny(async (envelope) => {
          try {
            const line = JSON.stringify({
              id: envelope && envelope.id || void 0,
              ts: (/* @__PURE__ */ new Date()).toISOString(),
              runId: ctx.run.runId,
              payload: envelope && envelope.payload || envelope,
              safe: true
            });
            await import_fs2.default.promises.appendFile(this.filePath, line + "\n");
          } catch (err) {
            ctx.logger.error("[ndjson-sink] Failed to write event:", err);
          }
        });
      }
      stop() {
        this.unsub?.unsubscribe();
        this.unsub = void 0;
      }
      resolveFile(p) {
        if (import_path5.default.isAbsolute(p)) return p;
        return import_path5.default.join(process.cwd(), p);
      }
    };
  }
});

// src/utils/json-text-extractor.ts
function extractTextFieldFromMalformedJson(content) {
  const fieldPatterns = [
    /^\s*\{\s*"text"\s*:\s*"/i,
    /^\s*\{\s*"response"\s*:\s*"/i,
    /^\s*\{\s*"message"\s*:\s*"/i
  ];
  for (const pattern of fieldPatterns) {
    const match = pattern.exec(content);
    if (match) {
      const valueStart = match[0].length;
      const remaining = content.substring(valueStart);
      let value = "";
      let i = 0;
      while (i < remaining.length) {
        const char = remaining[i];
        if (char === "\\" && i + 1 < remaining.length) {
          const nextChar = remaining[i + 1];
          if (nextChar === "n") {
            value += "\n";
          } else if (nextChar === "r") {
            value += "\r";
          } else if (nextChar === "t") {
            value += "	";
          } else if (nextChar === '"') {
            value += '"';
          } else if (nextChar === "\\") {
            value += "\\";
          } else {
            value += char + nextChar;
          }
          i += 2;
        } else if (char === '"') {
          break;
        } else {
          value += char;
          i++;
        }
      }
      if (value.trim().length > 0) {
        return value.trim();
      }
    }
  }
  return void 0;
}
function extractTextFromJson(content) {
  if (content === void 0 || content === null) return void 0;
  let parsed = content;
  if (typeof content === "string") {
    const trimmed = content.trim();
    if (!trimmed.startsWith("{") && !trimmed.startsWith("[")) {
      return trimmed.length > 0 ? trimmed : void 0;
    }
    try {
      parsed = JSON.parse(trimmed);
    } catch {
      const extracted = extractTextFieldFromMalformedJson(trimmed);
      if (extracted) {
        return extracted;
      }
      return trimmed.length > 0 ? trimmed : void 0;
    }
  }
  if (parsed && typeof parsed === "object") {
    const txt = parsed.text || parsed.response || parsed.message;
    if (typeof txt === "string" && txt.trim()) {
      return txt.trim();
    }
  }
  if (typeof content === "string") {
    const trimmed = content.trim();
    return trimmed.length > 0 ? trimmed : void 0;
  }
  return void 0;
}
var init_json_text_extractor = __esm({
  "src/utils/json-text-extractor.ts"() {
    "use strict";
  }
});

// src/footer.ts
function generateFooter(options = {}) {
  const { includeMetadata, includeSeparator = true } = options;
  const parts = [];
  if (includeSeparator) {
    parts.push("---");
    parts.push("");
  }
  parts.push(
    "*Powered by [Visor](https://probelabs.com/visor) from [Probelabs](https://probelabs.com)*"
  );
  if (includeMetadata) {
    const { lastUpdated, triggeredBy, commitSha } = includeMetadata;
    const commitInfo = commitSha ? ` | Commit: ${commitSha.substring(0, 7)}` : "";
    parts.push("");
    parts.push(`*Last updated: ${lastUpdated} | Triggered by: ${triggeredBy}${commitInfo}*`);
  }
  parts.push("");
  parts.push("\u{1F4A1} **TIP:** You can chat with Visor using `/visor ask <your question>`");
  return parts.join("\n");
}
var init_footer = __esm({
  "src/footer.ts"() {
    "use strict";
  }
});

// src/github-check-service.ts
var github_check_service_exports = {};
__export(github_check_service_exports, {
  GitHubCheckService: () => GitHubCheckService
});
var GitHubCheckService;
var init_github_check_service = __esm({
  "src/github-check-service.ts"() {
    "use strict";
    init_footer();
    GitHubCheckService = class {
      octokit;
      maxAnnotations = 50;
      // GitHub API limit
      constructor(octokit) {
        this.octokit = octokit;
      }
      /**
       * Create a new check run in queued status
       * M4: Includes engine_mode metadata in summary
       */
      async createCheckRun(options, summary) {
        try {
          const enhancedSummary = summary && options.engine_mode ? {
            ...summary,
            summary: `${summary.summary}

_Engine: ${options.engine_mode}_`
          } : summary;
          const response = await this.octokit.rest.checks.create({
            owner: options.owner,
            repo: options.repo,
            name: options.name,
            head_sha: options.head_sha,
            status: "queued",
            details_url: options.details_url,
            external_id: options.external_id,
            output: enhancedSummary ? {
              title: enhancedSummary.title,
              summary: enhancedSummary.summary,
              text: enhancedSummary.text
            } : void 0
          });
          return {
            id: response.data.id,
            url: response.data.html_url || ""
          };
        } catch (error) {
          throw new Error(
            `Failed to create check run: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Update check run to in_progress status
       */
      async updateCheckRunInProgress(owner, repo, check_run_id, summary) {
        try {
          await this.octokit.rest.checks.update({
            owner,
            repo,
            check_run_id,
            status: "in_progress",
            output: summary ? {
              title: summary.title,
              summary: summary.summary,
              text: summary.text
            } : void 0
          });
        } catch (error) {
          throw new Error(
            `Failed to update check run to in_progress: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Complete a check run with results based on failure conditions
       */
      async completeCheckRun(owner, repo, check_run_id, checkName, failureResults, reviewIssues = [], executionError, filesChangedInCommit, prNumber, currentCommitSha) {
        try {
          if (prNumber && currentCommitSha) {
            await this.clearOldAnnotations(
              owner,
              repo,
              prNumber,
              checkName,
              currentCommitSha,
              check_run_id
            );
          }
          const { conclusion, summary } = this.determineCheckRunConclusion(
            checkName,
            failureResults,
            reviewIssues,
            executionError
          );
          let filteredIssues = reviewIssues.filter(
            (issue) => !(issue.file === "system" && issue.line === 0)
          );
          if (filesChangedInCommit && filesChangedInCommit.length > 0) {
            filteredIssues = filteredIssues.filter(
              (issue) => filesChangedInCommit.some((changedFile) => issue.file === changedFile)
            );
          }
          const annotations = this.convertIssuesToAnnotations(filteredIssues);
          await this.octokit.rest.checks.update({
            owner,
            repo,
            check_run_id,
            status: "completed",
            conclusion,
            completed_at: (/* @__PURE__ */ new Date()).toISOString(),
            output: {
              title: summary.title,
              summary: summary.summary,
              text: summary.text,
              annotations: annotations.slice(0, this.maxAnnotations)
              // GitHub limit
            }
          });
        } catch (error) {
          throw new Error(
            `Failed to complete check run: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Determine check run conclusion based on failure conditions and issues
       */
      determineCheckRunConclusion(checkName, failureResults, reviewIssues, executionError) {
        if (executionError) {
          return {
            conclusion: "failure",
            summary: {
              title: "\u274C Check Execution Failed",
              summary: `The ${checkName} check failed to execute properly.`,
              text: `**Error:** ${executionError}

Please check your configuration and try again.`
            }
          };
        }
        const failedConditions = failureResults.filter((result) => result.failed);
        const criticalIssues = reviewIssues.filter((issue) => issue.severity === "critical").length;
        const errorIssues = reviewIssues.filter((issue) => issue.severity === "error").length;
        const warningIssues = reviewIssues.filter((issue) => issue.severity === "warning").length;
        const totalIssues = reviewIssues.length;
        let conclusion;
        let title;
        let summaryText;
        let details;
        if (failedConditions.length > 0) {
          conclusion = "failure";
          title = "\u{1F6A8} Check Failed";
          summaryText = `${checkName} check failed because fail_if condition was met.`;
          details = this.formatCheckDetails(failureResults, reviewIssues, {
            failedConditions: failedConditions.length,
            warningConditions: 0,
            criticalIssues,
            errorIssues,
            warningIssues,
            totalIssues
          });
        } else {
          conclusion = "success";
          if (criticalIssues > 0 || errorIssues > 0) {
            title = "\u2705 Check Passed (Issues Found)";
            summaryText = `${checkName} check passed. Found ${criticalIssues} critical and ${errorIssues} error issues, but fail_if condition was not met.`;
          } else if (warningIssues > 0) {
            title = "\u2705 Check Passed (Warnings Found)";
            summaryText = `${checkName} check passed. Found ${warningIssues} warning${warningIssues === 1 ? "" : "s"}, but fail_if condition was not met.`;
          } else {
            title = "\u2705 Check Passed";
            summaryText = `${checkName} check completed successfully with no issues found.`;
          }
          details = this.formatCheckDetails(failureResults, reviewIssues, {
            failedConditions: 0,
            warningConditions: 0,
            criticalIssues,
            errorIssues,
            warningIssues,
            totalIssues
          });
        }
        return {
          conclusion,
          summary: {
            title,
            summary: summaryText,
            text: details
          }
        };
      }
      /**
       * Format detailed check results for the check run summary
       */
      formatCheckDetails(failureResults, reviewIssues, counts) {
        const sections = [];
        sections.push("## \u{1F4CA} Summary");
        sections.push(`- **Total Issues:** ${counts.totalIssues}`);
        if (counts.criticalIssues > 0) {
          sections.push(`- **Critical Issues:** ${counts.criticalIssues}`);
        }
        if (counts.errorIssues > 0) {
          sections.push(`- **Error Issues:** ${counts.errorIssues}`);
        }
        if (counts.warningIssues > 0) {
          sections.push(`- **Warning Issues:** ${counts.warningIssues}`);
        }
        sections.push("");
        if (failureResults.length > 0) {
          sections.push("## \u{1F50D} Failure Condition Results");
          const failedConditions = failureResults.filter((result) => result.failed);
          const passedConditions = failureResults.filter((result) => !result.failed);
          if (failedConditions.length > 0) {
            sections.push("### Failed Conditions");
            failedConditions.forEach((condition) => {
              sections.push(
                `- **${condition.conditionName}**: ${condition.message || condition.expression}`
              );
              if (condition.severity) {
                const icon = this.getSeverityEmoji(condition.severity);
                sections.push(`  - Severity: ${icon} ${condition.severity}`);
              }
            });
            sections.push("");
          }
          if (passedConditions.length > 0) {
            sections.push("### Passed Conditions");
            passedConditions.forEach((condition) => {
              sections.push(
                `- **${condition.conditionName}**: ${condition.message || "Condition passed"}`
              );
            });
            sections.push("");
          }
        }
        if (reviewIssues.length > 0) {
          const issuesByCategory = this.groupIssuesByCategory(reviewIssues);
          sections.push("## Issues by Category");
          Object.entries(issuesByCategory).forEach(([category, issues]) => {
            if (issues.length > 0) {
              sections.push(
                `### ${category.charAt(0).toUpperCase() + category.slice(1)} (${issues.length})`
              );
              const displayIssues = issues.slice(0, 5);
              displayIssues.forEach((issue) => {
                const severityIcon = this.getSeverityEmoji(issue.severity);
                sections.push(`- ${severityIcon} **${issue.file}:${issue.line}** - ${issue.message}`);
              });
              if (issues.length > 5) {
                sections.push(`- *...and ${issues.length - 5} more ${category} issues*`);
              }
              sections.push("");
            }
          });
        }
        sections.push("");
        sections.push(generateFooter());
        return sections.join("\n");
      }
      /**
       * Convert review issues to GitHub check run annotations
       */
      convertIssuesToAnnotations(reviewIssues) {
        return reviewIssues.slice(0, this.maxAnnotations).map((issue) => ({
          path: issue.file,
          start_line: issue.line,
          end_line: issue.endLine || issue.line,
          annotation_level: this.mapSeverityToAnnotationLevel(issue.severity),
          message: issue.message,
          title: `${issue.category} Issue`,
          raw_details: issue.suggestion || void 0
        }));
      }
      /**
       * Map Visor issue severity to GitHub annotation level
       */
      mapSeverityToAnnotationLevel(severity) {
        switch (severity) {
          case "critical":
          case "error":
            return "failure";
          case "warning":
            return "warning";
          case "info":
          default:
            return "notice";
        }
      }
      /**
       * Group issues by category
       */
      groupIssuesByCategory(issues) {
        const grouped = {};
        issues.forEach((issue) => {
          const category = issue.category || "general";
          if (!grouped[category]) {
            grouped[category] = [];
          }
          grouped[category].push(issue);
        });
        return grouped;
      }
      /**
       * Get emoji for issue severity (allowed; step/category emojis are removed)
       */
      getSeverityEmoji(severity) {
        const iconMap = {
          critical: "\u{1F6A8}",
          error: "\u274C",
          warning: "\u26A0\uFE0F",
          info: "\u2139\uFE0F"
        };
        return iconMap[String(severity || "").toLowerCase()] || "";
      }
      /**
       * Create multiple check runs for different checks with failure condition support
       */
      async createMultipleCheckRuns(options, checkResults) {
        const results = [];
        for (const checkResult of checkResults) {
          try {
            const checkRun = await this.createCheckRun({
              ...options,
              name: `Visor: ${checkResult.checkName}`,
              external_id: `visor-${checkResult.checkName}-${options.head_sha.substring(0, 7)}`
            });
            await this.updateCheckRunInProgress(options.owner, options.repo, checkRun.id, {
              title: `Running ${checkResult.checkName} check...`,
              summary: `Analyzing code with ${checkResult.checkName} check using AI.`
            });
            await this.completeCheckRun(
              options.owner,
              options.repo,
              checkRun.id,
              checkResult.checkName,
              checkResult.failureResults,
              checkResult.reviewIssues,
              checkResult.executionError
            );
            results.push({
              checkName: checkResult.checkName,
              id: checkRun.id,
              url: checkRun.url
            });
          } catch (error) {
            console.error(`Failed to create check run for ${checkResult.checkName}:`, error);
          }
        }
        return results;
      }
      /**
       * Get check runs for a specific commit
       */
      async getCheckRuns(owner, repo, ref) {
        try {
          const response = await this.octokit.rest.checks.listForRef({
            owner,
            repo,
            ref,
            filter: "all"
          });
          return response.data.check_runs.filter((check) => check.name.startsWith("Visor:")).map((check) => ({
            id: check.id,
            name: check.name,
            status: check.status,
            conclusion: check.conclusion
          }));
        } catch (error) {
          throw new Error(
            `Failed to get check runs: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Get check runs for a specific commit SHA
       * Returns all check runs with the given name on this commit
       */
      async getCheckRunsForCommit(owner, repo, commitSha, checkName) {
        try {
          const checksResponse = await this.octokit.rest.checks.listForRef({
            owner,
            repo,
            ref: commitSha,
            check_name: `Visor: ${checkName}`
          });
          return checksResponse.data.check_runs.map((check) => ({
            id: check.id,
            head_sha: commitSha
          }));
        } catch (error) {
          throw new Error(
            `Failed to get check runs for commit ${commitSha}: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
      /**
       * Clear annotations from old check runs on the current commit
       * This prevents annotation accumulation when a check runs multiple times on the same commit
       * (e.g., force push, re-running checks)
       */
      async clearOldAnnotations(owner, repo, prNumber, checkName, currentCommitSha, currentCheckRunId) {
        try {
          const allCheckRuns = await this.getCheckRunsForCommit(
            owner,
            repo,
            currentCommitSha,
            checkName
          );
          const oldRuns = allCheckRuns.filter((run) => run.id !== currentCheckRunId);
          if (oldRuns.length === 0) {
            console.debug(`No old check runs to clear for ${checkName} on commit ${currentCommitSha}`);
            return;
          }
          console.debug(
            `Clearing ${oldRuns.length} old check run(s) for ${checkName} on commit ${currentCommitSha.substring(0, 7)} (keeping current run ${currentCheckRunId})`
          );
          for (const run of oldRuns) {
            try {
              await this.octokit.rest.checks.update({
                owner,
                repo,
                check_run_id: run.id,
                output: {
                  title: "Outdated",
                  summary: "This check has been superseded by a newer run.",
                  annotations: []
                  // Clear annotations
                }
              });
              console.debug(`\u2713 Cleared annotations from check run ${run.id}`);
            } catch (error) {
              console.debug(`Could not clear annotations for check run ${run.id}:`, error);
            }
          }
        } catch (error) {
          console.warn("Failed to clear old annotations:", error);
        }
      }
    };
  }
});

// src/github-comments.ts
var github_comments_exports = {};
__export(github_comments_exports, {
  CommentManager: () => CommentManager
});
var CommentManager;
var init_github_comments = __esm({
  "src/github-comments.ts"() {
    "use strict";
    init_human_id();
    init_logger();
    init_footer();
    CommentManager = class {
      octokit;
      retryConfig;
      constructor(octokit, retryConfig) {
        this.octokit = octokit;
        this.retryConfig = {
          maxRetries: 3,
          baseDelay: 1e3,
          maxDelay: 1e4,
          backoffFactor: 2,
          ...retryConfig
        };
      }
      /**
       * Find existing Visor comment by comment ID marker
       */
      async findVisorComment(owner, repo, prNumber, commentId) {
        try {
          const comments = await this.octokit.rest.issues.listComments({
            owner,
            repo,
            issue_number: prNumber,
            per_page: 100
            // GitHub default max
          });
          for (const comment of comments.data) {
            if (comment.body && this.isVisorComment(comment.body, commentId)) {
              return comment;
            }
          }
          return null;
        } catch (error) {
          if (this.isRateLimitError(
            error
          )) {
            await this.handleRateLimit(error);
            return this.findVisorComment(owner, repo, prNumber, commentId);
          }
          throw error;
        }
      }
      /**
       * Update existing comment or create new one with collision detection
       */
      async updateOrCreateComment(owner, repo, prNumber, content, options = {}) {
        const {
          commentId = this.generateCommentId(),
          triggeredBy = "unknown",
          allowConcurrentUpdates = false,
          commitSha,
          cachedGithubCommentId
        } = options;
        return this.withRetry(async () => {
          let existingComment = await this.findVisorComment(owner, repo, prNumber, commentId);
          if (!existingComment && cachedGithubCommentId) {
            try {
              const cachedComment = await this.octokit.rest.issues.getComment({
                owner,
                repo,
                comment_id: cachedGithubCommentId
              });
              if (cachedComment.data && this.isVisorComment(cachedComment.data.body || "", commentId)) {
                existingComment = cachedComment.data;
                logger.debug(
                  `[github-comments] Found comment via cached ID ${cachedGithubCommentId} (not visible in listComments yet)`
                );
              }
            } catch (_e) {
              logger.debug(
                `[github-comments] Cached comment ${cachedGithubCommentId} not found, will create new`
              );
            }
          }
          const formattedContent = this.formatCommentWithMetadata(content, {
            commentId,
            lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
            triggeredBy,
            commitSha
          });
          if (existingComment) {
            if (!allowConcurrentUpdates) {
              const currentComment = await this.octokit.rest.issues.getComment({
                owner,
                repo,
                comment_id: existingComment.id
              });
              if (currentComment.data.updated_at !== existingComment.updated_at) {
                throw new Error(
                  `Comment collision detected for comment ${commentId}. Another process may have updated it.`
                );
              }
            }
            const updatedComment = await this.octokit.rest.issues.updateComment({
              owner,
              repo,
              comment_id: existingComment.id,
              body: formattedContent
            });
            logger.info(
              `\u2705 Successfully updated comment (ID: ${commentId}, GitHub ID: ${existingComment.id}) on PR #${prNumber} in ${owner}/${repo}`
            );
            return updatedComment.data;
          } else {
            const newComment = await this.octokit.rest.issues.createComment({
              owner,
              repo,
              issue_number: prNumber,
              body: formattedContent
            });
            logger.info(
              `\u2705 Successfully created comment (ID: ${commentId}, GitHub ID: ${newComment.data.id}) on PR #${prNumber} in ${owner}/${repo}`
            );
            return newComment.data;
          }
        });
      }
      /**
       * Format comment content with metadata markers
       */
      formatCommentWithMetadata(content, metadata) {
        const { commentId, lastUpdated, triggeredBy, commitSha } = metadata;
        const footer = generateFooter({
          includeMetadata: {
            lastUpdated,
            triggeredBy,
            commitSha
          }
        });
        return `<!-- visor-comment-id:${commentId} -->
${content}

${footer}
<!-- /visor-comment-id:${commentId} -->`;
      }
      /**
       * Create collapsible sections for comment content
       */
      createCollapsibleSection(title, content, isExpanded = false) {
        const openAttribute = isExpanded ? " open" : "";
        return `<details${openAttribute}>
<summary>${title}</summary>

${content}

</details>`;
      }
      /**
       * Group review results by check type with collapsible sections
       */
      formatGroupedResults(results, groupBy = "check") {
        const grouped = this.groupResults(results, groupBy);
        const sections = [];
        for (const [groupKey, items] of Object.entries(grouped)) {
          const totalScore = items.reduce((sum, item) => sum + (item.score || 0), 0) / items.length;
          const totalIssues = items.reduce((sum, item) => sum + (item.issuesFound || 0), 0);
          const title = this.formatGroupTitle(groupKey, totalScore, totalIssues);
          const sectionContent = items.map((item) => item.content).join("\n\n");
          sections.push(this.createCollapsibleSection(title, sectionContent, totalIssues > 0));
        }
        return sections.join("\n\n");
      }
      /**
       * Generate unique comment ID
       */
      generateCommentId() {
        return generateShortHumanId();
      }
      /**
       * Check if comment is a Visor comment
       */
      isVisorComment(body, commentId) {
        if (commentId) {
          if (body.includes(`visor-comment-id:${commentId} `) || body.includes(`visor-comment-id:${commentId} -->`)) {
            return true;
          }
          if (commentId.startsWith("pr-review-") && body.includes("visor-review-")) {
            return true;
          }
          return false;
        }
        return body.includes("visor-comment-id:") && body.includes("<!-- /visor-comment-id:") || body.includes("visor-review-");
      }
      /**
       * Extract comment ID from comment body
       */
      extractCommentId(body) {
        const match = body.match(/visor-comment-id:([a-f0-9-]+)/);
        return match ? match[1] : null;
      }
      /**
       * Handle rate limiting with exponential backoff
       */
      async handleRateLimit(error) {
        const resetTime = error.response?.headers?.["x-ratelimit-reset"];
        if (resetTime) {
          const resetDate = new Date(parseInt(resetTime) * 1e3);
          const waitTime = Math.max(resetDate.getTime() - Date.now(), this.retryConfig.baseDelay);
          console.log(`Rate limit exceeded. Waiting ${Math.round(waitTime / 1e3)}s until reset...`);
          await this.sleep(Math.min(waitTime, this.retryConfig.maxDelay));
        } else {
          await this.sleep(this.retryConfig.baseDelay);
        }
      }
      /**
       * Check if error is a rate limit error
       */
      isRateLimitError(error) {
        return error.status === 403 && (error.response?.data?.message?.includes("rate limit") ?? false);
      }
      /**
       * Check if error should not be retried (auth errors, not found, etc.)
       */
      isNonRetryableError(error) {
        const nonRetryableStatuses = [401, 404, 422];
        const status = error.status || error.response?.status;
        if (status === 403) {
          return !this.isRateLimitError(error);
        }
        return status !== void 0 && nonRetryableStatuses.includes(status);
      }
      /**
       * Retry wrapper with exponential backoff
       */
      async withRetry(operation) {
        let lastError = new Error("Unknown error");
        for (let attempt = 0; attempt <= this.retryConfig.maxRetries; attempt++) {
          try {
            return await operation();
          } catch (error) {
            lastError = error instanceof Error ? error : new Error(String(error));
            if (attempt === this.retryConfig.maxRetries) {
              break;
            }
            if (this.isRateLimitError(
              error
            )) {
              await this.handleRateLimit(error);
            } else if (this.isNonRetryableError(error)) {
              throw error;
            } else {
              const computed = this.retryConfig.baseDelay * Math.pow(this.retryConfig.backoffFactor, attempt);
              const delay = computed > this.retryConfig.maxDelay ? Math.max(0, this.retryConfig.maxDelay - 1) : computed;
              await this.sleep(delay);
            }
          }
        }
        throw lastError;
      }
      /**
       * Sleep utility
       */
      sleep(ms) {
        return new Promise((resolve9) => {
          const t = setTimeout(resolve9, ms);
          if (typeof t.unref === "function") {
            try {
              t.unref();
            } catch {
            }
          }
        });
      }
      /**
       * Group results by specified criteria
       */
      groupResults(results, groupBy) {
        const grouped = {};
        for (const result of results) {
          const key = groupBy === "check" ? result.checkType : this.getSeverityGroup(result.score);
          if (!grouped[key]) {
            grouped[key] = [];
          }
          grouped[key].push(result);
        }
        return grouped;
      }
      /**
       * Get severity group based on score
       */
      getSeverityGroup(score) {
        if (!score) return "Unknown";
        if (score >= 90) return "Excellent";
        if (score >= 75) return "Good";
        if (score >= 50) return "Needs Improvement";
        return "Critical Issues";
      }
      // Emoji helper removed: plain titles are used in group headers
      /**
       * Format group title with score and issue count
       */
      formatGroupTitle(groupKey, score, issuesFound) {
        const formattedScore = Math.round(score);
        return `${groupKey} Review (Score: ${formattedScore}/100)${issuesFound > 0 ? ` - ${issuesFound} issues found` : ""}`;
      }
    };
  }
});

// src/frontends/github-frontend.ts
var github_frontend_exports = {};
__export(github_frontend_exports, {
  GitHubFrontend: () => GitHubFrontend
});
var GitHubFrontend;
var init_github_frontend = __esm({
  "src/frontends/github-frontend.ts"() {
    "use strict";
    init_logger();
    init_json_text_extractor();
    GitHubFrontend = class {
      name = "github";
      subs = [];
      checkRunIds = /* @__PURE__ */ new Map();
      revision = 0;
      cachedCommentId;
      // legacy single-thread id (kept for compatibility)
      // Group  (checkId  SectionState)
      stepStatusByGroup = /* @__PURE__ */ new Map();
      // Debounce/coalescing state
      debounceMs = 400;
      maxWaitMs = 2e3;
      _timer = null;
      _lastFlush = 0;
      _pendingIds = /* @__PURE__ */ new Set();
      // Mutex for serializing comment updates per group
      updateLocks = /* @__PURE__ */ new Map();
      minUpdateDelayMs = 1e3;
      // Minimum delay between updates (public for testing)
      // Cache of created GitHub comment IDs per group to handle API eventual consistency
      createdCommentGithubIds = /* @__PURE__ */ new Map();
      start(ctx) {
        const log2 = ctx.logger;
        const bus = ctx.eventBus;
        const octokit = ctx.octokit;
        const repo = ctx.run.repo;
        const pr = ctx.run.pr;
        const headSha = ctx.run.headSha;
        const canPostComments = !!(octokit && repo && pr);
        const canPostChecks = !!(octokit && repo && pr && headSha);
        const svc = canPostChecks ? new (init_github_check_service(), __toCommonJS(github_check_service_exports)).GitHubCheckService(octokit) : null;
        const CommentManager2 = (init_github_comments(), __toCommonJS(github_comments_exports)).CommentManager;
        const comments = canPostComments ? new CommentManager2(octokit) : null;
        const threadKey = repo && pr && headSha ? `${repo.owner}/${repo.name}#${pr}@${(headSha || "").substring(0, 7)}` : ctx.run.runId;
        this.cachedCommentId = `visor-thread-${threadKey}`;
        this.subs.push(
          bus.on("CheckScheduled", async (env) => {
            const ev = env && env.payload || env;
            try {
              if (!canPostChecks || !svc) return;
              if (this.checkRunIds.has(ev.checkId)) return;
              const group = this.getGroupForCheck(ctx, ev.checkId);
              this.upsertSectionState(group, ev.checkId, {
                status: "queued",
                lastUpdated: (/* @__PURE__ */ new Date()).toISOString()
              });
              const res = await svc.createCheckRun(
                {
                  owner: repo.owner,
                  repo: repo.name,
                  head_sha: headSha,
                  name: `Visor: ${ev.checkId}`,
                  external_id: `visor:${ctx.run.runId}:${ev.checkId}`,
                  engine_mode: "state-machine"
                },
                { title: `${ev.checkId}`, summary: "Queued" }
              );
              this.checkRunIds.set(ev.checkId, res.id);
            } catch (e) {
              log2.warn(
                `[github-frontend] createCheckRun failed for ${ev.checkId}: ${e instanceof Error ? e.message : e}`
              );
            }
          })
        );
        this.subs.push(
          bus.on("CheckCompleted", async (env) => {
            const ev = env && env.payload || env;
            try {
              if (canPostChecks && svc && this.checkRunIds.has(ev.checkId)) {
                const id = this.checkRunIds.get(ev.checkId);
                const issues = Array.isArray(ev.result?.issues) ? ev.result.issues : [];
                const failureResults = await this.evaluateFailureResults(ctx, ev.checkId, ev.result);
                await svc.completeCheckRun(
                  repo.owner,
                  repo.name,
                  id,
                  ev.checkId,
                  failureResults,
                  issues,
                  void 0,
                  void 0,
                  pr,
                  headSha
                );
              }
              if (canPostComments && comments) {
                const count = Array.isArray(ev.result?.issues) ? ev.result.issues.length : 0;
                const failureResults = await this.evaluateFailureResults(ctx, ev.checkId, ev.result);
                const failed = Array.isArray(failureResults) ? failureResults.some((r) => r && r.failed) : false;
                const group = this.getGroupForCheck(ctx, ev.checkId);
                const rawContent = ev?.result?.content;
                const extractedContent = extractTextFromJson(rawContent);
                this.upsertSectionState(group, ev.checkId, {
                  status: "completed",
                  conclusion: failed ? "failure" : "success",
                  issues: count,
                  lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
                  content: extractedContent
                });
                await this.updateGroupedComment(ctx, comments, group, ev.checkId);
              }
            } catch (e) {
              log2.warn(
                `[github-frontend] handle CheckCompleted failed: ${e instanceof Error ? e.message : e}`
              );
            }
          })
        );
        this.subs.push(
          bus.on("CheckErrored", async (env) => {
            const ev = env && env.payload || env;
            try {
              if (canPostChecks && svc && this.checkRunIds.has(ev.checkId)) {
                const id = this.checkRunIds.get(ev.checkId);
                await svc.completeCheckRun(
                  repo.owner,
                  repo.name,
                  id,
                  ev.checkId,
                  [],
                  [],
                  ev.error?.message || "Execution error",
                  void 0,
                  pr,
                  headSha
                );
              }
              if (canPostComments && comments) {
                const group = this.getGroupForCheck(ctx, ev.checkId);
                this.upsertSectionState(group, ev.checkId, {
                  status: "errored",
                  conclusion: "failure",
                  issues: 0,
                  lastUpdated: (/* @__PURE__ */ new Date()).toISOString(),
                  error: ev.error?.message || "Execution error"
                });
                await this.updateGroupedComment(ctx, comments, group, ev.checkId);
              }
            } catch (e) {
              log2.warn(
                `[github-frontend] handle CheckErrored failed: ${e instanceof Error ? e.message : e}`
              );
            }
          })
        );
        this.subs.push(
          bus.on("StateTransition", async (env) => {
            const ev = env && env.payload || env;
            try {
              if (ev.to === "Completed" || ev.to === "Error") {
                if (canPostComments && comments) {
                  for (const group of this.stepStatusByGroup.keys()) {
                    await this.updateGroupedComment(ctx, comments, group);
                  }
                }
              }
            } catch (e) {
              log2.warn(
                `[github-frontend] handle StateTransition failed: ${e instanceof Error ? e.message : e}`
              );
            }
          })
        );
      }
      stop() {
        for (const s of this.subs) s.unsubscribe();
        this.subs = [];
      }
      async buildFullBody(ctx, group) {
        const header = this.renderThreadHeader(ctx, group);
        const sections = this.renderSections(ctx, group);
        return `${header}

${sections}

<!-- visor:thread-end key="${this.threadKeyFor(ctx)}" -->`;
      }
      threadKeyFor(ctx) {
        const r = ctx.run;
        return r.repo && r.pr && r.headSha ? `${r.repo.owner}/${r.repo.name}#${r.pr}@${(r.headSha || "").substring(0, 7)}` : r.runId;
      }
      renderThreadHeader(ctx, group) {
        const header = {
          key: this.threadKeyFor(ctx),
          runId: ctx.run.runId,
          workflowId: ctx.run.workflowId,
          revision: this.revision,
          group,
          generatedAt: (/* @__PURE__ */ new Date()).toISOString()
        };
        return `<!-- visor:thread=${JSON.stringify(header)} -->`;
      }
      renderSections(ctx, group) {
        const lines = [];
        const groupMap = this.stepStatusByGroup.get(group) || /* @__PURE__ */ new Map();
        for (const [checkId, st] of groupMap.entries()) {
          const start = `<!-- visor:section=${JSON.stringify({ id: checkId, revision: this.revision })} -->`;
          const end = `<!-- visor:section-end id="${checkId}" -->`;
          const body = st.content && st.content.toString().trim().length > 0 ? st.content.toString().trim() : "";
          lines.push(`${start}
${body}
${end}`);
        }
        return lines.join("\\n\\n");
      }
      /**
       * Acquires a mutex lock for the given group and executes the update.
       * This ensures only one comment update happens at a time per group,
       * preventing race conditions where updates overwrite each other.
       *
       * Uses a proper queue-based mutex: each new caller chains onto the previous
       * lock, ensuring strict serialization even when multiple callers wait
       * simultaneously.
       */
      async updateGroupedComment(ctx, comments, group, changedIds) {
        const existingLock = this.updateLocks.get(group);
        let resolveLock;
        const ourLock = new Promise((resolve9) => {
          resolveLock = resolve9;
        });
        this.updateLocks.set(group, ourLock);
        try {
          if (existingLock) {
            try {
              await existingLock;
            } catch (error) {
              logger.warn(
                `[github-frontend] Previous update for group ${group} failed: ${error instanceof Error ? error.message : error}`
              );
            }
          }
          await this.performGroupedCommentUpdate(ctx, comments, group, changedIds);
        } finally {
          if (this.updateLocks.get(group) === ourLock) {
            this.updateLocks.delete(group);
          }
          resolveLock();
        }
      }
      /**
       * Performs the actual comment update with delay enforcement.
       */
      async performGroupedCommentUpdate(ctx, comments, group, changedIds) {
        try {
          if (!ctx.run.repo || !ctx.run.pr) return;
          const config = ctx.config;
          const prCommentEnabled = config?.output?.pr_comment?.enabled !== false;
          if (!prCommentEnabled) {
            logger.debug(
              `[github-frontend] PR comments disabled in config, skipping comment for group: ${group}`
            );
            return;
          }
          const timeSinceLastFlush = Date.now() - this._lastFlush;
          if (this._lastFlush > 0 && timeSinceLastFlush < this.minUpdateDelayMs) {
            const delay = this.minUpdateDelayMs - timeSinceLastFlush;
            logger.debug(
              `[github-frontend] Waiting ${delay}ms before next update to prevent rate limiting`
            );
            await this.sleep(delay);
          }
          this.revision++;
          const commentId = this.commentIdForGroup(ctx, group);
          const mergedBody = await this.mergeIntoExistingBody(ctx, comments, group, changedIds);
          const cachedGithubId = this.createdCommentGithubIds.get(commentId);
          const result = await comments.updateOrCreateComment(
            ctx.run.repo.owner,
            ctx.run.repo.name,
            ctx.run.pr,
            mergedBody,
            {
              commentId,
              triggeredBy: this.deriveTriggeredBy(ctx),
              commitSha: ctx.run.headSha,
              // Pass the cached GitHub comment ID if available
              cachedGithubCommentId: cachedGithubId
            }
          );
          if (result && result.id) {
            this.createdCommentGithubIds.set(commentId, result.id);
          }
          this._lastFlush = Date.now();
        } catch (e) {
          logger.debug(
            `[github-frontend] updateGroupedComment failed: ${e instanceof Error ? e.message : e}`
          );
        }
      }
      deriveTriggeredBy(ctx) {
        const ev = ctx.run.event || "";
        const actor = ctx.run.actor;
        const commentEvents = /* @__PURE__ */ new Set([
          "issue_comment",
          "issue_comment_created",
          "pr_comment",
          "comment",
          "pull_request_review_comment"
        ]);
        if (commentEvents.has(ev) && actor) return actor;
        if (ev) return ev;
        return actor || "unknown";
      }
      async mergeIntoExistingBody(ctx, comments, group, changedIds) {
        const repo = ctx.run.repo;
        const pr = ctx.run.pr;
        const existing = await comments.findVisorComment(
          repo.owner,
          repo.name,
          pr,
          this.commentIdForGroup(ctx, group)
        );
        if (!existing || !existing.body) return this.buildFullBody(ctx, group);
        const body = String(existing.body);
        const doc = this.parseSections(body);
        doc.header = {
          ...doc.header || {},
          key: this.threadKeyFor(ctx),
          revision: this.revision,
          group
        };
        if (changedIds) {
          const ids = Array.isArray(changedIds) ? changedIds : [changedIds];
          const fresh = this.renderSections(ctx, group);
          for (const id of ids) {
            const block = this.extractSectionById(fresh, id);
            if (block) doc.sections.set(id, block);
          }
        } else {
          const fresh = this.renderSections(ctx, group);
          const map = this.stepStatusByGroup.get(group) || /* @__PURE__ */ new Map();
          for (const [checkId] of map.entries()) {
            if (!doc.sections.has(checkId)) {
              const block = this.extractSectionById(fresh, checkId);
              if (block) doc.sections.set(checkId, block);
            }
          }
        }
        return this.serializeSections(doc);
      }
      parseSections(body) {
        const sections = /* @__PURE__ */ new Map();
        const headerRe = /<!--\s*visor:thread=(\{[\s\S]*?\})\s*-->/m;
        const startRe = /<!--\s*visor:section=(\{[\s\S]*?\})\s*-->/g;
        const endRe = /<!--\s*visor:section-end\s+id=\"([^\"]+)\"\s*-->/g;
        const safePick = (obj, allowed) => {
          if (!obj || typeof obj !== "object" || Array.isArray(obj)) return void 0;
          const out = /* @__PURE__ */ Object.create(null);
          for (const [k, t] of Object.entries(allowed)) {
            if (Object.prototype.hasOwnProperty.call(obj, k)) {
              const v = obj[k];
              if (t === "string" && typeof v === "string") out[k] = v;
              else if (t === "number" && typeof v === "number" && Number.isFinite(v)) out[k] = v;
            }
          }
          return out;
        };
        const safeParse = (text) => {
          try {
            return JSON.parse(text);
          } catch {
            return void 0;
          }
        };
        let header;
        try {
          const h = headerRe.exec(body);
          if (h) {
            const parsed = safeParse(h[1]);
            const picked = safePick(parsed, {
              key: "string",
              runId: "string",
              workflowId: "string",
              revision: "number",
              group: "string",
              generatedAt: "string"
            });
            header = picked;
          }
        } catch {
        }
        let cursor = 0;
        while (true) {
          const s = startRe.exec(body);
          if (!s) break;
          const metaRaw = safeParse(s[1]);
          const meta = safePick(metaRaw, { id: "string", revision: "number" }) || { id: "" };
          const startIdx = startRe.lastIndex;
          endRe.lastIndex = startIdx;
          const e = endRe.exec(body);
          if (!e) break;
          const id = typeof meta.id === "string" && meta.id ? String(meta.id) : String(e[1]);
          const content = body.substring(startIdx, e.index).trim();
          const block = `<!-- visor:section=${JSON.stringify(meta)} -->
${content}
<!-- visor:section-end id="${id}" -->`;
          sections.set(id, block);
          cursor = endRe.lastIndex;
          startRe.lastIndex = cursor;
        }
        return { header, sections };
      }
      serializeSections(doc) {
        const header = `<!-- visor:thread=${JSON.stringify({ ...doc.header || {}, generatedAt: (/* @__PURE__ */ new Date()).toISOString() })} -->`;
        const blocks = Array.from(doc.sections.values()).join("\n\n");
        const key = doc.header && doc.header.key || "";
        return `${header}

${blocks}

<!-- visor:thread-end key="${key}" -->`;
      }
      extractSectionById(rendered, id) {
        const rx = new RegExp(
          `<!--\\s*visor:section=(\\{[\\s\\S]*?\\})\\s*-->[\\s\\S]*?<!--\\s*visor:section-end\\s+id=\\"${this.escapeRegExp(id)}\\"\\s*-->`,
          "m"
        );
        const m = rx.exec(rendered);
        return m ? m[0] : void 0;
      }
      escapeRegExp(s) {
        return s.replace(/[.*+?^${}()|[\\]\\]/g, "\\$&");
      }
      getGroupForCheck(ctx, checkId) {
        try {
          const cfg = ctx.config || {};
          const g = cfg?.checks?.[checkId]?.group || cfg?.steps?.[checkId]?.group;
          if (typeof g === "string" && g.trim().length > 0) return g;
        } catch {
        }
        return "review";
      }
      upsertSectionState(group, checkId, patch) {
        let groupMap = this.stepStatusByGroup.get(group);
        if (!groupMap) {
          groupMap = /* @__PURE__ */ new Map();
          this.stepStatusByGroup.set(group, groupMap);
        }
        const prev = groupMap.get(checkId) || { status: "queued", lastUpdated: (/* @__PURE__ */ new Date()).toISOString() };
        groupMap.set(checkId, { ...prev, ...patch });
      }
      commentIdForGroup(ctx, group) {
        if (group === "dynamic") {
          return `visor-thread-dynamic-${ctx.run.runId}`;
        }
        const r = ctx.run;
        const base = r.repo && r.pr ? `${r.repo.owner}/${r.repo.name}#${r.pr}` : r.runId;
        return `visor-thread-${group}-${base}`;
      }
      /**
       * Compute failure condition results for a completed check so Check Runs map to the
       * correct GitHub conclusion. This mirrors the engine's evaluation for fail_if.
       */
      async evaluateFailureResults(ctx, checkId, result) {
        try {
          const config = ctx.config || {};
          const checks = config && config.checks || {};
          const checkCfg = checks[checkId] || {};
          const checkSchema = typeof checkCfg.schema === "string" ? checkCfg.schema : "code-review";
          const checkGroup = checkCfg.group || "default";
          const { FailureConditionEvaluator: FailureConditionEvaluator2 } = (init_failure_condition_evaluator(), __toCommonJS(failure_condition_evaluator_exports));
          const evaluator = new FailureConditionEvaluator2();
          const reviewSummary = { issues: Array.isArray(result?.issues) ? result.issues : [] };
          const failures = [];
          if (config.fail_if) {
            const failed = await evaluator.evaluateSimpleCondition(
              checkId,
              checkSchema,
              checkGroup,
              reviewSummary,
              config.fail_if
            );
            failures.push({
              conditionName: "global_fail_if",
              failed,
              expression: config.fail_if,
              severity: "error",
              haltExecution: false
            });
          }
          if (checkCfg.fail_if) {
            const failed = await evaluator.evaluateSimpleCondition(
              checkId,
              checkSchema,
              checkGroup,
              reviewSummary,
              checkCfg.fail_if
            );
            failures.push({
              conditionName: `${checkId}_fail_if`,
              failed,
              expression: checkCfg.fail_if,
              severity: "error",
              haltExecution: false
            });
          }
          return failures;
        } catch {
          return [];
        }
      }
      // Debounce helpers
      scheduleUpdate(ctx, comments, group, id) {
        if (id) this._pendingIds.add(id);
        const now = Date.now();
        const since = now - this._lastFlush;
        const remaining = this.maxWaitMs - since;
        if (this._timer) clearTimeout(this._timer);
        const wait = Math.max(0, Math.min(this.debounceMs, remaining));
        this._timer = setTimeout(async () => {
          const ids = Array.from(this._pendingIds);
          this._pendingIds.clear();
          this._timer = null;
          await this.updateGroupedComment(ctx, comments, group, ids.length > 0 ? ids : void 0);
          this._lastFlush = Date.now();
        }, wait);
      }
      async flushNow(ctx, comments, group) {
        if (this._timer) {
          clearTimeout(this._timer);
          this._timer = null;
        }
        const ids = Array.from(this._pendingIds);
        this._pendingIds.clear();
        await this.updateGroupedComment(ctx, comments, group, ids.length > 0 ? ids : void 0);
        this._lastFlush = Date.now();
      }
      /**
       * Sleep utility for enforcing delays
       */
      sleep(ms) {
        return new Promise((resolve9) => setTimeout(resolve9, ms));
      }
    };
  }
});

// src/slack/client.ts
var SlackClient;
var init_client = __esm({
  "src/slack/client.ts"() {
    "use strict";
    SlackClient = class {
      token;
      constructor(botToken) {
        if (!botToken || typeof botToken !== "string") {
          throw new Error("SlackClient: botToken is required");
        }
        this.token = botToken;
      }
      reactions = {
        add: async ({
          channel,
          timestamp,
          name
        }) => {
          const resp = await this.api("reactions.add", { channel, timestamp, name });
          if (!resp || resp.ok !== true) {
            const err = resp && resp.error || "unknown_error";
            console.warn(`Slack reactions.add failed (non-fatal): ${err}`);
            return { ok: false };
          }
          return { ok: true };
        },
        remove: async ({
          channel,
          timestamp,
          name
        }) => {
          const resp = await this.api("reactions.remove", { channel, timestamp, name });
          if (!resp || resp.ok !== true) {
            const err = resp && resp.error || "unknown_error";
            console.warn(`Slack reactions.remove failed (non-fatal): ${err}`);
            return { ok: false };
          }
          return { ok: true };
        }
      };
      chat = {
        postMessage: async ({
          channel,
          text,
          thread_ts
        }) => {
          const resp = await this.api("chat.postMessage", { channel, text, thread_ts });
          if (!resp || resp.ok !== true) {
            const err = resp && resp.error || "unknown_error";
            console.warn(`Slack chat.postMessage failed (non-fatal): ${err}`);
            return {
              ts: void 0,
              message: void 0,
              data: resp
            };
          }
          return {
            ts: resp.ts || resp.message && resp.message.ts || void 0,
            message: resp.message,
            data: resp
          };
        },
        update: async ({ channel, ts, text }) => {
          const resp = await this.api("chat.update", { channel, ts, text });
          if (!resp || resp.ok !== true) {
            const err = resp && resp.error || "unknown_error";
            console.warn(`Slack chat.update failed (non-fatal): ${err}`);
            return { ok: false, ts };
          }
          return { ok: true, ts: resp.ts || ts };
        }
      };
      async getBotUserId() {
        const resp = await this.api("auth.test", {});
        if (!resp || resp.ok !== true || !resp.user_id) {
          console.warn("Slack auth.test failed (non-fatal); bot user id unavailable");
          return "UNKNOWN_BOT";
        }
        return String(resp.user_id);
      }
      async fetchThreadReplies(channel, thread_ts, limit = 40) {
        try {
          const params = new URLSearchParams({
            channel,
            ts: thread_ts,
            limit: String(limit)
          });
          const res = await fetch(`https://slack.com/api/conversations.replies?${params.toString()}`, {
            method: "GET",
            headers: {
              Authorization: `Bearer ${this.token}`
            }
          });
          const resp = await res.json();
          if (!resp || resp.ok !== true || !Array.isArray(resp.messages)) {
            const err = resp && resp.error || "unknown_error";
            console.warn(
              `Slack conversations.replies failed (non-fatal): ${err} (channel=${channel}, ts=${thread_ts}, limit=${limit})`
            );
            return [];
          }
          return resp.messages.map((m) => ({
            ts: String(m.ts || ""),
            user: m.user,
            text: m.text,
            bot_id: m.bot_id,
            thread_ts: m.thread_ts
          }));
        } catch (e) {
          console.warn(
            `Slack conversations.replies failed (non-fatal): ${e instanceof Error ? e.message : String(e)} (channel=${channel}, ts=${thread_ts}, limit=${limit})`
          );
          return [];
        }
      }
      files = {
        /**
         * Upload a file to Slack using files.uploadV2 API
         * @param options Upload options including file content, filename, channel, and thread_ts
         */
        uploadV2: async ({
          content,
          filename,
          channel,
          thread_ts,
          title,
          initial_comment
        }) => {
          try {
            const getUrlResp = await this.api("files.getUploadURLExternal", {
              filename,
              length: content.length
            });
            if (!getUrlResp || getUrlResp.ok !== true || !getUrlResp.upload_url) {
              console.warn(
                `Slack files.getUploadURLExternal failed: ${getUrlResp?.error || "unknown"}`
              );
              return { ok: false };
            }
            const uploadResp = await fetch(getUrlResp.upload_url, {
              method: "POST",
              body: content
            });
            if (!uploadResp.ok) {
              console.warn(`Slack file upload to URL failed: ${uploadResp.status}`);
              return { ok: false };
            }
            const completeResp = await this.api("files.completeUploadExternal", {
              files: [{ id: getUrlResp.file_id, title: title || filename }],
              channel_id: channel,
              thread_ts,
              initial_comment
            });
            if (!completeResp || completeResp.ok !== true) {
              console.warn(
                `Slack files.completeUploadExternal failed: ${completeResp?.error || "unknown"}`
              );
              return { ok: false };
            }
            return {
              ok: true,
              file: completeResp.files?.[0] || { id: getUrlResp.file_id }
            };
          } catch (e) {
            console.warn(`Slack file upload failed: ${e instanceof Error ? e.message : String(e)}`);
            return { ok: false };
          }
        }
      };
      getWebClient() {
        return {
          conversations: {
            history: async ({ channel, limit }) => await this.api("conversations.history", { channel, limit }),
            open: async ({ users }) => await this.api("conversations.open", { users }),
            replies: async ({ channel, ts, limit }) => await this.api("conversations.replies", { channel, ts, limit })
          }
        };
      }
      async api(method, body) {
        const res = await fetch(`https://slack.com/api/${method}`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json; charset=utf-8",
            Authorization: `Bearer ${this.token}`
          },
          body: JSON.stringify(body)
        });
        return await res.json();
      }
    };
  }
});

// src/slack/markdown.ts
function extractMermaidDiagrams(text) {
  const diagrams = [];
  const regex = /```mermaid\s*\n([\s\S]*?)```/g;
  let match;
  while ((match = regex.exec(text)) !== null) {
    diagrams.push({
      fullMatch: match[0],
      code: match[1].trim(),
      startIndex: match.index,
      endIndex: match.index + match[0].length
    });
  }
  return diagrams;
}
async function renderMermaidToPng(mermaidCode) {
  const tmpDir = os.tmpdir();
  const inputFile = path20.join(
    tmpDir,
    `mermaid-${Date.now()}-${Math.random().toString(36).slice(2)}.mmd`
  );
  const outputFile = path20.join(
    tmpDir,
    `mermaid-${Date.now()}-${Math.random().toString(36).slice(2)}.png`
  );
  try {
    fs18.writeFileSync(inputFile, mermaidCode, "utf-8");
    const chromiumPaths = [
      "/usr/bin/chromium",
      "/usr/bin/chromium-browser",
      "/usr/bin/google-chrome",
      "/usr/bin/chrome"
    ];
    let chromiumPath;
    for (const p of chromiumPaths) {
      if (fs18.existsSync(p)) {
        chromiumPath = p;
        break;
      }
    }
    const env = { ...process.env };
    if (chromiumPath) {
      env.PUPPETEER_EXECUTABLE_PATH = chromiumPath;
    }
    const result = await new Promise((resolve9) => {
      const proc = (0, import_child_process2.spawn)(
        "npx",
        [
          "--yes",
          "@mermaid-js/mermaid-cli",
          "-i",
          inputFile,
          "-o",
          outputFile,
          "-e",
          "png",
          "-b",
          "white",
          "-w",
          "1200"
        ],
        {
          timeout: 6e4,
          // 60 second timeout (first run may download packages)
          stdio: ["pipe", "pipe", "pipe"],
          env
        }
      );
      let stderr = "";
      proc.stderr?.on("data", (data) => {
        stderr += data.toString();
      });
      proc.on("close", (code) => {
        if (code === 0) {
          resolve9({ success: true });
        } else {
          resolve9({ success: false, error: stderr || `Exit code ${code}` });
        }
      });
      proc.on("error", (err) => {
        resolve9({ success: false, error: err.message });
      });
    });
    if (!result.success) {
      console.warn(`Mermaid rendering failed: ${result.error}`);
      return null;
    }
    if (!fs18.existsSync(outputFile)) {
      console.warn("Mermaid output file not created");
      return null;
    }
    const pngBuffer = fs18.readFileSync(outputFile);
    return pngBuffer;
  } catch (e) {
    console.warn(`Mermaid rendering error: ${e instanceof Error ? e.message : String(e)}`);
    return null;
  } finally {
    try {
      if (fs18.existsSync(inputFile)) fs18.unlinkSync(inputFile);
      if (fs18.existsSync(outputFile)) fs18.unlinkSync(outputFile);
    } catch {
    }
  }
}
function replaceMermaidBlocks(text, diagrams, replacement = "_(See diagram above)_") {
  if (diagrams.length === 0) return text;
  const sorted = [...diagrams].sort((a, b) => b.startIndex - a.startIndex);
  let result = text;
  sorted.forEach((diagram, sortedIndex) => {
    const originalIndex = diagrams.length - 1 - sortedIndex;
    const rep = typeof replacement === "function" ? replacement(originalIndex) : replacement;
    result = result.slice(0, diagram.startIndex) + rep + result.slice(diagram.endIndex);
  });
  return result;
}
function markdownToSlack(text) {
  if (!text || typeof text !== "string") return "";
  let out = text;
  out = out.replace(
    /!\[([^\]]*)\]\(([^)\s]+)(?:\s+"[^"]*")?\)/g,
    (_m, alt, url) => `<${url}|${alt || "image"}>`
  );
  out = out.replace(
    /\[([^\]]+)\]\(([^)\s]+)(?:\s+"[^"]*")?\)/g,
    (_m, label, url) => `<${url}|${label}>`
  );
  out = out.replace(/\*\*([^*]+)\*\*/g, (_m, inner) => `*${inner}*`);
  out = out.replace(/__([^_]+)__/g, (_m, inner) => `*${inner}*`);
  const lines = out.split(/\r?\n/);
  let inCodeBlock = false;
  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    const trimmed = line.trimStart();
    if (/^```/.test(trimmed)) {
      inCodeBlock = !inCodeBlock;
      continue;
    }
    if (inCodeBlock) continue;
    const headerMatch = /^(#{1,6})\s+(.+)$/.exec(trimmed);
    if (headerMatch) {
      const [, hashes, headerText] = headerMatch;
      const prevLine = i > 0 ? lines[i - 1].trim() : "";
      const prevIsHeaderOrFence = /^#{1,6}\s+/.test(prevLine) || /^\*[^*]+\*$/.test(prevLine) || /^```/.test(prevLine);
      if (hashes.length <= 2 && i > 0 && prevLine !== "" && !prevIsHeaderOrFence) {
        lines[i] = `
*${headerText.trim()}*`;
      } else {
        lines[i] = `*${headerText.trim()}*`;
      }
      continue;
    }
    const bulletMatch = /^(\s*)([-*])\s+(.+)$/.exec(line);
    if (bulletMatch) {
      const [, indent, , rest] = bulletMatch;
      lines[i] = `${indent}\u2022 ${rest}`;
    }
  }
  out = lines.join("\n");
  return out;
}
function formatSlackText(text) {
  return markdownToSlack(text);
}
var import_child_process2, fs18, path20, os;
var init_markdown = __esm({
  "src/slack/markdown.ts"() {
    "use strict";
    import_child_process2 = require("child_process");
    fs18 = __toESM(require("fs"));
    path20 = __toESM(require("path"));
    os = __toESM(require("os"));
  }
});

// src/frontends/slack-frontend.ts
var slack_frontend_exports = {};
__export(slack_frontend_exports, {
  SlackFrontend: () => SlackFrontend
});
var SlackFrontend;
var init_slack_frontend = __esm({
  "src/frontends/slack-frontend.ts"() {
    "use strict";
    init_client();
    init_markdown();
    init_lazy_otel();
    SlackFrontend = class {
      name = "slack";
      subs = [];
      cfg;
      // Reactions ack/done per run (inbound Slack events only)
      acked = false;
      ackRef = null;
      ackName = "eyes";
      doneName = "thumbsup";
      errorNotified = false;
      constructor(config) {
        this.cfg = config || {};
      }
      start(ctx) {
        const bus = ctx.eventBus;
        try {
          const hasClient = !!(ctx.slack || ctx.slackClient || this.cfg?.botToken || process.env.SLACK_BOT_TOKEN);
          ctx.logger.info(`[slack-frontend] started; hasClient=${hasClient} defaultChannel=unset`);
        } catch {
        }
        try {
          const payload = this.getInboundSlackPayload(ctx);
          if (payload) {
            const ev = payload.event || {};
            const ch = String(ev.channel || "-");
            const ts = String(ev.ts || ev.event_ts || "-");
            const user = String(ev.user || ev.bot_id || "-");
            const type = String(ev.type || "-");
            const thread = String(ev.thread_ts || "");
            ctx.logger.info(
              `[slack-frontend] inbound event received: type=${type} channel=${ch} ts=${ts}` + (thread ? ` thread_ts=${thread}` : "") + ` user=${user}`
            );
          }
        } catch {
        }
        this.subs.push(
          bus.on("CheckCompleted", async (env) => {
            const ev = env && env.payload || env;
            await this.maybePostDirectReply(ctx, ev.checkId, ev.result).catch(() => {
            });
          })
        );
        this.subs.push(
          bus.on("CheckErrored", async (env) => {
            const ev = env && env.payload || env;
            const message = ev?.error?.message || "Execution error";
            await this.maybePostError(ctx, "Check failed", message, ev?.checkId).catch(() => {
            });
          })
        );
        this.subs.push(
          bus.on("StateTransition", async (env) => {
            const ev = env && env.payload || env;
            if (ev && (ev.to === "Completed" || ev.to === "Error")) {
              await this.finalizeReactions(ctx).catch(() => {
              });
            }
          })
        );
        this.subs.push(
          bus.on("Shutdown", async (env) => {
            const ev = env && env.payload || env;
            const message = ev?.error?.message || "Fatal error";
            await this.maybePostError(ctx, "Run failed", message).catch(() => {
            });
          })
        );
        this.subs.push(
          bus.on("CheckScheduled", async () => {
            await this.ensureAcknowledgement(ctx).catch(() => {
            });
          })
        );
        this.subs.push(
          bus.on("HumanInputRequested", async (env) => {
            try {
              const ev = env && env.payload || env;
              if (!ev || typeof ev.prompt !== "string" || !ev.checkId) return;
              let channel = ev.channel;
              let threadTs = ev.threadTs;
              if (!channel || !threadTs) {
                const payload = this.getInboundSlackPayload(ctx);
                const e = payload?.event;
                const derivedTs = String(e?.thread_ts || e?.ts || e?.event_ts || "");
                const derivedCh = String(e?.channel || "");
                if (derivedCh && derivedTs) {
                  channel = channel || derivedCh;
                  threadTs = threadTs || derivedTs;
                }
              }
              if (!channel || !threadTs) return;
              const { getPromptStateManager: getPromptStateManager2 } = await Promise.resolve().then(() => (init_prompt_state(), prompt_state_exports));
              const mgr = getPromptStateManager2();
              const prev = mgr.getWaiting(channel, threadTs);
              const text = String(ev.prompt);
              mgr.setWaiting(channel, threadTs, {
                checkName: String(ev.checkId),
                prompt: text,
                promptMessageTs: prev?.promptMessageTs,
                promptsPosted: (prev?.promptsPosted || 0) + 1
              });
              try {
                ctx.logger.info(
                  `[slack-frontend] registered human-input waiting state for ${channel} thread=${threadTs}`
                );
              } catch {
              }
            } catch (e) {
              try {
                ctx.logger.warn(
                  `[slack-frontend] HumanInputRequested handling failed: ${e instanceof Error ? e.message : String(e)}`
                );
              } catch {
              }
            }
          })
        );
        this.subs.push(
          bus.on("SnapshotSaved", async (env) => {
            try {
              const ev = env && env.payload || env;
              const channel = String(ev?.channel || "");
              const threadTs = String(ev?.threadTs || "");
              const filePath = String(ev?.filePath || "");
              if (!channel || !threadTs || !filePath) return;
              const { getPromptStateManager: getPromptStateManager2 } = await Promise.resolve().then(() => (init_prompt_state(), prompt_state_exports));
              const mgr = getPromptStateManager2();
              mgr.update(channel, threadTs, { snapshotPath: filePath });
              try {
                ctx.logger.info(
                  `[slack-frontend] snapshot path attached to waiting prompt: ${filePath}`
                );
              } catch {
              }
            } catch {
            }
          })
        );
      }
      stop() {
        for (const s of this.subs) s.unsubscribe();
        this.subs = [];
      }
      getSlack(ctx) {
        const injected = ctx.slack || ctx.slackClient;
        if (injected) return injected;
        try {
          const token = this.cfg?.botToken || process.env.SLACK_BOT_TOKEN;
          if (typeof token === "string" && token.trim()) {
            return new SlackClient(token.trim());
          }
        } catch {
        }
        return void 0;
      }
      getInboundSlackPayload(ctx) {
        try {
          const anyCfg = ctx.config || {};
          const slackCfg = anyCfg.slack || {};
          const endpoint = slackCfg.endpoint || "/bots/slack/support";
          const payload = ctx.webhookContext?.webhookData?.get(endpoint);
          return payload || null;
        } catch {
          return null;
        }
      }
      getInboundSlackEvent(ctx) {
        try {
          const payload = this.getInboundSlackPayload(ctx);
          const ev = payload?.event;
          const channel = String(ev?.channel || "");
          const ts = String(ev?.ts || ev?.event_ts || "");
          if (channel && ts) return { channel, ts };
        } catch {
        }
        return null;
      }
      isTelemetryEnabled(ctx) {
        try {
          const anyCfg = ctx.config || {};
          const slackCfg = anyCfg.slack || {};
          const telemetryCfg = slackCfg.telemetry ?? this.cfg?.telemetry;
          return telemetryCfg === true || telemetryCfg && typeof telemetryCfg === "object" && telemetryCfg.enabled === true;
        } catch {
          return false;
        }
      }
      async maybePostError(ctx, title, message, checkId) {
        if (this.errorNotified) return;
        if (!this.isTelemetryEnabled(ctx)) return;
        const slack = this.getSlack(ctx);
        if (!slack) return;
        const payload = this.getInboundSlackPayload(ctx);
        const ev = payload?.event;
        const channel = String(ev?.channel || "");
        const threadTs = String(ev?.thread_ts || ev?.ts || ev?.event_ts || "");
        if (!channel || !threadTs) return;
        let text = `\u274C ${title}`;
        if (checkId) text += `
Check: ${checkId}`;
        if (message) text += `
${message}`;
        const traceInfo = this.getTraceInfo();
        if (traceInfo?.traceId) {
          text += `

\`trace_id: ${traceInfo.traceId}\``;
        }
        const formattedText = formatSlackText(text);
        await slack.chat.postMessage({ channel, text: formattedText, thread_ts: threadTs });
        try {
          ctx.logger.info(
            `[slack-frontend] posted error notice to ${channel} thread=${threadTs} check=${checkId || "run"}`
          );
        } catch {
        }
        this.errorNotified = true;
      }
      async ensureAcknowledgement(ctx) {
        if (this.acked) return;
        const ref = this.getInboundSlackEvent(ctx);
        if (!ref) return;
        const slack = this.getSlack(ctx);
        if (!slack) return;
        try {
          const payload = this.getInboundSlackPayload(ctx);
          const ev = payload?.event;
          if (ev?.subtype === "bot_message") return;
          try {
            const botId = await slack.getBotUserId?.();
            if (botId && ev?.user && String(ev.user) === String(botId)) return;
          } catch {
          }
        } catch {
        }
        try {
          const anyCfg = ctx.config || {};
          const slackCfg = anyCfg.slack || {};
          if (slackCfg?.reactions?.enabled === false) return;
          this.ackName = slackCfg?.reactions?.ack || this.ackName;
          this.doneName = slackCfg?.reactions?.done || this.doneName;
        } catch {
        }
        await slack.reactions.add({ channel: ref.channel, timestamp: ref.ts, name: this.ackName });
        try {
          ctx.logger.info(
            `[slack-frontend] added acknowledgement reaction :${this.ackName}: channel=${ref.channel} ts=${ref.ts}`
          );
        } catch {
        }
        this.acked = true;
        this.ackRef = ref;
      }
      async finalizeReactions(ctx) {
        if (!this.acked || !this.ackRef) return;
        const slack = this.getSlack(ctx);
        if (!slack) return;
        try {
          try {
            await slack.reactions.remove({
              channel: this.ackRef.channel,
              timestamp: this.ackRef.ts,
              name: this.ackName
            });
          } catch {
          }
          await slack.reactions.add({
            channel: this.ackRef.channel,
            timestamp: this.ackRef.ts,
            name: this.doneName
          });
          try {
            ctx.logger.info(
              `[slack-frontend] replaced acknowledgement with completion reaction :${this.doneName}: channel=${this.ackRef.channel} ts=${this.ackRef.ts}`
            );
          } catch {
          }
        } finally {
          this.acked = false;
          this.ackRef = null;
        }
      }
      /**
       * Post direct replies into the originating Slack thread when appropriate.
       * This is independent of summary messages and is intended for chat-style flows
       * (e.g., AI answers and explicit chat/notify steps).
       */
      async maybePostDirectReply(ctx, checkId, result) {
        try {
          const cfg = ctx.config || {};
          const checkCfg = cfg.checks?.[checkId];
          if (!checkCfg) return;
          const slackRoot = cfg.slack || {};
          const showRawOutput = slackRoot.show_raw_output === true || this.cfg?.showRawOutput === true;
          const telemetryCfg = slackRoot.telemetry ?? this.cfg?.telemetry;
          const providerType = checkCfg.type || "";
          const isAi = providerType === "ai";
          const isLogChat = providerType === "log" && checkCfg.group === "chat";
          if (!isAi && !isLogChat) return;
          if (checkCfg.criticality === "internal") return;
          if (isAi) {
            const schema = checkCfg.schema;
            if (typeof schema === "string") {
              const simpleSchemas = ["code-review", "markdown", "text", "plain"];
              if (!simpleSchemas.includes(schema)) return;
            }
          }
          const slack = this.getSlack(ctx);
          if (!slack) return;
          const payload = this.getInboundSlackPayload(ctx);
          const ev = payload?.event;
          const channel = String(ev?.channel || "");
          const threadTs = String(ev?.thread_ts || ev?.ts || ev?.event_ts || "");
          if (!channel || !threadTs) return;
          const out = result?.output;
          let text;
          if (out && typeof out.text === "string" && out.text.trim().length > 0) {
            text = out.text.trim();
          } else if (isAi && typeof checkCfg.schema === "string") {
            if (typeof result?.content === "string" && result.content.trim().length > 0) {
              text = result.content.trim();
            }
          } else if (isLogChat && typeof result?.logOutput === "string") {
            const raw = result.logOutput;
            if (raw.trim().length > 0) {
              text = raw.trim();
            }
          } else if (isAi && showRawOutput && out !== void 0) {
            try {
              text = JSON.stringify(out, null, 2);
            } catch {
              text = String(out);
            }
          }
          if (!text) return;
          const diagrams = extractMermaidDiagrams(text);
          let processedText = text;
          if (diagrams.length > 0) {
            try {
              ctx.logger.info(
                `[slack-frontend] found ${diagrams.length} mermaid diagram(s) to render for ${checkId}`
              );
            } catch {
            }
            const uploadedCount = [];
            for (let i = 0; i < diagrams.length; i++) {
              const diagram = diagrams[i];
              try {
                ctx.logger.info(`[slack-frontend] rendering mermaid diagram ${i + 1}...`);
                const pngBuffer = await renderMermaidToPng(diagram.code);
                if (pngBuffer) {
                  ctx.logger.info(
                    `[slack-frontend] rendered diagram ${i + 1}, size=${pngBuffer.length} bytes, uploading...`
                  );
                  const filename = `diagram-${i + 1}.png`;
                  const uploadResult = await slack.files.uploadV2({
                    content: pngBuffer,
                    filename,
                    channel,
                    thread_ts: threadTs,
                    title: `Diagram ${i + 1}`
                  });
                  if (uploadResult.ok) {
                    uploadedCount.push(i);
                    ctx.logger.info(`[slack-frontend] uploaded mermaid diagram ${i + 1} to ${channel}`);
                  } else {
                    ctx.logger.warn(`[slack-frontend] upload failed for diagram ${i + 1}`);
                  }
                } else {
                  ctx.logger.warn(
                    `[slack-frontend] mermaid rendering returned null for diagram ${i + 1} (mmdc failed or not installed)`
                  );
                }
              } catch (e) {
                ctx.logger.warn(
                  `[slack-frontend] failed to render/upload mermaid diagram ${i + 1}: ${e instanceof Error ? e.message : String(e)}`
                );
              }
            }
            if (uploadedCount.length > 0) {
              processedText = replaceMermaidBlocks(
                text,
                diagrams,
                (idx) => uploadedCount.includes(idx) ? "_(See diagram above)_" : "_(Diagram rendering failed)_"
              );
            }
          }
          let decoratedText = processedText;
          const telemetryEnabled = telemetryCfg === true || telemetryCfg && typeof telemetryCfg === "object" && telemetryCfg.enabled === true;
          if (telemetryEnabled) {
            const traceInfo = this.getTraceInfo();
            if (traceInfo?.traceId) {
              const suffix = `\`trace_id: ${traceInfo.traceId}\``;
              decoratedText = `${decoratedText}

${suffix}`;
            }
          }
          const formattedText = formatSlackText(decoratedText);
          await slack.chat.postMessage({ channel, text: formattedText, thread_ts: threadTs });
          ctx.logger.info(
            `[slack-frontend] posted AI reply for ${checkId} to ${channel} thread=${threadTs}`
          );
        } catch (outerErr) {
          try {
            ctx.logger.warn(
              `[slack-frontend] maybePostDirectReply failed for ${checkId}: ${outerErr instanceof Error ? outerErr.message : String(outerErr)}`
            );
          } catch {
          }
        }
      }
      getTraceInfo() {
        try {
          const span = trace.getSpan(context.active());
          if (!span) return null;
          const ctx = span.spanContext();
          if (!ctx || !ctx.traceId) return null;
          return { traceId: ctx.traceId, spanId: ctx.spanId };
        } catch {
          return null;
        }
      }
    };
  }
});

// src/frontends/host.ts
var host_exports = {};
__export(host_exports, {
  FrontendsHost: () => FrontendsHost
});
var FrontendsHost;
var init_host = __esm({
  "src/frontends/host.ts"() {
    "use strict";
    FrontendsHost = class {
      bus;
      log;
      frontends = [];
      constructor(bus, log2) {
        this.bus = bus;
        this.log = log2;
      }
      async load(specs) {
        this.frontends = [];
        for (const spec of specs) {
          if (spec.name === "ndjson-sink") {
            const { NdjsonSink: NdjsonSink2 } = await Promise.resolve().then(() => (init_ndjson_sink(), ndjson_sink_exports));
            this.frontends.push(new NdjsonSink2(spec.config));
          } else if (spec.name === "github") {
            const { GitHubFrontend: GitHubFrontend2 } = await Promise.resolve().then(() => (init_github_frontend(), github_frontend_exports));
            this.frontends.push(new GitHubFrontend2());
          } else if (spec.name === "slack") {
            const { SlackFrontend: SlackFrontend2 } = await Promise.resolve().then(() => (init_slack_frontend(), slack_frontend_exports));
            this.frontends.push(new SlackFrontend2(spec.config));
          } else {
            this.log.warn(`[FrontendsHost] Unknown frontend '${spec.name}', skipping`);
          }
        }
      }
      async startAll(ctxFactory) {
        for (const f of this.frontends) {
          try {
            await f.start(ctxFactory());
            this.log.info(`[FrontendsHost] Started frontend '${f.name}'`);
          } catch (err) {
            this.log.error(`[FrontendsHost] Failed to start '${f.name}':`, err);
          }
        }
      }
      async stopAll() {
        for (const f of this.frontends) {
          try {
            await f.stop();
          } catch (err) {
            this.log.error(`[FrontendsHost] Failed to stop '${f.name}':`, err);
          }
        }
      }
    };
  }
});

// src/state-machine/execution/summary.ts
var summary_exports = {};
__export(summary_exports, {
  convertToReviewSummary: () => convertToReviewSummary
});
function convertToReviewSummary(groupedResults, statistics) {
  const allIssues = [];
  for (const checkResults of Object.values(groupedResults)) {
    for (const checkResult of checkResults) {
      if (checkResult.issues && checkResult.issues.length > 0) {
        allIssues.push(...checkResult.issues);
      }
    }
  }
  if (statistics) {
    for (const checkStats of statistics.checks) {
      if (checkStats.errorMessage) {
        allIssues.push({
          file: "system",
          line: 0,
          endLine: void 0,
          ruleId: "system/error",
          message: checkStats.errorMessage,
          severity: "error",
          category: "logic",
          suggestion: void 0,
          replacement: void 0
        });
      }
    }
  }
  return {
    issues: allIssues
  };
}
var init_summary = __esm({
  "src/state-machine/execution/summary.ts"() {
    "use strict";
  }
});

// src/sdk.ts
var sdk_exports = {};
__export(sdk_exports, {
  loadConfig: () => loadConfig,
  resolveChecks: () => resolveChecks,
  runChecks: () => runChecks
});
module.exports = __toCommonJS(sdk_exports);

// src/state-machine-execution-engine.ts
init_runner();
init_logger();
var path21 = __toESM(require("path"));
var fs19 = __toESM(require("fs"));
var StateMachineExecutionEngine = class _StateMachineExecutionEngine {
  workingDirectory;
  executionContext;
  debugServer;
  _lastContext;
  _lastRunner;
  constructor(workingDirectory, octokit, debugServer) {
    this.workingDirectory = workingDirectory || process.cwd();
    this.debugServer = debugServer;
  }
  /**
   * Execute checks using the state machine engine
   *
   * Converts CheckExecutionOptions -> executeGroupedChecks() -> AnalysisResult
   */
  async executeChecks(options) {
    const startTime = Date.now();
    const timestamp = (/* @__PURE__ */ new Date()).toISOString();
    try {
      if (options.config?.memory) {
        const { MemoryStore: MemoryStore2 } = await Promise.resolve().then(() => (init_memory_store(), memory_store_exports));
        const memoryStore = MemoryStore2.getInstance(options.config.memory);
        await memoryStore.initialize();
        logger.debug("Memory store initialized");
      }
      const { GitRepositoryAnalyzer: GitRepositoryAnalyzer2 } = await Promise.resolve().then(() => (init_git_repository_analyzer(), git_repository_analyzer_exports));
      const gitAnalyzer = new GitRepositoryAnalyzer2(options.workingDirectory);
      logger.info("Analyzing local git repository...");
      const repositoryInfo = await gitAnalyzer.analyzeRepository();
      if (!repositoryInfo.isGitRepository) {
        return this.createErrorResult(
          repositoryInfo,
          "Not a git repository or no changes found",
          startTime,
          timestamp,
          options.checks
        );
      }
      const prInfo = gitAnalyzer.toPRInfo(repositoryInfo);
      try {
        const evt = options.webhookContext?.eventType;
        if (evt) prInfo.eventType = evt;
      } catch {
      }
      const filteredChecks = this.filterChecksByTags(
        options.checks,
        options.config,
        options.tagFilter || options.config?.tag_filter
      );
      if (filteredChecks.length === 0) {
        logger.warn("No checks match the tag filter criteria");
        return this.createErrorResult(
          repositoryInfo,
          "No checks match the tag filter criteria",
          startTime,
          timestamp,
          options.checks
        );
      }
      try {
        const map = options?.webhookContext?.webhookData;
        if (map) {
          const { CheckProviderRegistry: CheckProviderRegistry2 } = await Promise.resolve().then(() => (init_check_provider_registry(), check_provider_registry_exports));
          const reg = CheckProviderRegistry2.getInstance();
          const p = reg.getProvider("http_input");
          if (p && typeof p.setWebhookContext === "function") p.setWebhookContext(map);
          const prev = this.executionContext || {};
          this.setExecutionContext({ ...prev, webhookContext: { webhookData: map } });
        }
      } catch {
      }
      logger.info(`Executing checks: ${filteredChecks.join(", ")}`);
      const executionResult = await this.executeGroupedChecks(
        prInfo,
        filteredChecks,
        options.timeout,
        options.config,
        options.outputFormat,
        options.debug,
        options.maxParallelism,
        options.failFast,
        options.tagFilter
      );
      const executionTime = Date.now() - startTime;
      const reviewSummary = this.convertGroupedResultsToReviewSummary(
        executionResult.results,
        executionResult.statistics
      );
      let debugInfo;
      if (options.debug && reviewSummary.debug) {
        debugInfo = {
          provider: reviewSummary.debug.provider,
          model: reviewSummary.debug.model,
          processingTime: reviewSummary.debug.processingTime,
          parallelExecution: options.checks.length > 1,
          checksExecuted: options.checks,
          totalApiCalls: reviewSummary.debug.totalApiCalls || options.checks.length,
          apiCallDetails: reviewSummary.debug.apiCallDetails
        };
      }
      try {
        const histSnap = this.getOutputHistorySnapshot();
        reviewSummary.history = histSnap;
      } catch {
      }
      return {
        repositoryInfo,
        reviewSummary,
        executionTime,
        timestamp,
        checksExecuted: filteredChecks,
        executionStatistics: executionResult.statistics,
        debug: debugInfo
      };
    } catch (error) {
      const message = error instanceof Error ? error.message : "Unknown error occurred";
      logger.error("Error executing checks: " + message);
      const strictEnv = process.env.VISOR_STRICT_ERRORS === "true";
      if (strictEnv) {
        throw error;
      }
      const fallbackRepositoryInfo = {
        title: "Error during analysis",
        body: `Error: ${message || "Unknown error"}`,
        author: "system",
        base: "main",
        head: "HEAD",
        files: [],
        totalAdditions: 0,
        totalDeletions: 0,
        isGitRepository: false,
        workingDirectory: options.workingDirectory || process.cwd()
      };
      return this.createErrorResult(
        fallbackRepositoryInfo,
        message || "Unknown error occurred",
        startTime,
        timestamp,
        options.checks
      );
    }
  }
  /**
   * Get execution context (used by state machine to propagate hooks)
   */
  getExecutionContext() {
    return this.executionContext;
  }
  /**
   * Set execution context for external callers
   */
  setExecutionContext(context2) {
    this.executionContext = context2;
  }
  /**
   * Reset per-run state (no-op for state machine engine)
   *
   * The state machine engine is stateless per-run by design.
   * Each execution creates a fresh journal and context.
   * This method exists only for backward compatibility with test framework.
   *
   * @deprecated This is a no-op. State machine engine doesn't maintain per-run state.
   */
  resetPerRunState() {
  }
  /**
   * Execute grouped checks using the state machine engine
   *
   * M4: Production-ready with full telemetry and debug server support
   */
  async executeGroupedChecks(prInfo, checks, timeout, config, outputFormat, debug, maxParallelism, failFast, tagFilter, _pauseGate) {
    if (debug) {
      logger.info("[StateMachine] Using state machine engine");
    }
    if (!config) {
      const { ConfigManager: ConfigManager2 } = await Promise.resolve().then(() => (init_config(), config_exports));
      const configManager = new ConfigManager2();
      config = await configManager.getDefaultConfig();
      logger.debug("[StateMachine] Using default configuration (no config provided)");
    }
    const configWithTagFilter = tagFilter ? {
      ...config,
      tag_filter: tagFilter
    } : config;
    const context2 = this.buildEngineContext(
      configWithTagFilter,
      prInfo,
      debug,
      maxParallelism,
      failFast,
      checks
      // Pass the explicit checks list
    );
    const { initializeWorkspace: initializeWorkspace2 } = (init_build_engine_context(), __toCommonJS(build_engine_context_exports));
    await initializeWorkspace2(context2);
    context2.executionContext = this.getExecutionContext();
    this._lastContext = context2;
    let frontendsHost;
    if (Array.isArray(configWithTagFilter.frontends) && configWithTagFilter.frontends.length > 0) {
      try {
        const { EventBus: EventBus2 } = await Promise.resolve().then(() => (init_event_bus(), event_bus_exports));
        const { FrontendsHost: FrontendsHost2 } = await Promise.resolve().then(() => (init_host(), host_exports));
        const bus = new EventBus2();
        context2.eventBus = bus;
        frontendsHost = new FrontendsHost2(bus, logger);
        if (process.env.VISOR_DEBUG === "true") {
          try {
            const fns = (configWithTagFilter.frontends || []).map((f) => ({
              name: f?.name,
              hasConfig: !!f?.config,
              cfg: f?.config || void 0
            }));
            logger.info(`[Frontends] Loading specs: ${JSON.stringify(fns)}`);
          } catch {
          }
        }
        await frontendsHost.load(configWithTagFilter.frontends);
        let owner;
        let name;
        let prNum;
        let headSha;
        try {
          const anyInfo = prInfo;
          owner = anyInfo?.eventContext?.repository?.owner?.login || process.env.GITHUB_REPOSITORY?.split("/")?.[0];
          name = anyInfo?.eventContext?.repository?.name || process.env.GITHUB_REPOSITORY?.split("/")?.[1];
          prNum = typeof anyInfo?.number === "number" ? anyInfo.number : void 0;
          headSha = anyInfo?.eventContext?.pull_request?.head?.sha || process.env.GITHUB_SHA;
        } catch {
        }
        const repoObj = owner && name ? { owner, name } : void 0;
        const octokit = this.executionContext?.octokit;
        if (!headSha && repoObj && prNum && octokit && typeof octokit.rest?.pulls?.get === "function") {
          try {
            const { data } = await octokit.rest.pulls.get({
              owner: repoObj.owner,
              repo: repoObj.name,
              pull_number: prNum
            });
            headSha = data && data.head && data.head.sha || headSha;
          } catch {
          }
        }
        try {
          const prev = this.getExecutionContext() || {};
          this.setExecutionContext({ ...prev, eventBus: bus });
          try {
            context2.executionContext = this.getExecutionContext();
          } catch {
          }
        } catch {
        }
        await frontendsHost.startAll(() => ({
          eventBus: bus,
          logger,
          // Provide the active (possibly tag-filtered) config so frontends can read groups, etc.
          config: configWithTagFilter,
          run: {
            runId: context2.sessionId,
            repo: repoObj,
            pr: prNum,
            headSha,
            event: context2.event || prInfo?.eventType,
            actor: prInfo?.eventContext?.sender?.login || (typeof process.env.GITHUB_ACTOR === "string" ? process.env.GITHUB_ACTOR : void 0)
          },
          octokit,
          webhookContext: this.executionContext?.webhookContext,
          // Surface any injected test doubles for Slack as well
          slack: this.executionContext?.slack || this.executionContext?.slackClient
        }));
        try {
          bus.on("HumanInputRequested", async (envelope) => {
            try {
              const ev = envelope && envelope.payload || envelope;
              let channel = ev?.channel;
              let threadTs = ev?.threadTs;
              if (!channel || !threadTs) {
                try {
                  const anyCfg = configWithTagFilter || {};
                  const slackCfg = anyCfg.slack || {};
                  const endpoint = slackCfg.endpoint || "/bots/slack/support";
                  const map = this.executionContext?.webhookContext?.webhookData;
                  const payload = map?.get(endpoint);
                  const e = payload?.event;
                  const derivedTs = String(e?.thread_ts || e?.ts || e?.event_ts || "");
                  const derivedCh = String(e?.channel || "");
                  if (derivedCh && derivedTs) {
                    channel = channel || derivedCh;
                    threadTs = threadTs || derivedTs;
                  }
                } catch {
                }
              }
              const checkId = String(ev?.checkId || "unknown");
              const threadKey = ev?.threadKey || (channel && threadTs ? `${channel}:${threadTs}` : "session");
              const baseDir = process.env.VISOR_SNAPSHOT_DIR || path21.resolve(process.cwd(), ".visor", "snapshots");
              fs19.mkdirSync(baseDir, { recursive: true });
              const filePath = path21.join(baseDir, `${threadKey}-${checkId}.json`);
              await this.saveSnapshotToFile(filePath);
              logger.info(`[Snapshot] Saved run snapshot: ${filePath}`);
              try {
                await bus.emit({
                  type: "SnapshotSaved",
                  checkId: ev?.checkId || "unknown",
                  channel,
                  threadTs,
                  threadKey,
                  filePath
                });
              } catch {
              }
            } catch (e) {
              logger.warn(
                `[Snapshot] Failed to save snapshot on HumanInputRequested: ${e instanceof Error ? e.message : String(e)}`
              );
            }
          });
        } catch {
        }
      } catch (err) {
        logger.warn(
          `[Frontends] Failed to initialize frontends: ${err instanceof Error ? err.message : String(err)}`
        );
      }
    }
    const runner = new StateMachineRunner(context2, this.debugServer);
    this._lastRunner = runner;
    const result = await runner.run();
    if (frontendsHost && typeof frontendsHost.stopAll === "function") {
      try {
        await frontendsHost.stopAll();
      } catch {
      }
    }
    if (debug) {
      logger.info("[StateMachine] Execution complete");
    }
    try {
      const { SessionRegistry: SessionRegistry2 } = await Promise.resolve().then(() => (init_session_registry(), session_registry_exports));
      const sessionRegistry = SessionRegistry2.getInstance();
      sessionRegistry.clearAllSessions();
    } catch (error) {
      logger.debug(`[StateMachine] Failed to cleanup sessions: ${error}`);
    }
    if (context2.workspace) {
      try {
        await context2.workspace.cleanup();
      } catch (error) {
        logger.debug(`[StateMachine] Failed to cleanup workspace: ${error}`);
      }
    }
    return result;
  }
  /**
   * Build the engine context for state machine execution
   */
  buildEngineContext(config, prInfo, debug, maxParallelism, failFast, requestedChecks) {
    const { buildEngineContextForRun: buildEngineContextForRun2 } = (init_build_engine_context(), __toCommonJS(build_engine_context_exports));
    return buildEngineContextForRun2(
      this.workingDirectory,
      config,
      prInfo,
      debug,
      maxParallelism,
      failFast,
      requestedChecks
    );
  }
  /**
   * Get output history snapshot for test framework compatibility
   * Extracts output history from the journal
   */
  getOutputHistorySnapshot() {
    const journal = this._lastContext?.journal;
    if (!journal) {
      logger.debug("[StateMachine][DEBUG] getOutputHistorySnapshot: No journal found");
      return {};
    }
    const sessionId = this._lastContext?.sessionId;
    if (!sessionId) {
      logger.debug("[StateMachine][DEBUG] getOutputHistorySnapshot: No sessionId found");
      return {};
    }
    const snapshot = journal.beginSnapshot();
    const allEntries = journal.readVisible(sessionId, snapshot, void 0);
    logger.debug(
      `[StateMachine][DEBUG] getOutputHistorySnapshot: Found ${allEntries.length} journal entries`
    );
    const outputHistory = {};
    for (const entry of allEntries) {
      const checkId = entry.checkId;
      if (!outputHistory[checkId]) {
        outputHistory[checkId] = [];
      }
      try {
        if (entry && typeof entry.result === "object" && entry.result.__skipped) {
          continue;
        }
      } catch {
      }
      const payload = entry.result.output !== void 0 ? entry.result.output : entry.result;
      try {
        if (payload && typeof payload === "object" && payload.forEachItems && Array.isArray(payload.forEachItems)) {
          continue;
        }
      } catch {
      }
      if (payload !== void 0) outputHistory[checkId].push(payload);
    }
    logger.debug(
      `[StateMachine][DEBUG] getOutputHistorySnapshot result: ${JSON.stringify(Object.keys(outputHistory))}`
    );
    for (const [checkId, outputs] of Object.entries(outputHistory)) {
      logger.debug(`[StateMachine][DEBUG]   ${checkId}: ${outputs.length} outputs`);
    }
    return outputHistory;
  }
  /**
   * Save a JSON snapshot of the last run's state and journal to a file (experimental).
   * Does not include secrets. Intended for debugging and future resume support.
   */
  async saveSnapshotToFile(filePath) {
    const fs20 = await import("fs/promises");
    const ctx = this._lastContext;
    const runner = this._lastRunner;
    if (!ctx || !runner) {
      throw new Error("No prior execution context to snapshot");
    }
    const journal = ctx.journal;
    const snapshotId = journal.beginSnapshot();
    const entries = journal.readVisible(ctx.sessionId, snapshotId, void 0);
    const state = runner.getState();
    const serializableState = serializeRunState(state);
    const payload = {
      version: 1,
      sessionId: ctx.sessionId,
      event: ctx.event,
      wave: state.wave,
      state: serializableState,
      journal: entries,
      requestedChecks: ctx.requestedChecks || []
    };
    await fs20.writeFile(filePath, JSON.stringify(payload, null, 2), "utf8");
  }
  /**
   * Load a snapshot JSON from file and return it. Resume support can build on this.
   */
  async loadSnapshotFromFile(filePath) {
    const fs20 = await import("fs/promises");
    const raw = await fs20.readFile(filePath, "utf8");
    return JSON.parse(raw);
  }
  /**
   * Filter checks by tag filter
   */
  filterChecksByTags(checks, config, tagFilter) {
    return checks.filter((checkName) => {
      const checkConfig = config?.checks?.[checkName];
      if (!checkConfig) {
        return true;
      }
      const checkTags = checkConfig.tags || [];
      if (!tagFilter || !tagFilter.include && !tagFilter.exclude) {
        return checkTags.length === 0;
      }
      if (checkTags.length === 0) {
        return true;
      }
      if (tagFilter.exclude && tagFilter.exclude.length > 0) {
        const hasExcludedTag = tagFilter.exclude.some((tag) => checkTags.includes(tag));
        if (hasExcludedTag) return false;
      }
      if (tagFilter.include && tagFilter.include.length > 0) {
        const hasIncludedTag = tagFilter.include.some((tag) => checkTags.includes(tag));
        if (!hasIncludedTag) return false;
      }
      return true;
    });
  }
  /**
   * Create an error result in AnalysisResult format
   */
  createErrorResult(repositoryInfo, errorMessage, startTime, timestamp, checksExecuted) {
    const executionTime = Date.now() - startTime;
    return {
      repositoryInfo,
      reviewSummary: {
        issues: [
          {
            file: "system",
            line: 0,
            endLine: void 0,
            ruleId: "system/error",
            message: errorMessage,
            severity: "error",
            category: "logic",
            suggestion: void 0,
            replacement: void 0
          }
        ]
      },
      executionTime,
      timestamp,
      checksExecuted
    };
  }
  /**
   * Convert GroupedCheckResults to ReviewSummary
   * Aggregates all check results into a single ReviewSummary
   */
  convertGroupedResultsToReviewSummary(groupedResults, statistics) {
    const { convertToReviewSummary: convertToReviewSummary2 } = (init_summary(), __toCommonJS(summary_exports));
    return convertToReviewSummary2(groupedResults, statistics);
  }
  /**
   * Evaluate failure conditions for a check result
   *
   * This method provides backward compatibility with the legacy engine by
   * delegating to the FailureConditionEvaluator.
   *
   * @param checkName - The name of the check being evaluated
   * @param reviewSummary - The review summary containing check results
   * @param config - The Visor configuration containing failure conditions
   * @param previousOutputs - Optional previous check outputs for cross-check conditions
   * @param authorAssociation - Optional GitHub author association for permission checks
   * @returns Array of failure condition evaluation results
   */
  async evaluateFailureConditions(checkName, reviewSummary, config, previousOutputs, authorAssociation) {
    const { FailureConditionEvaluator: FailureConditionEvaluator2 } = await Promise.resolve().then(() => (init_failure_condition_evaluator(), failure_condition_evaluator_exports));
    const evaluator = new FailureConditionEvaluator2();
    const { addEvent: addEvent2 } = await Promise.resolve().then(() => (init_trace_helpers(), trace_helpers_exports));
    const { addFailIfTriggered: addFailIfTriggered2 } = await Promise.resolve().then(() => (init_metrics(), metrics_exports));
    const checkConfig = config.checks?.[checkName];
    if (!checkConfig) {
      return [];
    }
    const rawSchema = checkConfig.schema || "code-review";
    const checkSchema = typeof rawSchema === "string" ? rawSchema : "code-review";
    const checkGroup = checkConfig.group || "default";
    const results = [];
    if (config.fail_if) {
      const failed = await evaluator.evaluateSimpleCondition(
        checkName,
        checkSchema,
        checkGroup,
        reviewSummary,
        config.fail_if,
        previousOutputs || {}
      );
      try {
        addEvent2("fail_if.evaluated", {
          "visor.check.id": checkName,
          scope: "global",
          expression: String(config.fail_if),
          result: failed ? "triggered" : "not_triggered"
        });
        if (failed) {
          addEvent2("fail_if.triggered", {
            "visor.check.id": checkName,
            scope: "global",
            expression: String(config.fail_if)
          });
          addFailIfTriggered2(checkName, "global");
        }
      } catch {
      }
      results.push({
        conditionName: "global_fail_if",
        failed,
        expression: config.fail_if,
        message: failed ? `Global failure condition met: ${config.fail_if}` : void 0,
        severity: "error",
        haltExecution: false
      });
    }
    if (checkConfig.fail_if) {
      const failed = await evaluator.evaluateSimpleCondition(
        checkName,
        checkSchema,
        checkGroup,
        reviewSummary,
        checkConfig.fail_if,
        previousOutputs || {}
      );
      try {
        addEvent2("fail_if.evaluated", {
          "visor.check.id": checkName,
          scope: "check",
          expression: String(checkConfig.fail_if),
          result: failed ? "triggered" : "not_triggered"
        });
        if (failed) {
          addEvent2("fail_if.triggered", {
            "visor.check.id": checkName,
            scope: "check",
            expression: String(checkConfig.fail_if)
          });
          addFailIfTriggered2(checkName, "check");
        }
      } catch {
      }
      results.push({
        conditionName: `${checkName}_fail_if`,
        failed,
        expression: checkConfig.fail_if,
        message: failed ? `Check failure condition met: ${checkConfig.fail_if}` : void 0,
        severity: "error",
        haltExecution: false
      });
    }
    const globalConditions = config.failure_conditions;
    const checkConditions = checkConfig.failure_conditions;
    if (globalConditions || checkConditions) {
      const legacyResults = await evaluator.evaluateConditions(
        checkName,
        checkSchema,
        checkGroup,
        reviewSummary,
        globalConditions,
        checkConditions,
        previousOutputs,
        authorAssociation
      );
      results.push(...legacyResults);
    }
    return results;
  }
  /**
   * Get repository status
   * @returns Repository status information
   */
  async getRepositoryStatus() {
    try {
      const { GitRepositoryAnalyzer: GitRepositoryAnalyzer2 } = await Promise.resolve().then(() => (init_git_repository_analyzer(), git_repository_analyzer_exports));
      const analyzer = new GitRepositoryAnalyzer2(this.workingDirectory);
      const info = await analyzer.analyzeRepository();
      return {
        isGitRepository: info.isGitRepository,
        branch: info.head,
        // Use head as branch name
        hasChanges: info.isGitRepository && (info.files?.length > 0 || false),
        filesChanged: info.isGitRepository ? info.files?.length || 0 : 0
      };
    } catch {
      return {
        isGitRepository: false,
        hasChanges: false
      };
    }
  }
  /**
   * Check if current directory is a git repository
   * @returns True if git repository, false otherwise
   */
  async isGitRepository() {
    const status = await this.getRepositoryStatus();
    return status.isGitRepository;
  }
  /**
   * Get list of available check types
   * @returns Array of check type names
   */
  static getAvailableCheckTypes() {
    const { CheckProviderRegistry: CheckProviderRegistry2 } = (init_check_provider_registry(), __toCommonJS(check_provider_registry_exports));
    const registry = CheckProviderRegistry2.getInstance();
    return registry.getAvailableProviders();
  }
  /**
   * Validate check types and return valid/invalid lists
   * @param checks - Array of check type names to validate
   * @returns Object with valid and invalid check types
   */
  static validateCheckTypes(checks) {
    const availableTypes = _StateMachineExecutionEngine.getAvailableCheckTypes();
    const valid = [];
    const invalid = [];
    for (const check of checks) {
      if (availableTypes.includes(check)) {
        valid.push(check);
      } else {
        invalid.push(check);
      }
    }
    return { valid, invalid };
  }
  /**
   * Format the status column for execution statistics
   * Used by execution-statistics-formatting tests
   */
  formatStatusColumn(stats) {
    if (stats.skipped) {
      if (stats.skipReason === "if_condition") {
        return "\u23ED if";
      } else if (stats.skipReason === "fail_fast") {
        return "\u23ED ff";
      } else if (stats.skipReason === "dependency_failed") {
        return "\u23ED dep";
      }
      return "\u23ED";
    }
    const totalRuns = stats.totalRuns;
    const successfulRuns = stats.successfulRuns;
    const failedRuns = stats.failedRuns;
    if (failedRuns > 0 && successfulRuns > 0) {
      return `\u2714/\u2716 ${successfulRuns}/${totalRuns}`;
    } else if (failedRuns > 0) {
      return totalRuns === 1 ? "\u2716" : `\u2716 \xD7${totalRuns}`;
    } else {
      return totalRuns === 1 ? "\u2714" : `\u2714 \xD7${totalRuns}`;
    }
  }
  /**
   * Format the details column for execution statistics
   * Used by execution-statistics-formatting tests
   */
  formatDetailsColumn(stats) {
    const parts = [];
    if (stats.outputsProduced !== void 0 && stats.outputsProduced > 0) {
      parts.push(`\u2192${stats.outputsProduced}`);
    }
    if (stats.issuesBySeverity.critical > 0) {
      parts.push(`${stats.issuesBySeverity.critical}\u{1F534}`);
    }
    if (stats.issuesBySeverity.error > 0 && stats.issuesBySeverity.critical === 0) {
      parts.push(`${stats.issuesBySeverity.error}\u274C`);
    }
    if (stats.issuesBySeverity.warning > 0) {
      parts.push(`${stats.issuesBySeverity.warning}\u26A0\uFE0F`);
    }
    if (stats.issuesBySeverity.info > 0 && stats.issuesBySeverity.critical === 0 && stats.issuesBySeverity.error === 0 && stats.issuesBySeverity.warning === 0) {
      parts.push(`${stats.issuesBySeverity.info}\u{1F4A1}`);
    }
    if (stats.errorMessage) {
      parts.push(this.truncate(stats.errorMessage, 40));
    }
    if (stats.skipCondition) {
      parts.push(this.truncate(stats.skipCondition, 40));
    }
    return parts.join(" ");
  }
  /**
   * Truncate a string to a maximum length
   * Used by formatDetailsColumn
   */
  truncate(str, maxLength) {
    if (str.length <= maxLength) {
      return str;
    }
    return str.substring(0, maxLength - 3) + "...";
  }
};
function serializeRunState(state) {
  return {
    ...state,
    levelQueue: state.levelQueue,
    eventQueue: state.eventQueue,
    activeDispatches: Array.from(state.activeDispatches.entries()),
    completedChecks: Array.from(state.completedChecks.values()),
    stats: Array.from(state.stats.entries()),
    historyLog: state.historyLog,
    forwardRunGuards: Array.from(state.forwardRunGuards.values()),
    currentLevelChecks: Array.from(state.currentLevelChecks.values()),
    currentWaveCompletions: Array.from(
      state.currentWaveCompletions || []
    ),
    // failedChecks is an internal Set added by stats/dispatch layers; keep it if present
    failedChecks: Array.from(state.failedChecks || []),
    pendingRunScopes: Array.from((state.pendingRunScopes || /* @__PURE__ */ new Map()).entries()).map(([k, v]) => [
      k,
      v
    ])
  };
}

// src/sdk.ts
init_config();
async function loadConfig(configOrPath, options) {
  const cm = new ConfigManager();
  if (typeof configOrPath === "object" && configOrPath !== null) {
    cm.validateConfig(configOrPath, options?.strict ?? false);
    const defaultConfig = {
      version: "1.0",
      checks: {},
      max_parallelism: 3,
      fail_fast: false
    };
    return {
      ...defaultConfig,
      ...configOrPath,
      checks: configOrPath.checks || {}
    };
  }
  if (typeof configOrPath === "string") {
    return cm.loadConfig(configOrPath);
  }
  return cm.findAndLoadConfig();
}
function resolveChecks(checkIds, config) {
  if (!config?.checks) return Array.from(new Set(checkIds));
  const resolved = /* @__PURE__ */ new Set();
  const visiting = /* @__PURE__ */ new Set();
  const result = [];
  const dfs = (id, stack = []) => {
    if (resolved.has(id)) return;
    if (visiting.has(id)) {
      const cycle = [...stack, id].join(" -> ");
      throw new Error(`Circular dependency detected involving check: ${id} (path: ${cycle})`);
    }
    visiting.add(id);
    const deps = config.checks[id]?.depends_on || [];
    for (const d of deps) dfs(d, [...stack, id]);
    if (!result.includes(id)) result.push(id);
    visiting.delete(id);
    resolved.add(id);
  };
  for (const id of checkIds) dfs(id);
  return result;
}
async function runChecks(opts = {}) {
  const cm = new ConfigManager();
  let config;
  if (opts.config) {
    cm.validateConfig(opts.config, opts.strictValidation ?? false);
    config = opts.config;
  } else if (opts.configPath) {
    config = await cm.loadConfig(opts.configPath);
  } else {
    config = await cm.findAndLoadConfig();
  }
  const checks = opts.checks && opts.checks.length > 0 ? resolveChecks(opts.checks, config) : Object.keys(config.checks || {});
  const engine = new StateMachineExecutionEngine(opts.cwd);
  if (opts.executionContext) {
    engine.setExecutionContext(opts.executionContext);
  }
  const result = await engine.executeChecks({
    checks,
    workingDirectory: opts.cwd,
    timeout: opts.timeoutMs,
    maxParallelism: opts.maxParallelism,
    failFast: opts.failFast,
    outputFormat: opts.output?.format,
    config,
    debug: opts.debug,
    tagFilter: opts.tagFilter
  });
  return result;
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  loadConfig,
  resolveChecks,
  runChecks
});
//# sourceMappingURL=sdk.js.map