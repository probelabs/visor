# Simple Jira MCP workflow example
# Demonstrates: JQL query â†’ pick issue â†’ AI analysis â†’ add label

version: "1.0"

ai_provider: anthropic
ai_model: claude-3-sonnet

# Jira MCP server configuration
ai_mcp_servers:
  jira:
    command: "npx"
    args: ["-y", "@aashari/mcp-server-atlassian-jira"]
    env:
      JIRA_BASE_URL: "${JIRA_BASE_URL}"
      JIRA_EMAIL: "${JIRA_EMAIL}"
      JIRA_API_TOKEN: "${JIRA_API_TOKEN}"

steps:
  # Main workflow: JQL â†’ Pick â†’ Analyze â†’ Label
  jira_issue_analysis_workflow:
    type: ai
    prompt: |
      Execute this Jira workflow using the available MCP tools:

      ## Step 1: Query Issues with JQL
      Search for issues using JQL: "project = DEV AND status = 'To Do' AND priority IN (High, Highest) ORDER BY created DESC"

      Limit results to maximum 10 issues for analysis.

      ## Step 2: Pick One Issue
      From the search results:
      1. Review each issue's summary and description
      2. Select the MOST RECENTLY CREATED issue that appears to be:
         - Well-defined (has clear description)
         - Not blocked by dependencies
         - Suitable for immediate analysis

      ## Step 3: Deep Analysis
      For the selected issue, perform comprehensive analysis:

      ### Technical Analysis:
      - **Complexity Score** (1-10): Based on technical requirements
      - **Effort Estimation**: Story points (1, 2, 3, 5, 8, 13)
      - **Risk Assessment**: Low/Medium/High
      - **Component Impact**: Which system components affected

      ### Business Analysis:
      - **Business Value**: Critical/High/Medium/Low
      - **User Impact**: How many users affected
      - **Urgency Level**: Immediate/Soon/Later
      - **Dependencies**: What blocks or depends on this

      ### Implementation Analysis:
      - **Approach Recommendation**: Suggested implementation strategy
      - **Testing Requirements**: What tests are needed
      - **Rollback Plan**: How to revert if needed
      - **Documentation Needs**: What docs need updating

      ## Step 4: Add Analysis Labels
      Based on your analysis, add appropriate labels to the issue:

      **Always add:**
      - "ai-analyzed"
      - Current date label: "analyzed-YYYY-MM-DD"

      **Complexity labels (pick one):**
      - "simple-fix" (score 1-3)
      - "moderate-complexity" (score 4-6)
      - "complex-implementation" (score 7-10)

      **Priority labels (pick one):**
      - "urgent-fix" (critical business impact)
      - "high-priority" (important but not urgent)
      - "normal-priority" (standard development)

      **Risk labels (pick one):**
      - "low-risk" (safe to implement)
      - "medium-risk" (needs careful testing)
      - "high-risk" (potential system impact)

      **Component labels (pick relevant ones):**
      - "frontend", "backend", "database", "api", "integration"

      ## Step 5: Add Analysis Comment
      Add a comment to the issue with:
      ```
      ðŸ¤– AI Analysis Summary

      **Complexity:** [score]/10 - [reasoning]
      **Effort:** [story points] points
      **Risk:** [level] - [explanation]
      **Priority:** [level] - [justification]

      **Recommended Approach:**
      [implementation strategy]

      **Key Considerations:**
      - [consideration 1]
      - [consideration 2]
      - [consideration 3]

      **Testing Focus:**
      [testing recommendations]

      ---
      *Analysis performed by Visor AI on [timestamp]*
      ```

      ## Step 6: Report Results
      Provide a summary of:
      - JQL query used and results count
      - Selected issue key and title
      - Analysis summary
      - Labels added
      - Comment added
      - Any errors or warnings

      Use the Jira MCP tools for all interactions. Be specific about which tools you're calling and with what parameters.

    on: ["manual"]
    tags: ["jira", "workflow", "analysis"]

  # Alternative: Analyze specific issue by key (simpler version)
  analyze_jira_issue_by_key:
    type: ai
    prompt: |
      Analyze a specific Jira issue using MCP tools:

      ## Instructions:
      If an issue key is provided in the context (e.g., "DEV-123"), use it.
      Otherwise, use this default JQL to find an issue: "project = DEV AND status = 'To Do' ORDER BY priority DESC, created DESC"

      ## Analysis Process:
      1. **Get Issue Details**: Retrieve full issue information
      2. **Evaluate Complexity**: Rate 1-10 based on description/requirements
      3. **Assess Risk**: Consider implementation challenges
      4. **Estimate Effort**: Suggest story points
      5. **Add Labels**:
         - "ai-quick-analysis"
         - Complexity: "simple" or "complex"
         - Risk: "safe" or "risky"
      6. **Add Comment**: Brief analysis summary

      ## Expected Output:
      - Issue analyzed: [KEY] - [TITLE]
      - Complexity: [rating]/10
      - Risk: [level]
      - Effort: [points] story points
      - Labels added: [list]
      - Analysis reasoning: [brief explanation]

    on: ["manual"]
    tags: ["jira", "quick-analysis"]

# Required environment variables:
# JIRA_BASE_URL=https://your-company.atlassian.net
# JIRA_EMAIL=your.email@company.com
# JIRA_API_TOKEN=your_jira_api_token
# ANTHROPIC_API_KEY=your_anthropic_key

output:
  json:
    enabled: true
  markdown:
    enabled: true