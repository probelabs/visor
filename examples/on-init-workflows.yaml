version: "1.0"

# on_init with Workflow Invocation Examples
# Demonstrates how on_init can invoke reusable workflows

tools:
  mock-fetch:
    name: mock-fetch
    description: Mock data fetcher
    inputSchema:
      type: object
      properties:
        source:
          type: string
      required: [source]
    exec: echo '{"source":"{{ args.source }}","data":"mock-data-123"}'
    parseJson: true
    timeout: 1000

checks:
  # Example 1: Simple workflow invocation in on_init
  test-workflow-invocation:
    type: command
    on_init:
      run:
        - workflow: data-enrichment
          with:
            data_source: "api-v1"
          as: enriched-data
    exec: |
      echo "Enriched data: {{ outputs['enriched-data'] | json }}"

  # Example 2: Multiple workflow invocations
  test-multiple-workflows:
    type: command
    on_init:
      run:
        - workflow: data-enrichment
          with:
            data_source: "source-1"
          as: data1
        - workflow: data-enrichment
          with:
            data_source: "source-2"
          as: data2
    exec: |
      echo "Data 1: {{ outputs.data1 | json }}"
      echo "Data 2: {{ outputs.data2 | json }}"

  # Example 3: Workflow with output_mapping
  test-workflow-mapping:
    type: command
    on_init:
      run:
        - workflow: multi-step-workflow
          with:
            input_value: "test"
          output_mapping:
            final_result: step2
          as: workflow-output
    exec: |
      echo "Workflow result: {{ outputs['workflow-output'] | json }}"

  # Example 4: Workflow with overrides
  test-workflow-overrides:
    type: command
    on_init:
      run:
        - workflow: data-enrichment
          with:
            data_source: "overridden-source"
          overrides:
            fetch-data:
              # Override specific check config
              timeout: 500
          as: overridden-data
    exec: |
      echo "{{ outputs['overridden-data'] | json }}"

  # Example 5: Mix tools, steps, and workflows
  test-mixed-invocations:
    type: command
    on_init:
      run:
        - tool: mock-fetch
          with:
            source: "tool-source"
          as: tool-data
        - workflow: data-enrichment
          with:
            data_source: "{{ outputs['tool-data'].source }}"
          as: workflow-data
        - step: process-data
          with:
            input: "{{ outputs['workflow-data'] }}"
          as: processed
    exec: |
      echo "Final: {{ outputs.processed | json }}"

  # Helper step for processing
  process-data:
    type: command
    exec: |
      echo '{"processed":true,"input":"{{ args.input }}"}'
    parseJson: true

  # Example 6: Dynamic workflow invocation with run_js
  test-dynamic-workflows:
    type: command
    on_init:
      run_js: |
        // Conditionally invoke different workflows
        const needsEnrichment = pr.title && pr.title.includes('[feature]');

        if (needsEnrichment) {
          return [
            {
              workflow: 'data-enrichment',
              with: { data_source: 'features-db' },
              as: 'feature-data'
            }
          ];
        }

        return [
          {
            workflow: 'simple-workflow',
            with: { mode: 'basic' },
            as: 'basic-data'
          }
        ];
    exec: |
      {% if outputs['feature-data'] %}
      echo "Feature mode: {{ outputs['feature-data'] | json }}"
      {% else %}
      echo "Basic mode: {{ outputs['basic-data'] | json }}"
      {% endif %}

  # Example 7: Nested workflows (workflow calls another workflow)
  test-nested-workflows:
    type: command
    on_init:
      run:
        - workflow: parent-workflow
          with:
            parent_input: "test"
          as: nested-result
    exec: |
      echo "Nested result: {{ outputs['nested-result'] | json }}"

# Reusable workflows
workflows:
  # Simple data enrichment workflow
  data-enrichment:
    inputs:
      data_source:
        type: string
        required: true
    checks:
      fetch-data:
        type: mcp
        method: mock-fetch
        transport: custom
        args:
          source: "{{ inputs.data_source }}"

      transform-data:
        type: command
        depends_on: [fetch-data]
        exec: |
          echo '{
            "original": {{ outputs["fetch-data"] | json }},
            "transformed": true,
            "timestamp": "'$(date +%s)'"
          }'
        parseJson: true
    output_mapping:
      result: transform-data

  # Multi-step workflow
  multi-step-workflow:
    inputs:
      input_value:
        type: string
        required: true
    checks:
      step1:
        type: command
        exec: echo '{"step":1,"value":"{{ inputs.input_value }}"}'
        parseJson: true

      step2:
        type: command
        depends_on: [step1]
        exec: |
          echo '{
            "step":2,
            "previous": {{ outputs.step1 | json }},
            "final":"completed"
          }'
        parseJson: true
    output_mapping:
      first: step1
      second: step2

  # Simple workflow for dynamic invocation
  simple-workflow:
    inputs:
      mode:
        type: string
        default: "basic"
    checks:
      simple-step:
        type: command
        exec: echo '{"mode":"{{ inputs.mode }}","status":"ok"}'
        parseJson: true
    output_mapping:
      result: simple-step

  # Parent workflow that invokes another workflow
  parent-workflow:
    inputs:
      parent_input:
        type: string
        required: true
    checks:
      parent-step:
        type: command
        exec: echo '{"parent":"{{ inputs.parent_input }}"}'
        parseJson: true

      # Note: This workflow doesn't directly invoke child workflow in on_init
      # But you can use step invocations to call other checks that use workflows
      child-caller:
        type: command
        depends_on: [parent-step]
        exec: |
          echo '{
            "parent": {{ outputs["parent-step"] | json }},
            "child": "simulated-child-result"
          }'
        parseJson: true
    output_mapping:
      result: child-caller

output:
  format: json
  verbose: true
